{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>torchzero provides efficient implementations of a wide range of optimization algorithms with pytorch optimizer interface, encompassing many classes of unconstrained optimization - convex and non-convex, local and global, derivative free, gradient based and second order, least squares, etc.</p> <p>The algorithms are designed to be as modular as possibe - they can be freely combined, for example all second order-like methods can be combined with any line search or trust region algorithm. Techniques like gradient clipping, weight decay, sharpness-aware minimization, cautious updates, gradient accumulation are their own modules and can be used with anything else.</p> <p>note: This project is being actively developed, there may be API changes, although at this point I am very happy with the API.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install torchzero\n</code></pre> <p>The github version may be a bit more recent and less tested:</p> <pre><code>pip install git+https://github.com/inikishev/torchzero\n</code></pre>"},{"location":"#how-to-use","title":"How to use","text":"<p>Each module represents a distinct step in the optimization process. Construct a <code>tz.Optimizer</code> optimizer with the desired modules and use as any other pytorch optimizer:</p> <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.ClipValue(1),\n    tz.m.Adam(),\n    tz.m.WeightDecay(1e-2),\n    tz.m.LR(1e-1)\n)\n</code></pre> <p>Here is what happens:</p> <ol> <li> <p>The gradient is passed to the <code>ClipValue(1)</code> module, which returns gradient with magnitudes clipped to be no larger than 1.</p> </li> <li> <p>Clipped gradient is passed to <code>Adam()</code>, which updates Adam momentum buffers and returns the Adam update.</p> </li> <li> <p>The Adam update is passed to <code>WeightDecay()</code> which adds a weight decay penalty to the Adam update. Since we placed it after Adam, the weight decay is decoupled. By moving <code>WeightDecay()</code> before <code>Adam()</code>, we can get coupled weight decay.</p> </li> <li> <p>Finally the update is passed to <code>LR(0.1)</code>, which multiplies it by the learning rate of 0.1.</p> </li> </ol>"},{"location":"#advanced-optimization","title":"Advanced optimization","text":"<p>Certain modules such as line searches and trust regions require a closure, similar to L-BFGS in PyTorch. Also some modules require closure to accept an additional <code>backward</code> argument, refer to example below:</p> <pre><code>model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1))\ninputs = torch.randn(100,10)\ntargets = torch.randn(100, 1)\n\noptimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.CubicRegularization(tz.m.Newton()),\n)\n\nfor i in range(1, 51):\n\n    def closure(backward=True):\n        preds = model(inputs)\n        loss = F.mse_loss(preds, targets)\n\n        # If backward=True, closure should call\n        # optimizer.zero_grad() and loss.backward()\n        if backward:\n            optimizer.zero_grad()\n            loss.backward()\n\n        return loss\n\n    loss = optimizer.step(closure)\n\n    if i % 10 == 0:\n        print(f\"step: {i}, loss: {loss.item():.4f}\")\n</code></pre> <p>The code above will also work with any other optimizer because all PyTorch optimizers and most custom ones support closure, so there is no need to rewrite training loop.</p>"},{"location":"#learn-more","title":"Learn more","text":"<p>To learn more about how to use torchzero check Basics.</p> <p>An overview of optimization algorithms in torchzero along with visualizations, explanations and benchmarks is available in the overview section.</p> <p>If you just want to see what algorithms are implemeted, check API reference.</p>"},{"location":"Basics/","title":"torchzero basics","text":"In\u00a0[1]: Copied! <pre>import torch\ntorch.manual_seed(0)\nfrom torch import nn\nfrom torch.nn import functional as F\nimport torchzero as tz\n</pre> import torch torch.manual_seed(0) from torch import nn from torch.nn import functional as F import torchzero as tz <p>In torchzero the optimization algorithm is represented as a sequence of modules, where each module is a distinct step in the optimization process.</p> <p>To construct an optimizer, pass the modules to <code>Optimizer</code> object, it can be a drop-in replacement for any PyTorch optimizer. All modules are available within the <code>torchzero.m</code> namespace.</p> In\u00a0[89]: Copied! <pre>model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1))\ninputs = torch.randn(100,10)\ntargets = torch.randn(100, 1)\n\noptimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.ClipValue(1),\n    tz.m.Adam(),\n    tz.m.WeightDecay(1e-2),\n    tz.m.LR(1e-1)\n)\n</pre> model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1)) inputs = torch.randn(100,10) targets = torch.randn(100, 1)  optimizer = tz.Optimizer(     model.parameters(),     tz.m.ClipValue(1),     tz.m.Adam(),     tz.m.WeightDecay(1e-2),     tz.m.LR(1e-1) ) <p>Here is what happens:</p> <ol> <li><p>The gradient is passed to the <code>ClipValue(1)</code> module, which returns gradient with magnitudes clipped to be no larger than 1.</p> </li> <li><p>Clipped gradient is passed to <code>Adam()</code>, which updates Adam momentum buffers and returns the Adam update.</p> </li> <li><p>The Adam update is passed to <code>WeightDecay()</code> which adds a weight decay penalty to the Adam update. Since we placed it after Adam, the weight decay is decoupled. By moving <code>WeightDecay()</code> before <code>Adam()</code>, we can get coupled weight decay.</p> </li> <li><p>Finally the update is passed to <code>LR(0.1)</code>, which multiplies it by the learning rate of 0.1.</p> </li> </ol> <p>The optimization loop is the same as with any other pytorch optimizer:</p> In\u00a0[3]: Copied! <pre>for i in range(1, 101):\n    preds = model(inputs)\n    loss = F.mse_loss(preds, targets)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if i % 20 == 0: print(f\"step: {i}, loss: {loss.item():.4f}\")\n</pre> for i in range(1, 101):     preds = model(inputs)     loss = F.mse_loss(preds, targets)     optimizer.zero_grad()     loss.backward()     optimizer.step()     if i % 20 == 0: print(f\"step: {i}, loss: {loss.item():.4f}\") <pre>step: 20, loss: 0.5673\nstep: 40, loss: 0.2976\nstep: 60, loss: 0.1544\nstep: 80, loss: 0.1057\nstep: 100, loss: 0.0926\n</pre> In\u00a0[91]: Copied! <pre>model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1))\ninputs = torch.randn(100,10)\ntargets = torch.randn(100, 1)\n\noptimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.ClipValue(1),\n    tz.m.Adam(),\n    tz.m.WeightDecay(1e-2),\n    tz.m.LR(1e-1)\n)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-1, total_steps=100, cycle_momentum=False)\n\nfor i in range(1, 101):\n    preds = model(inputs)\n    loss = F.mse_loss(preds, targets)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    scheduler.step()\n    if i % 20 == 1:\n        print(f\"step: {i}, loss: {loss.item():.4f}, lr: {optimizer.param_groups[0]['lr']:.4f}\")\n</pre> model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1)) inputs = torch.randn(100,10) targets = torch.randn(100, 1)  optimizer = tz.Optimizer(     model.parameters(),     tz.m.ClipValue(1),     tz.m.Adam(),     tz.m.WeightDecay(1e-2),     tz.m.LR(1e-1) ) scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-1, total_steps=100, cycle_momentum=False)  for i in range(1, 101):     preds = model(inputs)     loss = F.mse_loss(preds, targets)     optimizer.zero_grad()     loss.backward()     optimizer.step()     scheduler.step()     if i % 20 == 1:         print(f\"step: {i}, loss: {loss.item():.4f}, lr: {optimizer.param_groups[0]['lr']:.4f}\") <pre>step: 1, loss: 1.0595, lr: 0.0086\nstep: 21, loss: 0.6385, lr: 0.1661\nstep: 41, loss: 0.3592, lr: 0.1858\nstep: 61, loss: 0.1495, lr: 0.1134\nstep: 81, loss: 0.0904, lr: 0.0309\n</pre> In\u00a0[92]: Copied! <pre>model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1))\n\nparam_groups = [\n    {\"params\": model[0].parameters(), \"lr\": 1e-2}, # 1st linear\n    {\"params\": model[2].parameters(), \"lr\": 1e-1, \"beta2\": 0.95} # 2nd linear\n]\n\noptimizer = tz.Optimizer(\n    param_groups,\n    tz.m.ClipValue(1),\n    tz.m.Adam(beta2=0.99),\n    tz.m.WeightDecay(1e-2),\n    tz.m.LR(1e-1)\n)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=[1e-2, 1e-1], total_steps=100, cycle_momentum=False)\n</pre> model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1))  param_groups = [     {\"params\": model[0].parameters(), \"lr\": 1e-2}, # 1st linear     {\"params\": model[2].parameters(), \"lr\": 1e-1, \"beta2\": 0.95} # 2nd linear ]  optimizer = tz.Optimizer(     param_groups,     tz.m.ClipValue(1),     tz.m.Adam(beta2=0.99),     tz.m.WeightDecay(1e-2),     tz.m.LR(1e-1) ) scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=[1e-2, 1e-1], total_steps=100, cycle_momentum=False) In\u00a0[\u00a0]: Copied! <pre>model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1))\ninputs = torch.randn(100,10)\ntargets = torch.randn(100, 1)\n\noptimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.CubicRegularization(tz.m.Newton()),\n)\n\nfor i in range(1, 51):\n\n    def closure(backward=True):\n        preds = model(inputs)\n        loss = F.mse_loss(preds, targets)\n        if backward:\n            optimizer.zero_grad()\n            loss.backward()\n        return loss\n\n    loss = optimizer.step(closure)\n\n    if i % 10 == 0:\n        print(f\"step: {i}, loss: {loss.item():.4f}\")\n</pre> model = nn.Sequential(nn.Linear(10, 10), nn.ELU(), nn.Linear(10, 1)) inputs = torch.randn(100,10) targets = torch.randn(100, 1)  optimizer = tz.Optimizer(     model.parameters(),     tz.m.CubicRegularization(tz.m.Newton()), )  for i in range(1, 51):      def closure(backward=True):         preds = model(inputs)         loss = F.mse_loss(preds, targets)         if backward:             optimizer.zero_grad()             loss.backward()         return loss      loss = optimizer.step(closure)      if i % 10 == 0:         print(f\"step: {i}, loss: {loss.item():.4f}\") <pre>step: 10, loss: 0.6304\nstep: 20, loss: 0.1783\nstep: 30, loss: 0.0160\nstep: 40, loss: 0.0004\nstep: 50, loss: 0.0000\n</pre>"},{"location":"Basics/#torchzero-basics","title":"torchzero basics\u00b6","text":""},{"location":"Basics/#performing-optimization","title":"Performing optimization\u00b6","text":""},{"location":"Basics/#lr-schedulers","title":"LR schedulers\u00b6","text":"<p>An LR scheduler works like with any pytorch optimizer as long as you add an <code>LR</code> module, where the scheduling will happen.</p>"},{"location":"Basics/#per-parameter-settings","title":"Per-parameter settings\u00b6","text":"<p>Per-parameter settings are specified in param groups, in the same way as in pytorch optimizers.</p> <p>When a module is created, you can pass various settings to it, such as <code>Adam(beta1=0.95, beta2=0.99)</code>.</p> <p>Those settings can be overridden using param groups, which can be used to specify custom settings for only specific layers. Param groups should be a sequence of dictionaries, with each dictionary representing one parameter group. Each dictionary must have the <code>\"params\"</code> key with an iterable of parameters, and other keys with custom settings for that param group.</p>"},{"location":"Basics/#advanced-optimization","title":"Advanced optimization\u00b6","text":"<p>Certain modules require closure, for example line searches, trust region methods, gradient estimators and optimizers that rely on extra autograd. The closure is similar to one needed by L-BFGS in pytorch, however in torchzero it requires an additional <code>backward</code> argument with the default value of True.</p> <p>The closure evaluates and returns the loss. If <code>backward=True</code>, it should also call <code>optimizer.zero_grad()</code> and <code>loss.backward()</code>.</p> <p>For example, we can use Newton's method with cubic regularization to greatly speed up small scale optimization.</p>"},{"location":"API/","title":"Index","text":"<p>All modules are awailable in <code>tz.m</code> namespace (e.g. <code>tz.m.Adam</code>). There are a lot of modules, so they are vaguely split into sub-packages, although some of them can be hard to categorize. You can also view all modules on a single (very long) page.</p>"},{"location":"API/#optimization-algorithms","title":"Optimization algorithms","text":"<ul> <li>Adaptive - Adaptive per-parameter learning rates + some other deep learning optimizers, e.g. Adam, etc.</li> <li>Momentum - momentums and exponential moving averages.</li> <li>Conjugate gradient - conjugate gradient methods.</li> <li>Quasi-newton - quasi-newton methods that estimate the hessian using gradient information.</li> <li>Second order - \"True\" second order methods that use exact second order information.</li> <li>Gradient approximation - modules that estimate the gradient using function values.</li> <li>Least-squares - least-squares methods (Gauss-newton)</li> </ul>"},{"location":"API/#step-size-selection","title":"Step size selection","text":"<ul> <li>Step size - step size selection methods like Barzilai-Borwein and Polyak's step size.</li> <li>Line search - line search methods.</li> <li>Trust region - trust region methods.</li> </ul>"},{"location":"API/#auxillary-modules","title":"Auxillary modules","text":"<ul> <li>Clipping - gradient clipping, normalization, centralization, etc.</li> <li>Weight decay - weight decay.</li> <li>Operations - operations like adding modules, subtracting, grafting, tracking the maximum, etc.</li> <li>Projections - allows any other modules to be used in some projected space. This has multiple uses, one is to save memory by projecting into a smaller subspace, another is splitting parameters into smaller blocks or merging them into a single vector, another one is peforming optimization in a different dtype or viewing complex tensors as real. This can also do things like optimize in fourier domain.</li> <li>Smoothing - smoothing-based optimization, currently laplacian and gaussian smoothing are implemented.</li> <li>Miscellaneous - a lot of uncategorized modules, notably gradient accumulation, switching, automatic resetting, random restarts.</li> <li>Wrappers - this implements Wrap, which can turn most custom pytorch optimizers into chainable modules.</li> </ul>"},{"location":"API/all/","title":"List of all modules","text":"<p>A somewhat categorized list of modules is also available in Modules</p> <p>Classes:</p> <ul> <li> <code>AEGD</code>           \u2013            <p>AEGD (Adaptive gradient descent with energy) from https://arxiv.org/abs/2010.05109#page=10.26.</p> </li> <li> <code>ASAM</code>           \u2013            <p>Adaptive Sharpness-Aware Minimization from https://arxiv.org/pdf/2102.11600#page=6.52</p> </li> <li> <code>Abs</code>           \u2013            <p>Returns <code>abs(input)</code></p> </li> <li> <code>AccumulateMaximum</code>           \u2013            <p>Accumulates maximum of all past updates.</p> </li> <li> <code>AccumulateMean</code>           \u2013            <p>Accumulates mean of all past updates.</p> </li> <li> <code>AccumulateMinimum</code>           \u2013            <p>Accumulates minimum of all past updates.</p> </li> <li> <code>AccumulateProduct</code>           \u2013            <p>Accumulates product of all past updates.</p> </li> <li> <code>AccumulateSum</code>           \u2013            <p>Accumulates sum of all past updates.</p> </li> <li> <code>AdGD</code>           \u2013            <p>AdGD and AdGD-2 (https://arxiv.org/abs/2308.02261)</p> </li> <li> <code>AdaHessian</code>           \u2013            <p>AdaHessian: An Adaptive Second Order Optimizer for Machine Learning (https://arxiv.org/abs/2006.00719)</p> </li> <li> <code>Adagrad</code>           \u2013            <p>Adagrad, divides by sum of past squares of gradients.</p> </li> <li> <code>AdagradNorm</code>           \u2013            <p>Adagrad-Norm, divides by sum of past means of squares of gradients.</p> </li> <li> <code>Adam</code>           \u2013            <p>Adam. Divides gradient EMA by EMA of gradient squares with debiased step size.</p> </li> <li> <code>Adan</code>           \u2013            <p>Adaptive Nesterov Momentum Algorithm from https://arxiv.org/abs/2208.06677</p> </li> <li> <code>AdaptiveBacktracking</code>           \u2013            <p>Adaptive backtracking line search. After each line search procedure, a new initial step size is set</p> </li> <li> <code>AdaptiveBisection</code>           \u2013            <p>A line search that evaluates previous step size, if value increased, backtracks until the value stops decreasing,</p> </li> <li> <code>AdaptiveHeavyBall</code>           \u2013            <p>Adaptive heavy ball from https://hal.science/hal-04832983v1/file/OJMO_2024__5__A7_0.pdf.</p> </li> <li> <code>Add</code>           \u2013            <p>Add <code>other</code> to tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>Alternate</code>           \u2013            <p>Alternates between stepping with :code:<code>modules</code>.</p> </li> <li> <code>Averaging</code>           \u2013            <p>Average of past <code>history_size</code> updates.</p> </li> <li> <code>BBStab</code>           \u2013            <p>Stabilized Barzilai-Borwein method (https://arxiv.org/abs/1907.06409).</p> </li> <li> <code>BFGS</code>           \u2013            <p>Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno Quasi-Newton method. This is usually the most stable quasi-newton method.</p> </li> <li> <code>BacktrackOnSignChange</code>           \u2013            <p>Negates or undoes update for parameters where where gradient or update sign changes.</p> </li> <li> <code>Backtracking</code>           \u2013            <p>Backtracking line search.</p> </li> <li> <code>BarzilaiBorwein</code>           \u2013            <p>Barzilai-Borwein step size method.</p> </li> <li> <code>BinaryOperationBase</code>           \u2013            <p>Base class for operations that use update as the first operand. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> </li> <li> <code>BirginMartinezRestart</code>           \u2013            <p>the restart criterion for conjugate gradient methods designed by Birgin and Martinez.</p> </li> <li> <code>BoldDriver</code>           \u2013            <p>Multiplies step size by <code>nplus</code> if loss decreased compared to last iteration, otherwise multiplies by <code>nminus</code>.</p> </li> <li> <code>BroydenBad</code>           \u2013            <p>Broyden's \"bad\" Quasi-Newton method.</p> </li> <li> <code>BroydenGood</code>           \u2013            <p>Broyden's \"good\" Quasi-Newton method.</p> </li> <li> <code>CD</code>           \u2013            <p>Coordinate descent. Proposes a descent direction along a single coordinate.</p> </li> <li> <code>Cautious</code>           \u2013            <p>Negates update for parameters where update and gradient sign is inconsistent.</p> </li> <li> <code>CautiousWeightDecay</code>           \u2013            <p>Cautious weight decay (https://arxiv.org/pdf/2510.12402).</p> </li> <li> <code>CenteredEMASquared</code>           \u2013            <p>Maintains a centered exponential moving average of squared updates. This also maintains an additional</p> </li> <li> <code>CenteredSqrtEMASquared</code>           \u2013            <p>Maintains a centered exponential moving average of squared updates, outputs optionally debiased square root.</p> </li> <li> <code>Centralize</code>           \u2013            <p>Centralizes the update.</p> </li> <li> <code>Clip</code>           \u2013            <p>clip tensors to be in  <code>(min, max)</code> range. <code>min</code> and <code>`max</code>: can be None, numbers or modules.</p> </li> <li> <code>ClipModules</code>           \u2013            <p>Calculates <code>input(tensors).clip(min, max)</code>. <code>min</code> and <code>max</code> can be numbers or modules.</p> </li> <li> <code>ClipNorm</code>           \u2013            <p>Clips update norm to be no larger than <code>value</code>.</p> </li> <li> <code>ClipNormByEMA</code>           \u2013            <p>Clips norm to be no larger than the norm of an exponential moving average of past updates.</p> </li> <li> <code>ClipNormGrowth</code>           \u2013            <p>Clips update norm growth.</p> </li> <li> <code>ClipValue</code>           \u2013            <p>Clips update magnitude to be within <code>(-value, value)</code> range.</p> </li> <li> <code>ClipValueByEMA</code>           \u2013            <p>Clips magnitude of update to be no larger than magnitude of exponential moving average of past (unclipped) updates.</p> </li> <li> <code>ClipValueGrowth</code>           \u2013            <p>Clips update value magnitude growth.</p> </li> <li> <code>Clone</code>           \u2013            <p>Clones input. May be useful to store some intermediate result and make sure it doesn't get affected by in-place operations</p> </li> <li> <code>ConjugateDescent</code>           \u2013            <p>Conjugate Descent (CD).</p> </li> <li> <code>CopyMagnitude</code>           \u2013            <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> </li> <li> <code>CopySign</code>           \u2013            <p>Returns tensors with sign copied from <code>other(tensors)</code>.</p> </li> <li> <code>CubicRegularization</code>           \u2013            <p>Cubic regularization.</p> </li> <li> <code>CustomUnaryOperation</code>           \u2013            <p>Applies <code>getattr(tensor, name)</code> to each tensor</p> </li> <li> <code>DFP</code>           \u2013            <p>Davidon\u2013Fletcher\u2013Powell Quasi-Newton method.</p> </li> <li> <code>DNRTR</code>           \u2013            <p>Diagonal quasi-newton method.</p> </li> <li> <code>DYHS</code>           \u2013            <p>Dai-Yuan - Hestenes\u2013Stiefel hybrid conjugate gradient method.</p> </li> <li> <code>DaiYuan</code>           \u2013            <p>Dai\u2013Yuan nonlinear conjugate gradient method.</p> </li> <li> <code>Debias</code>           \u2013            <p>Multiplies the update by an Adam debiasing term based first and/or second momentum.</p> </li> <li> <code>Debias2</code>           \u2013            <p>Multiplies the update by an Adam debiasing term based on the second momentum.</p> </li> <li> <code>DiagonalBFGS</code>           \u2013            <p>Diagonal BFGS. This is simply BFGS with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> </li> <li> <code>DiagonalQuasiCauchi</code>           \u2013            <p>Diagonal quasi-cauchi method.</p> </li> <li> <code>DiagonalSR1</code>           \u2013            <p>Diagonal SR1. This is simply SR1 with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> </li> <li> <code>DiagonalWeightedQuasiCauchi</code>           \u2013            <p>Diagonal quasi-cauchi method.</p> </li> <li> <code>DirectWeightDecay</code>           \u2013            <p>Directly applies weight decay to parameters.</p> </li> <li> <code>Div</code>           \u2013            <p>Divide tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> </li> <li> <code>DivByLoss</code>           \u2013            <p>Divides update by loss times <code>alpha</code></p> </li> <li> <code>DivModules</code>           \u2013            <p>Calculates <code>input / other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> </li> <li> <code>Dogleg</code>           \u2013            <p>Dogleg trust region algorithm.</p> </li> <li> <code>Dropout</code>           \u2013            <p>Applies dropout to the update.</p> </li> <li> <code>DualNormCorrection</code>           \u2013            <p>Dual norm correction for dualizer based optimizers (https://github.com/leloykun/adaptive-muon).</p> </li> <li> <code>EMA</code>           \u2013            <p>Maintains an exponential moving average of update.</p> </li> <li> <code>EMASquared</code>           \u2013            <p>Maintains an exponential moving average of squared updates.</p> </li> <li> <code>ESGD</code>           \u2013            <p>Equilibrated Gradient Descent (https://arxiv.org/abs/1502.04390)</p> </li> <li> <code>EscapeAnnealing</code>           \u2013            <p>If parameters stop changing, this runs a backward annealing random search</p> </li> <li> <code>Exp</code>           \u2013            <p>Returns <code>exp(input)</code></p> </li> <li> <code>ExpHomotopy</code>           \u2013            </li> <li> <code>FDM</code>           \u2013            <p>Approximate gradients via finite difference method.</p> </li> <li> <code>Fill</code>           \u2013            <p>Outputs tensors filled with <code>value</code></p> </li> <li> <code>FillLoss</code>           \u2013            <p>Outputs tensors filled with loss value times <code>alpha</code></p> </li> <li> <code>FletcherReeves</code>           \u2013            <p>Fletcher\u2013Reeves nonlinear conjugate gradient method.</p> </li> <li> <code>FletcherVMM</code>           \u2013            <p>Fletcher's variable metric Quasi-Newton method.</p> </li> <li> <code>ForwardGradient</code>           \u2013            <p>Forward gradient method.</p> </li> <li> <code>FullMatrixAdagrad</code>           \u2013            <p>Full-matrix version of Adagrad, can be customized to make RMSprop or Adam (see examples).</p> </li> <li> <code>GGT</code>           \u2013            <p>GGT method from https://arxiv.org/pdf/1806.02958</p> </li> <li> <code>GGTBasis</code>           \u2013            <p>Run another optimizer in GGT eigenbasis. The eigenbasis is <code>rank</code>-sized, so it is possible to run expensive</p> </li> <li> <code>GaussNewton</code>           \u2013            <p>Gauss-newton method.</p> </li> <li> <code>GaussianSmoothing</code>           \u2013            <p>Gradient approximation via Gaussian smoothing method.</p> </li> <li> <code>Grad</code>           \u2013            <p>Outputs the gradient</p> </li> <li> <code>GradApproximator</code>           \u2013            <p>Base class for gradient approximations.</p> </li> <li> <code>GradSign</code>           \u2013            <p>Copies gradient sign to update.</p> </li> <li> <code>GradToNone</code>           \u2013            <p>Sets <code>grad</code> attribute to None on <code>objective</code>.</p> </li> <li> <code>GradientAccumulation</code>           \u2013            <p>Uses <code>n</code> steps to accumulate gradients, after <code>n</code> gradients have been accumulated, they are passed to :code:<code>modules</code> and parameters are updates.</p> </li> <li> <code>GradientCorrection</code>           \u2013            <p>Estimates gradient at minima along search direction assuming function is quadratic.</p> </li> <li> <code>GradientSampling</code>           \u2013            <p>Samples and aggregates gradients and values at perturbed points.</p> </li> <li> <code>Graft</code>           \u2013            <p>Outputs <code>direction</code> output rescaled to have the same norm as <code>magnitude</code> output.</p> </li> <li> <code>GraftGradToUpdate</code>           \u2013            <p>Outputs gradient grafted to update, that is gradient rescaled to have the same norm as the update.</p> </li> <li> <code>GraftInputToOutput</code>           \u2013            <p>Outputs <code>tensors</code> rescaled to have the same norm as <code>magnitude(tensors)</code>.</p> </li> <li> <code>GraftOutputToInput</code>           \u2013            <p>Outputs <code>magnitude(tensors)</code> rescaled to have the same norm as <code>tensors</code></p> </li> <li> <code>GraftToGrad</code>           \u2013            <p>Grafts update to the gradient, that is update is rescaled to have the same norm as the gradient.</p> </li> <li> <code>GraftToParams</code>           \u2013            <p>Grafts update to the parameters, that is update is rescaled to have the same norm as the parameters, but no smaller than <code>eps</code>.</p> </li> <li> <code>GramSchimdt</code>           \u2013            <p>outputs tensors made orthogonal to <code>other(tensors)</code> via Gram-Schmidt.</p> </li> <li> <code>Greenstadt1</code>           \u2013            <p>Greenstadt's first Quasi-Newton method.</p> </li> <li> <code>Greenstadt2</code>           \u2013            <p>Greenstadt's second Quasi-Newton method.</p> </li> <li> <code>HagerZhang</code>           \u2013            <p>Hager-Zhang nonlinear conjugate gradient method,</p> </li> <li> <code>HeavyBall</code>           \u2013            <p>Polyak's momentum (heavy-ball method).</p> </li> <li> <code>HestenesStiefel</code>           \u2013            <p>Hestenes\u2013Stiefel nonlinear conjugate gradient method.</p> </li> <li> <code>Horisho</code>           \u2013            <p>Horisho's variable metric Quasi-Newton method.</p> </li> <li> <code>HpuEstimate</code>           \u2013            <p>returns <code>y/||s||</code>, where <code>y</code> is difference between current and previous update (gradient), <code>s</code> is difference between current and previous parameters. The returned tensors are a finite difference approximation to hessian times previous update.</p> </li> <li> <code>ICUM</code>           \u2013            <p>Inverse Column-updating Quasi-Newton method. This is computationally cheaper than other Quasi-Newton methods</p> </li> <li> <code>Identity</code>           \u2013            <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> </li> <li> <code>ImprovedNewton</code>           \u2013            <p>Improved Newton's Method (INM).</p> </li> <li> <code>IntermoduleCautious</code>           \u2013            <p>Negaties update on :code:<code>main</code> module where it's sign doesn't match with output of <code>compare</code> module.</p> </li> <li> <code>InverseFreeNewton</code>           \u2013            <p>Inverse-free newton's method</p> </li> <li> <code>LBFGS</code>           \u2013            <p>Limited-memory BFGS algorithm. A line search or trust region is recommended.</p> </li> <li> <code>LR</code>           \u2013            <p>Learning rate. Adding this module also adds support for LR schedulers.</p> </li> <li> <code>LSR1</code>           \u2013            <p>Limited-memory SR1 algorithm. A line search or trust region is recommended.</p> </li> <li> <code>LambdaHomotopy</code>           \u2013            </li> <li> <code>LaplacianSmoothing</code>           \u2013            <p>Applies laplacian smoothing via a fast Fourier transform solver which can improve generalization.</p> </li> <li> <code>LastAbsoluteRatio</code>           \u2013            <p>Outputs ratio between absolute values of past two updates the numerator is determined by <code>numerator</code> argument.</p> </li> <li> <code>LastDifference</code>           \u2013            <p>Outputs difference between past two updates.</p> </li> <li> <code>LastGradDifference</code>           \u2013            <p>Outputs difference between past two gradients.</p> </li> <li> <code>LastProduct</code>           \u2013            <p>Outputs difference between past two updates.</p> </li> <li> <code>LastRatio</code>           \u2013            <p>Outputs ratio between past two updates, the numerator is determined by <code>numerator</code> argument.</p> </li> <li> <code>LerpModules</code>           \u2013            <p>Does a linear interpolation of <code>input(tensors)</code> and <code>end(tensors)</code> based on a scalar <code>weight</code>.</p> </li> <li> <code>LevenbergMarquardt</code>           \u2013            <p>Levenberg-Marquardt trust region algorithm.</p> </li> <li> <code>LineSearchBase</code>           \u2013            <p>Base class for line searches.</p> </li> <li> <code>Lion</code>           \u2013            <p>Lion (EvoLved Sign Momentum) optimizer from https://arxiv.org/abs/2302.06675.</p> </li> <li> <code>LiuStorey</code>           \u2013            <p>Liu-Storey nonlinear conjugate gradient method.</p> </li> <li> <code>LogHomotopy</code>           \u2013            </li> <li> <code>MARSCorrection</code>           \u2013            <p>MARS variance reduction correction.</p> </li> <li> <code>MSAM</code>           \u2013            <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> </li> <li> <code>MSAMMomentum</code>           \u2013            <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> </li> <li> <code>MatrixMomentum</code>           \u2013            <p>Second order momentum method.</p> </li> <li> <code>Maximum</code>           \u2013            <p>Outputs <code>maximum(tensors, other(tensors))</code></p> </li> <li> <code>MaximumModules</code>           \u2013            <p>Outputs elementwise maximum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>McCormick</code>           \u2013            <p>McCormicks's Quasi-Newton method.</p> </li> <li> <code>MeZO</code>           \u2013            <p>Gradient approximation via memory-efficient zeroth order optimizer (MeZO) - https://arxiv.org/abs/2305.17333.</p> </li> <li> <code>Mean</code>           \u2013            <p>Outputs a mean of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>MedianAveraging</code>           \u2013            <p>Median of past <code>history_size</code> updates.</p> </li> <li> <code>Minimum</code>           \u2013            <p>Outputs <code>minimum(tensors, other(tensors))</code></p> </li> <li> <code>MinimumModules</code>           \u2013            <p>Outputs elementwise minimum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>Mul</code>           \u2013            <p>Multiply tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> </li> <li> <code>MulByLoss</code>           \u2013            <p>Multiplies update by loss times <code>alpha</code></p> </li> <li> <code>MultiOperationBase</code>           \u2013            <p>Base class for operations that use operands. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> </li> <li> <code>Multistep</code>           \u2013            <p>Performs <code>steps</code> inner steps with <code>module</code> per each step.</p> </li> <li> <code>MuonAdjustLR</code>           \u2013            <p>LR adjustment for Muon from \"Muon is Scalable for LLM Training\" (https://github.com/MoonshotAI/Moonlight/tree/master).</p> </li> <li> <code>NAG</code>           \u2013            <p>Nesterov accelerated gradient method (nesterov momentum).</p> </li> <li> <code>NanToNum</code>           \u2013            <p>Convert <code>nan</code>, <code>inf</code> and <code>-</code>inf`` to numbers.</p> </li> <li> <code>NaturalGradient</code>           \u2013            <p>Natural gradient approximated via empirical fisher information matrix.</p> </li> <li> <code>Negate</code>           \u2013            <p>Returns <code>- input</code></p> </li> <li> <code>NegateOnLossIncrease</code>           \u2013            <p>Uses an extra forward pass to evaluate loss at <code>parameters+update</code>,</p> </li> <li> <code>NewDQN</code>           \u2013            <p>Diagonal quasi-newton method.</p> </li> <li> <code>NewSSM</code>           \u2013            <p>Self-scaling Quasi-Newton method.</p> </li> <li> <code>Newton</code>           \u2013            <p>Exact Newton's method via autograd.</p> </li> <li> <code>NewtonCG</code>           \u2013            <p>Newton's method with a matrix-free conjugate gradient or minimial-residual solver.</p> </li> <li> <code>NewtonCGSteihaug</code>           \u2013            <p>Newton's method with trust region and a matrix-free Steihaug-Toint conjugate gradient solver.</p> </li> <li> <code>NoiseSign</code>           \u2013            <p>Outputs random tensors with sign copied from the update.</p> </li> <li> <code>Noop</code>           \u2013            <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> </li> <li> <code>Normalize</code>           \u2013            <p>Normalizes the update.</p> </li> <li> <code>NormalizeByEMA</code>           \u2013            <p>Sets norm of the update to be the same as the norm of an exponential moving average of past updates.</p> </li> <li> <code>NystromPCG</code>           \u2013            <p>Newton's method with a Nystr\u00f6m-preconditioned conjugate gradient solver.</p> </li> <li> <code>NystromSketchAndSolve</code>           \u2013            <p>Newton's method with a Nystr\u00f6m sketch-and-solve solver.</p> </li> <li> <code>Ones</code>           \u2013            <p>Outputs ones</p> </li> <li> <code>Online</code>           \u2013            <p>Allows certain modules to be used for mini-batch optimization.</p> </li> <li> <code>OrthoGrad</code>           \u2013            <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> </li> <li> <code>Orthogonalize</code>           \u2013            <p>Uses Newton-Schulz iteration or SVD to compute the zeroth power / orthogonalization of update along first 2 dims.</p> </li> <li> <code>PSB</code>           \u2013            <p>Powell's Symmetric Broyden Quasi-Newton method.</p> </li> <li> <code>PSGDDenseNewton</code>           \u2013            <p>Dense hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDKronNewton</code>           \u2013            <p>Kron hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDKronWhiten</code>           \u2013            <p>Kron whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDLRANewton</code>           \u2013            <p>Low rank hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDLRAWhiten</code>           \u2013            <p>Low rank whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>Params</code>           \u2013            <p>Outputs parameters</p> </li> <li> <code>Pearson</code>           \u2013            <p>Pearson's Quasi-Newton method.</p> </li> <li> <code>PerturbWeights</code>           \u2013            <p>Changes the closure so that it evaluates loss and gradients at weights perturbed by a random perturbation.</p> </li> <li> <code>PolakRibiere</code>           \u2013            <p>Polak-Ribi\u00e8re-Polyak nonlinear conjugate gradient method.</p> </li> <li> <code>PolyakStepSize</code>           \u2013            <p>Polyak's subgradient method with known or unknown f*.</p> </li> <li> <code>Pow</code>           \u2013            <p>Take tensors to the power of <code>exponent</code>. <code>exponent</code> can be a number or a module.</p> </li> <li> <code>PowModules</code>           \u2013            <p>Calculates <code>input ** exponent</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> </li> <li> <code>PowellRestart</code>           \u2013            <p>Powell's two restarting criterions for conjugate gradient methods.</p> </li> <li> <code>Previous</code>           \u2013            <p>Maintains an update from n steps back, for example if n=1, returns previous update</p> </li> <li> <code>PrintLoss</code>           \u2013            <p>Prints var.get_loss().</p> </li> <li> <code>PrintParams</code>           \u2013            <p>Prints current update.</p> </li> <li> <code>PrintShape</code>           \u2013            <p>Prints shapes of the update.</p> </li> <li> <code>PrintUpdate</code>           \u2013            <p>Prints current update.</p> </li> <li> <code>Prod</code>           \u2013            <p>Outputs product of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>ProjectedGradientMethod</code>           \u2013            <p>Projected gradient method. Directly projects the gradient onto subspace conjugate to past directions.</p> </li> <li> <code>ProjectedNewtonRaphson</code>           \u2013            <p>Projected Newton Raphson method.</p> </li> <li> <code>ProjectionBase</code>           \u2013            <p>Base class for projections.</p> </li> <li> <code>RCopySign</code>           \u2013            <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> </li> <li> <code>RDSA</code>           \u2013            <p>Gradient approximation via Random-direction stochastic approximation (RDSA) method.</p> </li> <li> <code>RDiv</code>           \u2013            <p>Divide <code>other</code> by tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>RMSprop</code>           \u2013            <p>Divides graient by EMA of gradient squares.</p> </li> <li> <code>RPow</code>           \u2013            <p>Take <code>other</code> to the power of tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>RSub</code>           \u2013            <p>Subtract tensors from <code>other</code>. <code>other</code> can be a number or a module.</p> </li> <li> <code>Randn</code>           \u2013            <p>Outputs tensors filled with random numbers from a normal distribution with mean 0 and variance 1.</p> </li> <li> <code>RandomHvp</code>           \u2013            <p>Returns a hessian-vector product with a random vector, optionally times vector</p> </li> <li> <code>RandomReinitialize</code>           \u2013            <p>On each step with probability <code>p_reinit</code> trigger reinitialization,</p> </li> <li> <code>RandomSample</code>           \u2013            <p>Outputs tensors filled with random numbers from distribution depending on value of <code>distribution</code>.</p> </li> <li> <code>RandomStepSize</code>           \u2013            <p>Uses random global or layer-wise step size from <code>low</code> to <code>high</code>.</p> </li> <li> <code>RandomizedFDM</code>           \u2013            <p>Gradient approximation via a randomized finite-difference method.</p> </li> <li> <code>Reciprocal</code>           \u2013            <p>Returns <code>1 / input</code></p> </li> <li> <code>ReduceOperationBase</code>           \u2013            <p>Base class for reduction operations like Sum, Prod, Maximum. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> </li> <li> <code>Relative</code>           \u2013            <p>Multiplies update by absolute parameter values to make it relative to their magnitude, <code>min_value</code> is minimum allowed value to avoid getting stuck at 0.</p> </li> <li> <code>RelativeWeightDecay</code>           \u2013            <p>Weight decay relative to the mean absolute value of update, gradient or parameters depending on value of <code>norm_input</code> argument.</p> </li> <li> <code>RestartEvery</code>           \u2013            <p>Resets the state every n steps</p> </li> <li> <code>RestartOnStuck</code>           \u2013            <p>Resets the state when update (difference in parameters) is zero for multiple steps in a row.</p> </li> <li> <code>RestartStrategyBase</code>           \u2013            <p>Base class for restart strategies.</p> </li> <li> <code>Rprop</code>           \u2013            <p>Resilient propagation. The update magnitude gets multiplied by <code>nplus</code> if gradient didn't change the sign,</p> </li> <li> <code>SAM</code>           \u2013            <p>Sharpness-Aware Minimization from https://arxiv.org/pdf/2010.01412</p> </li> <li> <code>SG2</code>           \u2013            <p>second-order stochastic gradient</p> </li> <li> <code>SOAP</code>           \u2013            <p>SOAP (ShampoO with Adam in the Preconditioner's eigenbasis from https://arxiv.org/abs/2409.11321).</p> </li> <li> <code>SOAPBasis</code>           \u2013            <p>Run another optimizer in Shampoo eigenbases.</p> </li> <li> <code>SPSA</code>           \u2013            <p>Gradient approximation via Simultaneous perturbation stochastic approximation (SPSA) method.</p> </li> <li> <code>SPSA1</code>           \u2013            <p>One-measurement variant of SPSA. Unlike standard two-measurement SPSA, the estimated</p> </li> <li> <code>SR1</code>           \u2013            <p>Symmetric Rank 1. This works best with a trust region:</p> </li> <li> <code>SSVM</code>           \u2013            <p>Self-scaling variable metric Quasi-Newton method.</p> </li> <li> <code>SVRG</code>           \u2013            <p>Stochastic variance reduced gradient method (SVRG).</p> </li> <li> <code>SaveBest</code>           \u2013            <p>Saves best parameters found so far, ones that have lowest loss. Put this as the last module.</p> </li> <li> <code>ScalarProjection</code>           \u2013            <p>projetion that splits all parameters into individual scalars</p> </li> <li> <code>ScaleByGradCosineSimilarity</code>           \u2013            <p>Multiplies the update by cosine similarity with gradient.</p> </li> <li> <code>ScaleLRBySignChange</code>           \u2013            <p>learning rate gets multiplied by <code>nplus</code> if ascent/gradient didn't change the sign,</p> </li> <li> <code>ScaleModulesByCosineSimilarity</code>           \u2013            <p>Scales the output of <code>main</code> module by it's cosine similarity to the output</p> </li> <li> <code>ScipyMinimizeScalar</code>           \u2013            <p>Line search via :code:<code>scipy.optimize.minimize_scalar</code> which implements brent, golden search and bounded brent methods.</p> </li> <li> <code>Sequential</code>           \u2013            <p>On each step, this sequentially steps with <code>modules</code> <code>steps</code> times.</p> </li> <li> <code>Shampoo</code>           \u2013            <p>Shampoo from Preconditioned Stochastic Tensor Optimization (https://arxiv.org/abs/1802.09568).</p> </li> <li> <code>ShorR</code>           \u2013            <p>Shor\u2019s r-algorithm.</p> </li> <li> <code>Sign</code>           \u2013            <p>Returns <code>sign(input)</code></p> </li> <li> <code>SignConsistencyLRs</code>           \u2013            <p>Outputs per-weight learning rates based on consecutive sign consistency.</p> </li> <li> <code>SignConsistencyMask</code>           \u2013            <p>Outputs a mask of sign consistency of current and previous inputs.</p> </li> <li> <code>SixthOrder3P</code>           \u2013            <p>Sixth-order iterative method.</p> </li> <li> <code>SixthOrder3PM2</code>           \u2013            <p>Wang, Xiaofeng, and Yang Li. \"An efficient sixth-order Newton-type method for solving nonlinear systems.\" Algorithms 10.2 (2017): 45.</p> </li> <li> <code>SixthOrder5P</code>           \u2013            <p>Argyros, Ioannis K., et al. \"Extended convergence for two sixth order methods under the same weak conditions.\" Foundations 3.1 (2023): 127-139.</p> </li> <li> <code>SophiaH</code>           \u2013            <p>SophiaH optimizer from https://arxiv.org/abs/2305.14342</p> </li> <li> <code>Split</code>           \u2013            <p>Apply <code>true</code> modules to all parameters filtered by <code>filter</code>, apply <code>false</code> modules to all other parameters.</p> </li> <li> <code>Sqrt</code>           \u2013            <p>Returns <code>sqrt(input)</code></p> </li> <li> <code>SqrtEMASquared</code>           \u2013            <p>Maintains an exponential moving average of squared updates, outputs optionally debiased square root.</p> </li> <li> <code>SqrtHomotopy</code>           \u2013            </li> <li> <code>SquareHomotopy</code>           \u2013            </li> <li> <code>StepSize</code>           \u2013            <p>this is exactly the same as LR, except the <code>lr</code> parameter can be renamed to any other name to avoid clashes</p> </li> <li> <code>StrongWolfe</code>           \u2013            <p>Interpolation line search satisfying Strong Wolfe condition.</p> </li> <li> <code>Sub</code>           \u2013            <p>Subtract <code>other</code> from tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>SubModules</code>           \u2013            <p>Calculates <code>input - other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> </li> <li> <code>SubspaceNewton</code>           \u2013            <p>Subspace Newton. Performs a Newton step in a subspace (random or spanned by past gradients).</p> </li> <li> <code>Sum</code>           \u2013            <p>Outputs sum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>SumOfSquares</code>           \u2013            <p>Sets loss to be the sum of squares of values returned by the closure.</p> </li> <li> <code>Switch</code>           \u2013            <p>After <code>steps</code> steps switches to the next module.</p> </li> <li> <code>TerminateAfterNEvaluations</code>           \u2013            </li> <li> <code>TerminateAfterNSeconds</code>           \u2013            </li> <li> <code>TerminateAfterNSteps</code>           \u2013            </li> <li> <code>TerminateAll</code>           \u2013            </li> <li> <code>TerminateAny</code>           \u2013            </li> <li> <code>TerminateByGradientNorm</code>           \u2013            </li> <li> <code>TerminateByUpdateNorm</code>           \u2013            <p>update is calculated as parameter difference</p> </li> <li> <code>TerminateNever</code>           \u2013            </li> <li> <code>TerminateOnLossReached</code>           \u2013            </li> <li> <code>TerminateOnNoImprovement</code>           \u2013            </li> <li> <code>TerminationCriteriaBase</code>           \u2013            </li> <li> <code>ThomasOptimalMethod</code>           \u2013            <p>Thomas's \"optimal\" Quasi-Newton method.</p> </li> <li> <code>Threshold</code>           \u2013            <p>Outputs tensors thresholded such that values above <code>threshold</code> are set to <code>value</code>.</p> </li> <li> <code>To</code>           \u2013            <p>Cast modules to specified device and dtype</p> </li> <li> <code>TrustCG</code>           \u2013            <p>Trust region via Steihaug-Toint Conjugate Gradient method.</p> </li> <li> <code>TrustRegionBase</code>           \u2013            </li> <li> <code>TwoPointNewton</code>           \u2013            <p>two-point Newton method with frozen derivative with third order convergence.</p> </li> <li> <code>UnaryLambda</code>           \u2013            <p>Applies <code>fn</code> to input tensors.</p> </li> <li> <code>UnaryParameterwiseLambda</code>           \u2013            <p>Applies <code>fn</code> to each input tensor.</p> </li> <li> <code>Uniform</code>           \u2013            <p>Outputs tensors filled with random numbers from uniform distribution between <code>low</code> and <code>high</code>.</p> </li> <li> <code>UpdateGradientSignConsistency</code>           \u2013            <p>Compares update and gradient signs. Output will have 1s where signs match, and 0s where they don't.</p> </li> <li> <code>UpdateSign</code>           \u2013            <p>Outputs gradient with sign copied from the update.</p> </li> <li> <code>UpdateToNone</code>           \u2013            <p>Sets <code>update</code> attribute to None on <code>var</code>.</p> </li> <li> <code>VectorProjection</code>           \u2013            <p>projection that concatenates all parameters into a vector</p> </li> <li> <code>ViewAsReal</code>           \u2013            <p>View complex tensors as real tensors. Doesn't affect tensors that are already.</p> </li> <li> <code>Warmup</code>           \u2013            <p>Learning rate warmup, linearly increases learning rate multiplier from <code>start_lr</code> to <code>end_lr</code> over <code>steps</code> steps.</p> </li> <li> <code>WarmupNormClip</code>           \u2013            <p>Warmup via clipping of the update norm.</p> </li> <li> <code>WeightDecay</code>           \u2013            <p>Weight decay.</p> </li> <li> <code>WeightDropout</code>           \u2013            <p>Changes the closure so that it evaluates loss and gradients with random weights replaced with 0.</p> </li> <li> <code>WeightedAveraging</code>           \u2013            <p>Weighted average of past <code>len(weights)</code> updates.</p> </li> <li> <code>WeightedMean</code>           \u2013            <p>Outputs weighted mean of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>WeightedSum</code>           \u2013            <p>Outputs a weighted sum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>Wrap</code>           \u2013            <p>Wraps a pytorch optimizer to use it as a module.</p> </li> <li> <code>Zeros</code>           \u2013            <p>Outputs zeros</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>clip_grad_norm_</code>             \u2013              <p>Clips gradient of an iterable of parameters to specified norm value.</p> </li> <li> <code>clip_grad_value_</code>             \u2013              <p>Clips gradient of an iterable of parameters at specified value.</p> </li> <li> <code>decay_weights_</code>             \u2013              <p>directly decays weights in-place</p> </li> <li> <code>normalize_grads_</code>             \u2013              <p>Normalizes gradient of an iterable of parameters to specified norm value.</p> </li> <li> <code>orthogonalize_grads_</code>             \u2013              <p>Computes the zeroth power / orthogonalization of gradients of an iterable of parameters.</p> </li> <li> <code>orthograd_</code>             \u2013              <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.AEGD","title":"AEGD","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>AEGD (Adaptive gradient descent with energy) from https://arxiv.org/abs/2010.05109#page=10.26.</p> Note <p>AEGD has a learning rate hyperparameter that can't really be removed from the update rule. To avoid compounding learning rate mofications, remove the <code>tz.m.LR</code> module if you had it.</p> <p>Parameters:</p> <ul> <li> <code>lr</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate (default: 0.1)</p> </li> <li> <code>c</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>term added to the original objective function (default: 1)</p> </li> </ul> Reference <p>Liu, Hailiang, and Xuping Tian. \"AEGD: Adaptive gradient descent with energy.\" arXiv preprint arXiv:2010.05109 (2020).</p> Source code in <code>torchzero/modules/adaptive/aegd.py</code> <pre><code>class AEGD(TensorTransform):\n    \"\"\"AEGD (Adaptive gradient descent with energy) from https://arxiv.org/abs/2010.05109#page=10.26.\n\n    Note:\n        AEGD has a learning rate hyperparameter that can't really be removed from the update rule.\n        To avoid compounding learning rate mofications, remove the ``tz.m.LR`` module if you had it.\n\n    Args:\n        lr (float, optional): learning rate (default: 0.1)\n        c (float, optional): term added to the original objective function (default: 1)\n\n    Reference:\n        [Liu, Hailiang, and Xuping Tian. \"AEGD: Adaptive gradient descent with energy.\" arXiv preprint arXiv:2010.05109 (2020).](https://arxiv.org/pdf/2010.05109)\n    \"\"\"\n    def __init__(\n        self,\n        lr: float = 0.1,\n        c: float = 1,\n    ):\n        defaults = dict(c=c, lr=lr)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        tensors = TensorList(tensors)\n\n        c, lr = unpack_dicts(settings, 'c', 'lr', cls=NumberList)\n        r = unpack_states(states, tensors, 'r', init=lambda t: torch.full_like(t, float(loss + c[0])**0.5), cls=TensorList)\n\n        update = aegd_(\n            f=loss,\n            g=tensors,\n            r_=r,\n            c=c,\n            eta=lr,\n        )\n\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.ASAM","title":"ASAM","text":"<p>               Bases: <code>torchzero.modules.adaptive.sam.SAM</code></p> <p>Adaptive Sharpness-Aware Minimization from https://arxiv.org/pdf/2102.11600#page=6.52</p> <p>SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value. It performs two forward and backward passes per step.</p> <p>This implementation modifies the closure to return loss and calculate gradients of the SAM objective. All modules after this will use the modified objective.</p> Note <p>This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients at two points on each step.</p> <p>Parameters:</p> <ul> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Neighborhood size. Defaults to 0.05.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm of the SAM objective. Defaults to 2.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.ASAM--examples","title":"Examples:","text":"<p>ASAM-SGD:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ASAM(),\n    tz.m.LR(1e-2)\n)\n</code></pre> <p>ASAM-Adam:</p> <p><pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ASAM(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2)\n)\n</code></pre> References:     Kwon, J., Kim, J., Park, H., &amp; Choi, I. K. (2021, July). ASAM: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. In International Conference on Machine Learning (pp. 5905-5914). PMLR.</p> Source code in <code>torchzero/modules/adaptive/sam.py</code> <pre><code>class ASAM(SAM):\n    \"\"\"Adaptive Sharpness-Aware Minimization from https://arxiv.org/pdf/2102.11600#page=6.52\n\n    SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value.\n    It performs two forward and backward passes per step.\n\n    This implementation modifies the closure to return loss and calculate gradients\n    of the SAM objective. All modules after this will use the modified objective.\n\n    Note:\n        This module requires a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients at two points on each step.\n\n    Args:\n        rho (float, optional): Neighborhood size. Defaults to 0.05.\n        p (float, optional): norm of the SAM objective. Defaults to 2.\n\n    ### Examples:\n\n    ASAM-SGD:\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ASAM(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    ASAM-Adam:\n\n    ```\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ASAM(),\n        tz.m.Adam(),\n        tz.m.LR(1e-2)\n    )\n    ```\n    References:\n        [Kwon, J., Kim, J., Park, H., &amp; Choi, I. K. (2021, July). ASAM: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. In International Conference on Machine Learning (pp. 5905-5914). PMLR.](https://arxiv.org/abs/2102.11600)\n    \"\"\"\n    def __init__(self, rho: float = 0.5, p: float = 2, eps=1e-10):\n        super().__init__(rho=rho, p=p, eps=eps, asam=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Abs","title":"Abs","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>abs(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Abs(TensorTransform):\n    \"\"\"Returns ``abs(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_abs_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.AccumulateMaximum","title":"AccumulateMaximum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates maximum of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateMaximum(TensorTransform):\n    \"\"\"Accumulates maximum of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"maximum\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        maximum = unpack_states(states, tensors, 'maximum', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return maximum.maximum_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.AccumulateMean","title":"AccumulateMean","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates mean of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateMean(TensorTransform):\n    \"\"\"Accumulates mean of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"mean\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n        mean = unpack_states(states, tensors, 'mean', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return mean.add_(tensors).lazy_mul(decay, clone=True).div_(step)\n</code></pre>"},{"location":"API/all/#torchzero.modules.AccumulateMinimum","title":"AccumulateMinimum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates minimum of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateMinimum(TensorTransform):\n    \"\"\"Accumulates minimum of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"minimum\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        minimum = unpack_states(states, tensors, 'minimum', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return minimum.minimum_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.AccumulateProduct","title":"AccumulateProduct","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates product of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>, default:                   <code>'update'</code> )           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateProduct(TensorTransform):\n    \"\"\"Accumulates product of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0, target = 'update',):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prod = unpack_states(states, tensors, 'prod', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return prod.mul_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.AccumulateSum","title":"AccumulateSum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates sum of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateSum(TensorTransform):\n    \"\"\"Accumulates sum of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"sum\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        sum = unpack_states(states, tensors, 'sum', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return sum.add_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.AdGD","title":"AdGD","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>AdGD and AdGD-2 (https://arxiv.org/abs/2308.02261)</p> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class AdGD(TensorTransform):\n    \"\"\"AdGD and AdGD-2 (https://arxiv.org/abs/2308.02261)\"\"\"\n    def __init__(self, variant:Literal[1,2]=2, alpha_0:float = 1e-7, sqrt:bool=True, use_grad=True, inner: Chainable | None = None,):\n        defaults = dict(variant=variant, alpha_0=alpha_0, sqrt=sqrt)\n        super().__init__(defaults, uses_grad=use_grad, inner=inner,)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_g')\n        self.global_state['reset'] = True\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        variant = settings[0]['variant']\n        theta_0 = 0 if variant == 1 else 1/3\n        theta = self.global_state.get('theta', theta_0)\n\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        p = TensorList(params)\n        g = grads if self._uses_grad else tensors\n        assert g is not None\n        g = TensorList(g)\n\n        prev_p, prev_g = unpack_states(states, tensors, 'prev_p', 'prev_g', cls=TensorList)\n\n        # online\n        if self.global_state.get('reset', False):\n            del self.global_state['reset']\n            prev_p.copy_(p)\n            prev_g.copy_(g)\n            return\n\n        if step == 0:\n            alpha_0 = settings[0]['alpha_0']\n            if alpha_0 is None: alpha_0 = epsilon_step_size(g)\n            self.global_state['alpha']  = alpha_0\n            prev_p.copy_(p)\n            prev_g.copy_(g)\n            return\n\n        sqrt = settings[0]['sqrt']\n        alpha = self.global_state.get('alpha', math.inf)\n        L = (g - prev_g).global_vector_norm() / (p - prev_p).global_vector_norm()\n        eps = torch.finfo(L.dtype).tiny * 2\n\n        if variant == 1:\n            a1 = math.sqrt(1 + theta)*alpha\n            val = math.sqrt(2) if sqrt else 2\n            if L &gt; eps: a2 = 1 / (val*L)\n            else: a2 = math.inf\n\n        elif variant == 2:\n            a1 = math.sqrt(2/3 + theta)*alpha\n            a2 = alpha / math.sqrt(max(eps, 2 * alpha**2 * L**2 - 1))\n\n        else:\n            raise ValueError(variant)\n\n        alpha_new = min(a1, a2)\n        if alpha_new &lt; 0: alpha_new = max(a1, a2)\n        if alpha_new &gt; eps:\n            self.global_state['theta'] = alpha_new/alpha\n            self.global_state['alpha'] = alpha_new\n\n        prev_p.copy_(p)\n        prev_g.copy_(g)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            # alpha isn't None on 1st step\n            self.state.clear()\n            self.global_state.clear()\n            alpha = epsilon_step_size(TensorList(tensors), settings[0]['alpha_0'])\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n</code></pre>"},{"location":"API/all/#torchzero.modules.AdaHessian","title":"AdaHessian","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>AdaHessian: An Adaptive Second Order Optimizer for Machine Learning (https://arxiv.org/abs/2006.00719)</p> <p>This is similar to Adam, but the second momentum is replaced by square root of an exponential moving average of random hessian-vector products.</p> Notes <ul> <li> <p>In most cases AdaHessian should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply AdaHessian preconditioning to another module's output.</p> </li> <li> <p>This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>first momentum. Defaults to 0.9.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>second momentum for squared hessian diagonal estimates. Defaults to 0.999.</p> </li> <li> <code>averaging</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to enable block diagonal averaging over 1st dimension on parameters that have 2+ dimensions. This can be set per-parameter in param groups.</p> </li> <li> <code>block_size</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>size of block in the block-diagonal averaging.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating hessian diagonal estimate via a hessian-vector product. This value can be increased to reduce computational cost. Defaults to 1.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>division stability epsilon. Defaults to 1e-8.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to <code>\"autograd\"</code>. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of hessian-vector products with random vectors to evaluate each time when updating the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random vectors. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>)           \u2013            <p>Inner module. If this is specified, operations are performed in the following order. 1. compute hessian diagonal estimate. 2. pass inputs to <code>inner</code>. 3. momentum and preconditioning are applied to the ouputs of <code>inner</code>.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.AdaHessian--examples","title":"Examples:","text":"<p>Using AdaHessian:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.AdaHessian(),\n    tz.m.LR(0.1)\n)\n</code></pre> <p>AdaHessian preconditioner can be applied to any other module by passing it to the <code>inner</code> argument. Turn off AdaHessian's first momentum to get just the preconditioning. Here is an example of applying AdaHessian preconditioning to nesterov momentum (<code>tz.m.NAG</code>): <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.AdaHessian(beta1=0, inner=tz.m.NAG(0.9)),\n    tz.m.LR(0.1)\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/adahessian.py</code> <pre><code>class AdaHessian(Transform):\n    \"\"\"AdaHessian: An Adaptive Second Order Optimizer for Machine Learning (https://arxiv.org/abs/2006.00719)\n\n    This is similar to Adam, but the second momentum is replaced by square root of an exponential moving average of random hessian-vector products.\n\n    Notes:\n        - In most cases AdaHessian should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply AdaHessian preconditioning to another module's output.\n\n        - This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        beta1 (float, optional): first momentum. Defaults to 0.9.\n        beta2 (float, optional): second momentum for squared hessian diagonal estimates. Defaults to 0.999.\n        averaging (bool, optional):\n            whether to enable block diagonal averaging over 1st dimension on parameters that have 2+ dimensions.\n            This can be set per-parameter in param groups.\n        block_size (int, optional):\n            size of block in the block-diagonal averaging.\n        update_freq (int, optional):\n            frequency of updating hessian diagonal estimate via a hessian-vector product.\n            This value can be increased to reduce computational cost. Defaults to 1.\n        eps (float, optional):\n            division stability epsilon. Defaults to 1e-8.\n        hvp_method (str, optional):\n            Determines how hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        n_samples (int, optional):\n            number of hessian-vector products with random vectors to evaluate each time when updating\n            the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n        seed (int | None, optional): seed for random vectors. Defaults to None.\n        inner (Chainable | None, optional):\n            Inner module. If this is specified, operations are performed in the following order.\n            1. compute hessian diagonal estimate.\n            2. pass inputs to ``inner``.\n            3. momentum and preconditioning are applied to the ouputs of ``inner``.\n\n    ## Examples:\n\n    Using AdaHessian:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.AdaHessian(),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    AdaHessian preconditioner can be applied to any other module by passing it to the ``inner`` argument.\n    Turn off AdaHessian's first momentum to get just the preconditioning. Here is an example of applying\n    AdaHessian preconditioning to nesterov momentum (``tz.m.NAG``):\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.AdaHessian(beta1=0, inner=tz.m.NAG(0.9)),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.9,\n        beta2: float = 0.999,\n        averaging: bool = True,\n        block_size: int | None = None,\n        update_freq: int = 1,\n        eps: float = 1e-8,\n        hessian_power: float = 1,\n        distribution: Distributions = 'rademacher',\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        n_samples = 1,\n        zHz: bool = True,\n        debias: bool = True,\n        seed: int | None = None,\n\n        exp_avg_tfm: Chainable | None = None,\n        D_exp_avg_sq_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"exp_avg_tfm\"], defaults[\"D_exp_avg_sq_tfm\"]\n        super().__init__(defaults)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.set_child('D_exp_avg_sq', D_exp_avg_sq_tfm)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2, averaging, block_size = unpack_dicts(settings, 'beta1', 'beta2', 'averaging', 'block_size', cls=NumberList)\n\n        exp_avg, D_exp_avg_sq = unpack_states(states, params, 'exp_avg', 'D_exp_avg_sq', cls=TensorList)\n\n        # ---------------------------- hutchinson hessian ---------------------------- #\n        fs = settings[0]\n        step = self.increment_counter(\"step\", start=0) # 0 on 1st update\n        update_freq = fs['update_freq']\n\n        if step % update_freq == 0:\n            self.increment_counter(\"num_Ds\", start=1)\n\n            D, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = fs['n_samples'],\n                distribution = fs['distribution'],\n                hvp_method = fs['hvp_method'],\n                h = fs['h'],\n                zHz = fs[\"zHz\"],\n                generator = self.get_generator(params[0].device, fs[\"seed\"]),\n            )\n\n            D = TensorList(D).zipmap_args(_block_average, block_size, averaging)\n            D_exp_avg_sq.mul_(beta2).addcmul_(D, D, value=1-beta2)\n\n        # --------------------------------- momentum --------------------------------- #\n        tensors = objective.get_updates() # do this after hutchinson to not disturb autograd\n        exp_avg.lerp_(tensors, 1-beta1)\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2, eps, hessian_power = unpack_dicts(settings, 'beta1', 'beta2', 'eps', 'hessian_power', cls=NumberList)\n        exp_avg, D_exp_avg_sq = unpack_states(states, params, 'exp_avg', 'D_exp_avg_sq', cls=TensorList)\n\n        # ---------------------------------- debias ---------------------------------- #\n        if settings[0][\"debias\"]:\n            bias_correction1 = 1.0 - (beta1 ** (self.global_state[\"step\"] + 1))\n            bias_correction2 = 1.0 - (beta2 ** self.global_state[\"num_Ds\"])\n            exp_avg = exp_avg / bias_correction1\n            D_exp_avg_sq = D_exp_avg_sq / bias_correction2\n\n\n        # -------------------------------- transforms -------------------------------- #\n        exp_avg = TensorList(self.inner_step_tensors(\n            \"exp_avg\", tensors=exp_avg, clone=True, objective=objective, must_exist=False))\n\n        D_exp_avg_sq = TensorList(self.inner_step_tensors(\n            \"D_exp_avg_sq\", tensors=D_exp_avg_sq, clone=True, objective=objective, must_exist=False))\n\n        # ------------------------------ compute update ------------------------------ #\n        denom = D_exp_avg_sq.lazy_pow(hessian_power / 2) + eps\n        objective.updates = exp_avg / denom\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Adagrad","title":"Adagrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adagrad, divides by sum of past squares of gradients.</p> <p>This implementation is identical to <code>torch.optim.Adagrad</code>.</p> <p>Parameters:</p> <ul> <li> <code>lr_decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>learning rate decay. Defaults to 0.</p> </li> <li> <code>initial_accumulator_value</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>initial value of the sum of squares of gradients. Defaults to 0.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-10</code> )           \u2013            <p>division epsilon. Defaults to 1e-10.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>step size. Defaults to 1.</p> </li> <li> <code>pow</code>               (<code>float</code>)           \u2013            <p>power for gradients and accumulator root. Defaults to 2.</p> </li> <li> <code>use_sqrt</code>               (<code>bool</code>)           \u2013            <p>whether to take the root of the accumulator. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adagrad.py</code> <pre><code>class Adagrad(TensorTransform):\n    \"\"\"Adagrad, divides by sum of past squares of gradients.\n\n    This implementation is identical to ``torch.optim.Adagrad``.\n\n    Args:\n        lr_decay (float, optional): learning rate decay. Defaults to 0.\n        initial_accumulator_value (float, optional): initial value of the sum of squares of gradients. Defaults to 0.\n        eps (float, optional): division epsilon. Defaults to 1e-10.\n        alpha (float, optional): step size. Defaults to 1.\n        pow (float, optional): power for gradients and accumulator root. Defaults to 2.\n        use_sqrt (bool, optional): whether to take the root of the accumulator. Defaults to True.\n        inner (Chainable | None, optional): Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n\n        # hyperparams\n        lr_decay: float = 0,\n        initial_accumulator_value: float = 0,\n        eps: float = 1e-10,\n        alpha: float = 1,\n\n        # tfms\n        inner: Chainable | None = None,\n        accumulator_tfm: Chainable | None = None\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"accumulator_tfm\"]\n        super().__init__(defaults=defaults, inner=inner)\n\n        self.set_child('accumulator', accumulator_tfm)\n        self.add_projected_keys(\"grad\", \"accumulator\")\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        state[\"accumulator\"] = torch.full_like(tensor, fill_value=setting[\"initial_accumulator_value\"])\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_addcmul_([state[\"accumulator\"] for state in states], tensors, tensors)\n        self.increment_counter(\"step\", start=0)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors_ = TensorList(tensors)\n        step = self.global_state[\"step\"] # 0 on first apply\n        eps, alpha, lr_decay = unpack_dicts(settings, \"eps\", \"alpha\", \"lr_decay\", cls=NumberList)\n\n        accumulator = [state[\"accumulator\"] for state in states]\n        accumulator = TensorList(self.inner_step_tensors(\n            \"accumulator\", tensors=accumulator, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        denom = accumulator.sqrt().add_(eps)\n        tensors_ /= denom\n\n        clr = alpha / (1 + step * lr_decay)\n        tensors_.lazy_mul_(clr)\n\n        return tensors_\n</code></pre>"},{"location":"API/all/#torchzero.modules.AdagradNorm","title":"AdagradNorm","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adagrad-Norm, divides by sum of past means of squares of gradients.</p> <p>Parameters:</p> <ul> <li> <code>lr_decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>learning rate decay. Defaults to 0.</p> </li> <li> <code>initial_accumulator_value</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>initial value of the sum of squares of gradients. Defaults to 0.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-10</code> )           \u2013            <p>division epsilon. Defaults to 1e-10.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>step size. Defaults to 1.</p> </li> <li> <code>use_sqrt</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to take the root of the accumulator. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adagrad.py</code> <pre><code>class AdagradNorm(TensorTransform):\n    \"\"\"Adagrad-Norm, divides by sum of past means of squares of gradients.\n\n    Args:\n        lr_decay (float, optional): learning rate decay. Defaults to 0.\n        initial_accumulator_value (float, optional): initial value of the sum of squares of gradients. Defaults to 0.\n        eps (float, optional): division epsilon. Defaults to 1e-10.\n        alpha (float, optional): step size. Defaults to 1.\n        use_sqrt (bool, optional): whether to take the root of the accumulator. Defaults to True.\n        inner (Chainable | None, optional): Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        lr_decay: float = 0,\n        initial_accumulator_value: float = 0,\n        eps: float = 1e-10,\n        beta:float | None = None,\n        beta_debias: bool = True,\n        layerwise: bool = True,\n        use_sqrt: bool = True,\n        alpha: float = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults=defaults, inner=inner)\n\n    @torch.no_grad\n    def multi_tensor_initialize(self, tensors, params, grads, loss, states, settings):\n\n        # layerwise initialize in each state\n        if settings[0][\"layerwise\"]:\n            for tensor, state, setting in zip(tensors, states, settings):\n\n                initial_accumulator_value = setting[\"initial_accumulator_value\"]\n                state[\"accumulator\"] = torch.tensor(initial_accumulator_value, device=tensor.device, dtype=tensor.dtype)\n\n        # global initialize in global state\n        else:\n            initial_accumulator_value = settings[0][\"initial_accumulator_value\"]\n            tensor = tensors[0]\n            self.global_state[\"accumulator\"] = torch.tensor(initial_accumulator_value, device=tensor.device, dtype=tensor.dtype)\n\n    def _get_accumulator(self, states, settings) -&gt; torch.Tensor | TensorList:\n        layerwise = settings[0][\"layerwise\"]\n        if layerwise:\n            return TensorList(s[\"accumulator\"] for s in states)\n\n        return self.global_state[\"accumulator\"]\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        accumulator = self._get_accumulator(states, settings)\n        self.increment_counter(\"step\", start=0)\n\n        # compute squared gradient norm (gg)\n        if isinstance(accumulator, TensorList): gg = tensors.tensorwise_dot(tensors)\n        else: gg = tensors.dot(tensors)\n\n        # update the accumulator\n        beta = settings[0][\"beta\"]\n        if beta is None: accumulator.add_(gg) # pyright:ignore[reportArgumentType]\n        else: accumulator.lerp_(gg, weight=1-beta) # pyright:ignore[reportArgumentType, reportCallIssue]\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        accumulator = self._get_accumulator(states, settings)\n        eps, alpha, lr_decay = unpack_dicts(settings, \"eps\", \"alpha\", \"lr_decay\", cls=NumberList)\n        step = self.global_state[\"step\"] # 0 on 1st step\n        fs = settings[0]\n        beta = fs[\"beta\"]\n\n        # ------------------------ debias if beta is not None ------------------------ #\n        if fs[\"beta_debias\"] and beta is not None:\n            accumulator = accumulator / (1 - beta ** (step + 1))\n\n\n        # ---------------------------- compute denominator --------------------------- #\n        if fs[\"use_sqrt\"]:\n            denom = accumulator.sqrt().add_(eps) # pyright:ignore[reportArgumentType]\n        else:\n            denom = accumulator + eps # pyright:ignore[reportOperatorIssue]\n\n\n        # ---------------------------- compute the update ---------------------------- #\n        tensors /= denom\n        clr = alpha / (1 + step * lr_decay) # lr decay\n        tensors.lazy_mul_(clr)\n\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.Adam","title":"Adam","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adam. Divides gradient EMA by EMA of gradient squares with debiased step size.</p> <p>This implementation is identical to :code:<code>torch.optim.Adam</code>.</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum. Defaults to 0.9.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>second momentum. Defaults to 0.999.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon. Defaults to 1e-8.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>learning rate. Defaults to 1.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>)           \u2013            <p>power used in second momentum power and root. Defaults to 2.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to apply debiasing to momentums based on current step. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adam.py</code> <pre><code>class Adam(TensorTransform):\n    \"\"\"Adam. Divides gradient EMA by EMA of gradient squares with debiased step size.\n\n    This implementation is identical to :code:`torch.optim.Adam`.\n\n    Args:\n        beta1 (float, optional): momentum. Defaults to 0.9.\n        beta2 (float, optional): second momentum. Defaults to 0.999.\n        eps (float, optional): epsilon. Defaults to 1e-8.\n        alpha (float, optional): learning rate. Defaults to 1.\n        amsgrad (bool, optional): Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.\n        pow (float, optional): power used in second momentum power and root. Defaults to 2.\n        debias (bool, optional): whether to apply debiasing to momentums based on current step. Defaults to True.\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.9,\n        beta2: float = 0.999,\n        eps: float = 1e-8,\n        amsgrad: bool = False,\n        alpha: float = 1.,\n        debias: bool = True,\n\n        exp_avg_tfm: Chainable | None = None,\n        exp_avg_sq_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"exp_avg_tfm\"], defaults[\"exp_avg_sq_tfm\"]\n        super().__init__(defaults)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.set_child('exp_avg_sq', exp_avg_sq_tfm)\n\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        self.increment_counter(\"step\", start=0)\n        beta1, beta2 = unpack_dicts(settings, 'beta1','beta2', cls=NumberList)\n\n        # ----------------------------- initialize states ---------------------------- #\n        if settings[0][\"amsgrad\"]:\n            exp_avg, exp_avg_sq, max_exp_avg_sq = unpack_states(\n                states, tensors, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        # ------------------------------ update moments ------------------------------ #\n        exp_avg.lerp_(tensors, weight=1-beta1)\n        exp_avg_sq.mul_(beta2).addcmul_(tensors, tensors, value=1-beta2)\n\n        if max_exp_avg_sq is not None:\n            max_exp_avg_sq.maximum_(exp_avg_sq)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state[\"step\"] # 0 on 1st step\n        fs = settings[0]\n\n        if fs[\"amsgrad\"]: key = \"max_exp_avg_sq\"\n        else: key = \"exp_avg_sq\"\n        exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', key, cls=TensorList)\n        beta1, beta2, alpha, eps = unpack_dicts(settings, 'beta1', 'beta2', 'alpha', 'eps', cls=NumberList)\n\n        # -------------------------------- transforms -------------------------------- #\n        exp_avg = TensorList(self.inner_step_tensors(\n            \"exp_avg\", tensors=exp_avg, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        exp_avg_sq = TensorList(self.inner_step_tensors(\n            \"exp_avg_sq\", tensors=exp_avg_sq, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        # ---------------------------------- debias ---------------------------------- #\n        if fs[\"debias\"]:\n            alpha = debiased_step_size((step + 1), beta1=beta1, beta2=beta2, alpha=alpha)\n            exp_avg = exp_avg * alpha\n\n        # ---------------------------------- update ---------------------------------- #\n        return exp_avg / exp_avg_sq.sqrt().add_(eps)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Adan","title":"Adan","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adaptive Nesterov Momentum Algorithm from https://arxiv.org/abs/2208.06677</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.98</code> )           \u2013            <p>momentum. Defaults to 0.98.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.92</code> )           \u2013            <p>momentum for gradient differences. Defaults to 0.92.</p> </li> <li> <code>beta3</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>thrid (squared) momentum. Defaults to 0.99.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon. Defaults to 1e-8.</p> </li> </ul> <p>Example: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adan(),\n    tz.m.LR(1e-3),\n)\n</code></pre> Reference:     Xie, X., Zhou, P., Li, H., Lin, Z., &amp; Yan, S. (2024). Adan: Adaptive nesterov momentum algorithm for faster optimizing deep models. IEEE Transactions on Pattern Analysis and Machine Intelligence.</p> Source code in <code>torchzero/modules/adaptive/adan.py</code> <pre><code>class Adan(TensorTransform):\n    \"\"\"Adaptive Nesterov Momentum Algorithm from https://arxiv.org/abs/2208.06677\n\n    Args:\n        beta1 (float, optional): momentum. Defaults to 0.98.\n        beta2 (float, optional): momentum for gradient differences. Defaults to 0.92.\n        beta3 (float, optional): thrid (squared) momentum. Defaults to 0.99.\n        eps (float, optional): epsilon. Defaults to 1e-8.\n\n    Example:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adan(),\n        tz.m.LR(1e-3),\n    )\n    ```\n    Reference:\n        [Xie, X., Zhou, P., Li, H., Lin, Z., &amp; Yan, S. (2024). Adan: Adaptive nesterov momentum algorithm for faster optimizing deep models. IEEE Transactions on Pattern Analysis and Machine Intelligence](https://arxiv.org/abs/2208.06677).\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.98,\n        beta2: float = 0.92,\n        beta3: float = 0.99,\n        eps: float = 1e-8,\n\n        m_tfm: Chainable | None = None,\n        v_tfm: Chainable | None = None,\n        n_tfm: Chainable | None = None,\n    ):\n        defaults=dict(beta1=beta1, beta2=beta2, beta3=beta3, eps=eps)\n        super().__init__(defaults, uses_grad=False)\n\n        self.set_child(\"m\", m_tfm)\n        self.set_child(\"v\", v_tfm)\n        self.set_child(\"n\", n_tfm)\n\n        self.add_projected_keys(\"grad_sq\", \"m\", \"v\", \"g_prev\")\n        self.add_projected_keys(\"grad\", \"n\")\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        step = self.increment_counter(\"step\", start=0)\n\n        beta1, beta2, beta3 = unpack_dicts(settings, 'beta1','beta2','beta3', cls=NumberList)\n        g_prev, m, v, n = unpack_states(states, tensors, 'g_prev', 'm', 'v', 'n', cls=TensorList)\n\n        adan_update_(g=tensors, g_prev_=g_prev, m_=m, v_=v, n_=n, beta1=beta1, beta2=beta2, beta3=beta3, step=step+1)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        step = self.global_state[\"step\"] # 0 on 1st step\n\n        beta1, beta2, beta3, eps = unpack_dicts(settings, 'beta1','beta2','beta3', 'eps', cls=NumberList)\n        m, v, n = unpack_states(states, tensors, 'm', 'v', 'n')\n\n        # -------------------------------- transforms -------------------------------- #\n        m = TensorList(self.inner_step_tensors(\"m\", m, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n        v = TensorList(self.inner_step_tensors(\"v\", v, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n        n = TensorList(self.inner_step_tensors(\"n\", n, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        # ---------------------------------- update ---------------------------------- #\n        return adan_apply_(m_=m, v_=v, n_=n, beta1=beta1, beta2=beta2, beta3=beta3, eps=eps, step=step+1)\n</code></pre>"},{"location":"API/all/#torchzero.modules.AdaptiveBacktracking","title":"AdaptiveBacktracking","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Adaptive backtracking line search. After each line search procedure, a new initial step size is set such that optimal step size in the procedure would be found on the second line search iteration.</p> <p>Parameters:</p> <ul> <li> <code>init</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial step size. Defaults to 1.0.</p> </li> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplies each consecutive step size by this value. Defaults to 0.5.</p> </li> <li> <code>c</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>sufficient decrease condition. Defaults to 1e-4.</p> </li> <li> <code>condition</code>               (<code>Literal</code>, default:                   <code>'armijo'</code> )           \u2013            <p>termination condition, only ones that do not use gradient at f(x+a*d) can be specified. - \"armijo\" - sufficient decrease condition. - \"decrease\" - any decrease in objective function value satisfies the condition.</p> <p>\"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage. Defaults to 'armijo'.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>maximum number of function evaluations per step. Defaults to 10.</p> </li> <li> <code>target_iters</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>sets next step size such that this number of iterations are expected to be performed until optimal step size is found. Defaults to 1.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>if initial step size is optimal, it is multiplied by this value. Defaults to 2.0.</p> </li> <li> <code>scale_beta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>momentum for initial step size, at 0 disables momentum. Defaults to 0.0.</p> </li> </ul> Source code in <code>torchzero/modules/line_search/backtracking.py</code> <pre><code>class AdaptiveBacktracking(LineSearchBase):\n    \"\"\"Adaptive backtracking line search. After each line search procedure, a new initial step size is set\n    such that optimal step size in the procedure would be found on the second line search iteration.\n\n    Args:\n        init (float, optional): initial step size. Defaults to 1.0.\n        beta (float, optional): multiplies each consecutive step size by this value. Defaults to 0.5.\n        c (float, optional): sufficient decrease condition. Defaults to 1e-4.\n        condition (TerminationCondition, optional):\n            termination condition, only ones that do not use gradient at f(x+a*d) can be specified.\n            - \"armijo\" - sufficient decrease condition.\n            - \"decrease\" - any decrease in objective function value satisfies the condition.\n\n            \"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage.\n            Defaults to 'armijo'.\n        maxiter (int, optional): maximum number of function evaluations per step. Defaults to 10.\n        target_iters (int, optional):\n            sets next step size such that this number of iterations are expected\n            to be performed until optimal step size is found. Defaults to 1.\n        nplus (float, optional):\n            if initial step size is optimal, it is multiplied by this value. Defaults to 2.0.\n        scale_beta (float, optional):\n            momentum for initial step size, at 0 disables momentum. Defaults to 0.0.\n    \"\"\"\n    def __init__(\n        self,\n        init: float = 1.0,\n        beta: float = 0.5,\n        c: float = 1e-4,\n        condition: TerminationCondition = 'armijo',\n        maxiter: int = 20,\n        target_iters = 1,\n        nplus = 2.0,\n        scale_beta = 0.0,\n    ):\n        defaults=dict(init=init,beta=beta,c=c,condition=condition,maxiter=maxiter,target_iters=target_iters,nplus=nplus,scale_beta=scale_beta)\n        super().__init__(defaults=defaults)\n\n        self.global_state['beta_scale'] = 1.0\n        self.global_state['initial_scale'] = 1.0\n\n    def reset(self):\n        super().reset()\n        self.global_state['beta_scale'] = 1.0\n        self.global_state['initial_scale'] = 1.0\n\n    @torch.no_grad\n    def search(self, update, var):\n        init, beta, c,condition, maxiter, target_iters, nplus, scale_beta=itemgetter(\n            'init','beta','c','condition', 'maxiter','target_iters','nplus','scale_beta')(self.defaults)\n\n        objective = self.make_objective(var=var)\n\n        # directional derivative (0 if c = 0 because it is not needed)\n        if c == 0: d = 0\n        else: d = -sum(t.sum() for t in torch._foreach_mul(var.get_grads(), update))\n\n        # scale beta\n        beta = beta * self.global_state['beta_scale']\n\n        # scale step size so that decrease is expected at target_iters\n        init = init * self.global_state['initial_scale']\n\n        step_size = backtracking_line_search(objective, d, init=init, beta=beta, c=c, condition=condition, maxiter=maxiter)\n\n        # found an alpha that reduces loss\n        if step_size is not None:\n\n            # update initial_scale\n            # initial step size satisfied conditions, increase initial_scale by nplus\n            if step_size == init and target_iters &gt; 0:\n                self.global_state['initial_scale'] *= nplus ** target_iters\n\n                # clip by maximum possibel value to avoid overflow exception\n                self.global_state['initial_scale'] = min(\n                    self.global_state['initial_scale'],\n                    torch.finfo(var.params[0].dtype).max / 2,\n                )\n\n            else:\n                # otherwise make initial_scale such that target_iters iterations will satisfy armijo\n                init_target = step_size\n                for _ in range(target_iters):\n                    init_target = step_size / beta\n\n                self.global_state['initial_scale'] = _lerp(\n                    self.global_state['initial_scale'], init_target / init, 1-scale_beta\n                )\n\n            # revert beta_scale\n            self.global_state['beta_scale'] = min(1.0, self.global_state['beta_scale'] * math.sqrt(1.5))\n\n            return step_size\n\n        # on fail reduce beta scale value\n        self.global_state['beta_scale'] /= 1.5\n        return 0\n</code></pre>"},{"location":"API/all/#torchzero.modules.AdaptiveBisection","title":"AdaptiveBisection","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>A line search that evaluates previous step size, if value increased, backtracks until the value stops decreasing, otherwise forward-tracks until value stops decreasing.</p> <p>Parameters:</p> <ul> <li> <code>init</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial step size. Defaults to 1.0.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>multiplier to step size if initial step size is optimal. Defaults to 2.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplier to step size if initial step size is too big. Defaults to 0.5.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of function evaluations per step. Defaults to 10.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>when enabled, if line search failed, step size will continue decreasing on the next step. Otherwise it will restart the line search from <code>init</code> step size. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/line_search/adaptive.py</code> <pre><code>class AdaptiveBisection(LineSearchBase):\n    \"\"\"A line search that evaluates previous step size, if value increased, backtracks until the value stops decreasing,\n    otherwise forward-tracks until value stops decreasing.\n\n    Args:\n        init (float, optional): initial step size. Defaults to 1.0.\n        nplus (float, optional): multiplier to step size if initial step size is optimal. Defaults to 2.\n        nminus (float, optional): multiplier to step size if initial step size is too big. Defaults to 0.5.\n        maxiter (int, optional): maximum number of function evaluations per step. Defaults to 10.\n        adaptive (bool, optional):\n            when enabled, if line search failed, step size will continue decreasing on the next step.\n            Otherwise it will restart the line search from ``init`` step size. Defaults to True.\n    \"\"\"\n    def __init__(\n        self,\n        init: float = 1.0,\n        nplus: float = 2,\n        nminus: float = 0.5,\n        maxiter: int = 10,\n        adaptive=True,\n    ):\n        defaults=dict(init=init,nplus=nplus,nminus=nminus,maxiter=maxiter,adaptive=adaptive)\n        super().__init__(defaults=defaults)\n\n    def reset(self):\n        super().reset()\n\n    @torch.no_grad\n    def search(self, update, var):\n        init, nplus, nminus, maxiter, adaptive = itemgetter(\n            'init', 'nplus', 'nminus', 'maxiter', 'adaptive')(self.defaults)\n\n        objective = self.make_objective(var=var)\n\n        # scale a_prev\n        a_prev = self.global_state.get('a_prev', init)\n        if adaptive: a_prev = a_prev * self.global_state.get('init_scale', 1)\n\n        a_init = a_prev\n        if a_init &lt; torch.finfo(var.params[0].dtype).tiny * 2:\n            a_init = torch.finfo(var.params[0].dtype).max / 2\n\n        step_size, f, niter = adaptive_bisection(\n            objective,\n            a_init=a_init,\n            maxiter=maxiter,\n            nplus=nplus,\n            nminus=nminus,\n        )\n\n        # found an alpha that reduces loss\n        if step_size != 0:\n            assert (var.loss is None) or (math.isfinite(f) and f &lt; var.loss)\n            self.global_state['init_scale'] = 1\n\n            # if niter == 1, forward tracking failed to decrease function value compared to f_a_prev\n            if niter == 1 and step_size &gt;= a_init: step_size *= nminus\n\n            self.global_state['a_prev'] = step_size\n            return step_size\n\n        # on fail reduce beta scale value\n        self.global_state['init_scale'] = self.global_state.get('init_scale', 1) * nminus**maxiter\n        self.global_state['a_prev'] = init\n        return 0\n</code></pre>"},{"location":"API/all/#torchzero.modules.AdaptiveHeavyBall","title":"AdaptiveHeavyBall","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adaptive heavy ball from https://hal.science/hal-04832983v1/file/OJMO_2024__5__A7_0.pdf.</p> <p>Suitable for quadratic objectives with known f* (loss at minimum).</p> note <p>The step size is determined by the algorithm, so learning rate modules shouldn't be used.</p> <p>Parameters:</p> <ul> <li> <code>f_star</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>(estimated) minimal possible value of the objective function (lowest possible loss). Defaults to 0.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adaptive_heavyball.py</code> <pre><code>class AdaptiveHeavyBall(TensorTransform):\n    \"\"\"Adaptive heavy ball from https://hal.science/hal-04832983v1/file/OJMO_2024__5__A7_0.pdf.\n\n    Suitable for quadratic objectives with known f* (loss at minimum).\n\n    note:\n        The step size is determined by the algorithm, so learning rate modules shouldn't be used.\n\n    Args:\n        f_star (int, optional):\n            (estimated) minimal possible value of the objective function (lowest possible loss). Defaults to 0.\n    \"\"\"\n    def __init__(self, f_star: float = 0):\n        defaults = dict(f_star=f_star)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        tensors = TensorList(tensors)\n        f_star = settings[0]['f_star']\n\n        f_prev = self.global_state.get('f_prev', None)\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', init=[params,tensors], cls=TensorList)\n\n        # -------------------------------- first step -------------------------------- #\n        if f_prev is None:\n            self.global_state['f_prev'] = loss\n            h = 2*(loss - f_star) / tensors.dot(tensors)\n            return h * tensors\n\n        # ------------------------------- further steps ------------------------------ #\n        update = adaptive_heavy_ball(\n            f=loss, f_star=f_star, f_prev=f_prev, g=tensors, g_prev=g_prev, p=TensorList(params), p_prev=p_prev)\n\n        # --------------------------- store previous values -------------------------- #\n        self.global_state['f_prev'] = loss\n        p_prev.copy_(params)\n        g_prev.copy_(tensors)\n\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.Add","title":"Add","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Add <code>other</code> to tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>tensors + other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Add(BinaryOperationBase):\n    \"\"\"Add ``other`` to tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``tensors + other(tensors)``\n    \"\"\"\n    def __init__(self, other: Chainable | float, alpha: float = 1):\n        defaults = dict(alpha=alpha)\n        super().__init__(defaults, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        if isinstance(other, (int,float)): torch._foreach_add_(update, other * self.defaults['alpha'])\n        else: torch._foreach_add_(update, other, alpha=self.defaults['alpha'])\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.Alternate","title":"Alternate","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Alternates between stepping with :code:<code>modules</code>.</p> <p>That is, first step is performed with 1st module, second step with second module, etc.</p> <p>Parameters:</p> <ul> <li> <code>steps</code>               (<code>int | Iterable[int]</code>, default:                   <code>1</code> )           \u2013            <p>number of steps to perform with each module. Defaults to 1.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Alternate--examples","title":"Examples:","text":"<p>Alternate between Adam, SignSGD and RMSprop</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Alternate(\n        tz.m.Adam(),\n        [tz.m.SignSGD(), tz.m.Mul(0.5)],\n        tz.m.RMSprop(),\n    ),\n    tz.m.LR(1e-3),\n)\n</code></pre> Source code in <code>torchzero/modules/misc/switch.py</code> <pre><code>class Alternate(Module):\n    \"\"\"Alternates between stepping with :code:`modules`.\n\n    That is, first step is performed with 1st module, second step with second module, etc.\n\n    Args:\n        steps (int | Iterable[int], optional): number of steps to perform with each module. Defaults to 1.\n\n    ### Examples:\n    Alternate between Adam, SignSGD and RMSprop\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Alternate(\n            tz.m.Adam(),\n            [tz.m.SignSGD(), tz.m.Mul(0.5)],\n            tz.m.RMSprop(),\n        ),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    LOOP = True\n    def __init__(self, *modules: Chainable, steps: int | Iterable[int] = 1):\n        if isinstance(steps, Iterable):\n            steps = list(steps)\n            if len(steps) != len(modules):\n                raise ValueError(f\"steps must be the same length as modules, got {len(modules) = }, {len(steps) = }\")\n\n        defaults = dict(steps=steps)\n        super().__init__(defaults)\n\n        self.set_children_sequence(modules)\n        self.global_state['current_module_idx'] = 0\n        self.global_state['steps_to_next'] = steps[0] if isinstance(steps, list) else steps\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective):\n        # get current module\n        current_module_idx = self.global_state.setdefault('current_module_idx', 0)\n        module = self.children[f'module_{current_module_idx}']\n\n        # step\n        objective = module.step(objective.clone(clone_updates=False))\n\n        # number of steps until next module\n        steps = self.defaults['steps']\n        if isinstance(steps, int): steps = [steps]*len(self.children)\n\n        if 'steps_to_next' not in self.global_state:\n            self.global_state['steps_to_next'] = steps[0] if isinstance(steps, list) else steps\n\n        self.global_state['steps_to_next'] -= 1\n\n        # switch to next module\n        if self.global_state['steps_to_next'] == 0:\n            self.global_state['current_module_idx'] += 1\n\n            # loop to first module (or keep using last module on Switch)\n            if self.global_state['current_module_idx'] &gt; len(self.children) - 1:\n                if self.LOOP: self.global_state['current_module_idx'] = 0\n                else: self.global_state['current_module_idx'] = len(self.children) - 1\n\n            self.global_state['steps_to_next'] = steps[self.global_state['current_module_idx']]\n\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Alternate.LOOP","title":"LOOP  <code>class-attribute</code>","text":"<pre><code>LOOP = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.Averaging","title":"Averaging","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Average of past <code>history_size</code> updates.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>)           \u2013            <p>Number of past updates to average</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/averaging.py</code> <pre><code>class Averaging(TensorTransform):\n    \"\"\"Average of past ``history_size`` updates.\n\n    Args:\n        history_size (int): Number of past updates to average\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, history_size: int):\n        defaults = dict(history_size=history_size)\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\", \"average\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        history_size = setting['history_size']\n        if 'history' not in state:\n            state['history'] = deque(maxlen=history_size)\n            state['average'] = torch.zeros_like(tensor)\n\n        history = state['history']; average = state['average']\n        if len(history) == history_size: average -= history[0]\n        history.append(tensor)\n        average += tensor\n\n        return average / len(history)\n</code></pre>"},{"location":"API/all/#torchzero.modules.BBStab","title":"BBStab","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Stabilized Barzilai-Borwein method (https://arxiv.org/abs/1907.06409).</p> <p>This clips the norm of the Barzilai-Borwein update by <code>delta</code>, where <code>delta</code> can be adaptive if <code>c</code> is specified.</p> <p>Parameters:</p> <ul> <li> <code>c</code>               (<code>float</code>, default:                   <code>0.2</code> )           \u2013            <p>adaptive delta parameter. If <code>delta</code> is set to None, first <code>inf_iters</code> updates are performed with non-stabilized Barzilai-Borwein step size. Then delta is set to norm of the update that had the smallest norm, and multiplied by <code>c</code>. Defaults to 0.2.</p> </li> <li> <code>delta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Barzilai-Borwein update is clipped to this value. Set to <code>None</code> to use an adaptive choice. Defaults to None.</p> </li> <li> <code>type</code>               (<code>str</code>, default:                   <code>'geom'</code> )           \u2013            <p>one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long. Defaults to \"geom\". Note that \"long\" corresponds to BB1stab and \"short\" to BB2stab, however I found that \"geom\" works really well.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>step size will be applied to outputs of this module. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class BBStab(TensorTransform):\n    \"\"\"Stabilized Barzilai-Borwein method (https://arxiv.org/abs/1907.06409).\n\n    This clips the norm of the Barzilai-Borwein update by ``delta``, where ``delta`` can be adaptive if ``c`` is specified.\n\n    Args:\n        c (float, optional):\n            adaptive delta parameter. If ``delta`` is set to None, first ``inf_iters`` updates are performed\n            with non-stabilized Barzilai-Borwein step size. Then delta is set to norm of\n            the update that had the smallest norm, and multiplied by ``c``. Defaults to 0.2.\n        delta (float | None, optional):\n            Barzilai-Borwein update is clipped to this value. Set to ``None`` to use an adaptive choice. Defaults to None.\n        type (str, optional):\n            one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long.\n            Defaults to \"geom\". Note that \"long\" corresponds to BB1stab and \"short\" to BB2stab,\n            however I found that \"geom\" works really well.\n        inner (Chainable | None, optional):\n            step size will be applied to outputs of this module. Defaults to None.\n\n    \"\"\"\n    def __init__(\n        self,\n        c=0.2,\n        delta:float | None = None,\n        type: Literal[\"long\", \"short\", \"geom\", \"geom-fallback\"] = \"geom\",\n        alpha_0: float = 1e-7,\n        use_grad=True,\n        inf_iters: int = 3,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(type=type,alpha_0=alpha_0, c=c, delta=delta, inf_iters=inf_iters)\n        super().__init__(defaults, uses_grad=use_grad, inner=inner)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_g')\n        self.global_state['reset'] = True\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        prev_p, prev_g = unpack_states(states, tensors, 'prev_p', 'prev_g', cls=TensorList)\n        type = self.defaults['type']\n        c = self.defaults['c']\n        delta = self.defaults['delta']\n        inf_iters = self.defaults['inf_iters']\n\n        g = grads if self._uses_grad else tensors\n        assert g is not None\n        g = TensorList(g)\n\n        reset = self.global_state.get('reset', False)\n        self.global_state.pop('reset', None)\n\n        if step != 0 and not reset:\n            s = params-prev_p\n            y = g-prev_g\n            sy = s.dot(y)\n            eps = torch.finfo(sy.dtype).tiny\n\n            if type == 'short': alpha = _bb_short(s, y, sy, eps)\n            elif type == 'long': alpha = _bb_long(s, y, sy, eps)\n            elif type == 'geom': alpha = _bb_geom(s, y, sy, eps, fallback=False)\n            elif type == 'geom-fallback': alpha = _bb_geom(s, y, sy, eps, fallback=True)\n            else: raise ValueError(type)\n\n            if alpha is not None:\n\n                # adaptive delta\n                if delta is None:\n                    niters = self.global_state.get('niters', 0) # this accounts for skipped negative curvature steps\n                    self.global_state['niters'] = niters + 1\n\n\n                    if niters == 0: pass # 1st iteration is scaled GD step, shouldn't be used to find s_norm_min\n                    elif niters &lt;= inf_iters:\n                        s_norm_min = self.global_state.get('s_norm_min', None)\n                        if s_norm_min is None: s_norm_min = s.global_vector_norm()\n                        else: s_norm_min = min(s_norm_min, s.global_vector_norm())\n                        self.global_state['s_norm_min'] = s_norm_min\n                        # first few steps use delta=inf, so delta remains None\n\n                    else:\n                        delta = c * self.global_state['s_norm_min']\n\n                if delta is None: # delta is inf for first few steps\n                    self.global_state['alpha'] = alpha\n\n                # BBStab step size\n                else:\n                    a_stab = delta / g.global_vector_norm()\n                    self.global_state['alpha'] = min(alpha, a_stab)\n\n        prev_p.copy_(params)\n        prev_g.copy_(g)\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            alpha = epsilon_step_size(TensorList(tensors), settings[0]['alpha_0'])\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.BFGS","title":"BFGS","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno Quasi-Newton method. This is usually the most stable quasi-newton method.</p> Note <p>a line search or a trust region is recommended</p> Warning <p>this uses at least O(N^2) memory.</p> <p>Parameters:</p> <ul> <li> <code>init_scale</code>               (<code>float | Literal['auto']</code>, default:                   <code>'auto'</code> )           \u2013            <p>initial hessian matrix is set to identity times this.</p> <p>\"auto\" corresponds to a heuristic from Nocedal. Stephen J. Wright. Numerical Optimization p.142-143.</p> <p>Defaults to \"auto\".</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-32</code> )           \u2013            <p>tolerance on curvature condition. Defaults to 1e-32.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips update if maximum difference between current and previous gradients is less than this, to avoid instability. Defaults to 1e-32.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.</p> </li> <li> <code>restart_interval</code>               (<code>int | None | Literal['auto']</code>, default:                   <code>None</code> )           \u2013            <p>interval between resetting the hessian approximation.</p> <p>\"auto\" corresponds to number of decision variables + 1.</p> <p>None - no resets.</p> <p>Defaults to None.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>momentum on H or B. Defaults to None.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating H or B. Defaults to 1.</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to downscale first step before hessian approximation becomes available. Defaults to True.</p> </li> <li> <code>scale_second</code>               (<code>bool</code>)           \u2013            <p>whether to downscale second step. Defaults to False.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If true, all parameters are treated as a single vector. If False, the update rule is applied to each parameter separately. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to the output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.BFGS--examples","title":"Examples:","text":"<p>BFGS with backtracking line search:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.BFGS(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>BFGS with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.BFGS(inverse=False)),\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class BFGS(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno Quasi-Newton method. This is usually the most stable quasi-newton method.\n\n    Note:\n        a line search or a trust region is recommended\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Args:\n        init_scale (float | Literal[\"auto\"], optional):\n            initial hessian matrix is set to identity times this.\n\n            \"auto\" corresponds to a heuristic from Nocedal. Stephen J. Wright. Numerical Optimization p.142-143.\n\n            Defaults to \"auto\".\n        tol (float, optional):\n            tolerance on curvature condition. Defaults to 1e-32.\n        ptol (float | None, optional):\n            skips update if maximum difference between current and previous gradients is less than this, to avoid instability.\n            Defaults to 1e-32.\n        ptol_restart (bool, optional): whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.\n        restart_interval (int | None | Literal[\"auto\"], optional):\n            interval between resetting the hessian approximation.\n\n            \"auto\" corresponds to number of decision variables + 1.\n\n            None - no resets.\n\n            Defaults to None.\n        beta (float | None, optional): momentum on H or B. Defaults to None.\n        update_freq (int, optional): frequency of updating H or B. Defaults to 1.\n        scale_first (bool, optional):\n            whether to downscale first step before hessian approximation becomes available. Defaults to True.\n        scale_second (bool, optional): whether to downscale second step. Defaults to False.\n        concat_params (bool, optional):\n            If true, all parameters are treated as a single vector.\n            If False, the update rule is applied to each parameter separately. Defaults to True.\n        inner (Chainable | None, optional): preconditioning is applied to the output of this module. Defaults to None.\n\n    ## Examples:\n\n    BFGS with backtracking line search:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.BFGS(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    BFGS with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.BFGS(inverse=False)),\n    )\n    ```\n    \"\"\"\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return bfgs_H_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return bfgs_B_(B=B, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.BacktrackOnSignChange","title":"BacktrackOnSignChange","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Negates or undoes update for parameters where where gradient or update sign changes.</p> <p>This is part of RProp update rule.</p> <p>Parameters:</p> <ul> <li> <code>use_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, tracks sign change of the gradient, otherwise track sign change of the update. Defaults to True.</p> </li> <li> <code>backtrack</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, undoes the update when sign changes, otherwise negates it. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class BacktrackOnSignChange(TensorTransform):\n    \"\"\"Negates or undoes update for parameters where where gradient or update sign changes.\n\n    This is part of RProp update rule.\n\n    Args:\n        use_grad (bool, optional):\n            if True, tracks sign change of the gradient,\n            otherwise track sign change of the update. Defaults to True.\n        backtrack (bool, optional):\n            if True, undoes the update when sign changes, otherwise negates it.\n            Defaults to True.\n\n    \"\"\"\n    def __init__(self, use_grad = False, backtrack = True):\n        defaults = dict(use_grad=use_grad, backtrack=backtrack)\n        super().__init__(defaults, uses_grad=use_grad)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        tensors = TensorList(tensors)\n        backtrack = settings[0]['backtrack']\n\n        if self._uses_grad:\n            assert grads is not None\n            cur = TensorList(grads)\n        else: cur = tensors\n\n        tensors = backtrack_on_sign_change_(\n            tensors_ = tensors,\n            cur = cur,\n            prev_ = unpack_states(states, tensors, 'prev', cls=TensorList),\n            backtrack = backtrack,\n            step = step,\n        )\n\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.Backtracking","title":"Backtracking","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Backtracking line search.</p> <p>Parameters:</p> <ul> <li> <code>init</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial step size. Defaults to 1.0.</p> </li> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplies each consecutive step size by this value. Defaults to 0.5.</p> </li> <li> <code>c</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>sufficient decrease condition. Defaults to 1e-4.</p> </li> <li> <code>condition</code>               (<code>Literal</code>, default:                   <code>'armijo'</code> )           \u2013            <p>termination condition, only ones that do not use gradient at f(x+a*d) can be specified. - \"armijo\" - sufficient decrease condition. - \"decrease\" - any decrease in objective function value satisfies the condition.</p> <p>\"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage. Defaults to 'armijo'.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of function evaluations per step. Defaults to 10.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>when enabled, if line search failed, step size will continue decreasing on the next step. Otherwise it will restart the line search from <code>init</code> step size. Defaults to True.</p> </li> </ul> <p>Examples: Gradient descent with backtracking line search:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>L-BFGS with backtracking line search: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(),\n    tz.m.Backtracking()\n)\n</code></pre></p> Source code in <code>torchzero/modules/line_search/backtracking.py</code> <pre><code>class Backtracking(LineSearchBase):\n    \"\"\"Backtracking line search.\n\n    Args:\n        init (float, optional): initial step size. Defaults to 1.0.\n        beta (float, optional): multiplies each consecutive step size by this value. Defaults to 0.5.\n        c (float, optional): sufficient decrease condition. Defaults to 1e-4.\n        condition (TerminationCondition, optional):\n            termination condition, only ones that do not use gradient at f(x+a*d) can be specified.\n            - \"armijo\" - sufficient decrease condition.\n            - \"decrease\" - any decrease in objective function value satisfies the condition.\n\n            \"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage.\n            Defaults to 'armijo'.\n        maxiter (int, optional): maximum number of function evaluations per step. Defaults to 10.\n        adaptive (bool, optional):\n            when enabled, if line search failed, step size will continue decreasing on the next step.\n            Otherwise it will restart the line search from ``init`` step size. Defaults to True.\n\n    Examples:\n    Gradient descent with backtracking line search:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    L-BFGS with backtracking line search:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        init: float = 1.0,\n        beta: float = 0.5,\n        c: float = 1e-4,\n        condition: TerminationCondition = 'armijo',\n        maxiter: int = 10,\n        adaptive=True,\n    ):\n        defaults=dict(init=init,beta=beta,c=c,condition=condition,maxiter=maxiter,adaptive=adaptive)\n        super().__init__(defaults=defaults)\n\n    def reset(self):\n        super().reset()\n\n    @torch.no_grad\n    def search(self, update, var):\n        init, beta, c, condition, maxiter, adaptive = itemgetter(\n            'init', 'beta', 'c', 'condition', 'maxiter', 'adaptive')(self.defaults)\n\n        objective = self.make_objective(var=var)\n\n        # # directional derivative\n        if c == 0: d = 0\n        else: d = -sum(t.sum() for t in torch._foreach_mul(var.get_grads(), var.get_updates()))\n\n        # scale init\n        init_scale = self.global_state.get('init_scale', 1)\n        if adaptive: init = init * init_scale\n\n        step_size = backtracking_line_search(objective, d, init=init, beta=beta,c=c, condition=condition, maxiter=maxiter)\n\n        # found an alpha that reduces loss\n        if step_size is not None:\n            #self.global_state['beta_scale'] = min(1.0, self.global_state['beta_scale'] * math.sqrt(1.5))\n            self.global_state['init_scale'] = 1\n            return step_size\n\n        # on fail set init_scale to continue decreasing the step size\n        # or set to large step size when it becomes too small\n        if adaptive:\n            finfo = torch.finfo(var.params[0].dtype)\n            if init_scale &lt;= finfo.tiny * 2:\n                self.global_state[\"init_scale\"] = init * 2\n            else:\n                self.global_state['init_scale'] = init_scale * beta**maxiter\n        return 0\n</code></pre>"},{"location":"API/all/#torchzero.modules.BarzilaiBorwein","title":"BarzilaiBorwein","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Barzilai-Borwein step size method.</p> <p>Parameters:</p> <ul> <li> <code>type</code>               (<code>str</code>, default:                   <code>'geom'</code> )           \u2013            <p>one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long. Defaults to \"geom\".</p> </li> <li> <code>fallback</code>               (<code>float</code>)           \u2013            <p>step size when denominator is less than 0 (will happen on negative curvature). Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>step size will be applied to outputs of this module. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class BarzilaiBorwein(TensorTransform):\n    \"\"\"Barzilai-Borwein step size method.\n\n    Args:\n        type (str, optional):\n            one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long.\n            Defaults to \"geom\".\n        fallback (float, optional): step size when denominator is less than 0 (will happen on negative curvature). Defaults to 1e-3.\n        inner (Chainable | None, optional):\n            step size will be applied to outputs of this module. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        type: Literal[\"long\", \"short\", \"geom\", \"geom-fallback\"] = \"geom\",\n        alpha_0: float = 1e-7,\n        use_grad=True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(type=type, alpha_0=alpha_0)\n        super().__init__(defaults, uses_grad=use_grad, inner=inner)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_g')\n        self.global_state['reset'] = True\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        prev_p, prev_g = unpack_states(states, tensors, 'prev_p', 'prev_g', cls=TensorList)\n        type = self.defaults['type']\n\n        g = grads if self._uses_grad else tensors\n        assert g is not None\n\n        reset = self.global_state.get('reset', False)\n        self.global_state.pop('reset', None)\n\n        if step != 0 and not reset:\n            s = params-prev_p\n            y = g-prev_g\n            sy = s.dot(y)\n            eps = torch.finfo(sy.dtype).tiny * 2\n\n            if type == 'short': alpha = _bb_short(s, y, sy, eps)\n            elif type == 'long': alpha = _bb_long(s, y, sy, eps)\n            elif type == 'geom': alpha = _bb_geom(s, y, sy, eps, fallback=False)\n            elif type == 'geom-fallback': alpha = _bb_geom(s, y, sy, eps, fallback=True)\n            else: raise ValueError(type)\n\n            # if alpha is not None:\n            self.global_state['alpha'] = alpha\n\n        prev_p.copy_(params)\n        prev_g.copy_(g)\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            alpha = epsilon_step_size(TensorList(tensors), settings[0]['alpha_0'])\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.BinaryOperationBase","title":"BinaryOperationBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for operations that use update as the first operand. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> <p>Methods:</p> <ul> <li> <code>transform</code>             \u2013              <p>applies the operation to operands</p> </li> </ul> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class BinaryOperationBase(Module, ABC):\n    \"\"\"Base class for operations that use update as the first operand. This is an abstract class, subclass it and override `transform` method to use it.\"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, **operands: Chainable | Any):\n        super().__init__(defaults=defaults)\n\n        self.operands = {}\n        for k,v in operands.items():\n\n            if isinstance(v, (Module, Sequence)):\n                self.set_child(k, v)\n                self.operands[k] = self.children[k]\n            else:\n                self.operands[k] = v\n\n    @abstractmethod\n    def transform(self, objective: Objective, update: list[torch.Tensor], **operands: Any | list[torch.Tensor]) -&gt; Iterable[torch.Tensor]:\n        \"\"\"applies the operation to operands\"\"\"\n        raise NotImplementedError\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective: Objective) -&gt; Objective:\n        # pass cloned update to all module operands\n        processed_operands: dict[str, Any | list[torch.Tensor]] = self.operands.copy()\n\n        for k,v in self.operands.items():\n            if k in self.children:\n                v: Module\n                updated_obj = v.step(objective.clone(clone_updates=True))\n                processed_operands[k] = updated_obj.get_updates()\n                objective.update_attrs_from_clone_(updated_obj) # update loss, grad, etc if this module calculated them\n\n        transformed = self.transform(objective, update=objective.get_updates(), **processed_operands)\n        objective.updates = list(transformed)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.BinaryOperationBase.transform","title":"transform","text":"<pre><code>transform(objective: Objective, update: list[Tensor], **operands: Any | list[Tensor]) -&gt; Iterable[Tensor]\n</code></pre> <p>applies the operation to operands</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>@abstractmethod\ndef transform(self, objective: Objective, update: list[torch.Tensor], **operands: Any | list[torch.Tensor]) -&gt; Iterable[torch.Tensor]:\n    \"\"\"applies the operation to operands\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"API/all/#torchzero.modules.BirginMartinezRestart","title":"BirginMartinezRestart","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>the restart criterion for conjugate gradient methods designed by Birgin and Martinez.</p> <p>This criterion restarts when when the angle between dk+1 and \u2212gk+1 is not acute enough.</p> <p>The restart clears all states of <code>module</code>.</p> <p>Parameters:</p> <ul> <li> <code>module</code>               (<code>Module</code>)           \u2013            <p>module to restart, should be a conjugate gradient or possibly a quasi-newton method.</p> </li> <li> <code>cond</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>Restart is performed whenevr d^Tg &gt; -cond||d||||g||. The default condition value of 1e-3 is suggested by Birgin and Martinez.</p> </li> </ul> Reference <p>Birgin, Ernesto G., and Jos\u00e9 Mario Mart\u00ednez. \"A spectral conjugate gradient method for unconstrained optimization.\" Applied Mathematics &amp; Optimization 43.2 (2001): 117-128.</p> Source code in <code>torchzero/modules/restarts/restars.py</code> <pre><code>class BirginMartinezRestart(Module):\n    \"\"\"the restart criterion for conjugate gradient methods designed by Birgin and Martinez.\n\n    This criterion restarts when when the angle between dk+1 and \u2212gk+1 is not acute enough.\n\n    The restart clears all states of ``module``.\n\n    Args:\n        module (Module):\n            module to restart, should be a conjugate gradient or possibly a quasi-newton method.\n        cond (float, optional):\n            Restart is performed whenevr d^Tg &gt; -cond*||d||*||g||.\n            The default condition value of 1e-3 is suggested by Birgin and Martinez.\n\n    Reference:\n        Birgin, Ernesto G., and Jos\u00e9 Mario Mart\u00ednez. \"A spectral conjugate gradient method for unconstrained optimization.\" Applied Mathematics &amp; Optimization 43.2 (2001): 117-128.\n    \"\"\"\n    def __init__(self, module: Module, cond:float = 1e-3):\n        defaults=dict(cond=cond)\n        super().__init__(defaults)\n\n        self.set_child(\"module\", module)\n\n    def update(self, objective):\n        module = self.children['module']\n        module.update(objective)\n\n    def apply(self, objective):\n        module = self.children['module']\n        objective = module.apply(objective.clone(clone_updates=False))\n\n        cond = self.defaults['cond']\n        g = TensorList(objective.get_grads())\n        d = TensorList(objective.get_updates())\n        d_g = d.dot(g)\n        d_norm = d.global_vector_norm()\n        g_norm = g.global_vector_norm()\n\n        # d in our case is same direction as g so it has a minus sign\n        if -d_g &gt; -cond * d_norm * g_norm:\n            module.reset()\n            objective.updates = g.clone()\n            return objective\n\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.BoldDriver","title":"BoldDriver","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies step size by <code>nplus</code> if loss decreased compared to last iteration, otherwise multiplies by <code>nminus</code>.</p> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class BoldDriver(TensorTransform):\n    \"\"\"Multiplies step size by ``nplus`` if loss decreased compared to last iteration, otherwise multiplies by ``nminus``.\"\"\"\n    def __init__(self, a_init=1e-3, nplus=1.1, nminus=0.1, inner: Chainable | None = None):\n        defaults = dict(a_init=a_init, nplus=nplus, nminus=nminus)\n        super().__init__(defaults, uses_loss=True, inner=inner)\n        self.global_state[\"alpha\"] = a_init\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('f_prev')\n\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        fs = settings[0]\n        if \"f_prev\" not in self.global_state:\n            self.global_state[\"f_prev\"] = tofloat(loss)\n            return\n\n        if self.global_state[\"f_prev\"] &lt;= loss:\n            self.global_state[\"alpha\"] *= fs[\"nminus\"]\n\n        else:\n            self.global_state[\"alpha\"] *= fs[\"nplus\"]\n\n        self.global_state[\"f_prev\"] = tofloat(loss)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            self.state.clear()\n            self.global_state.clear()\n            self.global_state[\"alpha\"] = settings[0][\"a_init\"]\n            alpha = epsilon_step_size(TensorList(tensors), 1e-7)\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n</code></pre>"},{"location":"API/all/#torchzero.modules.BroydenBad","title":"BroydenBad","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Broyden's \"bad\" Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class BroydenBad(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Broyden's \"bad\" Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_bad_H_(H=H, s=s, y=y)\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_bad_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.BroydenGood","title":"BroydenGood","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Broyden's \"good\" Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class BroydenGood(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Broyden's \"good\" Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_good_H_(H=H, s=s, y=y)\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_good_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.CD","title":"CD","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Coordinate descent. Proposes a descent direction along a single coordinate. A line search such as <code>tz.m.ScipyMinimizeScalar(maxiter=8)</code> or a fixed step size can be used after this.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, scales direction by gradient estimate. If False, the scale is fixed to 1. Defaults to True.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to adapt finite difference step size, this requires an additional buffer. Defaults to True.</p> </li> <li> <code>index</code>               (<code>str</code>, default:                   <code>'cyclic2'</code> )           \u2013            <p>index selection strategy. - \"cyclic\" - repeatedly cycles through each coordinate, e.g. <code>1,2,3,1,2,3,...</code>. - \"cyclic2\" - cycles forward and then backward, e.g <code>1,2,3,3,2,1,1,2,3,...</code> (default). - \"random\" - picks coordinate randomly.</p> </li> <li> <code>threepoint</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use three points (three function evaluatins) to determine descent direction. if False, uses two points, but then <code>adaptive</code> can't be used. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/zeroth_order/cd.py</code> <pre><code>class CD(Module):\n    \"\"\"Coordinate descent. Proposes a descent direction along a single coordinate.\n    A line search such as ``tz.m.ScipyMinimizeScalar(maxiter=8)`` or a fixed step size can be used after this.\n\n    Args:\n        h (float, optional): finite difference step size. Defaults to 1e-3.\n        grad (bool, optional):\n            if True, scales direction by gradient estimate. If False, the scale is fixed to 1. Defaults to True.\n        adaptive (bool, optional):\n            whether to adapt finite difference step size, this requires an additional buffer. Defaults to True.\n        index (str, optional):\n            index selection strategy.\n            - \"cyclic\" - repeatedly cycles through each coordinate, e.g. ``1,2,3,1,2,3,...``.\n            - \"cyclic2\" - cycles forward and then backward, e.g ``1,2,3,3,2,1,1,2,3,...`` (default).\n            - \"random\" - picks coordinate randomly.\n        threepoint (bool, optional):\n            whether to use three points (three function evaluatins) to determine descent direction.\n            if False, uses two points, but then ``adaptive`` can't be used. Defaults to True.\n    \"\"\"\n    def __init__(self, h:float=1e-3, grad:bool=False, adaptive:bool=True, index:Literal['cyclic', 'cyclic2', 'random']=\"cyclic2\", threepoint:bool=True,):\n        defaults = dict(h=h, grad=grad, adaptive=adaptive, index=index, threepoint=threepoint)\n        super().__init__(defaults)\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective):\n        closure = objective.closure\n        if closure is None:\n            raise RuntimeError(\"CD requires closure\")\n\n        params = TensorList(objective.params)\n        ndim = params.global_numel()\n\n        grad_step_size = self.defaults['grad']\n        adaptive = self.defaults['adaptive']\n        index_strategy = self.defaults['index']\n        h = self.defaults['h']\n        threepoint = self.defaults['threepoint']\n\n        # ------------------------------ determine index ----------------------------- #\n        if index_strategy == 'cyclic':\n            idx = self.global_state.get('idx', 0) % ndim\n            self.global_state['idx'] = idx + 1\n\n        elif index_strategy == 'cyclic2':\n            idx = self.global_state.get('idx', 0)\n            self.global_state['idx'] = idx + 1\n            if idx &gt;= ndim * 2:\n                idx = self.global_state['idx'] = 0\n            if idx &gt;= ndim:\n                idx  = (2*ndim - idx) - 1\n\n        elif index_strategy == 'random':\n            if 'generator' not in self.global_state:\n                self.global_state['generator'] = random.Random(0)\n            generator = self.global_state['generator']\n            idx = generator.randrange(0, ndim)\n\n        else:\n            raise ValueError(index_strategy)\n\n        # -------------------------- find descent direction -------------------------- #\n        h_vec = None\n        if adaptive:\n            if threepoint:\n                h_vec = self.get_state(params, 'h_vec', init=lambda x: torch.full_like(x, h), cls=TensorList)\n                h = float(h_vec.flat_get(idx))\n            else:\n                warnings.warn(\"CD adaptive=True only works with threepoint=True\")\n\n        f_0 = objective.get_loss(False)\n        params.flat_set_lambda_(idx, lambda x: x + h)\n        f_p = closure(False)\n\n        # -------------------------------- threepoint -------------------------------- #\n        if threepoint:\n            params.flat_set_lambda_(idx, lambda x: x - 2*h)\n            f_n = closure(False)\n            params.flat_set_lambda_(idx, lambda x: x + h)\n\n            if adaptive:\n                assert h_vec is not None\n                if f_0 &lt;= f_p and f_0 &lt;= f_n:\n                    h_vec.flat_set_lambda_(idx, lambda x: max(x/2, 1e-10))\n                else:\n                    if abs(f_0 - f_n) &lt; 1e-12 or abs((f_p - f_0) / (f_0 - f_n) - 1) &lt; 1e-2:\n                        h_vec.flat_set_lambda_(idx, lambda x: min(x*2, 1e10))\n\n            if grad_step_size:\n                alpha = (f_p - f_n) / (2*h)\n\n            else:\n                if f_0 &lt; f_p and f_0 &lt; f_n: alpha = 0\n                elif f_p &lt; f_n: alpha = -1\n                else: alpha = 1\n\n        # --------------------------------- twopoint --------------------------------- #\n        else:\n            params.flat_set_lambda_(idx, lambda x: x - h)\n            if grad_step_size:\n                alpha = (f_p - f_0) / h\n            else:\n                if f_p &lt; f_0: alpha = -1\n                else: alpha = 1\n\n        # ----------------------------- create the update ---------------------------- #\n        update = params.zeros_like()\n        update.flat_set_(idx, alpha)\n        objective.updates = update\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Cautious","title":"Cautious","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Negates update for parameters where update and gradient sign is inconsistent. Optionally normalizes the update by the number of parameters that are not masked. This is meant to be used after any momentum-based modules.</p> <p>Parameters:</p> <ul> <li> <code>normalize</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>renormalize update after masking. only has effect when mode is 'zero'. Defaults to False.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for normalization. Defaults to 1e-6.</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'zero'</code> )           \u2013            <p>what to do with updates with inconsistent signs. - \"zero\" - set them to zero (as in paper) - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign) - \"backtrack\" - negate them</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Cautious--examples","title":"Examples:","text":"<p>Cautious Adam</p> <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.Adam(),\n    tz.m.Cautious(),\n    tz.m.LR(1e-2)\n)\n</code></pre> References <p>Cautious Optimizers: Improving Training with One Line of Code. Kaizhao Liang, Lizhang Chen, Bo Liu, Qiang Liu</p> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class Cautious(TensorTransform):\n    \"\"\"Negates update for parameters where update and gradient sign is inconsistent.\n    Optionally normalizes the update by the number of parameters that are not masked.\n    This is meant to be used after any momentum-based modules.\n\n    Args:\n        normalize (bool, optional):\n            renormalize update after masking.\n            only has effect when mode is 'zero'. Defaults to False.\n        eps (float, optional): epsilon for normalization. Defaults to 1e-6.\n        mode (str, optional):\n            what to do with updates with inconsistent signs.\n            - \"zero\" - set them to zero (as in paper)\n            - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign)\n            - \"backtrack\" - negate them\n\n    ## Examples:\n\n    Cautious Adam\n\n    ```python\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.Adam(),\n        tz.m.Cautious(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    References:\n        Cautious Optimizers: Improving Training with One Line of Code. Kaizhao Liang, Lizhang Chen, Bo Liu, Qiang Liu\n    \"\"\"\n\n    def __init__(\n        self,\n        normalize=False,\n        eps=1e-6,\n        mode: Literal[\"zero\", \"grad\", \"backtrack\"] = \"zero\",\n    ):\n        defaults = dict(normalize=normalize, eps=eps, mode=mode)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        mode, normalize, eps = itemgetter('mode', 'normalize', 'eps')(settings[0])\n        return cautious_(TensorList(tensors), TensorList(grads), normalize=normalize, eps=eps, mode=mode)\n</code></pre>"},{"location":"API/all/#torchzero.modules.CautiousWeightDecay","title":"CautiousWeightDecay","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Cautious weight decay (https://arxiv.org/pdf/2510.12402).</p> <p>Weight decay but only applied to updates where update sign matches weight decay sign.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>)           \u2013            <p>weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.CautiousWeightDecay--examples","title":"Examples:","text":"<p>Adam with non-decoupled cautious weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.CautiousWeightDecay(1e-3),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with decoupled cautious weight decay that still scales with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.CautiousWeightDecay(1e-3),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with fully decoupled cautious weight decay that doesn't scale with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.LR(1e-3),\n    tz.m.CautiousWeightDecay(1e-6)\n)\n</code></pre></p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class CautiousWeightDecay(TensorTransform):\n    \"\"\"Cautious weight decay (https://arxiv.org/pdf/2510.12402).\n\n    Weight decay but only applied to updates where update sign matches weight decay sign.\n\n    Args:\n        weight_decay (float): weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n        target (Target, optional): what to set on var. Defaults to 'update'.\n\n    ### Examples:\n\n    Adam with non-decoupled cautious weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.CautiousWeightDecay(1e-3),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with decoupled cautious weight decay that still scales with learning rate\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.CautiousWeightDecay(1e-3),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with fully decoupled cautious weight decay that doesn't scale with learning rate\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.LR(1e-3),\n        tz.m.CautiousWeightDecay(1e-6)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, weight_decay: float, ord: int = 2):\n\n        defaults = dict(weight_decay=weight_decay, ord=ord)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        weight_decay = NumberList(s['weight_decay'] for s in settings)\n        ord = settings[0]['ord']\n\n        return cautious_weight_decay_(as_tensorlist(tensors), as_tensorlist(params), weight_decay, ord)\n</code></pre>"},{"location":"API/all/#torchzero.modules.CenteredEMASquared","title":"CenteredEMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains a centered exponential moving average of squared updates. This also maintains an additional exponential moving average of un-squared updates, square of which is subtracted from the EMA.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class CenteredEMASquared(TensorTransform):\n    \"\"\"Maintains a centered exponential moving average of squared updates. This also maintains an additional\n    exponential moving average of un-squared updates, square of which is subtracted from the EMA.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    def __init__(self, beta: float = 0.99, amsgrad=False, pow:float=2):\n        defaults = dict(beta=beta, amsgrad=amsgrad, pow=pow)\n        super().__init__(defaults, uses_grad=False)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        amsgrad, pow = itemgetter('amsgrad', 'pow')(settings[0])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg, exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return centered_ema_sq_(\n            TensorList(tensors),\n            exp_avg_=exp_avg,\n            exp_avg_sq_=exp_avg_sq,\n            beta=beta,\n            max_exp_avg_sq_=max_exp_avg_sq,\n            pow=pow,\n        ).clone()\n</code></pre>"},{"location":"API/all/#torchzero.modules.CenteredSqrtEMASquared","title":"CenteredSqrtEMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains a centered exponential moving average of squared updates, outputs optionally debiased square root. This also maintains an additional exponential moving average of un-squared updates, square of which is subtracted from the EMA.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>debiased</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to multiply the output by a debiasing term from the Adam method. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class CenteredSqrtEMASquared(TensorTransform):\n    \"\"\"Maintains a centered exponential moving average of squared updates, outputs optionally debiased square root.\n    This also maintains an additional exponential moving average of un-squared updates, square of which is subtracted from the EMA.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        debiased (bool, optional): whether to multiply the output by a debiasing term from the Adam method. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    def __init__(self, beta: float = 0.99, amsgrad=False, debiased: bool = False, pow:float=2):\n        defaults = dict(beta=beta, amsgrad=amsgrad, debiased=debiased, pow=pow)\n        super().__init__(defaults, uses_grad=False)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        amsgrad, pow, debiased = itemgetter('amsgrad', 'pow', 'debiased')(settings[0])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg, exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return sqrt_centered_ema_sq_(\n            TensorList(tensors),\n            exp_avg_=exp_avg,\n            exp_avg_sq_=exp_avg_sq,\n            beta=beta,\n            debiased=debiased,\n            step=step,\n            max_exp_avg_sq_=max_exp_avg_sq,\n            pow=pow,\n        )\n</code></pre>"},{"location":"API/all/#torchzero.modules.Centralize","title":"Centralize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Centralizes the update.</p> <p>Parameters:</p> <ul> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are centralized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to centralize by global mean of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are centralized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> </ul> <p>Examples:</p> <p>Standard gradient centralization: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Centralize(dim=0),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>References: - Yong, H., Huang, J., Hua, X., &amp; Zhang, L. (2020). Gradient centralization: A new optimization technique for deep neural networks. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part I 16 (pp. 635-652). Springer International Publishing. https://arxiv.org/abs/2004.01461</p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class Centralize(TensorTransform):\n    \"\"\"Centralizes the update.\n\n    Args:\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are centralized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to centralize by global mean of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are centralized.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n\n    Examples:\n\n    Standard gradient centralization:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Centralize(dim=0),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    References:\n    - Yong, H., Huang, J., Hua, X., &amp; Zhang, L. (2020). Gradient centralization: A new optimization technique for deep neural networks. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part I 16 (pp. 635-652). Springer International Publishing. https://arxiv.org/abs/2004.01461\n    \"\"\"\n    def __init__(\n        self,\n        dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n        inverse_dims: bool = False,\n        min_size: int = 2,\n    ):\n        defaults = dict(dim=dim,min_size=min_size,inverse_dims=inverse_dims)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        dim, min_size, inverse_dims = itemgetter('dim', 'min_size', 'inverse_dims')(settings[0])\n\n        _centralize_(tensors_ = TensorList(tensors), dim=dim, inverse_dims=inverse_dims, min_size=min_size)\n\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.Clip","title":"Clip","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>clip tensors to be in  <code>(min, max)</code> range. <code>min</code> and <code>`max</code>: can be None, numbers or modules.</p> <p>If <code>min</code> and <code>max</code>  are modules, this calculates <code>tensors.clip(min(tensors), max(tensors))</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Clip(BinaryOperationBase):\n    \"\"\"clip tensors to be in  ``(min, max)`` range. ``min`` and ``max`: can be None, numbers or modules.\n\n    If ``min`` and ``max``  are modules, this calculates ``tensors.clip(min(tensors), max(tensors))``.\n    \"\"\"\n    def __init__(self, min: float | Chainable | None = None, max: float | Chainable | None = None):\n        super().__init__({}, min=min, max=max)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], min: float | list[torch.Tensor] | None, max: float | list[torch.Tensor] | None):\n        return TensorList(update).clamp_(min=min,  max=max)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ClipModules","title":"ClipModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input(tensors).clip(min, max)</code>. <code>min</code> and <code>max</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class ClipModules(MultiOperationBase):\n    \"\"\"Calculates ``input(tensors).clip(min, max)``. ``min`` and ``max`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable, min: float | Chainable | None = None, max: float | Chainable | None = None):\n        defaults = {}\n        super().__init__(defaults, input=input, min=min, max=max)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: list[torch.Tensor], min: float | list[torch.Tensor], max: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        return TensorList(input).clamp_(min=min, max=max)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ClipNorm","title":"ClipNorm","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update norm to be no larger than <code>value</code>.</p> <p>Parameters:</p> <ul> <li> <code>max_norm</code>               (<code>float</code>)           \u2013            <p>value to clip norm to.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are normalized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal numer of elements in a parameter or slice to clip norm. Defaults to 1.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>what this affects.</p> </li> </ul> <p>Examples:</p> <p>Gradient norm clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ClipNorm(1),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Update norm clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.ClipNorm(1),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class ClipNorm(TensorTransform):\n    \"\"\"Clips update norm to be no larger than ``value``.\n\n    Args:\n        max_norm (float): value to clip norm to.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are normalized.\n        min_size (int, optional):\n            minimal numer of elements in a parameter or slice to clip norm. Defaults to 1.\n        target (str, optional):\n            what this affects.\n\n    Examples:\n\n    Gradient norm clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ClipNorm(1),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Update norm clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.ClipNorm(1),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        max_norm: float,\n        ord: Metrics = 2,\n        dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n        inverse_dims: bool = False,\n        min_size: int = 1,\n    ):\n        defaults = dict(max_norm=max_norm,ord=ord,dim=dim,min_size=min_size,inverse_dims=inverse_dims)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        max_norm = NumberList(s['max_norm'] for s in settings)\n        ord, dim, min_size, inverse_dims = itemgetter('ord', 'dim', 'min_size', 'inverse_dims')(settings[0])\n        _clip_norm_(\n            tensors_ = TensorList(tensors),\n            min = 0,\n            max = max_norm,\n            norm_value = None,\n            ord = ord,\n            dim = dim,\n            inverse_dims=inverse_dims,\n            min_size = min_size,\n        )\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.ClipNormByEMA","title":"ClipNormByEMA","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips norm to be no larger than the norm of an exponential moving average of past updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for the exponential moving average. Defaults to 0.99.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>order of the norm. Defaults to 2.</p> </li> <li> <code>eps</code>               (<code>float</code>)           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.</p> </li> <li> <code>max_ema_growth</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.</p> </li> <li> <code>ema_init</code>               (<code>str</code>)           \u2013            <p>How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/ema_clipping.py</code> <pre><code>class ClipNormByEMA(TensorTransform):\n    \"\"\"Clips norm to be no larger than the norm of an exponential moving average of past updates.\n\n    Args:\n        beta (float, optional): beta for the exponential moving average. Defaults to 0.99.\n        ord (float, optional): order of the norm. Defaults to 2.\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n        tensorwise (bool, optional):\n            if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.\n        max_ema_growth (float | None, optional):\n            if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.\n        ema_init (str, optional):\n            How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.\n    \"\"\"\n    NORMALIZE = False\n    def __init__(\n        self,\n        beta=0.99,\n        ord: Metrics = 2,\n        tensorwise:bool=True,\n        max_ema_growth: float | None = 1.5,\n        init: float = 0.0,\n        min_norm: float = 1e-6,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(beta=beta, ord=ord, tensorwise=tensorwise, init=init, min_norm=min_norm, max_ema_growth=max_ema_growth)\n        super().__init__(defaults, inner=inner)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        eps = torch.finfo(tensors[0].dtype).tiny * 2\n        ord, tensorwise, init, max_ema_growth = itemgetter('ord', 'tensorwise', 'init', 'max_ema_growth')(settings[0])\n\n        beta, min_norm = unpack_dicts(settings, 'beta', 'min_norm', cls=NumberList)\n\n        exp_avg = unpack_states(states, tensors, 'exp_avg', init = lambda x: torch.full_like(x, init), cls=TensorList)\n\n        exp_avg.lerp_(tensors, 1-beta)\n\n        # ----------------------------- tensorwise update ---------------------------- #\n        if tensorwise:\n            tensors_norm = tensors.norm(ord)\n            ema_norm = exp_avg.metric(ord)\n\n            # clip ema norm growth\n            if max_ema_growth is not None:\n                prev_ema_norm = unpack_states(states, tensors, 'prev_ema_norm', init=ema_norm, cls=TensorList)\n                allowed_norm = (prev_ema_norm * max_ema_growth).clip(min=min_norm)\n\n                ema_denom = (ema_norm / allowed_norm).clip(min=1)\n                exp_avg.div_(ema_denom)\n                ema_norm.div_(ema_denom)\n\n                prev_ema_norm.set_(ema_norm)\n\n\n        # ------------------------------- global update ------------------------------ #\n        else:\n            tensors_norm = tensors.global_metric(ord)\n            ema_norm = exp_avg.global_metric(ord)\n\n            # clip ema norm growth\n            if max_ema_growth is not None:\n                prev_ema_norm = self.global_state.setdefault('prev_ema_norm', ema_norm)\n                allowed_norm = (prev_ema_norm * max_ema_growth).clip(min=min_norm[0])\n\n                if ema_norm &gt; allowed_norm:\n                    exp_avg.div_(ema_norm / allowed_norm)\n                    ema_norm = allowed_norm\n\n                prev_ema_norm.set_(ema_norm)\n\n\n        # ------------------- compute denominator to clip/normalize ------------------ #\n        denom = tensors_norm / ema_norm.clip(min=eps)\n        if self.NORMALIZE: denom.clip_(min=eps)\n        else: denom.clip_(min=1)\n        self.global_state['denom'] = denom\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        denom = self.global_state.pop('denom')\n        torch._foreach_div_(tensors, denom)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.ClipNormByEMA.NORMALIZE","title":"NORMALIZE  <code>class-attribute</code>","text":"<pre><code>NORMALIZE = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.ClipNormGrowth","title":"ClipNormGrowth","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update norm growth.</p> <p>Parameters:</p> <ul> <li> <code>add</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>additive clipping, next update norm is at most <code>previous norm + add</code>. Defaults to None.</p> </li> <li> <code>mul</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>multiplicative clipping, next update norm is at most <code>previous norm * mul</code>. Defaults to 1.5.</p> </li> <li> <code>min_value</code>               (<code>float | None</code>, default:                   <code>0.0001</code> )           \u2013            <p>minimum value for multiplicative clipping to prevent collapse to 0. Next norm is at most :code:<code>max(prev_norm, min_value) * mul</code>. Defaults to 1e-4.</p> </li> <li> <code>max_decay</code>               (<code>float | None</code>, default:                   <code>2</code> )           \u2013            <p>bounds the tracked multiplicative clipping decay to prevent collapse to 0. Next norm is at most :code:<code>max(previous norm * mul, max_decay)</code>. Defaults to 2.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to \"update\".</p> </li> </ul> Source code in <code>torchzero/modules/clipping/growth_clipping.py</code> <pre><code>class ClipNormGrowth(TensorTransform):\n    \"\"\"Clips update norm growth.\n\n    Args:\n        add (float | None, optional): additive clipping, next update norm is at most `previous norm + add`. Defaults to None.\n        mul (float | None, optional):\n            multiplicative clipping, next update norm is at most `previous norm * mul`. Defaults to 1.5.\n        min_value (float | None, optional):\n            minimum value for multiplicative clipping to prevent collapse to 0.\n            Next norm is at most :code:`max(prev_norm, min_value) * mul`. Defaults to 1e-4.\n        max_decay (float | None, optional):\n            bounds the tracked multiplicative clipping decay to prevent collapse to 0.\n            Next norm is at most :code:`max(previous norm * mul, max_decay)`.\n            Defaults to 2.\n        ord (float, optional): norm order. Defaults to 2.\n        tensorwise (bool, optional):\n            if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.\n        target (Target, optional): what to set on var. Defaults to \"update\".\n    \"\"\"\n    def __init__(\n        self,\n        add: float | None = None,\n        mul: float | None = 1.5,\n        min_value: float | None = 1e-4,\n        max_decay: float | None = 2,\n        ord: float = 2,\n        tensorwise=True,\n    ):\n        defaults = dict(add=add, mul=mul, min_value=min_value, max_decay=max_decay, ord=ord, tensorwise=tensorwise)\n        super().__init__(defaults)\n\n\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensorwise = settings[0]['tensorwise']\n        tensors = TensorList(tensors)\n\n        if tensorwise:\n            ts = tensors\n            stts = states\n            stns = settings\n\n        else:\n            ts = [tensors.to_vec()]\n            stts = [self.global_state]\n            stns = [settings[0]]\n\n\n        for t, state, setting in zip(ts, stts, stns):\n            if 'prev_norm' not in state:\n                state['prev_norm'] = torch.linalg.vector_norm(t, ord=setting['ord']) # pylint:disable=not-callable\n                state['prev_denom'] = 1\n                continue\n\n            _,  state['prev_norm'], state['prev_denom'] = norm_growth_clip_(\n                tensor_ = t,\n                prev_norm = state['prev_norm'],\n                add = setting['add'],\n                mul = setting['mul'],\n                min_value = setting['min_value'],\n                max_decay = setting['max_decay'],\n                ord = setting['ord'],\n            )\n\n        if not tensorwise:\n            tensors.from_vec_(ts[0])\n\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.ClipValue","title":"ClipValue","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update magnitude to be within <code>(-value, value)</code> range.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>float</code>)           \u2013            <p>value to clip to.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>refer to <code>target argument</code> in documentation.</p> </li> </ul> <p>Examples:</p> <p>Gradient clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ClipValue(1),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Update clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.ClipValue(1),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class ClipValue(TensorTransform):\n    \"\"\"Clips update magnitude to be within ``(-value, value)`` range.\n\n    Args:\n        value (float): value to clip to.\n        target (str): refer to ``target argument`` in documentation.\n\n    Examples:\n\n    Gradient clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ClipValue(1),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Update clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.ClipValue(1),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, value: float):\n        defaults = dict(value=value)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        value = [s['value'] for s in settings]\n        return TensorList(tensors).clip_([-v for v in value], value)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ClipValueByEMA","title":"ClipValueByEMA","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips magnitude of update to be no larger than magnitude of exponential moving average of past (unclipped) updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for the exponential moving average. Defaults to 0.99.</p> </li> <li> <code>ema_init</code>               (<code>str</code>)           \u2013            <p>How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.</p> </li> <li> <code>exp_avg_tfm</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional modules applied to exponential moving average before clipping by it. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/ema_clipping.py</code> <pre><code>class ClipValueByEMA(TensorTransform):\n    \"\"\"Clips magnitude of update to be no larger than magnitude of exponential moving average of past (unclipped) updates.\n\n    Args:\n        beta (float, optional): beta for the exponential moving average. Defaults to 0.99.\n        ema_init (str, optional):\n            How to initialize exponential moving average on first step,\n            \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.\n        exp_avg_tfm (Chainable | None, optional):\n            optional modules applied to exponential moving average before clipping by it. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        beta=0.99,\n        init: float = 0,\n\n        inner: Chainable | None = None,\n        exp_avg_tfm:Chainable | None=None,\n    ):\n        defaults = dict(beta=beta, init=init)\n        super().__init__(defaults, inner=inner)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        state[\"exp_avg\"] = tensor.abs() * setting[\"init\"]\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        beta = unpack_dicts(settings, 'beta', cls=NumberList)\n\n        exp_avg = unpack_states(states, tensors, 'exp_avg', must_exist=True, cls=TensorList)\n        exp_avg.lerp_(tensors.abs(), 1-beta)\n\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        exp_avg = unpack_states(states, tensors, 'exp_avg')\n\n        exp_avg = TensorList(\n            self.inner_step_tensors(\"exp_avg\", exp_avg, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        tensors.clip_(-exp_avg, exp_avg)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.ClipValueGrowth","title":"ClipValueGrowth","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update value magnitude growth.</p> <p>Parameters:</p> <ul> <li> <code>add</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>additive clipping, next update is at most <code>previous update + add</code>. Defaults to None.</p> </li> <li> <code>mul</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>multiplicative clipping, next update is at most <code>previous update * mul</code>. Defaults to 1.5.</p> </li> <li> <code>min_value</code>               (<code>float | None</code>, default:                   <code>0.0001</code> )           \u2013            <p>minimum value for multiplicative clipping to prevent collapse to 0. Next update is at most :code:<code>max(prev_update, min_value) * mul</code>. Defaults to 1e-4.</p> </li> <li> <code>max_decay</code>               (<code>float | None</code>, default:                   <code>2</code> )           \u2013            <p>bounds the tracked multiplicative clipping decay to prevent collapse to 0. Next update is at most :code:<code>max(previous update * mul, max_decay)</code>. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to \"update\".</p> </li> </ul> Source code in <code>torchzero/modules/clipping/growth_clipping.py</code> <pre><code>class ClipValueGrowth(TensorTransform):\n    \"\"\"Clips update value magnitude growth.\n\n    Args:\n        add (float | None, optional): additive clipping, next update is at most `previous update + add`. Defaults to None.\n        mul (float | None, optional): multiplicative clipping, next update is at most `previous update * mul`. Defaults to 1.5.\n        min_value (float | None, optional):\n            minimum value for multiplicative clipping to prevent collapse to 0.\n            Next update is at most :code:`max(prev_update, min_value) * mul`. Defaults to 1e-4.\n        max_decay (float | None, optional):\n            bounds the tracked multiplicative clipping decay to prevent collapse to 0.\n            Next update is at most :code:`max(previous update * mul, max_decay)`.\n            Defaults to 2.\n        target (Target, optional): what to set on var. Defaults to \"update\".\n    \"\"\"\n    def __init__(\n        self,\n        add: float | None = None,\n        mul: float | None = 1.5,\n        min_value: float | None = 1e-4,\n        max_decay: float | None = 2,\n    ):\n        defaults = dict(add=add, mul=mul, min_value=min_value, max_decay=max_decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"prev\")\n\n\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        add, mul, min_value, max_decay = itemgetter('add','mul','min_value','max_decay')(setting)\n        add: float | None\n\n        if add is None and mul is None:\n            return tensor\n\n        if 'prev' not in state:\n            state['prev'] = tensor.clone()\n            return tensor\n\n        prev: torch.Tensor = state['prev']\n\n        # additive bound\n        if add is not None:\n            growth = (tensor.abs() - prev.abs()).clip(min=0)\n            tensor.sub_(torch.where(growth &gt; add, (growth-add).copysign_(tensor), 0))\n\n        # multiplicative bound\n        growth = None\n        if mul is not None:\n            prev_magn = prev.abs()\n            if min_value is not None: prev_magn.clip_(min=min_value)\n            growth = (tensor.abs() / prev_magn).clamp_(min=1e-8)\n\n            denom = torch.where(growth &gt; mul, growth/mul, 1)\n\n            tensor.div_(denom)\n\n        # limit max growth decay\n        if max_decay is not None:\n            if growth is None:\n                prev_magn = prev.abs()\n                if min_value is not None: prev_magn.clip_(min=min_value)\n                growth = (tensor.abs() / prev_magn).clamp_(min=1e-8)\n\n            new_prev = torch.where(growth &lt; (1/max_decay), prev/max_decay, tensor)\n        else:\n            new_prev = tensor.clone()\n\n        state['prev'] = new_prev\n        return tensor\n</code></pre>"},{"location":"API/all/#torchzero.modules.Clone","title":"Clone","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Clones input. May be useful to store some intermediate result and make sure it doesn't get affected by in-place operations</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Clone(Module):\n    \"\"\"Clones input. May be useful to store some intermediate result and make sure it doesn't get affected by in-place operations\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [u.clone() for u in objective.get_updates()]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.ConjugateDescent","title":"ConjugateDescent","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Conjugate Descent (CD).</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class ConjugateDescent(ConguateGradientBase):\n    \"\"\"Conjugate Descent (CD).\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return conjugate_descent_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/all/#torchzero.modules.CopyMagnitude","title":"CopyMagnitude","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RCopySign(BinaryOperationBase):\n    \"\"\"Returns ``other(tensors)`` with sign copied from tensors.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        return [o.copysign_(u) for u, o in zip(update, other)]\n</code></pre>"},{"location":"API/all/#torchzero.modules.CopySign","title":"CopySign","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Returns tensors with sign copied from <code>other(tensors)</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class CopySign(BinaryOperationBase):\n    \"\"\"Returns tensors with sign copied from ``other(tensors)``.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        return [u.copysign_(o) for u, o in zip(update, other)]\n</code></pre>"},{"location":"API/all/#torchzero.modules.CubicRegularization","title":"CubicRegularization","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Cubic regularization.</p> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When :code:<code>hess_module</code> is GaussNewton, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>maxiter</code>               (<code>float</code>, default:                   <code>100</code> )           \u2013            <p>maximum iterations when solving cubic subproblem, defaults to 1e-7.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for the solver, defaults to 1e-8.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>fallback</code>               (<code>bool</code>)           \u2013            <p>if <code>True</code>, when <code>hess_module</code> maintains hessian inverse which can't be inverted efficiently, it will be inverted anyway. When <code>False</code> (default), a <code>RuntimeError</code> will be raised instead.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul> <p>Examples:</p> <p>Cubic regularized newton</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.CubicRegularization(tz.m.Newton()),\n)\n</code></pre> Source code in <code>torchzero/modules/trust_region/cubic_regularization.py</code> <pre><code>class CubicRegularization(TrustRegionBase):\n    \"\"\"Cubic regularization.\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set `inverse=False` when constructing them.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When :code:`hess_module` is GaussNewton, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        maxiter (float, optional): maximum iterations when solving cubic subproblem, defaults to 1e-7.\n        eps (float, optional): epsilon for the solver, defaults to 1e-8.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        fallback (bool, optional):\n            if ``True``, when ``hess_module`` maintains hessian inverse which can't be inverted efficiently, it will\n            be inverted anyway. When ``False`` (default), a ``RuntimeError`` will be raised instead.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n\n    Examples:\n        Cubic regularized newton\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.CubicRegularization(tz.m.Newton()),\n            )\n\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        maxiter: int = 100,\n        eps: float = 1e-8,\n        check_decrease:bool=False,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(maxiter=maxiter, eps=eps, check_decrease=check_decrease)\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            boundary_tol=None,\n            radius_fn=None,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        params = TensorList(params)\n\n        loss_at_params_plus_x_fn = None\n        if settings['check_decrease']:\n            def closure_plus_x(x):\n                x_unflat = vec_to_tensors(x, params)\n                params.add_(x_unflat)\n                loss_x = closure(False)\n                params.sub_(x_unflat)\n                return loss_x\n            loss_at_params_plus_x_fn = closure_plus_x\n\n\n        d, _ = ls_cubic_solver(f=f, g=g, H=H, M=1/radius, loss_at_params_plus_x_fn=loss_at_params_plus_x_fn,\n                               it_max=settings['maxiter'], epsilon=settings['eps'])\n        return d.neg_()\n</code></pre>"},{"location":"API/all/#torchzero.modules.CustomUnaryOperation","title":"CustomUnaryOperation","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies <code>getattr(tensor, name)</code> to each tensor</p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class CustomUnaryOperation(TensorTransform):\n    \"\"\"Applies ``getattr(tensor, name)`` to each tensor\n    \"\"\"\n    def __init__(self, name: str):\n        defaults = dict(name=name)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return getattr(tensors, settings[0]['name'])()\n</code></pre>"},{"location":"API/all/#torchzero.modules.DFP","title":"DFP","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Davidon\u2013Fletcher\u2013Powell Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class DFP(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Davidon\u2013Fletcher\u2013Powell Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return dfp_H_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return dfp_B(B=B, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.DNRTR","title":"DNRTR","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Diagonal quasi-newton method.</p> Reference <p>Andrei, Neculai. \"A diagonal quasi-Newton updating method for unconstrained optimization.\" Numerical Algorithms 81.2 (2019): 575-590.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DNRTR(HessianUpdateStrategy):\n    \"\"\"Diagonal quasi-newton method.\n\n    Reference:\n        Andrei, Neculai. \"A diagonal quasi-Newton updating method for unconstrained optimization.\" Numerical Algorithms 81.2 (2019): 575-590.\n    \"\"\"\n    def __init__(\n        self,\n        lb: float = 1e-2,\n        ub: float = 1e5,\n        init_scale: float | Literal[\"auto\"] = \"auto\",\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(lb=lb, ub=ub)\n        super().__init__(\n            defaults=defaults,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=False,\n            inner=inner,\n        )\n\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_wqc_B_(B=B, s=s, y=y)\n\n    def modify_B(self, B, state, setting):\n        return _truncate(B, setting['lb'], setting['ub'])\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/all/#torchzero.modules.DYHS","title":"DYHS","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Dai-Yuan - Hestenes\u2013Stiefel hybrid conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class DYHS(ConguateGradientBase):\n    \"\"\"Dai-Yuan - Hestenes\u2013Stiefel hybrid conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return dyhs_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/all/#torchzero.modules.DaiYuan","title":"DaiYuan","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Dai\u2013Yuan nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1)</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class DaiYuan(ConguateGradientBase):\n    \"\"\"Dai\u2013Yuan nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1)`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return dai_yuan_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Debias","title":"Debias","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies the update by an Adam debiasing term based first and/or second momentum.</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>first momentum, should be the same as first momentum used in modules before. Defaults to None.</p> </li> <li> <code>beta2</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>learning rate. Defaults to 1.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, assumes absolute value is used. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class Debias(TensorTransform):\n    \"\"\"Multiplies the update by an Adam debiasing term based first and/or second momentum.\n\n    Args:\n        beta1 (float | None, optional):\n            first momentum, should be the same as first momentum used in modules before. Defaults to None.\n        beta2 (float | None, optional):\n            second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.\n        alpha (float, optional): learning rate. Defaults to 1.\n        pow (float, optional): power, assumes absolute value is used. Defaults to 2.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, beta1: float | None = None, beta2: float | None = None, alpha: float = 1, pow:float=2):\n        defaults = dict(beta1=beta1, beta2=beta2, alpha=alpha, pow=pow)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        pow = settings[0]['pow']\n        alpha, beta1, beta2 = unpack_dicts(settings, 'alpha', 'beta1', 'beta2', cls=NumberList)\n\n        return debias(TensorList(tensors), step=step, beta1=beta1, beta2=beta2, alpha=alpha, pow=pow, inplace=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Debias2","title":"Debias2","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies the update by an Adam debiasing term based on the second momentum.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>0.999</code> )           \u2013            <p>second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, assumes absolute value is used. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class Debias2(TensorTransform):\n    \"\"\"Multiplies the update by an Adam debiasing term based on the second momentum.\n\n    Args:\n        beta (float | None, optional):\n            second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.\n        pow (float, optional): power, assumes absolute value is used. Defaults to 2.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, beta: float = 0.999, pow: float = 2,):\n        defaults = dict(beta=beta, pow=pow)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        pow = settings[0]['pow']\n        beta = NumberList(s['beta'] for s in settings)\n        return debias_second_momentum(TensorList(tensors), step=step, beta=beta, pow=pow, inplace=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.DiagonalBFGS","title":"DiagonalBFGS","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Diagonal BFGS. This is simply BFGS with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalBFGS(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Diagonal BFGS. This is simply BFGS with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.\"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_bfgs_H_(H=H, s=s, y=y, tol=setting['tol'])\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/all/#torchzero.modules.DiagonalQuasiCauchi","title":"DiagonalQuasiCauchi","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._HessianUpdateStrategyDefaults</code></p> <p>Diagonal quasi-cauchi method.</p> Reference <p>Zhu M., Nazareth J. L., Wolkowicz H. The quasi-Cauchy relation and diagonal updating //SIAM Journal on Optimization. \u2013 1999. \u2013 \u0422. 9. \u2013 \u2116. 4. \u2013 \u0421. 1192-1204.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalQuasiCauchi(_HessianUpdateStrategyDefaults):\n    \"\"\"Diagonal quasi-cauchi method.\n\n    Reference:\n        Zhu M., Nazareth J. L., Wolkowicz H. The quasi-Cauchy relation and diagonal updating //SIAM Journal on Optimization. \u2013 1999. \u2013 \u0422. 9. \u2013 \u2116. 4. \u2013 \u0421. 1192-1204.\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_qc_B_(B=B, s=s, y=y)\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/all/#torchzero.modules.DiagonalSR1","title":"DiagonalSR1","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Diagonal SR1. This is simply SR1 with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalSR1(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Diagonal SR1. This is simply SR1 with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.\"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_sr1_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_sr1_(H=B, s=y, y=s, tol=setting['tol'])\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/all/#torchzero.modules.DiagonalWeightedQuasiCauchi","title":"DiagonalWeightedQuasiCauchi","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._HessianUpdateStrategyDefaults</code></p> <p>Diagonal quasi-cauchi method.</p> Reference <p>Leong, Wah June, Sharareh Enshaei, and Sie Long Kek. \"Diagonal quasi-Newton methods via least change updating principle with weighted Frobenius norm.\" Numerical Algorithms 86 (2021): 1225-1241.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalWeightedQuasiCauchi(_HessianUpdateStrategyDefaults):\n    \"\"\"Diagonal quasi-cauchi method.\n\n    Reference:\n        Leong, Wah June, Sharareh Enshaei, and Sie Long Kek. \"Diagonal quasi-Newton methods via least change updating principle with weighted Frobenius norm.\" Numerical Algorithms 86 (2021): 1225-1241.\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_wqc_B_(B=B, s=s, y=y)\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/all/#torchzero.modules.DirectWeightDecay","title":"DirectWeightDecay","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Directly applies weight decay to parameters.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>)           \u2013            <p>weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> </ul> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class DirectWeightDecay(Module):\n    \"\"\"Directly applies weight decay to parameters.\n\n    Args:\n        weight_decay (float): weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n    \"\"\"\n    def __init__(self, weight_decay: float, ord: int = 2,):\n        defaults = dict(weight_decay=weight_decay, ord=ord)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        weight_decay = self.get_settings(objective.params, 'weight_decay', cls=NumberList)\n        ord = self.defaults['ord']\n\n        decay_weights_(objective.params, weight_decay, ord)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Div","title":"Div","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Divide tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>tensors / other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Div(BinaryOperationBase):\n    \"\"\"Divide tensors by ``other``. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``tensors / other(tensors)``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        torch._foreach_div_(update, other)\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.DivByLoss","title":"DivByLoss","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Divides update by loss times <code>alpha</code></p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class DivByLoss(TensorTransform):\n    \"\"\"Divides update by loss times ``alpha``\"\"\"\n    def __init__(self, alpha: float = 1, min_value:float = 1e-16, backward: bool = True):\n        defaults = dict(alpha=alpha, min_value=min_value, backward=backward)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        alpha, min_value = unpack_dicts(settings, 'alpha', 'min_value')\n        denom = [max(loss*a, mv) for a,mv in zip(alpha, min_value)]\n        torch._foreach_div_(tensors, denom)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.DivModules","title":"DivModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input / other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class DivModules(MultiOperationBase):\n    \"\"\"Calculates ``input / other``. ``input`` and ``other`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable | float, other: Chainable | float, other_first:bool=False):\n        defaults = {}\n        if other_first: super().__init__(defaults, other=other, input=input)\n        else: super().__init__(defaults, input=input, other=other)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: float | list[torch.Tensor], other: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        if isinstance(input, (int,float)):\n            assert isinstance(other, list)\n            return input / TensorList(other)\n\n        torch._foreach_div_(input, other)\n        return input\n</code></pre>"},{"location":"API/all/#torchzero.modules.Dogleg","title":"Dogleg","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Dogleg trust region algorithm.</p> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When :code:<code>hess_module</code> is GaussNewton, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.75</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/trust_region/dogleg.py</code> <pre><code>class Dogleg(TrustRegionBase):\n    \"\"\"Dogleg trust region algorithm.\n\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set `inverse=False` when constructing them.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When :code:`hess_module` is GaussNewton, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 2,\n        nminus: float = 0.25,\n        rho_good: float = 0.75,\n        rho_bad: float = 0.25,\n        boundary_tol: float | None = None,\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict()\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            boundary_tol=boundary_tol,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            radius_fn=torch.linalg.vector_norm,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        if radius &gt; 2: radius = self.global_state['radius'] = 2\n        eps = torch.finfo(g.dtype).tiny * 2\n\n        gHg = g.dot(H.matvec(g))\n        if gHg &lt;= eps:\n            return (radius / torch.linalg.vector_norm(g)) * g # pylint:disable=not-callable\n\n        p_cauchy = (g.dot(g) / gHg) * g\n        p_newton = H.solve(g)\n\n        a = p_newton - p_cauchy\n        b = p_cauchy\n\n        aa = a.dot(a)\n        if aa &lt; eps:\n            return (radius / torch.linalg.vector_norm(g)) * g # pylint:disable=not-callable\n\n        ab = a.dot(b)\n        bb = b.dot(b)\n        c = bb - radius**2\n        discriminant = (2*ab)**2 - 4*aa*c\n        beta = (-2*ab + torch.sqrt(discriminant.clip(min=0))) / (2 * aa)\n        return p_cauchy + beta * (p_newton - p_cauchy)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Dropout","title":"Dropout","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Applies dropout to the update.</p> <p>For each weight the update to that weight has <code>p</code> probability to be set to 0. This can be used to implement gradient dropout or update dropout depending on placement.</p> <p>Parameters:</p> <ul> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>probability that update for a weight is replaced with 0. Defaults to 0.5.</p> </li> <li> <code>graft</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, update after dropout is rescaled to have the same norm as before dropout. Defaults to False.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var, refer to documentation. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Dropout--examples","title":"Examples:","text":"<p>Gradient dropout.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Dropout(0.5),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre> <p>Update dropout.</p> <p>``python opt = tz.Optimizer(     model.parameters(),     tz.m.Adam(),     tz.m.Dropout(0.5),     tz.m.LR(1e-3) ) ```</p> Source code in <code>torchzero/modules/misc/regularization.py</code> <pre><code>class Dropout(Transform):\n    \"\"\"Applies dropout to the update.\n\n    For each weight the update to that weight has ``p`` probability to be set to 0.\n    This can be used to implement gradient dropout or update dropout depending on placement.\n\n    Args:\n        p (float, optional): probability that update for a weight is replaced with 0. Defaults to 0.5.\n        graft (bool, optional):\n            if True, update after dropout is rescaled to have the same norm as before dropout. Defaults to False.\n        target (Target, optional): what to set on var, refer to documentation. Defaults to 'update'.\n\n\n    ### Examples:\n\n    Gradient dropout.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Dropout(0.5),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Update dropout.\n\n    ``python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.Dropout(0.5),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, p: float = 0.5, graft: bool=False):\n        defaults = dict(p=p, graft=graft)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        p = NumberList(s['p'] for s in settings)\n        graft = settings[0]['graft']\n\n        if graft:\n            target_norm = tensors.global_vector_norm()\n            tensors.mul_(tensors.rademacher_like(1-p).add_(1).div_(2))\n            return tensors.mul_(target_norm / tensors.global_vector_norm()) # graft\n\n        return tensors.mul_(tensors.rademacher_like(1-p).add_(1).div_(2))\n</code></pre>"},{"location":"API/all/#torchzero.modules.DualNormCorrection","title":"DualNormCorrection","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Dual norm correction for dualizer based optimizers (https://github.com/leloykun/adaptive-muon). Orthogonalize already has this built in with the <code>dual_norm_correction</code> setting.</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>class DualNormCorrection(TensorTransform):\n    \"\"\"Dual norm correction for dualizer based optimizers (https://github.com/leloykun/adaptive-muon).\n    Orthogonalize already has this built in with the `dual_norm_correction` setting.\"\"\"\n    def __init__(self, channel_first: bool = True):\n        defaults = dict(channel_first=channel_first)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        assert grad is not None\n        if (tensor.ndim &gt;= 2) and (tensor.size(0) &gt; 1) and (tensor.size(1) &gt; 1):\n            return _dual_norm_correction(tensor, grad, channel_first=setting[\"channel_first\"])\n        return tensor\n</code></pre>"},{"location":"API/all/#torchzero.modules.EMA","title":"EMA","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an exponential moving average of update.</p> <p>Parameters:</p> <ul> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>dampening</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>momentum dampening. Defaults to 0.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to debias the EMA like in Adam. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use linear interpolation. Defaults to True.</p> </li> <li> <code>ema_init</code>               (<code>str</code>, default:                   <code>'zeros'</code> )           \u2013            <p>initial values for the EMA, \"zeros\" or \"update\".</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target to apply EMA to. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/momentum.py</code> <pre><code>class EMA(TensorTransform):\n    \"\"\"Maintains an exponential moving average of update.\n\n    Args:\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        dampening (float, optional): momentum dampening. Defaults to 0.\n        debias (bool, optional): whether to debias the EMA like in Adam. Defaults to False.\n        lerp (bool, optional): whether to use linear interpolation. Defaults to True.\n        ema_init (str, optional): initial values for the EMA, \"zeros\" or \"update\".\n        target (Target, optional): target to apply EMA to. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, momentum:float=0.9, dampening:float=0, debias: bool = False, lerp=True, ema_init: Literal['zeros', 'update'] = 'zeros'):\n        defaults = dict(momentum=momentum,dampening=dampening,debias=debias,lerp=lerp,ema_init=ema_init)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        debias, lerp, ema_init = itemgetter('debias','lerp','ema_init')(settings[0])\n\n        exp_avg = unpack_states(states, tensors, 'exp_avg',\n                                init=torch.zeros_like if ema_init=='zeros' else tensors, cls=TensorList)\n        momentum, dampening = unpack_dicts(settings, 'momentum','dampening', cls=NumberList)\n\n        exp_avg = ema_(TensorList(tensors), exp_avg_=exp_avg,beta=momentum,dampening=dampening,lerp=lerp)\n\n        if debias: return _debias(exp_avg, step=step, beta1=momentum, alpha=1, inplace=False)\n        else: return exp_avg.clone() # this has exp_avg storage so needs to be cloned\n</code></pre>"},{"location":"API/all/#torchzero.modules.EMASquared","title":"EMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an exponential moving average of squared updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>EMA_SQ_FN</code>             \u2013              <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code>, if <code>max_exp_avg_sq_</code> is not None, updates it with maximum of EMA.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class EMASquared(TensorTransform):\n    \"\"\"Maintains an exponential moving average of squared updates.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    EMA_SQ_FN: staticmethod = staticmethod(ema_sq_)\n\n    def __init__(self, beta:float=0.999, amsgrad=False, pow:float=2):\n        defaults = dict(beta=beta,pow=pow,amsgrad=amsgrad)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        amsgrad, pow = itemgetter('amsgrad', 'pow')(self.settings[params[0]])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return self.EMA_SQ_FN(TensorList(tensors), exp_avg_sq_=exp_avg_sq, beta=beta, max_exp_avg_sq_=max_exp_avg_sq, pow=pow).clone()\n</code></pre>"},{"location":"API/all/#torchzero.modules.EMASquared.EMA_SQ_FN","title":"EMA_SQ_FN","text":"<pre><code>EMA_SQ_FN(tensors: TensorList, exp_avg_sq_: TensorList, beta: float | NumberList, max_exp_avg_sq_: TensorList | None, pow: float = 2)\n</code></pre> <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code>, if <code>max_exp_avg_sq_</code> is not None, updates it with maximum of EMA.</p> <p>Returns <code>exp_avg_sq_</code> or <code>max_exp_avg_sq_</code>.</p> Source code in <code>torchzero/modules/opt_utils.py</code> <pre><code>def ema_sq_(\n    tensors: TensorList,\n    exp_avg_sq_: TensorList,\n    beta: float | NumberList,\n    max_exp_avg_sq_: TensorList | None,\n    pow: float = 2,\n):\n    \"\"\"\n    Updates `exp_avg_sq_` with EMA of squared `tensors`, if `max_exp_avg_sq_` is not None, updates it with maximum of EMA.\n\n    Returns `exp_avg_sq_` or `max_exp_avg_sq_`.\n    \"\"\"\n    lerp_power_(tensors=tensors, exp_avg_pow_=exp_avg_sq_,beta=beta,pow=pow)\n\n    # AMSGrad\n    if max_exp_avg_sq_ is not None:\n        max_exp_avg_sq_.maximum_(exp_avg_sq_)\n        exp_avg_sq_ = max_exp_avg_sq_\n\n    return exp_avg_sq_\n</code></pre>"},{"location":"API/all/#torchzero.modules.ESGD","title":"ESGD","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Equilibrated Gradient Descent (https://arxiv.org/abs/1502.04390)</p> <pre><code>This is similar to Adagrad, but the accumulates squared randomized hessian diagonal estimates instead of squared gradients.\n\nNotes:\n    - In most cases ESGD should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply ESGD preconditioning to another module's output.\n\n    - This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\nArgs:\n    damping (float, optional): added to denominator for stability. Defaults to 1e-4.\n    update_freq (int, optional):\n        frequency of updating hessian diagonal estimate via a hessian-vector product.\n        This value can be increased to reduce computational cost. Defaults to 20.\n    hvp_method (str, optional):\n        Determines how hessian-vector products are computed.\n\n        - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n        - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n        - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n        - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n        Defaults to ``\"autograd\"``.\n    h (float, optional):\n        The step size for finite difference if ``hvp_method`` is\n        ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n    n_samples (int, optional):\n        number of hessian-vector products with random vectors to evaluate each time when updating\n        the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n    seed (int | None, optional): seed for random vectors. Defaults to None.\n    inner (Chainable | None, optional):\n        Inner module. If this is specified, operations are performed in the following order.\n        1. compute hessian diagonal estimate.\n        2. pass inputs to :code:`inner`.\n        3. momentum and preconditioning are applied to the ouputs of :code:`inner`.\n\n### Examples:\n\nUsing ESGD:\n</code></pre> <p>```python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ESGD(),\n    tz.m.LR(0.1)\n)\n```\n\nESGD preconditioner can be applied to any other module by passing it to the :code:`inner` argument. Here is an example of applying\nESGD preconditioning to nesterov momentum (:code:`tz.m.NAG`):\n\n```python\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ESGD(beta1=0, inner=tz.m.NAG(0.9)),\n    tz.m.LR(0.1)\n)\n```\n</code></pre> Source code in <code>torchzero/modules/adaptive/esgd.py</code> <pre><code>class ESGD(Transform):\n    \"\"\"Equilibrated Gradient Descent (https://arxiv.org/abs/1502.04390)\n\n    This is similar to Adagrad, but the accumulates squared randomized hessian diagonal estimates instead of squared gradients.\n\n    Notes:\n        - In most cases ESGD should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply ESGD preconditioning to another module's output.\n\n        - This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        damping (float, optional): added to denominator for stability. Defaults to 1e-4.\n        update_freq (int, optional):\n            frequency of updating hessian diagonal estimate via a hessian-vector product.\n            This value can be increased to reduce computational cost. Defaults to 20.\n        hvp_method (str, optional):\n            Determines how hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        n_samples (int, optional):\n            number of hessian-vector products with random vectors to evaluate each time when updating\n            the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n        seed (int | None, optional): seed for random vectors. Defaults to None.\n        inner (Chainable | None, optional):\n            Inner module. If this is specified, operations are performed in the following order.\n            1. compute hessian diagonal estimate.\n            2. pass inputs to :code:`inner`.\n            3. momentum and preconditioning are applied to the ouputs of :code:`inner`.\n\n    ### Examples:\n\n    Using ESGD:\n```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ESGD(),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    ESGD preconditioner can be applied to any other module by passing it to the :code:`inner` argument. Here is an example of applying\n    ESGD preconditioning to nesterov momentum (:code:`tz.m.NAG`):\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ESGD(beta1=0, inner=tz.m.NAG(0.9)),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        damping: float = 1e-4,\n        update_freq: int = 20,\n        distribution: Distributions = 'gaussian',\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        n_samples = 1,\n        zHz: bool = False,\n        seed: int | None = None,\n        beta: float | None = None,\n        beta_debias: bool = True,\n\n        inner: Chainable | None = None,\n        Hz_sq_acc_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"Hz_sq_acc_tfm\"]\n        super().__init__(defaults, inner=inner)\n\n        self.set_child(\"Hz_sq_acc\", Hz_sq_acc_tfm)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n\n        fs = settings[0]\n        update_freq = fs['update_freq']\n\n        # ------------------------------- accumulate Hz ------------------------------ #\n        step = self.increment_counter(\"step\", start=0)\n\n        if step % update_freq == 0:\n            self.increment_counter(\"num_Hzs\", start=1)\n\n            Hz, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = fs['n_samples'],\n                distribution = fs['distribution'],\n                hvp_method = fs['hvp_method'],\n                h = fs['h'],\n                zHz = fs[\"zHz\"], # default is False, so it returns Hz, not z\u2299Hz\n                generator = self.get_generator(params[0].device, fs[\"seed\"]),\n            )\n\n            Hz = TensorList(Hz)\n            Hz_sq_acc = unpack_states(states, params, 'Hz_sq_acc', cls=TensorList)\n\n            beta = fs[\"beta\"]\n            if beta is None:\n                Hz_sq_acc.addcmul_(Hz, Hz)\n\n            else:\n                Hz_sq_acc.mul_(beta).addcmul_(Hz, Hz, value=1-beta)\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        tensors = TensorList(objective.get_updates())\n        Hz_sq_acc = unpack_states(states, tensors, 'Hz_sq_acc', cls=TensorList)\n        num_Hzs = self.global_state[\"num_Hzs\"]\n        fs = settings[0]\n\n        # ---------------------------------- debias ---------------------------------- #\n        beta = fs[\"beta\"]\n        beta_debias = fs[\"beta_debias\"]\n\n        if beta_debias and beta is not None:\n            bias_correction = 1.0 - beta ** num_Hzs\n            Hz_sq_acc = Hz_sq_acc / bias_correction\n\n        else:\n            Hz_sq_acc = Hz_sq_acc / num_Hzs\n\n        # ---------------------------------- update ---------------------------------- #\n        damping = [s[\"damping\"] for s in settings]\n\n        denom = (Hz_sq_acc / num_Hzs).sqrt_().add_(damping)\n\n        objective.updates = tensors.div_(denom)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.EscapeAnnealing","title":"EscapeAnnealing","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>If parameters stop changing, this runs a backward annealing random search</p> Source code in <code>torchzero/modules/misc/escape.py</code> <pre><code>class EscapeAnnealing(Module):\n    \"\"\"If parameters stop changing, this runs a backward annealing random search\"\"\"\n    def __init__(self, max_region:float = 1, max_iter:int = 1000, tol=1e-6, n_tol: int = 10):\n        defaults = dict(max_region=max_region, max_iter=max_iter, tol=tol, n_tol=n_tol)\n        super().__init__(defaults)\n\n\n    @torch.no_grad\n    def apply(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError(\"Escape requries closure\")\n\n        params = TensorList(objective.params)\n        settings = self.settings[params[0]]\n        max_region = self.get_settings(params, 'max_region', cls=NumberList)\n        max_iter = settings['max_iter']\n        tol = settings['tol']\n        n_tol = settings['n_tol']\n\n        n_bad = self.global_state.get('n_bad', 0)\n\n        prev_params = self.get_state(params, 'prev_params', cls=TensorList)\n        diff = params-prev_params\n        prev_params.copy_(params)\n\n        if diff.abs().global_max() &lt;= tol:\n            n_bad += 1\n\n        else:\n            n_bad = 0\n\n        self.global_state['n_bad'] = n_bad\n\n        # no progress\n        f_0 = objective.get_loss(False)\n        if n_bad &gt;= n_tol:\n            for i in range(1, max_iter+1):\n                alpha = max_region * (i / max_iter)\n                pert = params.sphere_like(radius=alpha)\n\n                params.add_(pert)\n                f_star = closure(False)\n\n                if math.isfinite(f_star) and f_star &lt; f_0-1e-12:\n                    objective.updates = None\n                    objective.stop = True\n                    objective.skip_update = True\n                    return objective\n\n                params.sub_(pert)\n\n            self.global_state['n_bad'] = 0\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Exp","title":"Exp","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>exp(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Exp(TensorTransform):\n    \"\"\"Returns ``exp(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_exp_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.ExpHomotopy","title":"ExpHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class ExpHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return loss.exp()\n</code></pre>"},{"location":"API/all/#torchzero.modules.FDM","title":"FDM","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>Approximate gradients via finite difference method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>magnitude of parameter perturbation. Defaults to 1e-3.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to 'closure'.</p> </li> </ul> <p>Examples: plain FDM:</p> <pre><code>fdm = tz.Optimizer(model.parameters(), tz.m.FDM(), tz.m.LR(1e-2))\n</code></pre> <p>Any gradient-based method can use FDM-estimated gradients. <pre><code>fdm_ncg = tz.Optimizer(\n    model.parameters(),\n    tz.m.FDM(),\n    # set hvp_method to \"forward\" so that it\n    # uses gradient difference instead of autograd\n    tz.m.NewtonCG(hvp_method=\"forward\"),\n    tz.m.Backtracking()\n)\n</code></pre></p> Source code in <code>torchzero/modules/grad_approximation/fdm.py</code> <pre><code>class FDM(GradApproximator):\n    \"\"\"Approximate gradients via finite difference method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): magnitude of parameter perturbation. Defaults to 1e-3.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        target (GradTarget, optional): what to set on var. Defaults to 'closure'.\n\n    Examples:\n    plain FDM:\n\n    ```python\n    fdm = tz.Optimizer(model.parameters(), tz.m.FDM(), tz.m.LR(1e-2))\n    ```\n\n    Any gradient-based method can use FDM-estimated gradients.\n    ```python\n    fdm_ncg = tz.Optimizer(\n        model.parameters(),\n        tz.m.FDM(),\n        # set hvp_method to \"forward\" so that it\n        # uses gradient difference instead of autograd\n        tz.m.NewtonCG(hvp_method=\"forward\"),\n        tz.m.Backtracking()\n    )\n    ```\n    \"\"\"\n    def __init__(self, h: float=1e-3, formula: _FD_Formula = 'central', target: GradTarget = 'closure'):\n        defaults = dict(h=h, formula=formula)\n        super().__init__(defaults, target=target)\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        grads = []\n        loss_approx = None\n\n        for p in params:\n            g = torch.zeros_like(p)\n            grads.append(g)\n\n            settings = self.settings[p]\n            h = settings['h']\n            fd_fn = _FD_FUNCS[settings['formula']]\n\n            p_flat = p.ravel(); g_flat = g.ravel()\n            for i in range(len(p_flat)):\n                loss, loss_approx, d = fd_fn(closure=closure, param=p_flat, idx=i, h=h, v_0=loss)\n                g_flat[i] = d\n\n        return grads, loss, loss_approx\n</code></pre>"},{"location":"API/all/#torchzero.modules.Fill","title":"Fill","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with <code>value</code></p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Fill(Module):\n    \"\"\"Outputs tensors filled with ``value``\"\"\"\n    def __init__(self, value: float):\n        defaults = dict(value=value)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.full_like(p, self.settings[p]['value']) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.FillLoss","title":"FillLoss","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with loss value times <code>alpha</code></p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class FillLoss(Module):\n    \"\"\"Outputs tensors filled with loss value times ``alpha``\"\"\"\n    def __init__(self, alpha: float = 1, backward: bool = True):\n        defaults = dict(alpha=alpha, backward=backward)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        alpha = self.get_settings(objective.params, 'alpha')\n        loss = objective.get_loss(backward=self.defaults['backward'])\n        objective.updates = [torch.full_like(p, loss*a) for p,a in zip(objective.params, alpha)]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.FletcherReeves","title":"FletcherReeves","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Fletcher\u2013Reeves nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class FletcherReeves(ConguateGradientBase):\n    \"\"\"Fletcher\u2013Reeves nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def initialize(self, p, g):\n        self.global_state['prev_gg'] = g.dot(g)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        gg = g.dot(g)\n        beta = fletcher_reeves_beta(gg, self.global_state['prev_gg'])\n        self.global_state['prev_gg'] = gg\n        return beta\n</code></pre>"},{"location":"API/all/#torchzero.modules.FletcherVMM","title":"FletcherVMM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Fletcher's variable metric Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Fletcher, R. (1970). A new approach to variable metric algorithms. The Computer Journal, 13(3), 317\u2013322. doi:10.1093/comjnl/13.3.317</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class FletcherVMM(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Fletcher's variable metric Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Fletcher, R. (1970). A new approach to variable metric algorithms. The Computer Journal, 13(3), 317\u2013322. doi:10.1093/comjnl/13.3.317\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return fletcher_vmm_H_(H=H, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.ForwardGradient","title":"ForwardGradient","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Forward gradient method.</p> <p>This method samples one or more directional derivatives evaluated via autograd jacobian-vector products. This is very similar to randomized finite difference.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution for random gradient samples. Defaults to \"gaussian\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>jvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to calculate jacobian vector product, note that with <code>forward</code> and 'central' this is equivalent to randomized finite difference. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Baydin, A. G., Pearlmutter, B. A., Syme, D., Wood, F., &amp; Torr, P. (2022). Gradients without backpropagation. arXiv preprint arXiv:2202.08587.</p> Source code in <code>torchzero/modules/grad_approximation/forward_gradient.py</code> <pre><code>class ForwardGradient(RandomizedFDM):\n    \"\"\"Forward gradient method.\n\n    This method samples one or more directional derivatives evaluated via autograd jacobian-vector products. This is very similar to randomized finite difference.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n\n    Args:\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        distribution (Distributions, optional): distribution for random gradient samples. Defaults to \"gaussian\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        jvp_method (str, optional):\n            how to calculate jacobian vector product, note that with `forward` and 'central' this is equivalent to randomized finite difference. Defaults to 'autograd'.\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Baydin, A. G., Pearlmutter, B. A., Syme, D., Wood, F., &amp; Torr, P. (2022). Gradients without backpropagation. arXiv preprint arXiv:2202.08587.\n    \"\"\"\n    PRE_MULTIPLY_BY_H = False\n    def __init__(\n        self,\n        n_samples: int = 1,\n        distribution: Distributions = \"gaussian\",\n        pre_generate = True,\n        jvp_method: Literal['autograd', 'forward', 'central'] = 'autograd',\n        h: float = 1e-3,\n        target: GradTarget = \"closure\",\n        seed: int | None | torch.Generator = None,\n    ):\n        super().__init__(h=h, n_samples=n_samples, distribution=distribution, target=target, pre_generate=pre_generate, seed=seed)\n        self.defaults['jvp_method'] = jvp_method\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        params = TensorList(params)\n        loss_approx = None\n\n        fs = self.settings[params[0]]\n        n_samples = fs['n_samples']\n        jvp_method = fs['jvp_method']\n        h = fs['h']\n        distribution = fs['distribution']\n        default = [None]*n_samples\n        perturbations = list(zip(*(self.state[p].get('perturbations', default) for p in params)))\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n        grad = None\n        for i in range(n_samples):\n            prt = perturbations[i]\n            if prt[0] is None:\n                prt = params.sample_like(distribution=distribution, variance=1, generator=generator)\n\n            else: prt = TensorList(prt)\n\n            if jvp_method == 'autograd':\n                with torch.enable_grad():\n                    loss, d = jvp(partial(closure, False), params=params, tangent=prt)\n\n            elif jvp_method == 'forward':\n                loss, d = jvp_fd_forward(partial(closure, False), params=params, tangent=prt, v_0=loss, h=h)\n\n            elif jvp_method == 'central':\n                loss_approx, d = jvp_fd_central(partial(closure, False), params=params, tangent=prt, h=h)\n\n            else: raise ValueError(jvp_method)\n\n            if grad is None: grad = prt * d\n            else: grad += prt * d\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/all/#torchzero.modules.ForwardGradient.PRE_MULTIPLY_BY_H","title":"PRE_MULTIPLY_BY_H  <code>class-attribute</code>","text":"<pre><code>PRE_MULTIPLY_BY_H = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.FullMatrixAdagrad","title":"FullMatrixAdagrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Full-matrix version of Adagrad, can be customized to make RMSprop or Adam (see examples).</p> Note <p>A more memory-efficient version equivalent to full matrix Adagrad on last n gradients is implemented in <code>tz.m.GGT</code>.</p> <p>Parameters:</p> <ul> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-12</code> )           \u2013            <p>regularization, scale of identity matrix added to accumulator. Defaults to 1e-12.</p> </li> <li> <code>precond_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the inverse square root of the accumulator. Defaults to 1.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>momentum for gradient outer product accumulators. if None, uses sum. Defaults to None.</p> </li> <li> <code>beta_debias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use debiasing, only has effect when <code>beta</code> is not <code>None</code>. Defaults to True.</p> </li> <li> <code>init</code>               (<code>Literal[str]</code>, default:                   <code>'identity'</code> )           \u2013            <p>how to initialize the accumulator. - \"identity\" - with identity matrix (default). - \"zeros\" - with zero matrix. - \"ones\" - with matrix of ones.  -\"GGT\" - with the first outer product</p> </li> <li> <code>matrix_power</code>               (<code>float</code>, default:                   <code>-0.5</code> )           \u2013            <p>accumulator matrix power. Defaults to -1/2.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if False, each parameter will have it's own accumulator. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>inner modules to apply preconditioning to. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.FullMatrixAdagrad--examples","title":"Examples:","text":"<p>Plain full-matrix adagrad <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.FullMatrixAdagrd(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Full-matrix RMSprop <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.FullMatrixAdagrad(beta=0.99),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Full-matrix Adam <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.FullMatrixAdagrad(beta=0.999, inner=tz.m.EMA(0.9)),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/adagrad.py</code> <pre><code>class FullMatrixAdagrad(TensorTransform):\n    \"\"\"Full-matrix version of Adagrad, can be customized to make RMSprop or Adam (see examples).\n\n    Note:\n        A more memory-efficient version equivalent to full matrix Adagrad on last n gradients is implemented in ``tz.m.GGT``.\n\n    Args:\n        reg (float, optional): regularization, scale of identity matrix added to accumulator. Defaults to 1e-12.\n        precond_freq (int, optional): frequency of updating the inverse square root of the accumulator. Defaults to 1.\n        beta (float | None, optional): momentum for gradient outer product accumulators. if None, uses sum. Defaults to None.\n        beta_debias (bool, optional): whether to use debiasing, only has effect when ``beta`` is not ``None``. Defaults to True.\n        init (Literal[str], optional):\n            how to initialize the accumulator.\n            - \"identity\" - with identity matrix (default).\n            - \"zeros\" - with zero matrix.\n            - \"ones\" - with matrix of ones.\n             -\"GGT\" - with the first outer product\n        matrix_power (float, optional): accumulator matrix power. Defaults to -1/2.\n        concat_params (bool, optional): if False, each parameter will have it's own accumulator. Defaults to True.\n        inner (Chainable | None, optional): inner modules to apply preconditioning to. Defaults to None.\n\n    ## Examples:\n\n    Plain full-matrix adagrad\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.FullMatrixAdagrd(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Full-matrix RMSprop\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.FullMatrixAdagrad(beta=0.99),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Full-matrix Adam\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.FullMatrixAdagrad(beta=0.999, inner=tz.m.EMA(0.9)),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        reg: float = 1e-12,\n        precond_freq: int = 1,\n        beta: float | None = None,\n        beta_debias: bool=True,\n        init: Literal[\"identity\", \"zeros\", \"GGT\"] = \"identity\",\n        matrix_power: float = -1/2,\n        matrix_power_method: MatrixPowerMethod = \"eigh_abs\",\n        concat_params=True,\n\n        inner: Chainable | None = None,\n        accumulator_tfm: Chainable | None = None\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"concat_params\"], defaults[\"accumulator_tfm\"]\n        super().__init__(defaults=defaults, inner=inner, concat_params=concat_params)\n\n        self.set_child(\"accumulator\", accumulator_tfm)\n        self.add_projected_keys(\"covariance\", \"accumulator\")\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n\n        G = tensor.ravel()\n        GGT = torch.outer(G, G)\n\n        # initialize\n        if \"accumulator\" not in state:\n            init = setting['init']\n            if init == 'identity': state['accumulator'] = torch.eye(GGT.size(0), device=GGT.device, dtype=GGT.dtype)\n            elif init == 'zeros': state['accumulator'] =  torch.zeros_like(GGT)\n            elif init == 'GGT': state['accumulator'] = GGT.clone()\n            else: raise ValueError(init)\n\n        # update\n        beta = setting['beta']\n        accumulator: torch.Tensor = state[\"accumulator\"]\n\n        if beta is None: accumulator.add_(GGT)\n        else: accumulator.lerp_(GGT, 1-beta)\n\n        # update number of GG\u1d40 in accumulator for divide\n        state['num_GGTs'] = state.get('num_GGTs', 0) + 1\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        step = state.get('step', 0)\n        state['step'] = step + 1\n\n        accumulator: torch.Tensor = state['accumulator']\n        accumulator = self.inner_step_tensors(\"accumulator\", [accumulator], clone=True, must_exist=False)[0]\n\n        precond_freq = setting['precond_freq']\n        reg = setting['reg']\n        beta = setting[\"beta\"]\n\n        # add regularizer\n        if reg != 0:\n            device = accumulator.device; dtype = accumulator.dtype\n            accumulator = accumulator + torch.eye(accumulator.size(0), device=device, dtype=dtype).mul_(reg)\n\n        # for single value use sqrt\n        if tensor.numel() == 1:\n            dir = tensor.mul_(accumulator.squeeze() ** setting[\"matrix_power\"])\n\n        # otherwise use matrix inverse square root\n        else:\n\n            # compute inverse square root and store to state\n            try:\n                if \"B\" not in state or step % precond_freq == 0:\n                    B = state[\"B\"] = _matrix_power(accumulator, setting[\"matrix_power\"], method=setting[\"matrix_power_method\"])\n                else:\n                    B = state[\"B\"]\n\n                dir = (B @ tensor.ravel()).view_as(tensor)\n\n            # fallback to diagonal Adagrad on fail\n            except torch.linalg.LinAlgError:\n                dir = tensor.mul_(accumulator.diagonal() ** setting[\"matrix_power\"])\n\n        # debias\n        if setting[\"beta_debias\"] and beta is not None:\n            num_GGTs = state.get('num_GGTs', 1)\n            bias_correction = 1 - beta ** num_GGTs\n            dir *= bias_correction ** 0.5\n\n        return dir\n</code></pre>"},{"location":"API/all/#torchzero.modules.GGT","title":"GGT","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>GGT method from https://arxiv.org/pdf/1806.02958</p> <p>The update rule is to stack recent gradients into M and compute eigendecomposition of M M^T via eigendecomposition of M^T M.</p> <p>This is equivalent to full-matrix Adagrad on recent gradients.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of past gradients to store. Defaults to 10.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the preconditioner (U and S). Defaults to 1.</p> </li> <li> <code>eig_tol</code>               (<code>float</code>, default:                   <code>1e-07</code> )           \u2013            <p>removes eigenvalues this much smaller than largest eigenvalue. Defaults to 1e-7.</p> </li> <li> <code>truncate</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>number of larges eigenvalues to keep. None to disable. Defaults to None.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>damping value. Defaults to 1e-4.</p> </li> <li> <code>rdamping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>value of damping relative to largest eigenvalue. Defaults to 0.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, treats all parameters as a single vector. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioner will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.GGT--examples","title":"Examples:","text":"<p>Limited-memory Adagrad</p> <p><pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGT(),\n    tz.m.LR(0.1)\n)\n</code></pre> Adam with L-Adagrad preconditioner (for debiasing second beta is 0.999 arbitrarily)</p> <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGT(inner=tz.m.EMA()),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.LR(0.01)\n)\n</code></pre> <p>Stable Adam with L-Adagrad preconditioner (this is what I would recommend)</p> <p><pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGT(inner=tz.m.EMA()),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.ClipNormByEMA(max_ema_growth=1.2),\n    tz.m.LR(0.01)\n)\n</code></pre> Reference:     Agarwal N. et al. Efficient full-matrix adaptive regularization //International Conference on Machine Learning. \u2013 PMLR, 2019. \u2013 \u0421. 102-110.</p> Source code in <code>torchzero/modules/adaptive/ggt.py</code> <pre><code>class GGT(TensorTransform):\n    \"\"\"\n    GGT method from https://arxiv.org/pdf/1806.02958\n\n    The update rule is to stack recent gradients into M and\n    compute eigendecomposition of M M^T via eigendecomposition of M^T M.\n\n    This is equivalent to full-matrix Adagrad on recent gradients.\n\n    Args:\n        history_size (int, optional): number of past gradients to store. Defaults to 10.\n        update_freq (int, optional): frequency of updating the preconditioner (U and S). Defaults to 1.\n        eig_tol (float, optional): removes eigenvalues this much smaller than largest eigenvalue. Defaults to 1e-7.\n        truncate (int, optional): number of larges eigenvalues to keep. None to disable. Defaults to None.\n        damping (float, optional): damping value. Defaults to 1e-4.\n        rdamping (float, optional): value of damping relative to largest eigenvalue. Defaults to 0.\n        concat_params (bool, optional): if True, treats all parameters as a single vector. Defaults to True.\n        inner (Chainable | None, optional): preconditioner will be applied to output of this module. Defaults to None.\n\n    ## Examples:\n\n    Limited-memory Adagrad\n\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGT(),\n        tz.m.LR(0.1)\n    )\n    ```\n    Adam with L-Adagrad preconditioner (for debiasing second beta is 0.999 arbitrarily)\n\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGT(inner=tz.m.EMA()),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.LR(0.01)\n    )\n    ```\n\n    Stable Adam with L-Adagrad preconditioner (this is what I would recommend)\n\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGT(inner=tz.m.EMA()),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.ClipNormByEMA(max_ema_growth=1.2),\n        tz.m.LR(0.01)\n    )\n    ```\n    Reference:\n        Agarwal N. et al. Efficient full-matrix adaptive regularization //International Conference on Machine Learning. \u2013 PMLR, 2019. \u2013 \u0421. 102-110.\n    \"\"\"\n\n    def __init__(\n        self,\n        history_size: int = 100,\n        update_freq: int = 1,\n        eig_tol: float = 1e-7,\n        truncate: int | None = None,\n        damping: float = 1e-4,\n        rdamping: float = 0,\n        matrix_power: float = -1/2,\n        basis_optimizer: LREOptimizerBase | None = None,\n        concat_params: bool = True,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults['concat_params']\n\n        super().__init__(defaults, concat_params=concat_params, inner=inner)\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n        history_size = setting['history_size']\n        update_freq = setting['update_freq']\n\n        if 'history' not in state: state['history'] = deque(maxlen=history_size)\n        history = state['history']\n\n        t = tensor.clone().view(-1)\n        history.append(t)\n\n        step = state.get('step', 0)\n        state['step'] = step + 1\n\n        if step % update_freq == 0 :\n\n            # compute new factors\n            L = state.get(\"L\", None)\n            U = state.get(\"U\", None)\n\n            L_new, U_new = ggt_update(\n                history,\n                damping=setting[\"damping\"],\n                rdamping=setting[\"rdamping\"],\n                truncate=setting[\"truncate\"],\n                eig_tol=setting[\"eig_tol\"],\n                matrix_power=setting[\"matrix_power\"],\n            )\n\n            # reproject basis optimizer\n            basis_optimizer: LREOptimizerBase | None = setting[\"basis_optimizer\"]\n            if basis_optimizer is not None:\n                if (L is not None) and (U is not None) and (L_new is not None) and (U_new is not None):\n                    basis_state = state[\"basis_state\"]\n                    basis_optimizer.reproject(L_old=L, Q_old=U, L_new=L_new, Q_new=U_new, state=basis_state)\n\n\n            # store new factors\n            if L_new is not None: state[\"L\"] = L_new\n            if U_new is not None: state[\"U\"] = U_new\n\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        g = tensor.view(-1)\n        U = state.get('U', None)\n\n        if U is None:\n            # fallback to element-wise preconditioning\n            history = torch.stack(tuple(state[\"history\"]), 0)\n            g /= history.square().mean(0).sqrt().add(1e-8)\n            return g.view_as(tensor)\n\n        L = state['L']\n\n        # step with basis optimizer\n        basis_optimizer: LREOptimizerBase | None = setting[\"basis_optimizer\"]\n        if basis_optimizer is not None:\n\n            if \"basis_state\" not in state: state[\"basis_state\"] = {}\n            basis_state = state[\"basis_state\"]\n\n            update = basis_optimizer.step(g, L=L, Q=U, state=basis_state)\n            return update.view_as(tensor)\n\n        # or just whiten\n        z = U.T @ g\n        update = (U * L.pow(setting[\"matrix_power\"])) @ z\n        return update.view_as(tensor)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GGTBasis","title":"GGTBasis","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Run another optimizer in GGT eigenbasis. The eigenbasis is <code>rank</code>-sized, so it is possible to run expensive methods such as Full-matrix Adagrad/Adam.</p> <p>The update rule is to stack recent gradients into M and compute eigendecomposition of M M^T via eigendecomposition of M^T M.</p> <p>This is equivalent to full-matrix Adagrad on recent gradients.</p> Note <p>the buffers of the <code>basis_opt</code> are re-projected whenever basis changes. The reprojection logic is not implemented on all modules. Some supported modules are:</p> <p><code>Adagrad</code>, <code>FullMatrixAdagrad</code>, <code>Adam</code>, <code>Adan</code>, <code>Lion</code>, <code>MARSCorrection</code>, <code>MSAMMomentum</code>, <code>RMSprop</code>, <code>GGT</code>, <code>EMA</code>, <code>HeavyBall</code>, <code>NAG</code>, <code>ClipNormByEMA</code>, <code>ClipValueByEMA</code>, <code>NormalizeByEMA</code>, <code>ClipValueGrowth</code>, <code>CoordinateMomentum</code>, <code>CubicAdam</code>.</p> <p>Additionally most modules with no internal buffers are supported, e.g. <code>Cautious</code>, <code>Sign</code>, <code>ClipNorm</code>, <code>Orthogonalize</code>, etc. However modules that use weight values, such as <code>WeighDecay</code> can't be supported, as weights can't be projected.</p> <p>Also, if you say use <code>EMA</code> on output of <code>Pow(2)</code>, the exponential average will be reprojected as gradient and not as squared gradients. Use modules like <code>EMASquared</code>, <code>SqrtEMASquared</code> to get correct reprojections.</p> <p>Parameters:</p> <ul> <li> <code>basis_opt</code>               (<code>Chainable</code>)           \u2013            <p>module or modules to run in GGT eigenbasis.</p> </li> <li> <code>history_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of past gradients to store, and rank of preconditioner. Defaults to 10.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the preconditioner (U and S). Defaults to 1.</p> </li> <li> <code>eig_tol</code>               (<code>float</code>, default:                   <code>1e-07</code> )           \u2013            <p>removes eigenvalues this much smaller than largest eigenvalue. Defaults to 1e-7.</p> </li> <li> <code>truncate</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>number of larges eigenvalues to keep. None to disable. Defaults to None.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>damping value. Defaults to 1e-4.</p> </li> <li> <code>rdamping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>value of damping relative to largest eigenvalue. Defaults to 0.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>)           \u2013            <p>if True, treats all parameters as a single vector. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>output of this module is projected and <code>basis_opt</code> will run on it, but preconditioners are updated from original gradients.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.GGTBasis--examples","title":"Examples:","text":"<p>Examples: Adam in GGT eigenbasis: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGTBasis(tz.m.Adam(beta2=0.99)),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Full-matrix Adam in GGT eigenbasis. We can define full-matrix Adam through <code>FullMatrixAdagrad</code>. <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGTBasis(\n        [tz.m.FullMatrixAdagrad(beta=0.99, inner=tz.m.EMA(0.9, debias=True))]\n    ),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>LaProp in GGT eigenbasis: <pre><code># we define LaProp through other modules, moved it out for brevity\nlaprop = (\n    tz.m.RMSprop(0.95),\n    tz.m.Debias(beta1=None, beta2=0.95),\n    tz.m.EMA(0.95),\n    tz.m.Debias(beta1=0.95, beta2=None),\n)\n\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGTBasis(laprop),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Reference <p>Agarwal N. et al. Efficient full-matrix adaptive regularization //International Conference on Machine Learning. \u2013 PMLR, 2019. \u2013 \u0421. 102-110.</p> Source code in <code>torchzero/modules/basis/ggt_basis.py</code> <pre><code>class GGTBasis(TensorTransform):\n    \"\"\"\n    Run another optimizer in GGT eigenbasis. The eigenbasis is ``rank``-sized, so it is possible to run expensive\n    methods such as Full-matrix Adagrad/Adam.\n\n    The update rule is to stack recent gradients into M and\n    compute eigendecomposition of M M^T via eigendecomposition of M^T M.\n\n    This is equivalent to full-matrix Adagrad on recent gradients.\n\n    Note:\n        the buffers of the ``basis_opt`` are re-projected whenever basis changes. The reprojection logic is not implemented on all modules. Some supported modules are:\n\n        ``Adagrad``, ``FullMatrixAdagrad``, ``Adam``, ``Adan``, ``Lion``, ``MARSCorrection``, ``MSAMMomentum``, ``RMSprop``, ``GGT``, ``EMA``, ``HeavyBall``, ``NAG``, ``ClipNormByEMA``, ``ClipValueByEMA``, ``NormalizeByEMA``, ``ClipValueGrowth``, ``CoordinateMomentum``, ``CubicAdam``.\n\n        Additionally most modules with no internal buffers are supported, e.g. ``Cautious``, ``Sign``, ``ClipNorm``, ``Orthogonalize``, etc. However modules that use weight values, such as ``WeighDecay`` can't be supported, as weights can't be projected.\n\n        Also, if you say use ``EMA`` on output of ``Pow(2)``, the exponential average will be reprojected as gradient and not as squared gradients. Use modules like ``EMASquared``, ``SqrtEMASquared`` to get correct reprojections.\n\n\n    Args:\n        basis_opt (Chainable): module or modules to run in GGT eigenbasis.\n        history_size (int, optional): number of past gradients to store, and rank of preconditioner. Defaults to 10.\n        update_freq (int, optional): frequency of updating the preconditioner (U and S). Defaults to 1.\n        eig_tol (float, optional): removes eigenvalues this much smaller than largest eigenvalue. Defaults to 1e-7.\n        truncate (int, optional): number of larges eigenvalues to keep. None to disable. Defaults to None.\n        damping (float, optional): damping value. Defaults to 1e-4.\n        rdamping (float, optional): value of damping relative to largest eigenvalue. Defaults to 0.\n        concat_params (bool, optional): if True, treats all parameters as a single vector. Defaults to True.\n        inner (Chainable | None, optional):\n            output of this module is projected and ``basis_opt`` will run on it, but preconditioners are updated\n            from original gradients.\n\n    ## Examples:\n\n    Examples:\n    Adam in GGT eigenbasis:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGTBasis(tz.m.Adam(beta2=0.99)),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Full-matrix Adam in GGT eigenbasis. We can define full-matrix Adam through ``FullMatrixAdagrad``.\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGTBasis(\n            [tz.m.FullMatrixAdagrad(beta=0.99, inner=tz.m.EMA(0.9, debias=True))]\n        ),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    LaProp in GGT eigenbasis:\n    ```python\n\n    # we define LaProp through other modules, moved it out for brevity\n    laprop = (\n        tz.m.RMSprop(0.95),\n        tz.m.Debias(beta1=None, beta2=0.95),\n        tz.m.EMA(0.95),\n        tz.m.Debias(beta1=0.95, beta2=None),\n    )\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGTBasis(laprop),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Reference:\n        Agarwal N. et al. Efficient full-matrix adaptive regularization //International Conference on Machine Learning. \u2013 PMLR, 2019. \u2013 \u0421. 102-110.\n    \"\"\"\n\n    def __init__(\n        self,\n        basis_opt: Chainable,\n        history_size: int = 100,\n        update_freq: int = 1,\n        eig_tol: float = 1e-7,\n        truncate: int | None = None,\n        damping: float = 1e-4,\n        rdamping: float = 0,\n        matrix_power: float = -1/2,\n        approx_sq_reproject:bool = False,\n        approx_cu_reproject:bool = False,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"basis_opt\"]\n\n        super().__init__(defaults, concat_params=True, inner=inner)\n        self.set_child(\"basis_opt\", basis_opt)\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n        history_size = setting['history_size']\n        update_freq = setting['update_freq']\n\n        if 'history' not in state: state['history'] = deque(maxlen=history_size)\n        history = state['history']\n\n        t = tensor.clone().view(-1)\n        history.append(t)\n\n        step = state.get('step', 0)\n        state['step'] = step + 1\n\n        if step % update_freq == 0 :\n\n            # compute new factors\n            L = state.get(\"L\", None)\n            U = state.get(\"U\", None)\n\n            L_new, U_new = ggt_update(\n                history,\n                damping=setting[\"damping\"],\n                rdamping=setting[\"rdamping\"],\n                truncate=setting[\"truncate\"],\n                eig_tol=setting[\"eig_tol\"],\n                matrix_power=setting[\"matrix_power\"],\n            )\n\n            if (L is not None) and (U is not None) and (L_new is not None) and (U_new is not None):\n                # reproject basis optimizer\n                # this happens after first step, so basis opt is initialized by then\n                # note that because we concatenate parameters, each buffer will a single rank-length vector\n                C = U_new.T @ U # change of basis matrix\n\n                # reproject gradient-like buffers\n                for (buff,) in self.get_child_projected_buffers(\"basis_opt\", \"grad\"):\n                    set_storage_(buff, C @ buff)\n\n                # reproject covariance diagonal-like buffers\n                for (buff,) in self.get_child_projected_buffers(\"basis_opt\", \"grad_sq\"):\n                    if setting[\"approx_sq_reproject\"]: set_storage_(buff, C.pow(2) @ buff)\n                    else: set_storage_(buff, (C @ buff.diag_embed() @ C.T).diagonal())\n\n                # reproject third order diagonal-like buffers\n                for (buff,) in self.get_child_projected_buffers(\"basis_opt\", \"grad_cu\"):\n                    buff_r = _cubic_reproject(C, buff, setting[\"approx_cu_reproject\"])\n                    set_storage_(buff, buff_r)\n\n                # reproject covariance-like buffers\n                for (buff,) in self.get_child_projected_buffers(\"basis_opt\", \"covariance\"):\n                    set_storage_(buff, C @ buff @ C.T)\n\n            # store new factors\n            if L_new is not None: state[\"L\"] = L_new\n            if U_new is not None: state[\"U\"] = U_new\n\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        g = tensor.view(-1)\n        U = state.get('U', None)\n\n        if U is None:\n            # fallback to element-wise preconditioning\n            history = torch.stack(tuple(state[\"history\"]), 0)\n            g /= history.square().mean(0).sqrt().add(1e-8)\n            return g.view_as(tensor)\n\n        # project\n        g_proj = U.T @ g\n\n        # step\n        dir_proj = self.inner_step_tensors(\"basis_opt\", tensors=[g_proj], clone=False, grads=[g_proj])[0]\n\n        # unproject\n        update = U @ dir_proj\n\n        # update = (U * L.pow(setting[\"matrix_power\"])) @ z\n        return update.view_as(tensor)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GaussNewton","title":"GaussNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Gauss-newton method.</p> <p>To use this, the closure should return a vector of values to minimize sum of squares of. Please add the <code>backward</code> argument, it will always be False but it is required. Gradients will be calculated via batched autograd within this module, you don't need to implement the backward pass. Please see below for an example.</p> Note <p>This method requires <code>ndim^2</code> memory, however, if it is used within <code>tz.m.TrustCG</code> trust region, the memory requirement is <code>ndim*m</code>, where <code>m</code> is number of values in the output.</p> <p>Parameters:</p> <ul> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>regularization parameter. Defaults to 1e-8.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of computing the jacobian. When jacobian is not computed, only residuals are computed and updated. Defaults to 1.</p> </li> <li> <code>batched</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use vmapping. Defaults to True.</p> </li> </ul> <p>Examples:</p> <p>minimizing the rosenbrock function: <pre><code>def rosenbrock(X):\n    x1, x2 = X\n    return torch.stack([(1 - x1), 100 * (x2 - x1**2)])\n\nX = torch.tensor([-1.1, 2.5], requires_grad=True)\nopt = tz.Optimizer([X], tz.m.GaussNewton(), tz.m.Backtracking())\n\n# define the closure for line search\ndef closure(backward=True):\n    return rosenbrock(X)\n\n# minimize\nfor iter in range(10):\n    loss = opt.step(closure)\n    print(f'{loss = }')\n</code></pre></p> <p>training a neural network with a matrix-free GN trust region: <pre><code>X = torch.randn(64, 20)\ny = torch.randn(64, 10)\n\nmodel = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.GaussNewton()),\n)\n\ndef closure(backward=True):\n    y_hat = model(X) # (64, 10)\n    return (y_hat - y).pow(2).mean(0) # (10, )\n\nfor i in range(100):\n    losses = opt.step(closure)\n    if i % 10 == 0:\n        print(f'{losses.mean() = }')\n</code></pre></p> Source code in <code>torchzero/modules/least_squares/gn.py</code> <pre><code>class GaussNewton(Transform):\n    \"\"\"Gauss-newton method.\n\n    To use this, the closure should return a vector of values to minimize sum of squares of.\n    Please add the ``backward`` argument, it will always be False but it is required.\n    Gradients will be calculated via batched autograd within this module, you don't need to\n    implement the backward pass. Please see below for an example.\n\n    Note:\n        This method requires ``ndim^2`` memory, however, if it is used within ``tz.m.TrustCG`` trust region,\n        the memory requirement is ``ndim*m``, where ``m`` is number of values in the output.\n\n    Args:\n        reg (float, optional): regularization parameter. Defaults to 1e-8.\n        update_freq (int, optional):\n            frequency of computing the jacobian. When jacobian is not computed, only residuals are computed and updated.\n            Defaults to 1.\n        batched (bool, optional): whether to use vmapping. Defaults to True.\n\n    Examples:\n\n    minimizing the rosenbrock function:\n    ```python\n    def rosenbrock(X):\n        x1, x2 = X\n        return torch.stack([(1 - x1), 100 * (x2 - x1**2)])\n\n    X = torch.tensor([-1.1, 2.5], requires_grad=True)\n    opt = tz.Optimizer([X], tz.m.GaussNewton(), tz.m.Backtracking())\n\n    # define the closure for line search\n    def closure(backward=True):\n        return rosenbrock(X)\n\n    # minimize\n    for iter in range(10):\n        loss = opt.step(closure)\n        print(f'{loss = }')\n    ```\n\n    training a neural network with a matrix-free GN trust region:\n    ```python\n    X = torch.randn(64, 20)\n    y = torch.randn(64, 10)\n\n    model = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.GaussNewton()),\n    )\n\n    def closure(backward=True):\n        y_hat = model(X) # (64, 10)\n        return (y_hat - y).pow(2).mean(0) # (10, )\n\n    for i in range(100):\n        losses = opt.step(closure)\n        if i % 10 == 0:\n            print(f'{losses.mean() = }')\n    ```\n    \"\"\"\n    def __init__(self, reg:float = 1e-8, update_freq: int= 1, batched:bool=True, inner: Chainable | None = None):\n        defaults=dict(update_freq=update_freq,batched=batched, reg=reg)\n        super().__init__(defaults=defaults)\n        if inner is not None: self.set_child('inner', inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        params = objective.params\n        closure = objective.closure\n        batched = fs['batched']\n        update_freq = fs['update_freq']\n\n        # compute residuals\n        r = objective.loss\n        if r is None:\n            assert closure is not None\n            with torch.enable_grad():\n                r = objective.get_loss(backward=False) # n_residuals\n                assert isinstance(r, torch.Tensor)\n\n        if r.numel() == 1:\n            r = r.view(1,1)\n            warnings.warn(\"Gauss-newton got a single residual. Make sure objective function returns a vector of residuals.\")\n\n        # set sum of squares scalar loss and it's gradient to objective\n        objective.loss = r.pow(2).sum()\n\n        step = self.increment_counter(\"step\", start=0)\n\n        if step % update_freq == 0:\n\n            # compute jacobian\n            with torch.enable_grad():\n                J_list = jacobian_wrt([r.ravel()], params, batched=batched)\n\n            J = self.global_state[\"J\"] = flatten_jacobian(J_list) # (n_residuals, ndim)\n\n        else:\n            J = self.global_state[\"J\"]\n\n        Jr = J.T @ r.detach() # (ndim)\n\n        # if there are more residuals, solve (J^T J)x = J^T r, so we need Jr\n        # otherwise solve (J J^T)z = r and set x = J^T z, so we need r\n        n_residuals, ndim = J.shape\n        if n_residuals &gt;= ndim or \"inner\" in self.children:\n            self.global_state[\"Jr\"] = Jr\n\n        else:\n            self.global_state[\"r\"] = r\n\n        objective.grads = vec_to_tensors(Jr, objective.params)\n\n        # set closure to calculate sum of squares for line searches etc\n        if closure is not None:\n            def sos_closure(backward=True):\n\n                if backward:\n                    objective.zero_grad()\n                    with torch.enable_grad():\n                        loss = closure(False).pow(2).sum()\n                        loss.backward()\n                    return loss\n\n                loss = closure(False).pow(2).sum()\n                return loss\n\n            objective.closure = sos_closure\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        fs = settings[0]\n        reg = fs['reg']\n\n        J: torch.Tensor = self.global_state['J']\n        nresiduals, ndim = J.shape\n        if nresiduals &gt;= ndim or \"inner\" in self.children:\n\n            # (J^T J)v = J^T r\n            Jr: torch.Tensor = self.global_state['Jr']\n\n            # inner step\n            if \"inner\" in self.children:\n\n                # var.grad is set to unflattened Jr\n                assert objective.grads is not None\n                objective = self.inner_step(\"inner\", objective, must_exist=True)\n                Jr_list = objective.get_updates()\n                Jr = torch.cat([t.ravel() for t in Jr_list])\n\n            JtJ = J.T @ J # (ndim, ndim)\n            if reg != 0:\n                JtJ.add_(torch.eye(JtJ.size(0), device=JtJ.device, dtype=JtJ.dtype).mul_(reg))\n\n            if nresiduals &gt;= ndim:\n                v, info = torch.linalg.solve_ex(JtJ, Jr) # pylint:disable=not-callable\n            else:\n                v = torch.linalg.lstsq(JtJ, Jr).solution # pylint:disable=not-callable\n\n            objective.updates = vec_to_tensors(v, objective.params)\n            return objective\n\n        # else:\n        # solve (J J^T)z = r and set v = J^T z\n        # we need (J^T J)v = J^T r\n        # if z is solution to (G G^T)z = r, and v = J^T z\n        # then (J^T J)v = (J^T J) (J^T z) = J^T (J J^T) z = J^T r\n        # therefore (J^T J)v = J^T r\n        # also this gives a minimum norm solution\n\n        r = self.global_state['r']\n\n        JJT = J @ J.T # (nresiduals, nresiduals)\n        if reg != 0:\n            JJT.add_(torch.eye(JJT.size(0), device=JJT.device, dtype=JJT.dtype).mul_(reg))\n\n        z, info = torch.linalg.solve_ex(JJT, r) # pylint:disable=not-callable\n        v = J.T @ z\n\n        objective.updates = vec_to_tensors(v, objective.params)\n        return objective\n\n    def get_H(self, objective=...):\n        J = self.global_state['J']\n        return linear_operator.AtA(J)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GaussianSmoothing","title":"GaussianSmoothing","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Gradient approximation via Gaussian smoothing method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-2.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of random gradient samples. Defaults to 100.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'forward2'</code> )           \u2013            <p>finite difference formula. Defaults to 'forward2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution. Defaults to \"gaussian\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Yurii Nesterov, Vladimir Spokoiny. (2015). Random Gradient-Free Minimization of Convex Functions. https://gwern.net/doc/math/2015-nesterov.pdf</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class GaussianSmoothing(RandomizedFDM):\n    \"\"\"\n    Gradient approximation via Gaussian smoothing method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-2.\n        n_samples (int, optional): number of random gradient samples. Defaults to 100.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'forward2'.\n        distribution (Distributions, optional): distribution. Defaults to \"gaussian\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n\n    References:\n        Yurii Nesterov, Vladimir Spokoiny. (2015). Random Gradient-Free Minimization of Convex Functions. https://gwern.net/doc/math/2015-nesterov.pdf\n    \"\"\"\n    def __init__(\n        self,\n        h: float = 1e-2,\n        n_samples: int = 100,\n        formula: _FD_Formula = \"forward2\",\n        distribution: Distributions = \"gaussian\",\n        pre_generate: bool = True,\n        return_approx_loss: bool = False,\n        target: GradTarget = \"closure\",\n        seed: int | None | torch.Generator = None,\n    ):\n        super().__init__(h=h, n_samples=n_samples,formula=formula,distribution=distribution,pre_generate=pre_generate,target=target,seed=seed, return_approx_loss=return_approx_loss)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Grad","title":"Grad","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs the gradient</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Grad(Module):\n    \"\"\"Outputs the gradient\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [g.clone() for g in objective.get_grads()]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradApproximator","title":"GradApproximator","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for gradient approximations. This is an abstract class, to use it, subclass it and override <code>approximate</code>.</p> <p>GradientApproximator modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure.</p> <p>Parameters:</p> <ul> <li> <code>defaults</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>dict with defaults. Defaults to None.</p> </li> <li> <code>target</code>               (<code>str</code>, default:                   <code>'closure'</code> )           \u2013            <p>whether to set <code>var.grad</code>, <code>var.update</code> or 'var.closure`. Defaults to 'closure'.</p> </li> </ul> <p>Example:</p> <p>Basic SPSA method implementation. <pre><code>class SPSA(GradApproximator):\n    def __init__(self, h=1e-3):\n        defaults = dict(h=h)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        perturbation = [rademacher_like(p) * self.settings[p]['h'] for p in params]\n\n        # evaluate params + perturbation\n        torch._foreach_add_(params, perturbation)\n        loss_plus = closure(False)\n\n        # evaluate params - perturbation\n        torch._foreach_sub_(params, perturbation)\n        torch._foreach_sub_(params, perturbation)\n        loss_minus = closure(False)\n\n        # restore original params\n        torch._foreach_add_(params, perturbation)\n\n        # calculate SPSA gradients\n        spsa_grads = []\n        for p, pert in zip(params, perturbation):\n            settings = self.settings[p]\n            h = settings['h']\n            d = (loss_plus - loss_minus) / (2*(h**2))\n            spsa_grads.append(pert * d)\n\n        # returns tuple: (grads, loss, loss_approx)\n        # loss must be with initial parameters\n        # since we only evaluated loss with perturbed parameters\n        # we only have loss_approx\n        return spsa_grads, None, loss_plus\n</code></pre></p> <p>Methods:</p> <ul> <li> <code>approximate</code>             \u2013              <p>Returns a tuple: <code>(grad, loss, loss_approx)</code>, make sure this resets parameters to their original values!</p> </li> <li> <code>pre_step</code>             \u2013              <p>This runs once before each step, whereas <code>approximate</code> may run multiple times per step if further modules</p> </li> </ul> Source code in <code>torchzero/modules/grad_approximation/grad_approximator.py</code> <pre><code>class GradApproximator(Module, ABC):\n    \"\"\"Base class for gradient approximations.\n    This is an abstract class, to use it, subclass it and override `approximate`.\n\n    GradientApproximator modifies the closure to evaluate the estimated gradients,\n    and further closure-based modules will use the modified closure.\n\n    Args:\n        defaults (dict[str, Any] | None, optional): dict with defaults. Defaults to None.\n        target (str, optional):\n            whether to set `var.grad`, `var.update` or 'var.closure`. Defaults to 'closure'.\n\n    Example:\n\n    Basic SPSA method implementation.\n    ```python\n    class SPSA(GradApproximator):\n        def __init__(self, h=1e-3):\n            defaults = dict(h=h)\n            super().__init__(defaults)\n\n        @torch.no_grad\n        def approximate(self, closure, params, loss):\n            perturbation = [rademacher_like(p) * self.settings[p]['h'] for p in params]\n\n            # evaluate params + perturbation\n            torch._foreach_add_(params, perturbation)\n            loss_plus = closure(False)\n\n            # evaluate params - perturbation\n            torch._foreach_sub_(params, perturbation)\n            torch._foreach_sub_(params, perturbation)\n            loss_minus = closure(False)\n\n            # restore original params\n            torch._foreach_add_(params, perturbation)\n\n            # calculate SPSA gradients\n            spsa_grads = []\n            for p, pert in zip(params, perturbation):\n                settings = self.settings[p]\n                h = settings['h']\n                d = (loss_plus - loss_minus) / (2*(h**2))\n                spsa_grads.append(pert * d)\n\n            # returns tuple: (grads, loss, loss_approx)\n            # loss must be with initial parameters\n            # since we only evaluated loss with perturbed parameters\n            # we only have loss_approx\n            return spsa_grads, None, loss_plus\n    ```\n    \"\"\"\n    def __init__(self, defaults: dict[str, Any] | None = None, return_approx_loss:bool=False, target: GradTarget = 'closure'):\n        super().__init__(defaults)\n        self._target: GradTarget = target\n        self._return_approx_loss = return_approx_loss\n\n    @abstractmethod\n    def approximate(self, closure: Callable, params: list[torch.Tensor], loss: torch.Tensor | None) -&gt; tuple[Iterable[torch.Tensor], torch.Tensor | None, torch.Tensor | None]:\n        \"\"\"Returns a tuple: ``(grad, loss, loss_approx)``, make sure this resets parameters to their original values!\"\"\"\n\n    def pre_step(self, objective: Objective) -&gt; None:\n        \"\"\"This runs once before each step, whereas `approximate` may run multiple times per step if further modules\n        evaluate gradients at multiple points. This is useful for example to pre-generate new random perturbations.\"\"\"\n\n    @torch.no_grad\n    def update(self, objective):\n        self.pre_step(objective)\n\n        if objective.closure is None: raise RuntimeError(\"Gradient approximation requires closure\")\n        params, closure, loss = objective.params, objective.closure, objective.loss\n\n        if self._target == 'closure':\n\n            def approx_closure(backward=True):\n                if backward:\n                    # set loss to None because closure might be evaluated at different points\n                    grad, l, l_approx = self.approximate(closure=closure, params=params, loss=None)\n                    for p, g in zip(params, grad): p.grad = g\n                    if l is not None: return l\n                    if self._return_approx_loss and l_approx is not None: return l_approx\n                    return closure(False)\n\n                return closure(False)\n\n            objective.closure = approx_closure\n            return\n\n        # if var.grad is not None:\n        #     warnings.warn('Using grad approximator when `var.grad` is already set.')\n        grad, loss, loss_approx = self.approximate(closure=closure, params=params, loss=loss)\n        if loss_approx is not None: objective.loss_approx = loss_approx\n        if loss is not None: objective.loss = objective.loss_approx = loss\n        if self._target == 'grad': objective.grads = list(grad)\n        elif self._target == 'update': objective.updates = list(grad)\n        else: raise ValueError(self._target)\n        return\n\n    def apply(self, objective):\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradApproximator.approximate","title":"approximate","text":"<pre><code>approximate(closure: Callable, params: list[Tensor], loss: Tensor | None) -&gt; tuple[Iterable[Tensor], Tensor | None, Tensor | None]\n</code></pre> <p>Returns a tuple: <code>(grad, loss, loss_approx)</code>, make sure this resets parameters to their original values!</p> Source code in <code>torchzero/modules/grad_approximation/grad_approximator.py</code> <pre><code>@abstractmethod\ndef approximate(self, closure: Callable, params: list[torch.Tensor], loss: torch.Tensor | None) -&gt; tuple[Iterable[torch.Tensor], torch.Tensor | None, torch.Tensor | None]:\n    \"\"\"Returns a tuple: ``(grad, loss, loss_approx)``, make sure this resets parameters to their original values!\"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradApproximator.pre_step","title":"pre_step","text":"<pre><code>pre_step(objective: Objective) -&gt; None\n</code></pre> <p>This runs once before each step, whereas <code>approximate</code> may run multiple times per step if further modules evaluate gradients at multiple points. This is useful for example to pre-generate new random perturbations.</p> Source code in <code>torchzero/modules/grad_approximation/grad_approximator.py</code> <pre><code>def pre_step(self, objective: Objective) -&gt; None:\n    \"\"\"This runs once before each step, whereas `approximate` may run multiple times per step if further modules\n    evaluate gradients at multiple points. This is useful for example to pre-generate new random perturbations.\"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradSign","title":"GradSign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Copies gradient sign to update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GradSign(TensorTransform):\n    \"\"\"Copies gradient sign to update.\"\"\"\n    def __init__(self):\n        super().__init__(uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        return [t.copysign_(g) for t,g in zip(tensors, grads)]\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradToNone","title":"GradToNone","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Sets <code>grad</code> attribute to None on <code>objective</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class GradToNone(Module):\n    \"\"\"Sets ``grad`` attribute to None on ``objective``.\"\"\"\n    def __init__(self): super().__init__()\n    def apply(self, objective):\n        objective.grads = None\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradientAccumulation","title":"GradientAccumulation","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Uses <code>n</code> steps to accumulate gradients, after <code>n</code> gradients have been accumulated, they are passed to :code:<code>modules</code> and parameters are updates.</p> <p>Accumulating gradients for <code>n</code> steps is equivalent to increasing batch size by <code>n</code>. Increasing the batch size is more computationally efficient, but sometimes it is not feasible due to memory constraints.</p> Note <p>Technically this can accumulate any inputs, including updates generated by previous modules. As long as this module is first, it will accumulate the gradients.</p> <p>Parameters:</p> <ul> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>number of gradients to accumulate.</p> </li> <li> <code>mean</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, uses mean of accumulated gradients, otherwise uses sum. Defaults to True.</p> </li> <li> <code>stop</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>this module prevents next modules from stepping unless <code>n</code> gradients have been accumulate. Setting this argument to False disables that. Defaults to True.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.GradientAccumulation--examples","title":"Examples:","text":"<p>Adam with gradients accumulated for 16 batches.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GradientAccumulation(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/misc/gradient_accumulation.py</code> <pre><code>class GradientAccumulation(Module):\n    \"\"\"Uses ``n`` steps to accumulate gradients, after ``n`` gradients have been accumulated, they are passed to :code:`modules` and parameters are updates.\n\n    Accumulating gradients for ``n`` steps is equivalent to increasing batch size by ``n``. Increasing the batch size\n    is more computationally efficient, but sometimes it is not feasible due to memory constraints.\n\n    Note:\n        Technically this can accumulate any inputs, including updates generated by previous modules. As long as this module is first, it will accumulate the gradients.\n\n    Args:\n        n (int): number of gradients to accumulate.\n        mean (bool, optional): if True, uses mean of accumulated gradients, otherwise uses sum. Defaults to True.\n        stop (bool, optional):\n            this module prevents next modules from stepping unless ``n`` gradients have been accumulate. Setting this argument to False disables that. Defaults to True.\n\n    ## Examples:\n\n    Adam with gradients accumulated for 16 batches.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GradientAccumulation(),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(self, n: int, mean=True, stop=True):\n        defaults = dict(n=n, mean=mean, stop=stop)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"accumulator\")\n\n\n    @torch.no_grad\n    def apply(self, objective):\n        accumulator = self.get_state(objective.params, 'accumulator')\n        settings = self.defaults\n        n = settings['n']; mean = settings['mean']; stop = settings['stop']\n        step = self.increment_counter(\"step\", 0)\n\n        # add update to accumulator\n        torch._foreach_add_(accumulator, objective.get_updates())\n\n        # step with accumulated updates\n        if (step + 1) % n == 0:\n            if mean:\n                torch._foreach_div_(accumulator, n)\n\n            objective.updates = accumulator\n\n            # zero accumulator\n            self.clear_state_keys('accumulator')\n\n        else:\n            # prevent update\n            if stop:\n                objective.updates = None\n                objective.stop=True\n                objective.skip_update=True\n\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradientCorrection","title":"GradientCorrection","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Estimates gradient at minima along search direction assuming function is quadratic.</p> <p>This can useful as inner module for second order methods with inexact line search.</p>"},{"location":"API/all/#torchzero.modules.GradientCorrection--example","title":"Example:","text":"<p>L-BFGS with gradient correction</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(inner=tz.m.GradientCorrection()),\n    tz.m.Backtracking()\n)\n</code></pre> Reference <p>HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class GradientCorrection(TensorTransform):\n    \"\"\"\n    Estimates gradient at minima along search direction assuming function is quadratic.\n\n    This can useful as inner module for second order methods with inexact line search.\n\n    ## Example:\n    L-BFGS with gradient correction\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(inner=tz.m.GradientCorrection()),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Reference:\n        HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394\n\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        if 'p_prev' not in states[0]:\n            p_prev = unpack_states(states, tensors, 'p_prev', init=params)\n            g_prev = unpack_states(states, tensors, 'g_prev', init=tensors)\n            return tensors\n\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', cls=TensorList)\n        g_hat = gradient_correction(TensorList(tensors), params-p_prev, tensors-g_prev)\n\n        p_prev.copy_(params)\n        g_prev.copy_(tensors)\n        return g_hat\n</code></pre>"},{"location":"API/all/#torchzero.modules.GradientSampling","title":"GradientSampling","text":"<p>               Bases: <code>torchzero.core.reformulation.Reformulation</code></p> <p>Samples and aggregates gradients and values at perturbed points.</p> <p>This module can be used for gaussian homotopy and gradient sampling methods.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules that will be optimizing the modified objective. if None, returns gradient of the modified objective as the update. Defaults to None.</p> </li> <li> <code>sigma</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial magnitude of the perturbations. Defaults to 1.</p> </li> <li> <code>n</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of perturbations per step. Defaults to 100.</p> </li> <li> <code>aggregate</code>               (<code>str</code>, default:                   <code>'mean'</code> )           \u2013            <p>how to aggregate values and gradients - \"mean\" - uses mean of the gradients, as in gaussian homotopy. - \"max\" - uses element-wise maximum of the gradients. - \"min\" - uses element-wise minimum of the gradients. - \"min-norm\" - picks gradient with the lowest norm.</p> <p>Defaults to 'mean'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution for random perturbations. Defaults to 'gaussian'.</p> </li> <li> <code>include_x0</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to include gradient at un-perturbed point. Defaults to True.</p> </li> <li> <code>fixed</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, perturbations do not get replaced by new random perturbations until termination criteria is satisfied. Defaults to True.</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, perturbations are pre-generated before each step. This requires more memory to store all of them, but ensures they do not change when closure is evaluated multiple times. Defaults to True.</p> </li> <li> <code>termination</code>               (<code>TerminationCriteriaBase | Sequence[TerminationCriteriaBase] | None</code>, default:                   <code>None</code> )           \u2013            <p>a termination criteria module, sigma will be multiplied by <code>decay</code> when termination criteria is satisfied, and new perturbations will be generated if <code>fixed</code>. Defaults to None.</p> </li> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0.6666666666666666</code> )           \u2013            <p>sigma multiplier on termination criteria. Defaults to 2/3.</p> </li> <li> <code>reset_on_termination</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to reset states of all other modules on termination. Defaults to True.</p> </li> <li> <code>sigma_strategy</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>strategy for adapting sigma. If condition is satisfied, sigma is multiplied by <code>sigma_nplus</code>, otherwise it is multiplied by <code>sigma_nminus</code>. - \"grad-norm\" - at least <code>sigma_target</code> gradients should have lower norm than at un-perturbed point. - \"value\" - at least <code>sigma_target</code> values (losses) should be lower than at un-perturbed point. - None - doesn't use adaptive sigma.</p> <p>This introduces a side-effect to the closure, so it should be left at None of you use trust region or line search to optimize the modified objective. Defaults to None.</p> </li> <li> <code>sigma_target</code>               (<code>int</code>, default:                   <code>0.2</code> )           \u2013            <p>number of elements to satisfy the condition in <code>sigma_strategy</code>. Defaults to 1.</p> </li> <li> <code>sigma_nplus</code>               (<code>float</code>, default:                   <code>1.3333333333333333</code> )           \u2013            <p>sigma multiplier when <code>sigma_strategy</code> condition is satisfied. Defaults to 4/3.</p> </li> <li> <code>sigma_nminus</code>               (<code>float</code>, default:                   <code>0.6666666666666666</code> )           \u2013            <p>sigma multiplier when <code>sigma_strategy</code> condition is not satisfied. Defaults to 2/3.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/smoothing/sampling.py</code> <pre><code>class GradientSampling(Reformulation):\n    \"\"\"Samples and aggregates gradients and values at perturbed points.\n\n    This module can be used for gaussian homotopy and gradient sampling methods.\n\n    Args:\n        modules (Chainable | None, optional):\n            modules that will be optimizing the modified objective.\n            if None, returns gradient of the modified objective as the update. Defaults to None.\n        sigma (float, optional): initial magnitude of the perturbations. Defaults to 1.\n        n (int, optional): number of perturbations per step. Defaults to 100.\n        aggregate (str, optional):\n            how to aggregate values and gradients\n            - \"mean\" - uses mean of the gradients, as in gaussian homotopy.\n            - \"max\" - uses element-wise maximum of the gradients.\n            - \"min\" - uses element-wise minimum of the gradients.\n            - \"min-norm\" - picks gradient with the lowest norm.\n\n            Defaults to 'mean'.\n        distribution (Distributions, optional): distribution for random perturbations. Defaults to 'gaussian'.\n        include_x0 (bool, optional): whether to include gradient at un-perturbed point. Defaults to True.\n        fixed (bool, optional):\n            if True, perturbations do not get replaced by new random perturbations until termination criteria is satisfied. Defaults to True.\n        pre_generate (bool, optional):\n            if True, perturbations are pre-generated before each step.\n            This requires more memory to store all of them,\n            but ensures they do not change when closure is evaluated multiple times.\n            Defaults to True.\n        termination (TerminationCriteriaBase | Sequence[TerminationCriteriaBase] | None, optional):\n            a termination criteria module, sigma will be multiplied by ``decay`` when termination criteria is satisfied,\n            and new perturbations will be generated if ``fixed``. Defaults to None.\n        decay (float, optional): sigma multiplier on termination criteria. Defaults to 2/3.\n        reset_on_termination (bool, optional): whether to reset states of all other modules on termination. Defaults to True.\n        sigma_strategy (str | None, optional):\n            strategy for adapting sigma. If condition is satisfied, sigma is multiplied by ``sigma_nplus``,\n            otherwise it is multiplied by ``sigma_nminus``.\n            - \"grad-norm\" - at least ``sigma_target`` gradients should have lower norm than at un-perturbed point.\n            - \"value\" - at least ``sigma_target`` values (losses) should be lower than at un-perturbed point.\n            - None - doesn't use adaptive sigma.\n\n            This introduces a side-effect to the closure, so it should be left at None of you use\n            trust region or line search to optimize the modified objective.\n            Defaults to None.\n        sigma_target (int, optional):\n            number of elements to satisfy the condition in ``sigma_strategy``. Defaults to 1.\n        sigma_nplus (float, optional): sigma multiplier when ``sigma_strategy`` condition is satisfied. Defaults to 4/3.\n        sigma_nminus (float, optional): sigma multiplier when ``sigma_strategy`` condition is not satisfied. Defaults to 2/3.\n        seed (int | None, optional): seed. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        modules: Chainable | None = None,\n        sigma: float = 1.,\n        n:int = 100,\n        aggregate: Literal['mean', 'max', 'min', 'min-norm', 'min-value'] = 'mean',\n        distribution: Distributions = 'gaussian',\n        include_x0: bool = True,\n\n        fixed: bool=True,\n        pre_generate: bool = True,\n        termination: TerminationCriteriaBase | Sequence[TerminationCriteriaBase] | None = None,\n        decay: float = 2/3,\n        reset_on_termination: bool = True,\n\n        sigma_strategy: Literal['grad-norm', 'value'] | None = None,\n        sigma_target: int | float = 0.2,\n        sigma_nplus: float = 4/3,\n        sigma_nminus: float = 2/3,\n\n        seed: int | None = None,\n    ):\n\n        defaults = dict(sigma=sigma, n=n, aggregate=aggregate, distribution=distribution, seed=seed, include_x0=include_x0, fixed=fixed, decay=decay, reset_on_termination=reset_on_termination, sigma_strategy=sigma_strategy, sigma_target=sigma_target, sigma_nplus=sigma_nplus, sigma_nminus=sigma_nminus, pre_generate=pre_generate)\n        super().__init__(defaults, modules)\n\n        if termination is not None:\n            self.set_child('termination', make_termination_criteria(extra=termination))\n\n    @torch.no_grad\n    def pre_step(self, objective):\n        params = TensorList(objective.params)\n\n        fixed = self.defaults['fixed']\n\n        # check termination criteria\n        if 'termination' in self.children:\n            termination = cast(TerminationCriteriaBase, self.children['termination'])\n            if termination.should_terminate(objective):\n\n                # decay sigmas\n                states = [self.state[p] for p in params]\n                settings = [self.settings[p] for p in params]\n\n                for state, setting in zip(states, settings):\n                    if 'sigma' not in state: state['sigma'] = setting['sigma']\n                    state['sigma'] *= setting['decay']\n\n                # reset on sigmas decay\n                if self.defaults['reset_on_termination']:\n                    objective.post_step_hooks.append(partial(_reset_except_self, self=self))\n\n                # clear perturbations\n                self.global_state.pop('perts', None)\n\n        # pre-generate perturbations if not already pre-generated or not fixed\n        if self.defaults['pre_generate'] and (('perts' not in self.global_state) or (not fixed)):\n            states = [self.state[p] for p in params]\n            settings = [self.settings[p] for p in params]\n\n            n = self.defaults['n'] - self.defaults['include_x0']\n            generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n            perts = [params.sample_like(self.defaults['distribution'], generator=generator) for _ in range(n)]\n\n            self.global_state['perts'] = perts\n\n    @torch.no_grad\n    def closure(self, backward, closure, params, objective):\n        params = TensorList(params)\n        loss_agg = None\n        grad_agg = None\n\n        states = [self.state[p] for p in params]\n        settings = [self.settings[p] for p in params]\n        sigma_inits = [s['sigma'] for s in settings]\n        sigmas = [s.setdefault('sigma', si) for s, si in zip(states, sigma_inits)]\n\n        include_x0 = self.defaults['include_x0']\n        pre_generate = self.defaults['pre_generate']\n        aggregate: Literal['mean', 'max', 'min', 'min-norm', 'min-value'] = self.defaults['aggregate']\n        sigma_strategy: Literal['grad-norm', 'value'] | None = self.defaults['sigma_strategy']\n        distribution = self.defaults['distribution']\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n\n        n_finite = 0\n        n_good = 0\n        f_0 = None; g_0 = None\n\n        # evaluate at x_0\n        if include_x0:\n            f_0 = objective.get_loss(backward=backward)\n\n            isfinite = math.isfinite(f_0)\n            if isfinite:\n                n_finite += 1\n                loss_agg = f_0\n\n            if backward:\n                g_0 = objective.get_grads()\n                if isfinite: grad_agg = g_0\n\n        # evaluate at x_0 + p for each perturbation\n        if pre_generate:\n            perts = self.global_state['perts']\n        else:\n            perts = [None] * (self.defaults['n'] - include_x0)\n\n        x_0 = [p.clone() for p in params]\n\n        for pert in perts:\n            loss = None; grad = None\n\n            # generate if not pre-generated\n            if pert is None:\n                pert = params.sample_like(distribution, generator=generator)\n\n            # add perturbation and evaluate\n            pert = pert * sigmas\n            torch._foreach_add_(params, pert)\n\n            with torch.enable_grad() if backward else nullcontext():\n                loss = closure(backward)\n\n            if math.isfinite(loss):\n                n_finite += 1\n\n                # add loss\n                if loss_agg is None:\n                    loss_agg = loss\n                else:\n                    if aggregate == 'mean':\n                        loss_agg += loss\n\n                    elif (aggregate=='min') or (aggregate=='min-value') or (aggregate=='min-norm' and not backward):\n                        loss_agg = loss_agg.clamp(max=loss)\n\n                    elif aggregate == 'max':\n                        loss_agg = loss_agg.clamp(min=loss)\n\n                # add grad\n                if backward:\n                    grad = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n                    if grad_agg is None:\n                        grad_agg = grad\n                    else:\n                        if aggregate == 'mean':\n                            torch._foreach_add_(grad_agg, grad)\n\n                        elif aggregate == 'min':\n                            grad_agg_abs = torch._foreach_abs(grad_agg)\n                            torch._foreach_minimum_(grad_agg_abs, torch._foreach_abs(grad))\n                            grad_agg = [g_abs.copysign(g) for g_abs, g in zip(grad_agg_abs, grad_agg)]\n\n                        elif aggregate == 'max':\n                            grad_agg_abs = torch._foreach_abs(grad_agg)\n                            torch._foreach_maximum_(grad_agg_abs, torch._foreach_abs(grad))\n                            grad_agg = [g_abs.copysign(g) for g_abs, g in zip(grad_agg_abs, grad_agg)]\n\n                        elif aggregate == 'min-norm':\n                            if TensorList(grad).global_vector_norm() &lt; TensorList(grad_agg).global_vector_norm():\n                                grad_agg = grad\n                                loss_agg = loss\n\n                        elif aggregate == 'min-value':\n                            if loss &lt; loss_agg:\n                                grad_agg = grad\n                                loss_agg = loss\n\n            # undo perturbation\n            torch._foreach_copy_(params, x_0)\n\n            # adaptive sigma\n            # by value\n            if sigma_strategy == 'value':\n                if f_0 is None:\n                    with torch.enable_grad() if backward else nullcontext():\n                        f_0 = closure(False)\n\n                if loss &lt; f_0:\n                    n_good += 1\n\n            # by gradient norm\n            elif sigma_strategy == 'grad-norm' and backward and math.isfinite(loss):\n                assert grad is not None\n                if g_0 is None:\n                    with torch.enable_grad() if backward else nullcontext():\n                        closure()\n                        g_0 = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n\n                if TensorList(grad).global_vector_norm() &lt; TensorList(g_0).global_vector_norm():\n                    n_good += 1\n\n        # update sigma if strategy is enabled\n        if sigma_strategy is not None:\n\n            sigma_target = self.defaults['sigma_target']\n            if isinstance(sigma_target, float):\n                sigma_target = int(max(1, n_finite * sigma_target))\n\n            if n_good &gt;= sigma_target:\n                key = 'sigma_nplus'\n            else:\n                key = 'sigma_nminus'\n\n            for p in params:\n                self.state[p]['sigma'] *= self.settings[p][key]\n\n        # if no finite losses, just return inf\n        if n_finite == 0:\n            assert loss_agg is None and grad_agg is None\n            loss = torch.tensor(torch.inf, dtype=params[0].dtype, device=params[0].device)\n            grad = [torch.full_like(p, torch.inf) for p in params]\n            return loss, grad\n\n        assert loss_agg is not None\n\n        # no post processing needed when aggregate is 'max', 'min', 'min-norm', 'min-value'\n        if aggregate != 'mean':\n            return loss_agg, grad_agg\n\n        # on mean divide by number of evals\n        loss_agg /= n_finite\n\n        if backward:\n            assert grad_agg is not None\n            torch._foreach_div_(grad_agg, n_finite)\n\n        return loss_agg, grad_agg\n</code></pre>"},{"location":"API/all/#torchzero.modules.Graft","title":"Graft","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Outputs <code>direction</code> output rescaled to have the same norm as <code>magnitude</code> output.</p> <p>Parameters:</p> <ul> <li> <code>direction</code>               (<code>Chainable</code>)           \u2013            <p>module to use the direction from</p> </li> <li> <code>magnitude</code>               (<code>Chainable</code>)           \u2013            <p>module to use the magnitude from</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to calculate norm per-tensor or globally. Defaults to True.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>clips denominator to be no less than this value. Defaults to 1e-6.</p> </li> <li> <code>strength</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>strength of grafting. Defaults to 1.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Graft--example","title":"Example:","text":"<p>Shampoo grafted to Adam <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GraftModules(\n        direction = tz.m.Shampoo(),\n        magnitude = tz.m.Adam(),\n    ),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Reference <p>Agarwal, N., Anil, R., Hazan, E., Koren, T., &amp; Zhang, C. (2020). Disentangling adaptive gradient methods from learning rates. arXiv preprint arXiv:2002.11803.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class Graft(MultiOperationBase):\n    \"\"\"Outputs ``direction`` output rescaled to have the same norm as ``magnitude`` output.\n\n    Args:\n        direction (Chainable): module to use the direction from\n        magnitude (Chainable): module to use the magnitude from\n        tensorwise (bool, optional): whether to calculate norm per-tensor or globally. Defaults to True.\n        ord (float, optional): norm order. Defaults to 2.\n        eps (float, optional): clips denominator to be no less than this value. Defaults to 1e-6.\n        strength (float, optional): strength of grafting. Defaults to 1.\n\n    ### Example:\n\n    Shampoo grafted to Adam\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GraftModules(\n            direction = tz.m.Shampoo(),\n            magnitude = tz.m.Adam(),\n        ),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Reference:\n        [Agarwal, N., Anil, R., Hazan, E., Koren, T., &amp; Zhang, C. (2020). Disentangling adaptive gradient methods from learning rates. arXiv preprint arXiv:2002.11803.](https://arxiv.org/pdf/2002.11803)\n    \"\"\"\n    def __init__(self, direction: Chainable, magnitude: Chainable, tensorwise:bool=True, ord:Metrics=2, eps:float = 1e-6, strength:float=1):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps, strength=strength)\n        super().__init__(defaults, direction=direction, magnitude=magnitude)\n\n    @torch.no_grad\n    def transform(self, objective, magnitude: list[torch.Tensor], direction:list[torch.Tensor]):\n        tensorwise, ord, eps, strength = itemgetter('tensorwise','ord','eps', 'strength')(self.defaults)\n        return TensorList(direction).graft_(magnitude, tensorwise=tensorwise, ord=ord, eps=eps, strength=strength)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GraftGradToUpdate","title":"GraftGradToUpdate","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs gradient grafted to update, that is gradient rescaled to have the same norm as the update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GraftGradToUpdate(TensorTransform):\n    \"\"\"Outputs gradient grafted to update, that is gradient rescaled to have the same norm as the update.\"\"\"\n    def __init__(self, tensorwise:bool=False, ord:Metrics=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(settings[0])\n        return TensorList(grads).graft(tensors, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GraftInputToOutput","title":"GraftInputToOutput","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>tensors</code> rescaled to have the same norm as <code>magnitude(tensors)</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class GraftInputToOutput(BinaryOperationBase):\n    \"\"\"Outputs ``tensors`` rescaled to have the same norm as ``magnitude(tensors)``.\"\"\"\n    def __init__(self, magnitude: Chainable, tensorwise:bool=True, ord:float=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, magnitude=magnitude)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], magnitude: list[torch.Tensor]):\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(self.defaults)\n        return TensorList(update).graft_(magnitude, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GraftOutputToInput","title":"GraftOutputToInput","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>magnitude(tensors)</code> rescaled to have the same norm as <code>tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class GraftOutputToInput(BinaryOperationBase):\n    \"\"\"Outputs ``magnitude(tensors)`` rescaled to have the same norm as ``tensors``\"\"\"\n\n    def __init__(self, direction: Chainable, tensorwise:bool=True, ord:float=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, direction=direction)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], direction: list[torch.Tensor]):\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(self.defaults)\n        return TensorList(direction).graft_(update, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GraftToGrad","title":"GraftToGrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Grafts update to the gradient, that is update is rescaled to have the same norm as the gradient.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GraftToGrad(TensorTransform):\n    \"\"\"Grafts update to the gradient, that is update is rescaled to have the same norm as the gradient.\"\"\"\n    def __init__(self, tensorwise:bool=False, ord:Metrics=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(settings[0])\n        return TensorList(tensors).graft_(grads, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GraftToParams","title":"GraftToParams","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Grafts update to the parameters, that is update is rescaled to have the same norm as the parameters, but no smaller than <code>eps</code>.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GraftToParams(TensorTransform):\n    \"\"\"Grafts update to the parameters, that is update is rescaled to have the same norm as the parameters, but no smaller than ``eps``.\"\"\"\n    def __init__(self, tensorwise:bool=False, ord:Metrics=2, eps:float = 1e-4):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(settings[0])\n        return TensorList(tensors).graft_(params, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/all/#torchzero.modules.GramSchimdt","title":"GramSchimdt","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>outputs tensors made orthogonal to <code>other(tensors)</code> via Gram-Schmidt.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class GramSchimdt(BinaryOperationBase):\n    \"\"\"outputs tensors made orthogonal to ``other(tensors)`` via Gram-Schmidt.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        update = TensorList(update); other = TensorList(other)\n        min = torch.finfo(update[0].dtype).tiny * 2\n        return update - (other*update) / (other*other).clip(min=min)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Greenstadt1","title":"Greenstadt1","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Greenstadt's first Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Greenstadt1(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Greenstadt's first Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return greenstadt1_H_(H=H, s=s, y=y, g_prev=g_prev)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Greenstadt2","title":"Greenstadt2","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Greenstadt's second Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Greenstadt2(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Greenstadt's second Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return greenstadt2_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.HagerZhang","title":"HagerZhang","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Hager-Zhang nonlinear conjugate gradient method,</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class HagerZhang(ConguateGradientBase):\n    \"\"\"Hager-Zhang nonlinear conjugate gradient method,\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return hager_zhang_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/all/#torchzero.modules.HeavyBall","title":"HeavyBall","text":"<p>               Bases: <code>torchzero.modules.momentum.momentum.EMA</code></p> <p>Polyak's momentum (heavy-ball method).</p> <p>Parameters:</p> <ul> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>dampening</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>momentum dampening. Defaults to 0.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to debias the EMA like in Adam. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, this becomes exponential moving average. Defaults to False.</p> </li> <li> <code>ema_init</code>               (<code>str</code>, default:                   <code>'update'</code> )           \u2013            <p>initial values for the EMA, \"zeros\" or \"update\".</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target to apply EMA to. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/momentum.py</code> <pre><code>class HeavyBall(EMA):\n    \"\"\"Polyak's momentum (heavy-ball method).\n\n    Args:\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        dampening (float, optional): momentum dampening. Defaults to 0.\n        debias (bool, optional): whether to debias the EMA like in Adam. Defaults to False.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, this becomes exponential moving average. Defaults to False.\n        ema_init (str, optional): initial values for the EMA, \"zeros\" or \"update\".\n        target (Target, optional): target to apply EMA to. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, momentum:float=0.9, dampening:float=0, debias: bool = False, lerp=False, ema_init: Literal['zeros', 'update'] = 'update'):\n        super().__init__(momentum=momentum, dampening=dampening, debias=debias, lerp=lerp, ema_init=ema_init)\n</code></pre>"},{"location":"API/all/#torchzero.modules.HestenesStiefel","title":"HestenesStiefel","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Hestenes\u2013Stiefel nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class HestenesStiefel(ConguateGradientBase):\n    \"\"\"Hestenes\u2013Stiefel nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return hestenes_stiefel_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Horisho","title":"Horisho","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Horisho's variable metric Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Horisho(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Horisho's variable metric Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394\n    \"\"\"\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return hoshino_H_(H=H, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.HpuEstimate","title":"HpuEstimate","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>returns <code>y/||s||</code>, where <code>y</code> is difference between current and previous update (gradient), <code>s</code> is difference between current and previous parameters. The returned tensors are a finite difference approximation to hessian times previous update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class HpuEstimate(TensorTransform):\n    \"\"\"returns ``y/||s||``, where ``y`` is difference between current and previous update (gradient), ``s`` is difference between current and previous parameters. The returned tensors are a finite difference approximation to hessian times previous update.\"\"\"\n    def __init__(self):\n        defaults = dict()\n        super().__init__(defaults)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_params', 'prev_update')\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        prev_params, prev_update = self.get_state(params, 'prev_params', 'prev_update') # initialized to 0\n        s = torch._foreach_sub(params, prev_params)\n        y = torch._foreach_sub(tensors, prev_update)\n        for p, c in zip(prev_params, params): p.copy_(c)\n        for p, c in zip(prev_update, tensors): p.copy_(c)\n        torch._foreach_div_(y, torch.linalg.norm(torch.cat([t.ravel() for t in s])).clip(min=1e-8)) # pylint:disable=not-callable\n        self.store(params, 'y', y)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return [self.state[p]['y'] for p in params]\n</code></pre>"},{"location":"API/all/#torchzero.modules.ICUM","title":"ICUM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Inverse Column-updating Quasi-Newton method. This is computationally cheaper than other Quasi-Newton methods due to only updating one column of the inverse hessian approximation per step.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Lopes, V. L., &amp; Mart\u00ednez, J. M. (1995). Convergence properties of the inverse column-updating method. Optimization Methods &amp; Software, 6(2), 127\u2013144. from https://www.ime.unicamp.br/sites/default/files/pesquisa/relatorios/rp-1993-76.pdf</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ICUM(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Inverse Column-updating Quasi-Newton method. This is computationally cheaper than other Quasi-Newton methods\n    due to only updating one column of the inverse hessian approximation per step.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Lopes, V. L., &amp; Mart\u00ednez, J. M. (1995). Convergence properties of the inverse column-updating method. Optimization Methods &amp; Software, 6(2), 127\u2013144. from https://www.ime.unicamp.br/sites/default/files/pesquisa/relatorios/rp-1993-76.pdf\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return icum_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Identity","title":"Identity","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Identity(Module):\n    \"\"\"Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.\"\"\"\n    def __init__(self, *args, **kwargs): super().__init__()\n    def update(self, objective): pass\n    def apply(self, objective): return objective\n    def get_H(self, objective):\n        n = sum(p.numel() for p in objective.params)\n        p = objective.params[0]\n        return ScaledIdentity(shape=(n,n), device=p.device, dtype=p.dtype)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ImprovedNewton","title":"ImprovedNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Improved Newton's Method (INM).</p> Reference <p>Saheya, B., et al. \"A new Newton-like method for solving nonlinear equations.\" SpringerPlus 5.1 (2016): 1269.</p> Source code in <code>torchzero/modules/second_order/inm.py</code> <pre><code>class ImprovedNewton(Transform):\n    \"\"\"Improved Newton's Method (INM).\n\n    Reference:\n        [Saheya, B., et al. \"A new Newton-like method for solving nonlinear equations.\" SpringerPlus 5.1 (2016): 1269.](https://d-nb.info/1112813721/34)\n    \"\"\"\n\n    def __init__(\n        self,\n        damping: float = 0,\n        eigval_fn: Callable[[torch.Tensor], torch.Tensor] | None = None,\n        eigv_tol: float | None = None,\n        truncate: int | None = None,\n        update_freq: int = 1,\n        precompute_inverse: bool | None = None,\n        use_lstsq: bool = False,\n        hessian_method: HessianMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"update_freq\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner, )\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        _, f_list, J = objective.hessian(\n            hessian_method=fs['hessian_method'],\n            h=fs['h'],\n            at_x0=True\n        )\n        if f_list is None: f_list = objective.get_grads()\n\n        f = torch.cat([t.ravel() for t in f_list])\n        J = _eigval_fn(J, fs[\"eigval_fn\"])\n\n        x_list = TensorList(objective.params)\n        f_list = TensorList(objective.get_grads())\n        x_prev, f_prev = unpack_states(states, objective.params, \"x_prev\", \"f_prev\", cls=TensorList)\n\n        # initialize on 1st step, do Newton step\n        if \"H\" not in self.global_state:\n            x_prev.copy_(x_list)\n            f_prev.copy_(f_list)\n            P = J\n\n        # INM update\n        else:\n            s_list = x_list - x_prev\n            y_list = f_list - f_prev\n            x_prev.copy_(x_list)\n            f_prev.copy_(f_list)\n\n            P = inm(f, J, s=s_list.to_vec(), y=y_list.to_vec())\n\n        # update state\n        precompute_inverse = fs[\"precompute_inverse\"]\n        if precompute_inverse is None:\n            precompute_inverse = fs[\"__update_freq\"] &gt;= 10\n\n        _newton_update_state_(\n            H=P,\n            state = self.global_state,\n            damping = fs[\"damping\"],\n            eigval_fn = fs[\"eigval_fn\"],\n            eigv_tol = fs[\"eigv_tol\"],\n            truncate = fs[\"truncate\"],\n            precompute_inverse = precompute_inverse,\n            use_lstsq = fs[\"use_lstsq\"]\n        )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n        fs = settings[0]\n\n        b = torch.cat([t.ravel() for t in updates])\n        sol = _newton_solve(b=b, state=self.global_state, use_lstsq=fs[\"use_lstsq\"])\n\n        vec_to_tensors_(sol, updates)\n        return objective\n\n\n    def get_H(self,objective=...):\n        return _newton_get_H(self.global_state)\n</code></pre>"},{"location":"API/all/#torchzero.modules.IntermoduleCautious","title":"IntermoduleCautious","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Negaties update on :code:<code>main</code> module where it's sign doesn't match with output of <code>compare</code> module.</p> <p>Parameters:</p> <ul> <li> <code>main</code>               (<code>Chainable</code>)           \u2013            <p>main module or sequence of modules whose update will be cautioned.</p> </li> <li> <code>compare</code>               (<code>Chainable</code>)           \u2013            <p>modules or sequence of modules to compare the sign to.</p> </li> <li> <code>normalize</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>renormalize update after masking. Defaults to False.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for normalization. Defaults to 1e-6.</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'zero'</code> )           \u2013            <p>what to do with updates with inconsistent signs. - \"zero\" - set them to zero (as in paper) - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign) - \"backtrack\" - negate them</p> </li> </ul> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class IntermoduleCautious(Module):\n    \"\"\"Negaties update on :code:`main` module where it's sign doesn't match with output of ``compare`` module.\n\n    Args:\n        main (Chainable): main module or sequence of modules whose update will be cautioned.\n        compare (Chainable): modules or sequence of modules to compare the sign to.\n        normalize (bool, optional):\n            renormalize update after masking. Defaults to False.\n        eps (float, optional): epsilon for normalization. Defaults to 1e-6.\n        mode (str, optional):\n            what to do with updates with inconsistent signs.\n            - \"zero\" - set them to zero (as in paper)\n            - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign)\n            - \"backtrack\" - negate them\n    \"\"\"\n    def __init__(\n        self,\n        main: Chainable,\n        compare: Chainable,\n        normalize=False,\n        eps=1e-6,\n        mode: Literal[\"zero\", \"grad\", \"backtrack\"] = \"zero\",\n    ):\n\n        defaults = dict(normalize=normalize, eps=eps, mode=mode)\n        super().__init__(defaults)\n\n        self.set_child('main', main)\n        self.set_child('compare', compare)\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective):\n        main = self.children['main']\n        compare = self.children['compare']\n\n        main_var = main.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(main_var)\n\n        compare_var = compare.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(compare_var)\n\n        mode, normalize, eps = itemgetter('mode', 'normalize', 'eps')(self.defaults)\n        objective.updates = cautious_(\n            TensorList(main_var.get_updates()),\n            TensorList(compare_var.get_updates()),\n            normalize=normalize,\n            mode=mode,\n            eps=eps,\n        )\n\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.InverseFreeNewton","title":"InverseFreeNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Inverse-free newton's method</p> <p>Reference     Massalski, Marcin, and Magdalena Nockowska-Rosiak. \"INVERSE-FREE NEWTON'S METHOD.\" Journal of Applied Analysis &amp; Computation 15.4 (2025): 2238-2257.</p> Source code in <code>torchzero/modules/second_order/ifn.py</code> <pre><code>class InverseFreeNewton(Transform):\n    \"\"\"Inverse-free newton's method\n\n    Reference\n        [Massalski, Marcin, and Magdalena Nockowska-Rosiak. \"INVERSE-FREE NEWTON'S METHOD.\" Journal of Applied Analysis &amp; Computation 15.4 (2025): 2238-2257.](https://www.jaac-online.com/article/doi/10.11948/20240428)\n    \"\"\"\n    def __init__(\n        self,\n        update_freq: int = 1,\n        hessian_method: HessianMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(hessian_method=hessian_method, h=h)\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        _, _, H = objective.hessian(\n            hessian_method=fs['hessian_method'],\n            h=fs['h'],\n            at_x0=True\n        )\n\n        self.global_state[\"H\"] = H\n\n        # inverse free part\n        if 'Y' not in self.global_state:\n            num = H.T\n            denom = (torch.linalg.norm(H, 1) * torch.linalg.norm(H, float('inf'))) # pylint:disable=not-callable\n\n            finfo = torch.finfo(H.dtype)\n            self.global_state['Y'] = num.div_(denom.clip(min=finfo.tiny * 2, max=finfo.max / 2))\n\n        else:\n            Y = self.global_state['Y']\n            I2 = torch.eye(Y.size(0), device=Y.device, dtype=Y.dtype).mul_(2)\n            I2 -= H @ Y\n            self.global_state['Y'] = Y @ I2\n\n\n    def apply_states(self, objective, states, settings):\n        Y = self.global_state[\"Y\"]\n        g = torch.cat([t.ravel() for t in objective.get_updates()])\n        objective.updates = vec_to_tensors(Y@g, objective.params)\n        return objective\n\n    def get_H(self,objective=...):\n        return DenseWithInverse(A = self.global_state[\"H\"], A_inv=self.global_state[\"Y\"])\n</code></pre>"},{"location":"API/all/#torchzero.modules.LBFGS","title":"LBFGS","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Limited-memory BFGS algorithm. A line search or trust region is recommended.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>number of past parameter differences and gradient differences to store. Defaults to 10.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips updating the history if maximum absolute value of parameter difference is less than this value. Defaults to 1e-10.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever parameter difference is less then <code>ptol</code>, L-BFGS state will be reset. Defaults to None.</p> </li> <li> <code>gtol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips updating the history if if maximum absolute value of gradient difference is less than this value. Defaults to 1e-10.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever gradient difference is less then <code>gtol</code>, L-BFGS state will be reset. Defaults to None.</p> </li> <li> <code>sy_tol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>history will not be updated whenever s\u22c5y is less than this value (negative s\u22c5y means negative curvature)</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>makes first step, when hessian approximation is not available, small to reduce number of line search iterations. Defaults to True.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>how often to update L-BFGS history. Larger values may be better for stochastic optimization. Defaults to 1.</p> </li> <li> <code>damping</code>               (<code>Union</code>, default:                   <code>None</code> )           \u2013            <p>damping to use, can be \"powell\" or \"double\". Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional inner modules applied after updating L-BFGS history and before preconditioning. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.LBFGS--examples","title":"Examples:","text":"<p>L-BFGS with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(100),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>L-BFGS with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.LBFGS())\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/lbfgs.py</code> <pre><code>class LBFGS(TensorTransform):\n    \"\"\"Limited-memory BFGS algorithm. A line search or trust region is recommended.\n\n    Args:\n        history_size (int, optional):\n            number of past parameter differences and gradient differences to store. Defaults to 10.\n        ptol (float | None, optional):\n            skips updating the history if maximum absolute value of\n            parameter difference is less than this value. Defaults to 1e-10.\n        ptol_restart (bool, optional):\n            If true, whenever parameter difference is less then ``ptol``,\n            L-BFGS state will be reset. Defaults to None.\n        gtol (float | None, optional):\n            skips updating the history if if maximum absolute value of\n            gradient difference is less than this value. Defaults to 1e-10.\n        ptol_restart (bool, optional):\n            If true, whenever gradient difference is less then ``gtol``,\n            L-BFGS state will be reset. Defaults to None.\n        sy_tol (float | None, optional):\n            history will not be updated whenever s\u22c5y is less than this value (negative s\u22c5y means negative curvature)\n        scale_first (bool, optional):\n            makes first step, when hessian approximation is not available,\n            small to reduce number of line search iterations. Defaults to True.\n        update_freq (int, optional):\n            how often to update L-BFGS history. Larger values may be better for stochastic optimization. Defaults to 1.\n        damping (DampingStrategyType, optional):\n            damping to use, can be \"powell\" or \"double\". Defaults to None.\n        inner (Chainable | None, optional):\n            optional inner modules applied after updating L-BFGS history and before preconditioning. Defaults to None.\n\n    ## Examples:\n\n    L-BFGS with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(100),\n        tz.m.Backtracking()\n    )\n    ```\n\n    L-BFGS with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.LBFGS())\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        history_size=10,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        gtol_restart: bool = False,\n        sy_tol: float = 1e-32,\n        scale_first:bool=True,\n        update_freq = 1,\n        damping: DampingStrategyType = None,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(\n            history_size=history_size,\n            scale_first=scale_first,\n            ptol=ptol,\n            gtol=gtol,\n            ptol_restart=ptol_restart,\n            gtol_restart=gtol_restart,\n            sy_tol=sy_tol,\n            damping = damping,\n        )\n        super().__init__(defaults, inner=inner, update_freq=update_freq)\n\n        self.global_state['s_history'] = deque(maxlen=history_size)\n        self.global_state['y_history'] = deque(maxlen=history_size)\n        self.global_state['sy_history'] = deque(maxlen=history_size)\n\n    def _reset_self(self):\n        self.state.clear()\n        self.global_state['step'] = 0\n        self.global_state['s_history'].clear()\n        self.global_state['y_history'].clear()\n        self.global_state['sy_history'].clear()\n\n    def reset(self):\n        self._reset_self()\n        for c in self.children.values(): c.reset()\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('p_prev', 'g_prev')\n        self.global_state.pop('step', None)\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        p = as_tensorlist(params)\n        g = as_tensorlist(tensors)\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        # history of s and k\n        s_history: deque[TensorList] = self.global_state['s_history']\n        y_history: deque[TensorList] = self.global_state['y_history']\n        sy_history: deque[torch.Tensor] = self.global_state['sy_history']\n\n        ptol = self.defaults['ptol']\n        gtol = self.defaults['gtol']\n        ptol_restart = self.defaults['ptol_restart']\n        gtol_restart = self.defaults['gtol_restart']\n        sy_tol = self.defaults['sy_tol']\n        damping = self.defaults['damping']\n\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', cls=TensorList)\n\n        # 1st step - there are no previous params and grads, lbfgs will do normalized SGD step\n        if step == 0:\n            s = None; y = None; sy = None\n        else:\n            s = p - p_prev\n            y = g - g_prev\n\n            if damping is not None:\n                s, y = apply_damping(damping, s=s, y=y, g=g, H=self.get_H())\n\n            sy = s.dot(y)\n            # damping to be added here\n\n        below_tol = False\n        # tolerance on parameter difference to avoid exploding after converging\n        if ptol is not None:\n            if s is not None and s.abs().global_max() &lt;= ptol:\n                if ptol_restart:\n                    self._reset_self()\n                sy = None\n                below_tol = True\n\n        # tolerance on gradient difference to avoid exploding when there is no curvature\n        if gtol is not None:\n            if y is not None and y.abs().global_max() &lt;= gtol:\n                if gtol_restart: self._reset_self()\n                sy = None\n                below_tol = True\n\n        # store previous params and grads\n        if not below_tol:\n            p_prev.copy_(p)\n            g_prev.copy_(g)\n\n        # update effective preconditioning state\n        if sy is not None and sy &gt; sy_tol:\n            assert s is not None and y is not None and sy is not None\n\n            s_history.append(s)\n            y_history.append(y)\n            sy_history.append(sy)\n\n    def get_H(self, objective=...):\n        s_history = [tl.to_vec() for tl in self.global_state['s_history']]\n        y_history = [tl.to_vec() for tl in self.global_state['y_history']]\n        sy_history = self.global_state['sy_history']\n        return LBFGSLinearOperator(s_history, y_history, sy_history)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        scale_first = self.defaults['scale_first']\n\n        tensors = as_tensorlist(tensors)\n\n        s_history = self.global_state['s_history']\n        y_history = self.global_state['y_history']\n        sy_history = self.global_state['sy_history']\n\n        # precondition\n        dir = lbfgs_Hx(\n            x=tensors,\n            s_history=s_history,\n            y_history=y_history,\n            sy_history=sy_history,\n        )\n\n        # scale 1st step\n        if scale_first and self.global_state.get('step', 1) == 1:\n            dir *= initial_step_size(dir, eps=1e-7)\n\n        return dir\n</code></pre>"},{"location":"API/all/#torchzero.modules.LR","title":"LR","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Learning rate. Adding this module also adds support for LR schedulers.</p> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class LR(TensorTransform):\n    \"\"\"Learning rate. Adding this module also adds support for LR schedulers.\"\"\"\n    def __init__(self, lr: float):\n        defaults=dict(lr=lr)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return lazy_lr(TensorList(tensors), lr=[s['lr'] for s in settings], inplace=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.LSR1","title":"LSR1","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Limited-memory SR1 algorithm. A line search or trust region is recommended.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>number of past parameter differences and gradient differences to store. Defaults to 10.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>skips updating the history if maximum absolute value of parameter difference is less than this value. Defaults to None.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever parameter difference is less then <code>ptol</code>, L-SR1 state will be reset. Defaults to None.</p> </li> <li> <code>gtol</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>skips updating the history if if maximum absolute value of gradient difference is less than this value. Defaults to None.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever gradient difference is less then <code>gtol</code>, L-SR1 state will be reset. Defaults to None.</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>makes first step, when hessian approximation is not available, small to reduce number of line search iterations. Defaults to False.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>how often to update L-SR1 history. Larger values may be better for stochastic optimization. Defaults to 1.</p> </li> <li> <code>damping</code>               (<code>Union</code>, default:                   <code>None</code> )           \u2013            <p>damping to use, can be \"powell\" or \"double\". Defaults to None.</p> </li> <li> <code>compact</code>               (<code>bool</code>)           \u2013            <p>if True, uses a compact representation verstion of L-SR1. It is much faster computationally, but less stable.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional inner modules applied after updating L-SR1 history and before preconditioning. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.LSR1--examples","title":"Examples:","text":"<p>L-SR1 with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SR1(),\n    tz.m.StrongWolfe(c2=0.1, fallback=True)\n)\n</code></pre></p> <p>L-SR1 with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.LSR1())\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/lsr1.py</code> <pre><code>class LSR1(TensorTransform):\n    \"\"\"Limited-memory SR1 algorithm. A line search or trust region is recommended.\n\n    Args:\n        history_size (int, optional):\n            number of past parameter differences and gradient differences to store. Defaults to 10.\n        ptol (float | None, optional):\n            skips updating the history if maximum absolute value of\n            parameter difference is less than this value. Defaults to None.\n        ptol_restart (bool, optional):\n            If true, whenever parameter difference is less then ``ptol``,\n            L-SR1 state will be reset. Defaults to None.\n        gtol (float | None, optional):\n            skips updating the history if if maximum absolute value of\n            gradient difference is less than this value. Defaults to None.\n        ptol_restart (bool, optional):\n            If true, whenever gradient difference is less then ``gtol``,\n            L-SR1 state will be reset. Defaults to None.\n        scale_first (bool, optional):\n            makes first step, when hessian approximation is not available,\n            small to reduce number of line search iterations. Defaults to False.\n        update_freq (int, optional):\n            how often to update L-SR1 history. Larger values may be better for stochastic optimization. Defaults to 1.\n        damping (DampingStrategyType, optional):\n            damping to use, can be \"powell\" or \"double\". Defaults to None.\n        compact (bool, optional):\n            if True, uses a compact representation verstion of L-SR1. It is much faster computationally, but less stable.\n        inner (Chainable | None, optional):\n            optional inner modules applied after updating L-SR1 history and before preconditioning. Defaults to None.\n\n    ## Examples:\n\n    L-SR1 with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SR1(),\n        tz.m.StrongWolfe(c2=0.1, fallback=True)\n    )\n    ```\n\n    L-SR1 with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.LSR1())\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        history_size=10,\n        ptol: float | None = None,\n        ptol_restart: bool = False,\n        gtol: float | None = None,\n        gtol_restart: bool = False,\n        scale_first:bool=False,\n        update_freq = 1,\n        damping: DampingStrategyType = None,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(\n            history_size=history_size,\n            scale_first=scale_first,\n            ptol=ptol,\n            gtol=gtol,\n            ptol_restart=ptol_restart,\n            gtol_restart=gtol_restart,\n            damping = damping,\n        )\n        super().__init__(defaults, inner=inner, update_freq=update_freq)\n\n        self.global_state['s_history'] = deque(maxlen=history_size)\n        self.global_state['y_history'] = deque(maxlen=history_size)\n\n    def _reset_self(self):\n        self.state.clear()\n        self.global_state['step'] = 0\n        self.global_state['s_history'].clear()\n        self.global_state['y_history'].clear()\n\n    def reset(self):\n        self._reset_self()\n        for c in self.children.values(): c.reset()\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('p_prev', 'g_prev')\n        self.global_state.pop('step', None)\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        p = as_tensorlist(params)\n        g = as_tensorlist(tensors)\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        # history of s and k\n        s_history: deque = self.global_state['s_history']\n        y_history: deque = self.global_state['y_history']\n\n        ptol = self.defaults['ptol']\n        gtol = self.defaults['gtol']\n        ptol_restart = self.defaults['ptol_restart']\n        gtol_restart = self.defaults['gtol_restart']\n        damping = self.defaults['damping']\n\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', cls=TensorList)\n\n        # 1st step - there are no previous params and grads, lsr1 will do normalized SGD step\n        if step == 0:\n            s = None; y = None; sy = None\n        else:\n            s = p - p_prev\n            y = g - g_prev\n\n            if damping is not None:\n                s, y = apply_damping(damping, s=s, y=y, g=g, H=self.get_H())\n\n            sy = s.dot(y)\n            # damping to be added here\n\n        below_tol = False\n        # tolerance on parameter difference to avoid exploding after converging\n        if ptol is not None:\n            if s is not None and s.abs().global_max() &lt;= ptol:\n                if ptol_restart: self._reset_self()\n                sy = None\n                below_tol = True\n\n        # tolerance on gradient difference to avoid exploding when there is no curvature\n        if gtol is not None:\n            if y is not None and y.abs().global_max() &lt;= gtol:\n                if gtol_restart: self._reset_self()\n                sy = None\n                below_tol = True\n\n        # store previous params and grads\n        if not below_tol:\n            p_prev.copy_(p)\n            g_prev.copy_(g)\n\n        # update effective preconditioning state\n        if sy is not None:\n            assert s is not None and y is not None and sy is not None\n\n            s_history.append(s)\n            y_history.append(y)\n\n    def get_H(self, objective=...):\n        s_history = [tl.to_vec() for tl in self.global_state['s_history']]\n        y_history = [tl.to_vec() for tl in self.global_state['y_history']]\n        return LSR1LinearOperator(s_history, y_history)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        scale_first = self.defaults['scale_first']\n\n        tensors = as_tensorlist(tensors)\n\n        s_history = self.global_state['s_history']\n        y_history = self.global_state['y_history']\n\n        # precondition\n        dir = lsr1_Hx(\n            x=tensors,\n            s_history=s_history,\n            y_history=y_history,\n        )\n\n        # scale 1st step\n        if scale_first and self.global_state.get('step', 1) == 1:\n            dir *= initial_step_size(dir, eps=1e-7)\n\n        return dir\n</code></pre>"},{"location":"API/all/#torchzero.modules.LambdaHomotopy","title":"LambdaHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class LambdaHomotopy(HomotopyBase):\n    def __init__(self, fn: Callable[[torch.Tensor], torch.Tensor]):\n        defaults = dict(fn=fn)\n        super().__init__(defaults)\n\n    def loss_transform(self, loss): return self.defaults['fn'](loss)\n</code></pre>"},{"location":"API/all/#torchzero.modules.LaplacianSmoothing","title":"LaplacianSmoothing","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies laplacian smoothing via a fast Fourier transform solver which can improve generalization.</p> <p>Parameters:</p> <ul> <li> <code>sigma</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>controls the amount of smoothing. Defaults to 1.</p> </li> <li> <code>layerwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, applies smoothing to each parameter's gradient separately, Otherwise applies it to all gradients, concatenated into a single vector. Defaults to True.</p> </li> <li> <code>min_numel</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>minimum number of elements in a parameter to apply laplacian smoothing to. Only has effect if <code>layerwise</code> is True. Defaults to 4.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>what to set on var.</p> </li> </ul> <p>Examples: Laplacian Smoothing Gradient Descent optimizer as in the paper</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LaplacianSmoothing(),\n    tz.m.LR(1e-2),\n)\n</code></pre> Reference <p>Osher, S., Wang, B., Yin, P., Luo, X., Barekat, F., Pham, M., &amp; Lin, A. (2022). Laplacian smoothing gradient descent. Research in the Mathematical Sciences, 9(3), 55.</p> Source code in <code>torchzero/modules/smoothing/laplacian.py</code> <pre><code>class LaplacianSmoothing(TensorTransform):\n    \"\"\"Applies laplacian smoothing via a fast Fourier transform solver which can improve generalization.\n\n    Args:\n        sigma (float, optional): controls the amount of smoothing. Defaults to 1.\n        layerwise (bool, optional):\n            If True, applies smoothing to each parameter's gradient separately,\n            Otherwise applies it to all gradients, concatenated into a single vector. Defaults to True.\n        min_numel (int, optional):\n            minimum number of elements in a parameter to apply laplacian smoothing to.\n            Only has effect if `layerwise` is True. Defaults to 4.\n        target (str, optional):\n            what to set on var.\n\n    Examples:\n    Laplacian Smoothing Gradient Descent optimizer as in the paper\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LaplacianSmoothing(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Reference:\n        Osher, S., Wang, B., Yin, P., Luo, X., Barekat, F., Pham, M., &amp; Lin, A. (2022). Laplacian smoothing gradient descent. Research in the Mathematical Sciences, 9(3), 55.\n\n    \"\"\"\n    def __init__(self, sigma:float = 1, layerwise=True, min_numel = 4):\n        defaults = dict(sigma = sigma, layerwise=layerwise, min_numel=min_numel)\n        super().__init__(defaults)\n        # precomputed denominator for when layerwise=False\n        self.global_state['full_denominator'] = None\n\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        layerwise = settings[0]['layerwise']\n\n        # layerwise laplacian smoothing\n        if layerwise:\n\n            # precompute the denominator for each layer and store it in each parameters state\n            smoothed_target = TensorList()\n            for p, t, state, setting in zip(params, tensors, states, settings):\n                if p.numel() &gt; setting['min_numel']:\n                    if 'denominator' not in state: state['denominator'] = _precompute_denominator(p, setting['sigma'])\n                    smoothed_target.append(torch.fft.ifft(torch.fft.fft(t.view(-1)) / state['denominator']).real.view_as(t)) #pylint:disable=not-callable\n                else:\n                    smoothed_target.append(t)\n\n            return smoothed_target\n\n        # else\n        # full laplacian smoothing\n        # precompute full denominator\n        tensors = TensorList(tensors)\n        if self.global_state.get('full_denominator', None) is None:\n            self.global_state['full_denominator'] = _precompute_denominator(tensors.to_vec(), settings[0]['sigma'])\n\n        # apply the smoothing\n        vec = tensors.to_vec()\n        return tensors.from_vec(torch.fft.ifft(torch.fft.fft(vec) / self.global_state['full_denominator']).real)#pylint:disable=not-callable\n</code></pre>"},{"location":"API/all/#torchzero.modules.LastAbsoluteRatio","title":"LastAbsoluteRatio","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs ratio between absolute values of past two updates the numerator is determined by <code>numerator</code> argument.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastAbsoluteRatio(TensorTransform):\n    \"\"\"Outputs ratio between absolute values of past two updates the numerator is determined by ``numerator`` argument.\"\"\"\n    def __init__(self, numerator: Literal['cur', 'prev'] = 'cur', eps:float=1e-8):\n        defaults = dict(numerator=numerator, eps=eps)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', init = torch.ones_like) # initialized to ones\n        numerator = settings[0]['numerator']\n        eps = NumberList(s['eps'] for s in settings)\n\n        torch._foreach_abs_(tensors)\n        torch._foreach_clamp_min_(prev, eps)\n\n        if numerator == 'cur': ratio = torch._foreach_div(tensors, prev)\n        else: ratio = torch._foreach_div(prev, tensors)\n        for p, c in zip(prev, tensors): p.set_(c)\n        return ratio\n</code></pre>"},{"location":"API/all/#torchzero.modules.LastDifference","title":"LastDifference","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs difference between past two updates.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastDifference(TensorTransform):\n    \"\"\"Outputs difference between past two updates.\"\"\"\n    def __init__(self,):\n        super().__init__()\n        self.add_projected_keys(\"grad\", \"prev_tensors\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev_tensors = unpack_states(states, tensors, 'prev_tensors') # initialized to 0\n        difference = torch._foreach_sub(tensors, prev_tensors)\n        for p, c in zip(prev_tensors, tensors): p.set_(c)\n        return difference\n</code></pre>"},{"location":"API/all/#torchzero.modules.LastGradDifference","title":"LastGradDifference","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs difference between past two gradients.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastGradDifference(Module):\n    \"\"\"Outputs difference between past two gradients.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.add_projected_keys(\"grad\", \"prev_grad\")\n\n    @torch.no_grad\n    def apply(self, objective):\n        grad = objective.get_grads()\n        prev_grad = self.get_state(objective.params, 'prev_grad') # initialized to 0\n        difference = torch._foreach_sub(grad, prev_grad)\n        for p, c in zip(prev_grad, grad): p.copy_(c)\n        objective.updates = list(difference)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.LastProduct","title":"LastProduct","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs difference between past two updates.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastProduct(TensorTransform):\n    \"\"\"Outputs difference between past two updates.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', init=torch.ones_like) # initialized to 1 for prod\n        prod = torch._foreach_mul(tensors, prev)\n        for p, c in zip(prev, tensors): p.set_(c)\n        return prod\n</code></pre>"},{"location":"API/all/#torchzero.modules.LastRatio","title":"LastRatio","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs ratio between past two updates, the numerator is determined by <code>numerator</code> argument.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastRatio(TensorTransform):\n    \"\"\"Outputs ratio between past two updates, the numerator is determined by ``numerator`` argument.\"\"\"\n    def __init__(self, numerator: Literal['cur', 'prev'] = 'cur'):\n        defaults = dict(numerator=numerator)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', init = torch.ones_like) # initialized to ones\n        numerator = settings[0]['numerator']\n        if numerator == 'cur': ratio = torch._foreach_div(tensors, prev)\n        else: ratio = torch._foreach_div(prev, tensors)\n        for p, c in zip(prev, tensors): p.set_(c)\n        return ratio\n</code></pre>"},{"location":"API/all/#torchzero.modules.LerpModules","title":"LerpModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Does a linear interpolation of <code>input(tensors)</code> and <code>end(tensors)</code> based on a scalar <code>weight</code>.</p> <p>The output is given by <code>output = input(tensors) + weight * (end(tensors) - input(tensors))</code></p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class LerpModules(MultiOperationBase):\n    \"\"\"Does a linear interpolation of ``input(tensors)`` and ``end(tensors)`` based on a scalar ``weight``.\n\n    The output is given by ``output = input(tensors) + weight * (end(tensors) - input(tensors))``\n    \"\"\"\n    def __init__(self, input: Chainable, end: Chainable, weight: float):\n        defaults = dict(weight=weight)\n        super().__init__(defaults, input=input, end=end)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: list[torch.Tensor], end: list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        torch._foreach_lerp_(input, end, weight=self.defaults['weight'])\n        return input\n</code></pre>"},{"location":"API/all/#torchzero.modules.LevenbergMarquardt","title":"LevenbergMarquardt","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Levenberg-Marquardt trust region algorithm.</p> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>y</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>when <code>y=0</code>, identity matrix is added to hessian, when <code>y=1</code>, diagonal of the hessian approximation is added. Values between interpolate. This should only be used with Gauss-Newton. Defaults to 0.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When <code>hess_module</code> is <code>Newton</code> or <code>GaussNewton</code>, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, trust radius is multiplied by square root of gradient norm.</p> </li> <li> <code>fallback</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if <code>True</code>, when <code>hess_module</code> maintains hessian inverse which can't be inverted efficiently, it will be inverted anyway. When <code>False</code> (default), a <code>RuntimeError</code> will be raised instead.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.LevenbergMarquardt--examples","title":"Examples:","text":"<p>Gauss-Newton with Levenberg-Marquardt trust-region</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.GaussNewton()),\n)\n</code></pre> <p>LM-SR1 <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n)\n</code></pre></p> Source code in <code>torchzero/modules/trust_region/levenberg_marquardt.py</code> <pre><code>class LevenbergMarquardt(TrustRegionBase):\n    \"\"\"Levenberg-Marquardt trust region algorithm.\n\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set ``inverse=False`` when constructing them.\n        y (float, optional):\n            when ``y=0``, identity matrix is added to hessian, when ``y=1``, diagonal of the hessian approximation\n            is added. Values between interpolate. This should only be used with Gauss-Newton. Defaults to 0.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When ``hess_module`` is ``Newton`` or ``GaussNewton``, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        adaptive (bool, optional):\n            if True, trust radius is multiplied by square root of gradient norm.\n        fallback (bool, optional):\n            if ``True``, when ``hess_module`` maintains hessian inverse which can't be inverted efficiently, it will\n            be inverted anyway. When ``False`` (default), a ``RuntimeError`` will be raised instead.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n    ### Examples:\n\n    Gauss-Newton with Levenberg-Marquardt trust-region\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.GaussNewton()),\n    )\n    ```\n\n    LM-SR1\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        y: float = 0,\n        adaptive: bool = False,\n        fallback: bool = False,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(y=y, fallback=fallback, adaptive=adaptive)\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            boundary_tol=None,\n            radius_fn=None,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        y = settings['y']\n        adaptive = settings[\"adaptive\"]\n\n        if isinstance(H, linear_operator.DenseInverse):\n            if settings['fallback']:\n                H = H.to_dense()\n            else:\n                raise RuntimeError(\n                    f\"{self.children['hess_module']} maintains a hessian inverse. \"\n                    \"LevenbergMarquardt requires the hessian, not the inverse. \"\n                    \"If that module is a quasi-newton module, pass `inverse=False` on initialization. \"\n                    \"Or pass `fallback=True` to LevenbergMarquardt to allow inverting the hessian inverse, \"\n                    \"however that can be inefficient and unstable.\"\n                )\n\n        reg = 1/radius\n        if adaptive: reg = reg * torch.linalg.vector_norm(g).sqrt()\n\n        if y == 0:\n            return H.solve_plus_diag(g, reg) # pyright:ignore[reportAttributeAccessIssue]\n\n        diag = H.diagonal()\n        diag = torch.where(diag &lt; torch.finfo(diag.dtype).tiny * 2, 1, diag)\n        if y != 1: diag = (diag*y) + (1-y)\n        return H.solve_plus_diag(g, diag*reg)\n</code></pre>"},{"location":"API/all/#torchzero.modules.LineSearchBase","title":"LineSearchBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for line searches.</p> <p>This is an abstract class, to use it, subclass it and override <code>search</code>.</p> <p>Parameters:</p> <ul> <li> <code>defaults</code>               (<code>dict[str, Any] | None</code>)           \u2013            <p>dictionary with defaults.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>if this is specified, the search method will terminate upon evaluating the objective this many times, and step size with the lowest loss value will be used. This is useful when passing <code>make_objective</code> to an external library which doesn't have a maxiter option. Defaults to None.</p> </li> </ul> Other useful methods <ul> <li><code>evaluate_f</code> - returns loss with a given scalar step size</li> <li><code>evaluate_f_d</code> - returns loss and directional derivative with a given scalar step size</li> <li><code>make_objective</code> - creates a function that accepts a scalar step size and returns loss. This can be passed to a scalar solver, such as scipy.optimize.minimize_scalar.</li> <li><code>make_objective_with_derivative</code> - creates a function that accepts a scalar step size and returns a tuple with loss and directional derivative. This can be passed to a scalar solver.</li> </ul> <p>Examples:</p>"},{"location":"API/all/#torchzero.modules.LineSearchBase--basic-line-search","title":"Basic line search","text":"<p>This evaluates all step sizes in a range by using the :code:<code>self.evaluate_step_size</code> method. <pre><code>class GridLineSearch(LineSearch):\n    def __init__(self, start, end, num):\n        defaults = dict(start=start,end=end,num=num)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def search(self, update, var):\n\n        start = self.defaults[\"start\"]\n        end = self.defaults[\"end\"]\n        num = self.defaults[\"num\"]\n\n        lowest_loss = float(\"inf\")\n        best_step_size = best_step_size\n\n        for step_size in torch.linspace(start,end,num):\n            loss = self.evaluate_step_size(step_size.item(), var=var, backward=False)\n            if loss &lt; lowest_loss:\n                lowest_loss = loss\n                best_step_size = step_size\n\n        return best_step_size\n</code></pre></p>"},{"location":"API/all/#torchzero.modules.LineSearchBase--using-external-solver-via-selfmake_objective","title":"Using external solver via self.make_objective","text":"<p>Here we let :code:<code>scipy.optimize.minimize_scalar</code> solver find the best step size via :code:<code>self.make_objective</code></p> <pre><code>class ScipyMinimizeScalar(LineSearch):\n    def __init__(self, method: str | None = None):\n        defaults = dict(method=method)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def search(self, update, var):\n        objective = self.make_objective(var=var)\n        method = self.defaults[\"method\"]\n\n        res = self.scopt.minimize_scalar(objective, method=method)\n        return res.x\n</code></pre> <p>Methods:</p> <ul> <li> <code>evaluate_f</code>             \u2013              <p>evaluate function value at alpha <code>step_size</code>.</p> </li> <li> <code>evaluate_f_d</code>             \u2013              <p>evaluate function value and directional derivative in the direction of the update at step size <code>step_size</code>.</p> </li> <li> <code>evaluate_f_d_g</code>             \u2013              <p>evaluate function value, directional derivative, and gradient list at step size <code>step_size</code>.</p> </li> <li> <code>search</code>             \u2013              <p>Finds the step size to use</p> </li> </ul> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>class LineSearchBase(Module, ABC):\n    \"\"\"Base class for line searches.\n\n    This is an abstract class, to use it, subclass it and override `search`.\n\n    Args:\n        defaults (dict[str, Any] | None): dictionary with defaults.\n        maxiter (int | None, optional):\n            if this is specified, the search method will terminate upon evaluating\n            the objective this many times, and step size with the lowest loss value will be used.\n            This is useful when passing `make_objective` to an external library which\n            doesn't have a maxiter option. Defaults to None.\n\n    Other useful methods:\n        * ``evaluate_f`` - returns loss with a given scalar step size\n        * ``evaluate_f_d`` - returns loss and directional derivative with a given scalar step size\n        * ``make_objective`` - creates a function that accepts a scalar step size and returns loss. This can be passed to a scalar solver, such as scipy.optimize.minimize_scalar.\n        * ``make_objective_with_derivative`` - creates a function that accepts a scalar step size and returns a tuple with loss and directional derivative. This can be passed to a scalar solver.\n\n    Examples:\n\n    #### Basic line search\n\n    This evaluates all step sizes in a range by using the :code:`self.evaluate_step_size` method.\n    ```python\n    class GridLineSearch(LineSearch):\n        def __init__(self, start, end, num):\n            defaults = dict(start=start,end=end,num=num)\n            super().__init__(defaults)\n\n        @torch.no_grad\n        def search(self, update, var):\n\n            start = self.defaults[\"start\"]\n            end = self.defaults[\"end\"]\n            num = self.defaults[\"num\"]\n\n            lowest_loss = float(\"inf\")\n            best_step_size = best_step_size\n\n            for step_size in torch.linspace(start,end,num):\n                loss = self.evaluate_step_size(step_size.item(), var=var, backward=False)\n                if loss &lt; lowest_loss:\n                    lowest_loss = loss\n                    best_step_size = step_size\n\n            return best_step_size\n    ```\n\n    #### Using external solver via self.make_objective\n\n    Here we let :code:`scipy.optimize.minimize_scalar` solver find the best step size via :code:`self.make_objective`\n\n    ```python\n    class ScipyMinimizeScalar(LineSearch):\n        def __init__(self, method: str | None = None):\n            defaults = dict(method=method)\n            super().__init__(defaults)\n\n        @torch.no_grad\n        def search(self, update, var):\n            objective = self.make_objective(var=var)\n            method = self.defaults[\"method\"]\n\n            res = self.scopt.minimize_scalar(objective, method=method)\n            return res.x\n    ```\n    \"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, maxiter: int | None = None):\n        super().__init__(defaults)\n        self._maxiter = maxiter\n        self._reset()\n\n    def _reset(self):\n        self._current_step_size: float = 0\n        self._lowest_loss = float('inf')\n        self._best_step_size: float = 0\n        self._current_iter = 0\n        self._initial_params = None\n\n    def set_step_size_(\n        self,\n        step_size: float,\n        params: list[torch.Tensor],\n        update: list[torch.Tensor],\n    ):\n        if not math.isfinite(step_size): return\n\n         # avoid overflow error\n        step_size = clip_by_finfo(tofloat(step_size), torch.finfo(update[0].dtype))\n\n        # skip is parameters are already at suggested step size\n        if self._current_step_size == step_size: return\n\n        assert self._initial_params is not None\n        if step_size == 0:\n            new_params = [p.clone() for p in self._initial_params]\n        else:\n            new_params = torch._foreach_sub(self._initial_params, update, alpha=step_size)\n\n        for c, n in zip(params, new_params):\n            set_storage_(c, n)\n\n        self._current_step_size = step_size\n\n    def _set_per_parameter_step_size_(\n        self,\n        step_size: Sequence[float],\n        params: list[torch.Tensor],\n        update: list[torch.Tensor],\n    ):\n\n        assert self._initial_params is not None\n        if not np.isfinite(step_size).all(): step_size = [0 for _ in step_size]\n\n        if any(s!=0 for s in step_size):\n            new_params = torch._foreach_sub(self._initial_params, torch._foreach_mul(update, step_size))\n        else:\n            new_params = [p.clone() for p in self._initial_params]\n\n        for c, n in zip(params, new_params):\n            set_storage_(c, n)\n\n    def _loss(self, step_size: float, var: Objective, closure, params: list[torch.Tensor],\n              update: list[torch.Tensor], backward:bool=False) -&gt; float:\n\n        # if step_size is 0, we might already know the loss\n        if (var.loss is not None) and (step_size == 0):\n            return tofloat(var.loss)\n\n        # check max iter\n        if self._maxiter is not None and self._current_iter &gt;= self._maxiter: raise MaxLineSearchItersReached\n        self._current_iter += 1\n\n        # set new lr and evaluate loss with it\n        self.set_step_size_(step_size, params=params, update=update)\n        if backward:\n            with torch.enable_grad(): loss = closure()\n        else:\n            loss = closure(False)\n\n        # if it is the best so far, record it\n        if loss &lt; self._lowest_loss:\n            self._lowest_loss = tofloat(loss)\n            self._best_step_size = step_size\n\n        # if evaluated loss at step size 0, set it to var.loss\n        if step_size == 0:\n            var.loss = loss\n            if backward: var.grads = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n\n        return tofloat(loss)\n\n    def _loss_derivative_gradient(self, step_size: float, var: Objective, closure,\n                         params: list[torch.Tensor], update: list[torch.Tensor]):\n        # if step_size is 0, we might already know the derivative\n        if (var.grads is not None) and (step_size == 0):\n            loss = self._loss(step_size=step_size,var=var,closure=closure,params=params,update=update,backward=False)\n            derivative = - sum(t.sum() for t in torch._foreach_mul(var.grads, update))\n\n        else:\n            # loss with a backward pass sets params.grad\n            loss = self._loss(step_size=step_size,var=var,closure=closure,params=params,update=update,backward=True)\n\n            # directional derivative\n            derivative = - sum(t.sum() for t in torch._foreach_mul([p.grad if p.grad is not None\n                                                                    else torch.zeros_like(p) for p in params], update))\n\n        assert var.grads is not None\n        return loss, tofloat(derivative), var.grads\n\n    def _loss_derivative(self, step_size: float, var: Objective, closure,\n                         params: list[torch.Tensor], update: list[torch.Tensor]):\n        return self._loss_derivative_gradient(step_size=step_size, var=var,closure=closure,params=params,update=update)[:2]\n\n    def evaluate_f(self, step_size: float, var: Objective, backward:bool=False):\n        \"\"\"evaluate function value at alpha `step_size`.\"\"\"\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return self._loss(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates(),backward=backward)\n\n    def evaluate_f_d(self, step_size: float, var: Objective):\n        \"\"\"evaluate function value and directional derivative in the direction of the update at step size `step_size`.\"\"\"\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return self._loss_derivative(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n\n    def evaluate_f_d_g(self, step_size: float, var: Objective):\n        \"\"\"evaluate function value, directional derivative, and gradient list at step size `step_size`.\"\"\"\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return self._loss_derivative_gradient(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n\n    def make_objective(self, var: Objective, backward:bool=False):\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return partial(self._loss, var=var, closure=closure, params=var.params, update=var.get_updates(), backward=backward)\n\n    def make_objective_with_derivative(self, var: Objective):\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return partial(self._loss_derivative, var=var, closure=closure, params=var.params, update=var.get_updates())\n\n    def make_objective_with_derivative_and_gradient(self, var: Objective):\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return partial(self._loss_derivative_gradient, var=var, closure=closure, params=var.params, update=var.get_updates())\n\n    @abstractmethod\n    def search(self, update: list[torch.Tensor], var: Objective) -&gt; float:\n        \"\"\"Finds the step size to use\"\"\"\n\n    @torch.no_grad\n    def apply(self, objective: Objective) -&gt; Objective:\n        self._reset()\n\n        params = objective.params\n        self._initial_params = [p.clone() for p in params]\n        update = objective.get_updates()\n\n        try:\n            step_size = self.search(update=update, var=objective)\n        except MaxLineSearchItersReached:\n            step_size = self._best_step_size\n\n        step_size = clip_by_finfo(step_size, torch.finfo(update[0].dtype))\n\n        # set loss_approx\n        if objective.loss_approx is None: objective.loss_approx = self._lowest_loss\n\n        # if this is last module, directly update parameters to avoid redundant operations\n        if objective.modular is not None and self is objective.modular.modules[-1]:\n            self.set_step_size_(step_size, params=params, update=update)\n\n            objective.stop = True; objective.skip_update = True\n            return objective\n\n        # revert parameters and multiply update by step size\n        self.set_step_size_(0, params=params, update=update)\n        torch._foreach_mul_(objective.updates, step_size)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.LineSearchBase.evaluate_f","title":"evaluate_f","text":"<pre><code>evaluate_f(step_size: float, var: Objective, backward: bool = False)\n</code></pre> <p>evaluate function value at alpha <code>step_size</code>.</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>def evaluate_f(self, step_size: float, var: Objective, backward:bool=False):\n    \"\"\"evaluate function value at alpha `step_size`.\"\"\"\n    closure = var.closure\n    if closure is None: raise RuntimeError('line search requires closure')\n    return self._loss(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates(),backward=backward)\n</code></pre>"},{"location":"API/all/#torchzero.modules.LineSearchBase.evaluate_f_d","title":"evaluate_f_d","text":"<pre><code>evaluate_f_d(step_size: float, var: Objective)\n</code></pre> <p>evaluate function value and directional derivative in the direction of the update at step size <code>step_size</code>.</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>def evaluate_f_d(self, step_size: float, var: Objective):\n    \"\"\"evaluate function value and directional derivative in the direction of the update at step size `step_size`.\"\"\"\n    closure = var.closure\n    if closure is None: raise RuntimeError('line search requires closure')\n    return self._loss_derivative(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n</code></pre>"},{"location":"API/all/#torchzero.modules.LineSearchBase.evaluate_f_d_g","title":"evaluate_f_d_g","text":"<pre><code>evaluate_f_d_g(step_size: float, var: Objective)\n</code></pre> <p>evaluate function value, directional derivative, and gradient list at step size <code>step_size</code>.</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>def evaluate_f_d_g(self, step_size: float, var: Objective):\n    \"\"\"evaluate function value, directional derivative, and gradient list at step size `step_size`.\"\"\"\n    closure = var.closure\n    if closure is None: raise RuntimeError('line search requires closure')\n    return self._loss_derivative_gradient(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n</code></pre>"},{"location":"API/all/#torchzero.modules.LineSearchBase.search","title":"search","text":"<pre><code>search(update: list[Tensor], var: Objective) -&gt; float\n</code></pre> <p>Finds the step size to use</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>@abstractmethod\ndef search(self, update: list[torch.Tensor], var: Objective) -&gt; float:\n    \"\"\"Finds the step size to use\"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.Lion","title":"Lion","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Lion (EvoLved Sign Momentum) optimizer from https://arxiv.org/abs/2302.06675.</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>dampening for momentum. Defaults to 0.9.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum factor. Defaults to 0.99.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/lion.py</code> <pre><code>class Lion(TensorTransform):\n    \"\"\"Lion (EvoLved Sign Momentum) optimizer from https://arxiv.org/abs/2302.06675.\n\n    Args:\n        beta1 (float, optional): dampening for momentum. Defaults to 0.9.\n        beta2 (float, optional): momentum factor. Defaults to 0.99.\n    \"\"\"\n\n    def __init__(self, beta1: float = 0.9, beta2: float = 0.99):\n        defaults = dict(beta1=beta1, beta2=beta2)\n        super().__init__(defaults)\n\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        beta1, beta2 = unpack_dicts(settings, 'beta1', 'beta2', cls=NumberList)\n        exp_avg = unpack_states(states, tensors, 'exp_avg', cls=TensorList)\n        return lion_(TensorList(tensors), exp_avg, beta1, beta2)\n</code></pre>"},{"location":"API/all/#torchzero.modules.LiuStorey","title":"LiuStorey","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Liu-Storey nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class LiuStorey(ConguateGradientBase):\n    \"\"\"Liu-Storey nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return liu_storey_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/all/#torchzero.modules.LogHomotopy","title":"LogHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class LogHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return (loss+1e-12).log()\n</code></pre>"},{"location":"API/all/#torchzero.modules.MARSCorrection","title":"MARSCorrection","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>MARS variance reduction correction.</p> <p>Place any other momentum-based optimizer after this, make sure <code>beta</code> parameter matches with momentum in the optimizer.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>use the same beta as you use in the momentum module. Defaults to 0.9.</p> </li> <li> <code>scaling</code>               (<code>float</code>, default:                   <code>0.025</code> )           \u2013            <p>controls the scale of gradient correction in variance reduction. Defaults to 0.025.</p> </li> <li> <code>max_norm</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>clips norm of corrected gradients, None to disable. Defaults to 1.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.MARSCorrection--examples","title":"Examples:","text":"<p>Mars-AdamW <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.MARSCorrection(beta=0.95),\n    tz.m.Adam(beta1=0.95, beta2=0.99),\n    tz.m.WeightDecay(1e-3),\n    tz.m.LR(0.1)\n)\n</code></pre></p> <p>Mars-Lion <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.MARSCorrection(beta=0.9),\n    tz.m.Lion(beta1=0.9),\n    tz.m.LR(0.1)\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/mars.py</code> <pre><code>class MARSCorrection(TensorTransform):\n    \"\"\"MARS variance reduction correction.\n\n    Place any other momentum-based optimizer after this,\n    make sure ``beta`` parameter matches with momentum in the optimizer.\n\n    Args:\n        beta (float, optional): use the same beta as you use in the momentum module. Defaults to 0.9.\n        scaling (float, optional): controls the scale of gradient correction in variance reduction. Defaults to 0.025.\n        max_norm (float, optional): clips norm of corrected gradients, None to disable. Defaults to 1.\n\n    ## Examples:\n\n    Mars-AdamW\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.MARSCorrection(beta=0.95),\n        tz.m.Adam(beta1=0.95, beta2=0.99),\n        tz.m.WeightDecay(1e-3),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    Mars-Lion\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.MARSCorrection(beta=0.9),\n        tz.m.Lion(beta1=0.9),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        beta: float = 0.9,\n        scaling: float = 0.025,\n        max_norm: float | None = 1,\n    ):\n        defaults = dict(beta=beta, scaling=scaling, max_norm=max_norm)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"g_prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        g_prev = unpack_states(states, tensors, 'g_prev', init=tensors, cls=TensorList)\n        beta, scaling = unpack_dicts(settings, 'beta', 'scaling', cls=NumberList)\n        max_norm = settings[0]['max_norm']\n\n        return mars_correction_(\n            tensors_=TensorList(tensors),\n            g_prev_=g_prev,\n            beta=beta,\n            scaling=scaling,\n            max_norm=max_norm,\n        )\n</code></pre>"},{"location":"API/all/#torchzero.modules.MSAM","title":"MSAM","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> Note <p>Please make sure to place <code>tz.m.LR</code> inside the <code>modules</code> argument. For example, <code>tz.m.MSAMObjective([tz.m.Adam(), tz.m.LR(1e-3)])</code>. Putting LR after MSAM will lead to an incorrect update rule.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable</code>)           \u2013            <p>modules that will optimize the MSAM objective. Make sure <code>tz.m.LR</code> is one of them.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.3</code> )           \u2013            <p>perturbation strength. Defaults to 0.3.</p> </li> <li> <code>nesterov</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use nesterov momentum formula. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, MSAM momentum becomes similar to exponential moving average. Defaults to False.</p> </li> </ul> <p>Examples: AdamW-MSAM</p> <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.MSAMObjective(\n        [tz.m.Adam(), tz.m.WeightDecay(1e-3), tz.m.LR(1e-3)],\n        rho=1.\n    )\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/msam.py</code> <pre><code>class MSAM(Transform):\n    \"\"\"Momentum-SAM from https://arxiv.org/pdf/2401.12033.\n\n    Note:\n        Please make sure to place ``tz.m.LR`` inside the ``modules`` argument. For example,\n        ``tz.m.MSAMObjective([tz.m.Adam(), tz.m.LR(1e-3)])``. Putting LR after MSAM will lead\n        to an incorrect update rule.\n\n    Args:\n        modules (Chainable): modules that will optimize the MSAM objective. Make sure ``tz.m.LR`` is one of them.\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        rho (float, optional): perturbation strength. Defaults to 0.3.\n        nesterov (bool, optional): whether to use nesterov momentum formula. Defaults to False.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, MSAM momentum becomes similar to exponential moving average.\n            Defaults to False.\n\n    Examples:\n    AdamW-MSAM\n\n    ```py\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.MSAMObjective(\n            [tz.m.Adam(), tz.m.WeightDecay(1e-3), tz.m.LR(1e-3)],\n            rho=1.\n        )\n    )\n    ```\n    \"\"\"\n    def __init__(self, modules: Chainable, momentum:float=0.9, rho:float=0.3, weight_decay:float=0, nesterov=False, lerp=False):\n        defaults = dict(momentum=momentum, rho=rho, weight_decay=weight_decay, nesterov=nesterov, lerp=lerp)\n        super().__init__(defaults)\n\n        self.set_child('modules', modules)\n        self.add_projected_keys(\"grad\", \"velocity\")\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        velocity = unpack_states(states, objective.params, 'velocity', cls=TensorList)\n        fs = settings[0]\n\n        momentum, rho, weight_decay = unpack_dicts(settings, 'momentum', 'rho', 'weight_decay', cls=NumberList)\n\n        return msam_(\n            TensorList(objective.get_updates()),\n            params=TensorList(objective.params),\n            velocity_=velocity,\n            momentum=momentum,\n            lr=None,\n            rho=rho,\n            weight_decay=weight_decay,\n            nesterov=fs['nesterov'],\n            lerp=fs['lerp'],\n\n            # inner args\n            inner=self.children[\"modules\"],\n            objective=objective,\n        )\n</code></pre>"},{"location":"API/all/#torchzero.modules.MSAMMomentum","title":"MSAMMomentum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> <p>This implementation expresses the update rule as function of gradient. This way it can be used as a drop-in replacement for momentum strategies in other optimizers.</p> <p>To combine MSAM with other optimizers in the way done in the official implementation, e.g. to make Adam_MSAM, use <code>tz.m.MSAMObjective</code> module.</p> <p>Note     MSAM has a learning rate hyperparameter that can't really be removed from the update rule.     To avoid compounding learning rate mofications, remove the <code>tz.m.LR</code> module if you had it.</p> <p>Parameters:</p> <ul> <li> <code>lr</code>               (<code>float</code>)           \u2013            <p>learning rate. Adding this module adds support for learning rate schedulers.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.3</code> )           \u2013            <p>perturbation strength. Defaults to 0.3.</p> </li> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>weight decay. It is applied to perturbed parameters, so it is differnet from applying :code:<code>tz.m.WeightDecay</code> after MSAM. Defaults to 0.</p> </li> <li> <code>nesterov</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use nesterov momentum formula. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.MSAMMomentum--examples","title":"Examples:","text":"<p>MSAM</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.MSAM(1e-3)\n)\n</code></pre> <p>Adam with MSAM instead of exponential average. Note that this is different from Adam_MSAM. To make Adam_MSAM and such, use the <code>tz.m.MSAMObjective</code> module.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.RMSprop(0.999, inner=tz.m.MSAM(1e-3)),\n    tz.m.Debias(0.9, 0.999),\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/msam.py</code> <pre><code>class MSAMMomentum(TensorTransform):\n    \"\"\"Momentum-SAM from https://arxiv.org/pdf/2401.12033.\n\n    This implementation expresses the update rule as function of gradient. This way it can be used as a drop-in\n    replacement for momentum strategies in other optimizers.\n\n    To combine MSAM with other optimizers in the way done in the official implementation,\n    e.g. to make Adam_MSAM, use ``tz.m.MSAMObjective`` module.\n\n    Note\n        MSAM has a learning rate hyperparameter that can't really be removed from the update rule.\n        To avoid compounding learning rate mofications, remove the ``tz.m.LR`` module if you had it.\n\n    Args:\n        lr (float): learning rate. Adding this module adds support for learning rate schedulers.\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        rho (float, optional): perturbation strength. Defaults to 0.3.\n        weight_decay (float, optional):\n            weight decay. It is applied to perturbed parameters, so it is differnet\n            from applying :code:`tz.m.WeightDecay` after MSAM. Defaults to 0.\n        nesterov (bool, optional): whether to use nesterov momentum formula. Defaults to False.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.\n\n    ### Examples:\n\n    MSAM\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.MSAM(1e-3)\n    )\n    ```\n\n    Adam with MSAM instead of exponential average. Note that this is different from Adam_MSAM.\n    To make Adam_MSAM and such, use the ``tz.m.MSAMObjective`` module.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.RMSprop(0.999, inner=tz.m.MSAM(1e-3)),\n        tz.m.Debias(0.9, 0.999),\n    )\n    ```\n    \"\"\"\n\n    def __init__(self, lr: float, momentum:float=0.9, rho:float=0.3,  weight_decay:float=0, nesterov=False, lerp=False,):\n        defaults = dict(lr = lr, momentum=momentum, rho=rho, nesterov=nesterov, lerp=lerp, weight_decay=weight_decay)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"velocity\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        velocity = unpack_states(states, tensors, 'velocity', cls=TensorList)\n        fs = settings[0]\n\n        lr, momentum, rho, weight_decay = unpack_dicts(settings, 'lr','momentum','rho','weight_decay', cls=NumberList)\n\n        return msam_(\n            TensorList(tensors),\n            params=TensorList(params),\n            velocity_=velocity,\n            momentum=momentum,\n            lr=lr,\n            rho=rho,\n            weight_decay=weight_decay,\n            nesterov=fs['nesterov'],\n            lerp=fs['lerp'],\n\n            # inner args\n            inner=None,\n            objective=None,\n        )\n</code></pre>"},{"location":"API/all/#torchzero.modules.MatrixMomentum","title":"MatrixMomentum","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Second order momentum method.</p> <p>Matrix momentum is useful for convex objectives, also for some reason it has very really good generalization on elastic net logistic regression.</p> Notes <ul> <li> <p><code>mu</code> needs to be tuned very carefully. It is supposed to be smaller than (1/largest eigenvalue), otherwise this will be very unstable. I have devised an adaptive version of this - <code>tz.m.AdaptiveMatrixMomentum</code>, and it works well without having to tune <code>mu</code>, however the adaptive version doesn't work on stochastic objectives.</p> </li> <li> <p>In most cases <code>MatrixMomentum</code> should be the first module in the chain because it relies on autograd.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>mu</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>this has a similar role to (1 - beta) in normal momentum. Defaults to 0.1.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to <code>\"autograd\"</code>. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>hvp_tfm</code>               (<code>Chainable | None</code>)           \u2013            <p>optional module applied to hessian-vector products. Defaults to None.</p> </li> </ul> Reference <p>Orr, Genevieve, and Todd Leen. \"Using curvature information for fast stochastic search.\" Advances in neural information processing systems 9 (1996).</p> Source code in <code>torchzero/modules/adaptive/matrix_momentum.py</code> <pre><code>class MatrixMomentum(Transform):\n    \"\"\"Second order momentum method.\n\n    Matrix momentum is useful for convex objectives, also for some reason it has very really good generalization on elastic net logistic regression.\n\n    Notes:\n        - ``mu`` needs to be tuned very carefully. It is supposed to be smaller than (1/largest eigenvalue), otherwise this will be very unstable. I have devised an adaptive version of this - ``tz.m.AdaptiveMatrixMomentum``, and it works well without having to tune ``mu``, however the adaptive version doesn't work on stochastic objectives.\n\n        - In most cases ``MatrixMomentum`` should be the first module in the chain because it relies on autograd.\n\n        - This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument.\n\n    Args:\n        mu (float, optional): this has a similar role to (1 - beta) in normal momentum. Defaults to 0.1.\n        hvp_method (str, optional):\n            Determines how hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        hvp_tfm (Chainable | None, optional): optional module applied to hessian-vector products. Defaults to None.\n\n    Reference:\n        Orr, Genevieve, and Todd Leen. \"Using curvature information for fast stochastic search.\" Advances in neural information processing systems 9 (1996).\n    \"\"\"\n\n    def __init__(\n        self,\n        lr:float,\n        mu=0.1,\n        hvp_method: HVPMethod = \"autograd\",\n        h: float = 1e-3,\n        adaptive:bool = False,\n        adapt_freq: int | None = None,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(lr=lr, mu=mu, hvp_method=hvp_method, h=h, adaptive=adaptive, adapt_freq=adapt_freq)\n        super().__init__(defaults, inner=inner)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('p_prev')\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        step = self.increment_counter(\"step\", 0)\n        p = TensorList(objective.params)\n        p_prev = unpack_states(states, p, 'p_prev', init=p)\n\n        fs = settings[0]\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n\n        if step &gt; 0:\n            s = p - p_prev\n\n            Hs, _ = objective.hessian_vector_product(s, at_x0=True, rgrad=None, hvp_method=hvp_method, h=h, retain_graph=False)\n            Hs = [t.detach() for t in Hs]\n\n            self.store(p, (\"Hs\", \"s\"), (Hs, s))\n\n            # -------------------------------- adaptive mu ------------------------------- #\n            if fs[\"adaptive\"]:\n                g = TensorList(objective.get_grads())\n\n                if fs[\"adapt_freq\"] is None:\n                    # ---------------------------- deterministic case ---------------------------- #\n                    g_prev = unpack_states(states, p, \"g_prev\", cls=TensorList)\n                    y = g - g_prev\n                    g_prev.copy_(g)\n                    denom = y.global_vector_norm()\n                    denom = denom.clip(min=torch.finfo(denom.dtype).tiny * 2)\n                    self.global_state[\"mu_mul\"] = s.global_vector_norm() / denom\n\n                else:\n                    # -------------------------------- stochastic -------------------------------- #\n                    adapt_freq = self.defaults[\"adapt_freq\"]\n\n                    # we start on 1nd step, and want to adapt when we start, so use (step - 1)\n                    if (step - 1) % adapt_freq == 0:\n                        assert objective.closure is not None\n                        params = TensorList(objective.params)\n                        p_cur = params.clone()\n\n                        # move to previous params and evaluate p_prev with current mini-batch\n                        params.copy_(unpack_states(states, p, 'p_prev'))\n                        with torch.enable_grad():\n                            objective.closure()\n                        g_prev = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n                        y = g - g_prev\n\n                        # move back to current params\n                        params.copy_(p_cur)\n\n                        denom = y.global_vector_norm()\n                        denom = denom.clip(min=torch.finfo(denom.dtype).tiny * 2)\n                        self.global_state[\"mu_mul\"] = s.global_vector_norm() / denom\n\n        torch._foreach_copy_(p_prev, objective.params)\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        update = TensorList(objective.get_updates())\n        lr, mu = unpack_dicts(settings, \"lr\", 'mu', cls=NumberList)\n\n        if \"mu_mul\" in self.global_state:\n            mu = mu * self.global_state[\"mu_mul\"]\n\n        # --------------------------------- 1st step --------------------------------- #\n        # p_prev is not available so make a small step\n        step = self.global_state[\"step\"]\n        if step == 1:\n            if self.defaults[\"adaptive\"]:\n                # initialize\n                unpack_states(states, objective.params, \"g_prev\", init=objective.get_grads())\n\n            update.mul_(lr) # separate so that initial_step_size can clip correctly\n            update.mul_(initial_step_size(update, 1e-7))\n            return objective\n\n        # -------------------------- matrix momentum update -------------------------- #\n        s, Hs = unpack_states(states, objective.params, 's', 'Hs', cls=TensorList)\n\n        update.mul_(lr).sub_(s).add_(Hs*mu)\n        objective.updates = update\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Maximum","title":"Maximum","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>maximum(tensors, other(tensors))</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Maximum(BinaryOperationBase):\n    \"\"\"Outputs ``maximum(tensors, other(tensors))``\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        torch._foreach_maximum_(update, other)\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.MaximumModules","title":"MaximumModules","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs elementwise maximum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class MaximumModules(ReduceOperationBase):\n    \"\"\"Outputs elementwise maximum of ``inputs`` that can be modules or numbers.\"\"\"\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        maximum = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_maximum_(maximum, v)\n\n        return maximum\n</code></pre>"},{"location":"API/all/#torchzero.modules.McCormick","title":"McCormick","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>McCormicks's Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.</p> <p>This is \"Algorithm 2\", attributed to McCormick in this paper. However for some reason this method is also called Pearson's 2nd method in other sources.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class McCormick(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"McCormicks's Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.\n\n        This is \"Algorithm 2\", attributed to McCormick in this paper. However for some reason this method is also called Pearson's 2nd method in other sources.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return mccormick_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.MeZO","title":"MeZO","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>Gradient approximation via memory-efficient zeroth order optimizer (MeZO) - https://arxiv.org/abs/2305.17333.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central2'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'rademacher'</code> )           \u2013            <p>distribution. Defaults to \"rademacher\". If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Malladi, S., Gao, T., Nichani, E., Damian, A., Lee, J. D., Chen, D., &amp; Arora, S. (2023). Fine-tuning language models with just forward passes. Advances in Neural Information Processing Systems, 36, 53038-53075. https://arxiv.org/abs/2305.17333</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class MeZO(GradApproximator):\n    \"\"\"Gradient approximation via memory-efficient zeroth order optimizer (MeZO) - https://arxiv.org/abs/2305.17333.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"rademacher\".\n            If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Malladi, S., Gao, T., Nichani, E., Damian, A., Lee, J. D., Chen, D., &amp; Arora, S. (2023). Fine-tuning language models with just forward passes. Advances in Neural Information Processing Systems, 36, 53038-53075. https://arxiv.org/abs/2305.17333\n    \"\"\"\n\n    def __init__(self, h: float=1e-3, n_samples: int = 1, formula: _FD_Formula = 'central2',\n                 distribution: Distributions = 'rademacher', return_approx_loss: bool = False, target: GradTarget = 'closure'):\n\n        defaults = dict(h=h, formula=formula, n_samples=n_samples, distribution=distribution)\n        super().__init__(defaults, return_approx_loss=return_approx_loss, target=target)\n\n    def _seeded_perturbation(self, params: list[torch.Tensor], distribution, seed, h):\n        prt = TensorList(params).sample_like(\n            distribution=distribution,\n            variance=h,\n            generator=torch.Generator(params[0].device).manual_seed(seed)\n        )\n        return prt\n\n    def pre_step(self, objective):\n        h = NumberList(self.settings[p]['h'] for p in objective.params)\n\n        n_samples = self.defaults['n_samples']\n        distribution = self.defaults['distribution']\n\n        step = objective.current_step\n\n        # create functions that generate a deterministic perturbation from seed based on current step\n        prt_fns = []\n        for i in range(n_samples):\n\n            prt_fn = partial(self._seeded_perturbation, params=objective.params, distribution=distribution, seed=1_000_000*step + i, h=h)\n            prt_fns.append(prt_fn)\n\n        self.global_state['prt_fns'] = prt_fns\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        params = TensorList(params)\n        loss_approx = None\n\n        h = NumberList(self.settings[p]['h'] for p in params)\n        n_samples = self.defaults['n_samples']\n        fd_fn = _RFD_FUNCS[self.defaults['formula']]\n\n        prt_fns = self.global_state['prt_fns']\n\n        grad = None\n        for i in range(n_samples):\n            loss, loss_approx, d = fd_fn(closure=closure, params=params, p_fn=prt_fns[i], h=h, f_0=loss)\n            if grad is None: grad = prt_fns[i]().mul_(d)\n            else: grad += prt_fns[i]().mul_(d)\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/all/#torchzero.modules.Mean","title":"Mean","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.Sum</code></p> <p>Outputs a mean of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class Mean(Sum):\n    \"\"\"Outputs a mean of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = True\n</code></pre>"},{"location":"API/all/#torchzero.modules.Mean.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.MedianAveraging","title":"MedianAveraging","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Median of past <code>history_size</code> updates.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>)           \u2013            <p>Number of past updates to average</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/averaging.py</code> <pre><code>class MedianAveraging(TensorTransform):\n    \"\"\"Median of past ``history_size`` updates.\n\n    Args:\n        history_size (int): Number of past updates to average\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, history_size: int,):\n        defaults = dict(history_size = history_size)\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        history_size = setting['history_size']\n\n        if 'history' not in state:\n            state['history'] = deque(maxlen=history_size)\n\n        history = state['history']\n        history.append(tensor)\n\n        stacked = torch.stack(tuple(history), 0)\n        return torch.quantile(stacked, 0.5, dim = 0)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Minimum","title":"Minimum","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>minimum(tensors, other(tensors))</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Minimum(BinaryOperationBase):\n    \"\"\"Outputs ``minimum(tensors, other(tensors))``\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        torch._foreach_minimum_(update, other)\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.MinimumModules","title":"MinimumModules","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs elementwise minimum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class MinimumModules(ReduceOperationBase):\n    \"\"\"Outputs elementwise minimum of ``inputs`` that can be modules or numbers.\"\"\"\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        minimum = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_minimum_(minimum, v)\n\n        return minimum\n</code></pre>"},{"location":"API/all/#torchzero.modules.Mul","title":"Mul","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Multiply tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>tensors * other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Mul(BinaryOperationBase):\n    \"\"\"Multiply tensors by ``other``. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``tensors * other(tensors)``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        torch._foreach_mul_(update, other)\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.MulByLoss","title":"MulByLoss","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies update by loss times <code>alpha</code></p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class MulByLoss(TensorTransform):\n    \"\"\"Multiplies update by loss times ``alpha``\"\"\"\n    def __init__(self, alpha: float = 1, min_value:float = 1e-16, backward: bool = True):\n        defaults = dict(alpha=alpha, min_value=min_value, backward=backward)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        alpha, min_value = unpack_dicts(settings, 'alpha', 'min_value')\n        mul = [max(loss*a, mv) for a,mv in zip(alpha, min_value)]\n        torch._foreach_mul_(tensors, mul)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.MultiOperationBase","title":"MultiOperationBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for operations that use operands. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> <p>Methods:</p> <ul> <li> <code>transform</code>             \u2013              <p>applies the operation to operands</p> </li> </ul> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class MultiOperationBase(Module, ABC):\n    \"\"\"Base class for operations that use operands. This is an abstract class, subclass it and override `transform` method to use it.\"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, **operands: Chainable | Any):\n        super().__init__(defaults=defaults)\n\n        self.operands = {}\n        for k,v in operands.items():\n\n            if isinstance(v, (Module, Sequence)):\n                self.set_child(k, v)\n                self.operands[k] = self.children[k]\n            else:\n                self.operands[k] = v\n\n        if not self.children:\n            raise ValueError('At least one operand must be a module')\n\n    @abstractmethod\n    def transform(self, objective: Objective, **operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        \"\"\"applies the operation to operands\"\"\"\n        raise NotImplementedError\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective: Objective) -&gt; Objective:\n        # pass cloned update to all module operands\n        processed_operands: dict[str, Any | list[torch.Tensor]] = self.operands.copy()\n\n        for k,v in self.operands.items():\n            if k in self.children:\n                v: Module\n                updated_obj = v.step(objective.clone(clone_updates=True))\n                processed_operands[k] = updated_obj.get_updates()\n                objective.update_attrs_from_clone_(updated_obj) # update loss, grad, etc if this module calculated them\n\n        transformed = self.transform(objective, **processed_operands)\n        objective.updates = transformed\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.MultiOperationBase.transform","title":"transform","text":"<pre><code>transform(objective: Objective, **operands: Any | list[Tensor]) -&gt; list[Tensor]\n</code></pre> <p>applies the operation to operands</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>@abstractmethod\ndef transform(self, objective: Objective, **operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n    \"\"\"applies the operation to operands\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"API/all/#torchzero.modules.Multistep","title":"Multistep","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Performs <code>steps</code> inner steps with <code>module</code> per each step.</p> <p>The update is taken to be the parameter difference between parameters before and after the inner loop.</p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class Multistep(Module):\n    \"\"\"Performs ``steps`` inner steps with ``module`` per each step.\n\n    The update is taken to be the parameter difference between parameters before and after the inner loop.\"\"\"\n    def __init__(self, module: Chainable, steps: int):\n        defaults = dict(steps=steps)\n        super().__init__(defaults)\n        self.set_child('module', module)\n\n    @torch.no_grad\n    def apply(self, objective):\n        return _sequential_step(self, objective, sequential=False)\n</code></pre>"},{"location":"API/all/#torchzero.modules.MuonAdjustLR","title":"MuonAdjustLR","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>LR adjustment for Muon from \"Muon is Scalable for LLM Training\" (https://github.com/MoonshotAI/Moonlight/tree/master). Orthogonalize already has this built in with the <code>adjust_lr</code> setting, however you might want to move this to be later in the chain.</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>class MuonAdjustLR(Transform):\n    \"\"\"LR adjustment for Muon from \"Muon is Scalable for LLM Training\" (https://github.com/MoonshotAI/Moonlight/tree/master).\n    Orthogonalize already has this built in with the ``adjust_lr`` setting, however you might want to move this to be later in the chain.\"\"\"\n    def __init__(self, channel_first: bool = True, alpha: float = 1):\n        defaults = dict(channel_first=channel_first, alpha=alpha)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alphas = [s['alpha'] for s in settings]\n        channel_first = [s[\"channel_first=channel_first\"] for s in settings]\n        tensors_alphas = [\n            (t, adjust_lr_for_muon(a, t.shape, cf)) for t, a, cf in zip(tensors, alphas, channel_first) if _is_at_least_2d(t, channel_first=cf)\n        ]\n        tensors = [i[0] for i in tensors_alphas]\n        a = [i[1] for i in alphas]\n        torch._foreach_mul_(tensors, a)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.NAG","title":"NAG","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Nesterov accelerated gradient method (nesterov momentum).</p> <p>Parameters:</p> <ul> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>dampening</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>momentum dampening. Defaults to 0.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target to apply EMA to. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/momentum.py</code> <pre><code>class NAG(TensorTransform):\n    \"\"\"Nesterov accelerated gradient method (nesterov momentum).\n\n    Args:\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        dampening (float, optional): momentum dampening. Defaults to 0.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.\n        target (Target, optional): target to apply EMA to. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, momentum:float=0.9, dampening:float=0, lerp=False):\n        defaults = dict(momentum=momentum,dampening=dampening, lerp=lerp)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"velocity\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        velocity = unpack_states(states, tensors, 'velocity', cls=TensorList)\n        lerp = self.settings[params[0]]['lerp']\n\n        momentum,dampening = unpack_dicts(settings, 'momentum','dampening', cls=NumberList)\n        return nag_(TensorList(tensors), velocity_=velocity,momentum=momentum,dampening=dampening,lerp=lerp)\n</code></pre>"},{"location":"API/all/#torchzero.modules.NanToNum","title":"NanToNum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Convert <code>nan</code>, <code>inf</code> and <code>-</code>inf`` to numbers.</p> <p>Parameters:</p> <ul> <li> <code>nan</code>               (<code>optional</code>, default:                   <code>None</code> )           \u2013            <p>the value to replace NaNs with. Default is zero.</p> </li> <li> <code>posinf</code>               (<code>optional</code>, default:                   <code>None</code> )           \u2013            <p>if a Number, the value to replace positive infinity values with. If None, positive infinity values are replaced with the greatest finite value representable by input's dtype. Default is None.</p> </li> <li> <code>neginf</code>               (<code>optional</code>, default:                   <code>None</code> )           \u2013            <p>if a Number, the value to replace negative infinity values with. If None, negative infinity values are replaced with the lowest finite value representable by input's dtype. Default is None.</p> </li> </ul> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class NanToNum(TensorTransform):\n    \"\"\"Convert ``nan``, ``inf`` and `-`inf`` to numbers.\n\n    Args:\n        nan (optional): the value to replace NaNs with. Default is zero.\n        posinf (optional): if a Number, the value to replace positive infinity values with.\n            If None, positive infinity values are replaced with the greatest finite value\n            representable by input's dtype. Default is None.\n        neginf (optional): if a Number, the value to replace negative infinity values with.\n            If None, negative infinity values are replaced with the lowest finite value\n            representable by input's dtype. Default is None.\n    \"\"\"\n    def __init__(self, nan=None, posinf=None, neginf=None):\n        defaults = dict(nan=nan, posinf=posinf, neginf=neginf)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        nan, posinf, neginf = unpack_dicts(settings, 'nan', 'posinf', 'neginf')\n        return [t.nan_to_num_(nan_i, posinf_i, neginf_i) for t, nan_i, posinf_i, neginf_i in zip(tensors, nan, posinf, neginf)]\n</code></pre>"},{"location":"API/all/#torchzero.modules.NaturalGradient","title":"NaturalGradient","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Natural gradient approximated via empirical fisher information matrix.</p> <p>To use this, either pass vector of per-sample losses to the step method, or make sure the closure returns it. Gradients will be calculated via batched autograd within this module, you don't need to implement the backward pass. When using closure, please add the <code>backward</code> argument, it will always be False but it is required. See below for an example.</p> Note <p>Empirical fisher information matrix may give a really bad approximation in some cases. If that is the case, set <code>sqrt</code> to True to perform whitening instead, which is way more robust.</p> <p>Parameters:</p> <ul> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>regularization parameter. Defaults to 1e-8.</p> </li> <li> <code>sqrt</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, uses square root of empirical fisher information matrix. Both EFIM and it's square root can be calculated and stored efficiently without ndim^2 memory. Square root whitens the gradient and often performs much better, especially when you try to use NGD with a vector that isn't strictly per-sample gradients, but rather for example different losses.</p> </li> <li> <code>gn_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, uses Gauss-Newton G^T @ f as the gradient, which is effectively sum weighted by value and is equivalent to squaring the values. That makes the kernel trick solver incorrect, but for some reason it still works. If False, uses sum of per-sample gradients. This has an effect when <code>sqrt=False</code>, and affects the <code>grad</code> attribute. Defaults to False.</p> </li> <li> <code>batched</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use vmapping. Defaults to True.</p> </li> </ul> <p>Examples:</p> <p>training a neural network: <pre><code>X = torch.randn(64, 20)\ny = torch.randn(64, 10)\n\nmodel = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NaturalGradient(),\n    tz.m.LR(3e-2)\n)\n\nfor i in range(100):\n    y_hat = model(X) # (64, 10)\n    losses = (y_hat - y).pow(2).mean(0) # (10, )\n    opt.step(loss=losses)\n    if i % 10 == 0:\n        print(f'{losses.mean() = }')\n</code></pre></p> <p>training a neural network - closure version <pre><code>X = torch.randn(64, 20)\ny = torch.randn(64, 10)\n\nmodel = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NaturalGradient(),\n    tz.m.LR(3e-2)\n)\n\ndef closure(backward=True):\n    y_hat = model(X) # (64, 10)\n    return (y_hat - y).pow(2).mean(0) # (10, )\n\nfor i in range(100):\n    losses = opt.step(closure)\n    if i % 10 == 0:\n    print(f'{losses.mean() = }')\n</code></pre></p> <p>minimizing the rosenbrock function with a mix of natural gradient, whitening and gauss-newton: <pre><code>def rosenbrock(X):\n    x1, x2 = X\n    return torch.stack([(1 - x1).abs(), (10 * (x2 - x1**2).abs())])\n\nX = torch.tensor([-1.1, 2.5], requires_grad=True)\nopt = tz.Optimizer([X], tz.m.NaturalGradient(sqrt=True, gn_grad=True), tz.m.LR(0.05))\n\nfor iter in range(200):\n    losses = rosenbrock(X)\n    opt.step(loss=losses)\n    if iter % 20 == 0:\n        print(f'{losses.mean() = }')\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/natural_gradient.py</code> <pre><code>class NaturalGradient(Transform):\n    \"\"\"Natural gradient approximated via empirical fisher information matrix.\n\n    To use this, either pass vector of per-sample losses to the step method, or make sure\n    the closure returns it. Gradients will be calculated via batched autograd within this module,\n    you don't need to implement the backward pass. When using closure, please add the ``backward`` argument,\n    it will always be False but it is required. See below for an example.\n\n    Note:\n        Empirical fisher information matrix may give a really bad approximation in some cases.\n        If that is the case, set ``sqrt`` to True to perform whitening instead, which is way more robust.\n\n    Args:\n        reg (float, optional): regularization parameter. Defaults to 1e-8.\n        sqrt (bool, optional):\n            if True, uses square root of empirical fisher information matrix. Both EFIM and it's square\n            root can be calculated and stored efficiently without ndim^2 memory. Square root\n            whitens the gradient and often performs much better, especially when you try to use NGD\n            with a vector that isn't strictly per-sample gradients, but rather for example different losses.\n        gn_grad (bool, optional):\n            if True, uses Gauss-Newton G^T @ f as the gradient, which is effectively sum weighted by value\n            and is equivalent to squaring the values. That makes the kernel trick solver incorrect, but for\n            some reason it still works. If False, uses sum of per-sample gradients.\n            This has an effect when ``sqrt=False``, and affects the ``grad`` attribute.\n            Defaults to False.\n        batched (bool, optional): whether to use vmapping. Defaults to True.\n\n    Examples:\n\n    training a neural network:\n    ```python\n    X = torch.randn(64, 20)\n    y = torch.randn(64, 10)\n\n    model = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NaturalGradient(),\n        tz.m.LR(3e-2)\n    )\n\n    for i in range(100):\n        y_hat = model(X) # (64, 10)\n        losses = (y_hat - y).pow(2).mean(0) # (10, )\n        opt.step(loss=losses)\n        if i % 10 == 0:\n            print(f'{losses.mean() = }')\n    ```\n\n    training a neural network - closure version\n    ```python\n    X = torch.randn(64, 20)\n    y = torch.randn(64, 10)\n\n    model = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NaturalGradient(),\n        tz.m.LR(3e-2)\n    )\n\n    def closure(backward=True):\n        y_hat = model(X) # (64, 10)\n        return (y_hat - y).pow(2).mean(0) # (10, )\n\n    for i in range(100):\n        losses = opt.step(closure)\n        if i % 10 == 0:\n        print(f'{losses.mean() = }')\n    ```\n\n    minimizing the rosenbrock function with a mix of natural gradient, whitening and gauss-newton:\n    ```python\n    def rosenbrock(X):\n        x1, x2 = X\n        return torch.stack([(1 - x1).abs(), (10 * (x2 - x1**2).abs())])\n\n    X = torch.tensor([-1.1, 2.5], requires_grad=True)\n    opt = tz.Optimizer([X], tz.m.NaturalGradient(sqrt=True, gn_grad=True), tz.m.LR(0.05))\n\n    for iter in range(200):\n        losses = rosenbrock(X)\n        opt.step(loss=losses)\n        if iter % 20 == 0:\n            print(f'{losses.mean() = }')\n    ```\n    \"\"\"\n    def __init__(self, reg:float = 1e-8, sqrt:bool=False, gn_grad:bool=False, batched:bool=True, ):\n        super().__init__(defaults=dict(batched=batched, reg=reg, sqrt=sqrt, gn_grad=gn_grad))\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n        closure = objective.closure\n        fs = settings[0]\n        batched = fs['batched']\n        gn_grad = fs['gn_grad']\n\n        # compute per-sample losses\n        f = objective.loss\n        if f is None:\n            assert closure is not None\n            with torch.enable_grad():\n                f = objective.get_loss(backward=False) # n_out\n                assert isinstance(f, torch.Tensor)\n\n        # compute per-sample gradients\n        with torch.enable_grad():\n            G_list = jacobian_wrt([f.ravel()], params, batched=batched)\n\n        # set scalar loss and it's grad to objective\n        objective.loss = f.sum()\n        G = self.global_state[\"G\"] = flatten_jacobian(G_list) # (n_samples, ndim)\n\n        if gn_grad:\n            g = self.global_state[\"g\"] = G.H @ f.detach()\n\n        else:\n            g = self.global_state[\"g\"] = G.sum(0)\n\n        objective.grads = vec_to_tensors(g, params)\n\n        # set closure to calculate scalar value for line searches etc\n        if closure is not None:\n\n            def ngd_closure(backward=True):\n\n                if backward:\n                    objective.zero_grad()\n                    with torch.enable_grad():\n                        loss = closure(False)\n                        if gn_grad: loss = loss.pow(2)\n                        loss = loss.sum()\n                        loss.backward()\n                    return loss\n\n                loss = closure(False)\n                if gn_grad: loss = loss.pow(2)\n                return loss.sum()\n\n            objective.closure = ngd_closure\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        params = objective.params\n        fs = settings[0]\n        reg = fs['reg']\n        sqrt = fs['sqrt']\n\n        G: torch.Tensor = self.global_state['G'] # (n_samples, n_dim)\n\n        if sqrt:\n            # this computes U, S &lt;- SVD(M), then calculate update as U S^-1 U\u1d40g,\n            # but it computes it through eigendecompotision\n            L, U = ggt_update(G.H, damping=reg, rdamping=1e-16, truncate=0, eig_tol=1e-12)\n\n            if U is None or L is None:\n\n                # fallback to element-wise\n                g = self.global_state[\"g\"]\n                g /= G.square().mean(0).sqrt().add(reg)\n                objective.updates = vec_to_tensors(g, params)\n                return objective\n\n            # whiten\n            z = U.T @ self.global_state[\"g\"]\n            v = (U * L.rsqrt()) @ z\n            objective.updates = vec_to_tensors(v, params)\n            return objective\n\n        # we need (G^T G)v = g\n        # where g = G^T\n        # so we need to solve (G^T G)v = G^T\n        GGt = G @ G.H # (n_samples, n_samples)\n\n        if reg != 0:\n            GGt.add_(torch.eye(GGt.size(0), device=GGt.device, dtype=GGt.dtype).mul_(reg))\n\n        z, _ = torch.linalg.solve_ex(GGt, torch.ones_like(GGt[0])) # pylint:disable=not-callable\n        v = G.H @ z\n\n        objective.updates = vec_to_tensors(v, params)\n        return objective\n\n\n    def get_H(self, objective=...):\n        if \"G\" not in self.global_state: return linear_operator.ScaledIdentity()\n        G = self.global_state['G']\n        return linear_operator.AtA(G)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Negate","title":"Negate","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>- input</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Negate(TensorTransform):\n    \"\"\"Returns ``- input``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_neg_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.NegateOnLossIncrease","title":"NegateOnLossIncrease","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Uses an extra forward pass to evaluate loss at <code>parameters+update</code>, if loss is larger than at <code>parameters</code>, the update is set to 0 if <code>backtrack=False</code> and to <code>-update</code> otherwise</p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class NegateOnLossIncrease(Module):\n    \"\"\"Uses an extra forward pass to evaluate loss at ``parameters+update``,\n    if loss is larger than at ``parameters``,\n    the update is set to 0 if ``backtrack=False`` and to ``-update`` otherwise\"\"\"\n    def __init__(self, backtrack=False):\n        defaults = dict(backtrack=backtrack)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError('NegateOnLossIncrease requires closure')\n        backtrack = self.defaults['backtrack']\n\n        update = objective.get_updates()\n        f_0 = objective.get_loss(backward=False)\n\n        torch._foreach_sub_(objective.params, update)\n        f_1 = closure(False)\n\n        if f_1 &lt;= f_0:\n            # if var.is_last and var.last_module_lrs is None:\n            #     var.stop = True\n            #     var.skip_update = True\n            #     return var\n\n            torch._foreach_add_(objective.params, update)\n            return objective\n\n        torch._foreach_add_(objective.params, update)\n        if backtrack:\n            torch._foreach_neg_(objective.updates)\n        else:\n            torch._foreach_zero_(objective.updates)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.NewDQN","title":"NewDQN","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.diagonal_quasi_newton.DNRTR</code></p> <p>Diagonal quasi-newton method.</p> Reference <p>Nosrati, Mahsa, and Keyvan Amini. \"A new diagonal quasi-Newton algorithm for unconstrained optimization problems.\" Applications of Mathematics 69.4 (2024): 501-512.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class NewDQN(DNRTR):\n    \"\"\"Diagonal quasi-newton method.\n\n    Reference:\n        Nosrati, Mahsa, and Keyvan Amini. \"A new diagonal quasi-Newton algorithm for unconstrained optimization problems.\" Applications of Mathematics 69.4 (2024): 501-512.\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return new_dqn_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.NewSSM","title":"NewSSM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Self-scaling Quasi-Newton method.</p> Note <p>a line search such as <code>tz.m.StrongWolfe()</code> is required.</p> Warning <p>this uses roughly O(N^2) memory.</p> Reference <p>Moghrabi, I. A., Hassan, B. A., &amp; Askar, A. (2022). New self-scaling quasi-newton methods for unconstrained optimization. Int. J. Math. Comput. Sci., 17, 1061U.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class NewSSM(HessianUpdateStrategy):\n    \"\"\"Self-scaling Quasi-Newton method.\n\n    Note:\n        a line search such as ``tz.m.StrongWolfe()`` is required.\n\n    Warning:\n        this uses roughly O(N^2) memory.\n\n    Reference:\n        Moghrabi, I. A., Hassan, B. A., &amp; Askar, A. (2022). New self-scaling quasi-newton methods for unconstrained optimization. Int. J. Math. Comput. Sci., 17, 1061U.\n    \"\"\"\n    def __init__(\n        self,\n        type: Literal[1, 2] = 1,\n        init_scale: float | Literal[\"auto\"] = \"auto\",\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        super().__init__(\n            defaults=dict(type=type),\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            uses_loss=True,\n            inner=inner,\n        )\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        f = state['f']\n        f_prev = state['f_prev']\n        return new_ssm1(H=H, s=s, y=y, f=f, f_prev=f_prev, type=setting['type'], tol=setting['tol'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.Newton","title":"Newton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Exact Newton's method via autograd.</p> <p>Newton's method produces a direction jumping to the stationary point of quadratic approximation of the target function. The update rule is given by <code>(H + yI)\u207b\u00b9g</code>, where <code>H</code> is the hessian and <code>g</code> is the gradient, <code>y</code> is the <code>damping</code> parameter.</p> <p><code>g</code> can be output of another module, if it is specifed in <code>inner</code> argument.</p> Note <p>In most cases Newton should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> Note <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating the hessian. The closure must accept a <code>backward</code> argument (refer to documentation).</p> <p>Parameters:</p> <ul> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>tikhonov regularizer value. Defaults to 0.</p> </li> <li> <code>eigval_fn</code>               (<code>Callable | None</code>, default:                   <code>None</code> )           \u2013            <p>function to apply to eigenvalues, for example <code>torch.abs</code> or <code>lambda L: torch.clip(L, min=1e-8)</code>. If this is specified, eigendecomposition will be used to invert the hessian.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>updates hessian every <code>update_freq</code> steps.</p> </li> <li> <code>precompute_inverse</code>               (<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>if <code>True</code>, whenever hessian is computed, also computes the inverse. This is more efficient when <code>update_freq</code> is large. If <code>None</code>, this is <code>True</code> if <code>update_freq &gt;= 10</code>.</p> </li> <li> <code>use_lstsq</code>               (<code>(bool, Optional)</code>, default:                   <code>False</code> )           \u2013            <p>if True, least squares will be used to solve the linear system, this can prevent it from exploding when hessian is indefinite. If False, tries cholesky, if it fails tries LU, and then least squares. If <code>eigval_fn</code> is specified, eigendecomposition is always used and this argument is ignored.</p> </li> <li> <code>hessian_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>Determines how hessian is computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd to compute <code>ndim</code> batched hessian-vector products. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd to compute <code>ndim</code> hessian-vector products using for loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"functional_revrev\"</code> - uses <code>torch.autograd.functional</code> with \"reverse-over-reverse\" strategy and a for-loop. This is generally equivalent to <code>\"autograd\"</code>.</li> <li><code>\"functional_fwdrev\"</code> - uses <code>torch.autograd.functional</code> with vectorized \"forward-over-reverse\" strategy. Faster than <code>\"functional_fwdrev\"</code> but uses more memory (<code>\"batched_autograd\"</code> seems to be faster)</li> <li><code>\"func\"</code> - uses <code>torch.func.hessian</code> which uses \"forward-over-reverse\" strategy. This method is the fastest and is recommended, however it is more restrictive and fails with some operators which is why it isn't the default.</li> <li><code>\"gfd_forward\"</code> - computes <code>ndim</code> hessian-vector products via gradient finite difference using a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"gfd_central\"</code> - computes <code>ndim</code> hessian-vector products via gradient finite difference using a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> <li><code>\"fd\"</code> - uses function values to estimate gradient and hessian via finite difference. This uses less evaluations than chaining <code>\"gfd_*\"</code> after <code>tz.m.FDM</code>.</li> <li><code>\"thoad\"</code> - uses <code>thoad</code> library, can be significantly faster than pytorch but limited operator coverage.</li> </ul> <p>Defaults to <code>\"batched_autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size if hessian is compute via finite-difference.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules to apply hessian preconditioner to. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Newton--see-also","title":"See also","text":"<ul> <li><code>tz.m.NewtonCG</code>: uses a matrix-free conjugate gradient solver and hessian-vector products. useful for large scale problems as it doesn't form the full hessian.</li> <li><code>tz.m.NewtonCGSteihaug</code>: trust region version of <code>tz.m.NewtonCG</code>.</li> <li><code>tz.m.ImprovedNewton</code>: Newton with additional rank one correction to the hessian, can be faster than Newton.</li> <li><code>tz.m.InverseFreeNewton</code>: an inverse-free variant of Newton's method.</li> <li><code>tz.m.quasi_newton</code>: large collection of quasi-newton methods that estimate the hessian.</li> </ul>"},{"location":"API/all/#torchzero.modules.Newton--notes","title":"Notes","text":""},{"location":"API/all/#torchzero.modules.Newton--implementation-details","title":"Implementation details","text":"<p><code>(H + yI)\u207b\u00b9g</code> is calculated by solving the linear system <code>(H + yI)x = g</code>. The linear system is solved via cholesky decomposition, if that fails, LU decomposition, and if that fails, least squares. Least squares can be forced by setting <code>use_lstsq=True</code>.</p> <p>Additionally, if <code>eigval_fn</code> is specified, eigendecomposition of the hessian is computed, <code>eigval_fn</code> is applied to the eigenvalues, and <code>(H + yI)\u207b\u00b9</code> is computed using the computed eigenvectors and transformed eigenvalues. This is more generally more computationally expensive but not by much.</p>"},{"location":"API/all/#torchzero.modules.Newton--handling-non-convexity","title":"Handling non-convexity","text":"<p>Standard Newton's method does not handle non-convexity well without some modifications. This is because it jumps to the stationary point, which may be the maxima of the quadratic approximation.</p> <p>A modification to handle non-convexity is to modify the eignevalues to be positive, for example by setting <code>eigval_fn = lambda L: L.abs().clip(min=1e-4)</code>.</p>"},{"location":"API/all/#torchzero.modules.Newton--examples","title":"Examples:","text":"<p>Newton's method with backtracking line search</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Newton(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Newton's method for non-convex optimization.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Newton(eigval_fn = lambda L: L.abs().clip(min=1e-4)),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Newton preconditioning applied to momentum</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Newton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(0.1)\n)\n</code></pre> Source code in <code>torchzero/modules/second_order/newton.py</code> <pre><code>class Newton(Transform):\n    \"\"\"Exact Newton's method via autograd.\n\n    Newton's method produces a direction jumping to the stationary point of quadratic approximation of the target function.\n    The update rule is given by ``(H + yI)\u207b\u00b9g``, where ``H`` is the hessian and ``g`` is the gradient, ``y`` is the ``damping`` parameter.\n\n    ``g`` can be output of another module, if it is specifed in ``inner`` argument.\n\n    Note:\n        In most cases Newton should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n    Note:\n        This module requires the a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients for calculating the hessian.\n        The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        damping (float, optional): tikhonov regularizer value. Defaults to 0.\n        eigval_fn (Callable | None, optional):\n            function to apply to eigenvalues, for example ``torch.abs`` or ``lambda L: torch.clip(L, min=1e-8)``.\n            If this is specified, eigendecomposition will be used to invert the hessian.\n        update_freq (int, optional):\n            updates hessian every ``update_freq`` steps.\n        precompute_inverse (bool, optional):\n            if ``True``, whenever hessian is computed, also computes the inverse. This is more efficient\n            when ``update_freq`` is large. If ``None``, this is ``True`` if ``update_freq &gt;= 10``.\n        use_lstsq (bool, Optional):\n            if True, least squares will be used to solve the linear system, this can prevent it from exploding\n            when hessian is indefinite. If False, tries cholesky, if it fails tries LU, and then least squares.\n            If ``eigval_fn`` is specified, eigendecomposition is always used and this argument is ignored.\n        hessian_method (str):\n            Determines how hessian is computed.\n\n            - ``\"batched_autograd\"`` - uses autograd to compute ``ndim`` batched hessian-vector products. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd to compute ``ndim`` hessian-vector products using for loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"functional_revrev\"`` - uses ``torch.autograd.functional`` with \"reverse-over-reverse\" strategy and a for-loop. This is generally equivalent to ``\"autograd\"``.\n            - ``\"functional_fwdrev\"`` - uses ``torch.autograd.functional`` with vectorized \"forward-over-reverse\" strategy. Faster than ``\"functional_fwdrev\"`` but uses more memory (``\"batched_autograd\"`` seems to be faster)\n            - ``\"func\"`` - uses ``torch.func.hessian`` which uses \"forward-over-reverse\" strategy. This method is the fastest and is recommended, however it is more restrictive and fails with some operators which is why it isn't the default.\n            - ``\"gfd_forward\"`` - computes ``ndim`` hessian-vector products via gradient finite difference using a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"gfd_central\"`` - computes ``ndim`` hessian-vector products via gradient finite difference using a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n            - ``\"fd\"`` - uses function values to estimate gradient and hessian via finite difference. This uses less evaluations than chaining ``\"gfd_*\"`` after ``tz.m.FDM``.\n            - ``\"thoad\"`` - uses ``thoad`` library, can be significantly faster than pytorch but limited operator coverage.\n\n            Defaults to ``\"batched_autograd\"``.\n        h (float, optional):\n            finite difference step size if hessian is compute via finite-difference.\n        inner (Chainable | None, optional): modules to apply hessian preconditioner to. Defaults to None.\n\n    # See also\n\n    * ``tz.m.NewtonCG``: uses a matrix-free conjugate gradient solver and hessian-vector products.\n    useful for large scale problems as it doesn't form the full hessian.\n    * ``tz.m.NewtonCGSteihaug``: trust region version of ``tz.m.NewtonCG``.\n    * ``tz.m.ImprovedNewton``: Newton with additional rank one correction to the hessian, can be faster than Newton.\n    * ``tz.m.InverseFreeNewton``: an inverse-free variant of Newton's method.\n    * ``tz.m.quasi_newton``: large collection of quasi-newton methods that estimate the hessian.\n\n    # Notes\n\n    ## Implementation details\n\n    ``(H + yI)\u207b\u00b9g`` is calculated by solving the linear system ``(H + yI)x = g``.\n    The linear system is solved via cholesky decomposition, if that fails, LU decomposition, and if that fails, least squares. Least squares can be forced by setting ``use_lstsq=True``.\n\n    Additionally, if ``eigval_fn`` is specified, eigendecomposition of the hessian is computed,\n    ``eigval_fn`` is applied to the eigenvalues, and ``(H + yI)\u207b\u00b9`` is computed using the computed eigenvectors and transformed eigenvalues. This is more generally more computationally expensive but not by much.\n\n    ## Handling non-convexity\n\n    Standard Newton's method does not handle non-convexity well without some modifications.\n    This is because it jumps to the stationary point, which may be the maxima of the quadratic approximation.\n\n    A modification to handle non-convexity is to modify the eignevalues to be positive,\n    for example by setting ``eigval_fn = lambda L: L.abs().clip(min=1e-4)``.\n\n    # Examples:\n\n    Newton's method with backtracking line search\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Newton(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Newton's method for non-convex optimization.\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Newton(eigval_fn = lambda L: L.abs().clip(min=1e-4)),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Newton preconditioning applied to momentum\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Newton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        damping: float = 0,\n        eigval_fn: Callable[[torch.Tensor], torch.Tensor] | None = None,\n        eigv_tol: float | None = None,\n        truncate: int | None = None,\n        update_freq: int = 1,\n        precompute_inverse: bool | None = None,\n        use_lstsq: bool = False,\n        hessian_method: HessianMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['update_freq'], defaults[\"inner\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        precompute_inverse = fs[\"precompute_inverse\"]\n        if precompute_inverse is None:\n            precompute_inverse = fs[\"__update_freq\"] &gt;= 10\n\n        __, _, H = objective.hessian(hessian_method=fs[\"hessian_method\"], h=fs[\"h\"], at_x0=True)\n\n        _newton_update_state_(\n            state = self.global_state,\n            H=H,\n            damping = fs[\"damping\"],\n            eigval_fn = fs[\"eigval_fn\"],\n            eigv_tol = fs[\"eigv_tol\"],\n            truncate = fs[\"truncate\"],\n            precompute_inverse = precompute_inverse,\n            use_lstsq = fs[\"use_lstsq\"]\n        )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n        fs = settings[0]\n\n        b = torch.cat([t.ravel() for t in updates])\n        sol = _newton_solve(b=b, state=self.global_state, use_lstsq=fs[\"use_lstsq\"])\n\n        vec_to_tensors_(sol, updates)\n        return objective\n\n    def get_H(self,objective=...):\n        return _newton_get_H(self.global_state)\n</code></pre>"},{"location":"API/all/#torchzero.modules.NewtonCG","title":"NewtonCG","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with a matrix-free conjugate gradient or minimial-residual solver.</p> Notes <ul> <li> <p>In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> Warning <p>CG may fail if hessian is not positive-definite.</p> <p>Parameters:</p> <ul> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Maximum number of iterations for the conjugate gradient solver. By default, this is set to the number of dimensions in the objective function, which is the theoretical upper bound for CG convergence. Setting this to a smaller value (truncated Newton) can still generate good search directions. Defaults to None.</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>Relative tolerance for the conjugate gradient solver to determine convergence. Defaults to 1e-4.</p> </li> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>Regularization parameter (damping) added to the Hessian diagonal. This helps ensure the system is positive-definite. Defaults to 1e-8.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are evaluated.</p> <ul> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>For NewtonCG <code>\"batched_autograd\"</code> is equivalent to <code>\"autograd\"</code>. Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>warm_start</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, the conjugate gradient solver is initialized with the solution from the previous optimization step. This can accelerate convergence, especially in truncated Newton methods. Defaults to False.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>NewtonCG will attempt to apply preconditioning to the output of this module.</p> </li> </ul> <p>Examples: Newton-CG with a backtracking line search:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NewtonCG(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Truncated Newton method (useful for large-scale problems): <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NewtonCG(maxiter=10),\n    tz.m.Backtracking()\n)\n</code></pre></p> Source code in <code>torchzero/modules/second_order/newton_cg.py</code> <pre><code>class NewtonCG(Transform):\n    \"\"\"Newton's method with a matrix-free conjugate gradient or minimial-residual solver.\n\n    Notes:\n        * In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n        * This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Warning:\n        CG may fail if hessian is not positive-definite.\n\n    Args:\n        maxiter (int | None, optional):\n            Maximum number of iterations for the conjugate gradient solver.\n            By default, this is set to the number of dimensions in the\n            objective function, which is the theoretical upper bound for CG\n            convergence. Setting this to a smaller value (truncated Newton)\n            can still generate good search directions. Defaults to None.\n        tol (float, optional):\n            Relative tolerance for the conjugate gradient solver to determine\n            convergence. Defaults to 1e-4.\n        reg (float, optional):\n            Regularization parameter (damping) added to the Hessian diagonal.\n            This helps ensure the system is positive-definite. Defaults to 1e-8.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are evaluated.\n\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            For NewtonCG ``\"batched_autograd\"`` is equivalent to ``\"autograd\"``. Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        warm_start (bool, optional):\n            If ``True``, the conjugate gradient solver is initialized with the\n            solution from the previous optimization step. This can accelerate\n            convergence, especially in truncated Newton methods.\n            Defaults to False.\n        inner (Chainable | None, optional):\n            NewtonCG will attempt to apply preconditioning to the output of this module.\n\n    Examples:\n    Newton-CG with a backtracking line search:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NewtonCG(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Truncated Newton method (useful for large-scale problems):\n    ```\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NewtonCG(maxiter=10),\n        tz.m.Backtracking()\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        maxiter: int | None = None,\n        tol: float = 1e-8,\n        reg: float = 1e-8,\n        hvp_method: HVPMethod = \"autograd\",\n        solver: Literal['cg', 'minres'] = 'cg',\n        npc_terminate: bool = False,\n        h: float = 1e-3, # tuned 1e-4 or 1e-3\n        miniter:int = 1,\n        warm_start=False,\n        warm_beta:float=0,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults, inner=inner)\n\n        self._num_hvps = 0\n        self._num_hvps_last_step = 0\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n\n        # ---------------------- Hessian vector product function --------------------- #\n        _, H_mv = objective.list_Hvp_function(hvp_method=hvp_method, h=h, at_x0=True)\n        objective.temp = H_mv\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        self._num_hvps_last_step = 0\n        H_mv = objective.poptemp()\n\n        fs = settings[0]\n        tol = fs['tol']\n        reg = fs['reg']\n        maxiter = fs['maxiter']\n        solver = fs['solver'].lower().strip()\n        warm_start = fs['warm_start']\n        npc_terminate = fs[\"npc_terminate\"]\n\n        # ---------------------------------- run cg ---------------------------------- #\n        x0 = None\n        if warm_start:\n            x0 = unpack_states(states, objective.params, 'prev_x', cls=TensorList)\n\n        b = TensorList(objective.get_updates())\n\n        if solver == 'cg':\n            d, _ = cg(A_mv=H_mv, b=b, x0=x0, tol=tol, maxiter=maxiter,\n                      miniter=fs[\"miniter\"], reg=reg, npc_terminate=npc_terminate)\n\n        elif solver == 'minres':\n            d = minres(A_mv=H_mv, b=b, x0=x0, tol=tol, maxiter=maxiter, reg=reg, npc_terminate=npc_terminate)\n\n        else:\n            raise ValueError(f\"Unknown solver {solver}\")\n\n        if warm_start:\n            assert x0 is not None\n            x0.lerp_(d, weight = 1-fs[\"warm_beta\"])\n\n        objective.updates = d\n        self._num_hvps += self._num_hvps_last_step\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.NewtonCGSteihaug","title":"NewtonCGSteihaug","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with trust region and a matrix-free Steihaug-Toint conjugate gradient solver.</p> Notes <ul> <li> <p>In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. Defaults to 0.0.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>100</code> )           \u2013            <p>maximum number of trust radius reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>max_history</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>CG will store this many intermediate solutions, reusing them when trust radius is reduced instead of re-running CG. Each solution storage requires 2N memory. Defaults to 100.</p> </li> <li> <code>boundary_tol</code>               (<code>float | None</code>, default:                   <code>1e-06</code> )           \u2013            <p>The trust region only increases when suggested step's norm is at least <code>(1-boundary_tol)*trust_region</code>. This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of CG iterations per step. Each iteration requies one backward pass if <code>hvp_method=\"forward\"</code>, two otherwise. Defaults to None.</p> </li> <li> <code>miniter</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal number of CG iterations. This prevents making no progress</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>terminates CG when norm of the residual is less than this value. Defaults to 1e-8. when initial guess is below tolerance. Defaults to 1.</p> </li> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>hessian regularization. Defaults to 1e-8.</p> </li> <li> <code>solver</code>               (<code>str</code>, default:                   <code>'cg'</code> )           \u2013            <p>solver, \"cg\" or \"minres\". \"cg\" is recommended. Defaults to 'cg'.</p> </li> <li> <code>adapt_tol</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, whenever trust radius collapses to smallest representable number, the tolerance is multiplied by 0.1. Defaults to True.</p> </li> <li> <code>npc_terminate</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to terminate CG/MINRES whenever negative curvature is detected. Defaults to False.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'fd_central'</code> )           \u2013            <p>either <code>\"fd_forward\"</code> to use forward formula which requires one backward pass per hessian-vector product, or <code>\"fd_central\"</code> to use a more accurate central formula which requires two backward passes. <code>\"fd_forward\"</code> is usually accurate enough. Defaults to <code>\"fd_forward\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>applies preconditioning to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.NewtonCGSteihaug--examples","title":"Examples:","text":"<p>Trust-region Newton-CG:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NewtonCGSteihaug(),\n)\n</code></pre>"},{"location":"API/all/#torchzero.modules.NewtonCGSteihaug--reference","title":"Reference:","text":"<pre><code>Steihaug, Trond. \"The conjugate gradient method and trust regions in large scale optimization.\" SIAM Journal on Numerical Analysis 20.3 (1983): 626-637.\n</code></pre> Source code in <code>torchzero/modules/second_order/newton_cg.py</code> <pre><code>class NewtonCGSteihaug(Transform):\n    \"\"\"Newton's method with trust region and a matrix-free Steihaug-Toint conjugate gradient solver.\n\n    Notes:\n        * In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n        * This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted. Defaults to 0.0.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust radius reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        max_history (int, optional):\n            CG will store this many intermediate solutions, reusing them when trust radius is reduced\n            instead of re-running CG. Each solution storage requires 2N memory. Defaults to 100.\n        boundary_tol (float | None, optional):\n            The trust region only increases when suggested step's norm is at least `(1-boundary_tol)*trust_region`.\n            This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.\n\n        maxiter (int | None, optional):\n            maximum number of CG iterations per step. Each iteration requies one backward pass if `hvp_method=\"forward\"`, two otherwise. Defaults to None.\n        miniter (int, optional):\n            minimal number of CG iterations. This prevents making no progress\n        tol (float, optional):\n            terminates CG when norm of the residual is less than this value. Defaults to 1e-8.\n            when initial guess is below tolerance. Defaults to 1.\n        reg (float, optional): hessian regularization. Defaults to 1e-8.\n        solver (str, optional): solver, \"cg\" or \"minres\". \"cg\" is recommended. Defaults to 'cg'.\n        adapt_tol (bool, optional):\n            if True, whenever trust radius collapses to smallest representable number,\n            the tolerance is multiplied by 0.1. Defaults to True.\n        npc_terminate (bool, optional):\n            whether to terminate CG/MINRES whenever negative curvature is detected. Defaults to False.\n\n        hvp_method (str, optional):\n            either ``\"fd_forward\"`` to use forward formula which requires one backward pass per hessian-vector product, or ``\"fd_central\"`` to use a more accurate central formula which requires two backward passes. ``\"fd_forward\"`` is usually accurate enough. Defaults to ``\"fd_forward\"``.\n        h (float, optional): finite difference step size. Defaults to 1e-3.\n\n        inner (Chainable | None, optional):\n            applies preconditioning to output of this module. Defaults to None.\n\n    ### Examples:\n    Trust-region Newton-CG:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NewtonCGSteihaug(),\n    )\n    ```\n\n    ### Reference:\n        Steihaug, Trond. \"The conjugate gradient method and trust regions in large scale optimization.\" SIAM Journal on Numerical Analysis 20.3 (1983): 626-637.\n    \"\"\"\n    def __init__(\n        self,\n        # trust region settings\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        init: float = 1,\n        max_attempts: int = 100,\n        max_history: int = 100,\n        boundary_tol: float = 1e-6, # tuned\n\n        # cg settings\n        maxiter: int | None = None,\n        miniter: int = 1,\n        tol: float = 1e-8,\n        reg: float = 1e-8,\n        solver: Literal['cg', \"minres\"] = 'cg',\n        adapt_tol: bool = False,\n        terminate_on_tr: bool = True,\n        npc_terminate: bool = False,\n\n        # hvp settings\n        hvp_method: Literal[\"fd_forward\", \"fd_central\"] = \"fd_central\",\n        h: float = 1e-3, # tuned 1e-4 or 1e-3\n\n        # inner\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults, inner=inner)\n\n        self._num_hvps = 0\n        self._num_hvps_last_step = 0\n\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n\n        # ---------------------- Hessian vector product function --------------------- #\n        _, H_mv = objective.list_Hvp_function(hvp_method=hvp_method, h=h, at_x0=True)\n        objective.temp = H_mv\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        self._num_hvps_last_step = 0\n\n        H_mv = objective.poptemp()\n        params = TensorList(objective.params)\n        fs = settings[0]\n\n        tol = fs['tol'] * self.global_state.get('tol_mul', 1)\n        solver = fs['solver'].lower().strip()\n\n        reg=fs[\"reg\"]\n        maxiter=fs[\"maxiter\"]\n        max_attempts=fs[\"max_attempts\"]\n        init=fs[\"init\"]\n        npc_terminate=fs[\"npc_terminate\"]\n        miniter=fs[\"miniter\"]\n        max_history=fs[\"max_history\"]\n\n\n        # ------------------------------- trust region ------------------------------- #\n        success = False\n        d = None\n        orig_params = [p.clone() for p in params]\n        b = TensorList(objective.get_updates())\n        solution = None\n        closure = objective.closure\n        assert closure is not None\n\n        while not success:\n            max_attempts -= 1\n            if max_attempts &lt; 0: break\n\n            trust_radius = self.global_state.get('trust_radius', init)\n\n            # -------------- make sure trust radius isn't too small or large ------------- #\n            finfo = torch.finfo(orig_params[0].dtype)\n            if trust_radius &lt; finfo.tiny * 2:\n                trust_radius = self.global_state['trust_radius'] = init\n\n                if fs[\"adapt_tol\"]:\n                    self.global_state[\"tol_mul\"] = self.global_state.get(\"tol_mul\", 1) * 0.1\n\n                if fs[\"terminate_on_tr\"]:\n                    objective.should_terminate = True\n\n            elif trust_radius &gt; finfo.max / 2:\n                trust_radius = self.global_state['trust_radius'] = init\n\n            # ----------------------------------- solve ---------------------------------- #\n            d = None\n            if solution is not None and solution.history is not None:\n                d = find_within_trust_radius(solution.history, trust_radius)\n\n            if d is None:\n                if solver == 'cg':\n                    d, solution = cg(\n                        A_mv=H_mv,\n                        b=b,\n                        tol=tol,\n                        maxiter=maxiter,\n                        reg=reg,\n                        trust_radius=trust_radius,\n                        miniter=miniter,\n                        npc_terminate=npc_terminate,\n                        history_size=max_history,\n                    )\n\n                elif solver == 'minres':\n                    d = minres(A_mv=H_mv, b=b, trust_radius=trust_radius, tol=tol, maxiter=maxiter, reg=reg, npc_terminate=npc_terminate)\n\n                else:\n                    raise ValueError(f\"unknown solver {solver}\")\n\n            # ---------------------------- update trust radius --------------------------- #\n            self.global_state[\"trust_radius\"], success = default_radius(\n                params = params,\n                closure = closure,\n                f = tofloat(objective.get_loss(False)),\n                g = b,\n                H = H_mv,\n                d = d,\n                trust_radius = trust_radius,\n                eta = fs[\"eta\"],\n                nplus = fs[\"nplus\"],\n                nminus = fs[\"nminus\"],\n                rho_good = fs[\"rho_good\"],\n                rho_bad = fs[\"rho_bad\"],\n                boundary_tol = fs[\"boundary_tol\"],\n\n                init = cast(int, None), # init isn't used because check_overflow=False\n                state = cast(dict, None), # not used\n                settings = cast(dict, None), # not used\n                check_overflow = False, # this is checked manually to adapt tolerance\n            )\n\n        # --------------------------- assign new direction --------------------------- #\n        assert d is not None\n        if success:\n            objective.updates = d\n\n        else:\n            objective.updates = params.zeros_like()\n\n        self._num_hvps += self._num_hvps_last_step\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.NoiseSign","title":"NoiseSign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs random tensors with sign copied from the update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class NoiseSign(TensorTransform):\n    \"\"\"Outputs random tensors with sign copied from the update.\"\"\"\n    def __init__(self, distribution:Distributions = 'normal', variance:float | None = None):\n        defaults = dict(distribution=distribution, variance=variance)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        variance = unpack_dicts(settings, 'variance')\n        return TensorList(tensors).sample_like(settings[0]['distribution'], variance=variance).copysign_(tensors)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Noop","title":"Noop","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Identity(Module):\n    \"\"\"Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.\"\"\"\n    def __init__(self, *args, **kwargs): super().__init__()\n    def update(self, objective): pass\n    def apply(self, objective): return objective\n    def get_H(self, objective):\n        n = sum(p.numel() for p in objective.params)\n        p = objective.params[0]\n        return ScaledIdentity(shape=(n,n), device=p.device, dtype=p.dtype)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Normalize","title":"Normalize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Normalizes the update.</p> <p>Parameters:</p> <ul> <li> <code>norm_value</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>desired norm value.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are normalized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>what this affects.</p> </li> </ul> <p>Examples: Gradient normalization: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Normalize(1),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Update normalization:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.Normalize(1),\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class Normalize(TensorTransform):\n    \"\"\"Normalizes the update.\n\n    Args:\n        norm_value (float): desired norm value.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are normalized.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n        target (str, optional):\n            what this affects.\n\n    Examples:\n    Gradient normalization:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Normalize(1),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Update normalization:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.Normalize(1),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        norm_value: float = 1,\n        ord: Metrics = 2,\n        dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n        inverse_dims: bool = False,\n        min_size: int = 1,\n    ):\n        defaults = dict(norm_value=norm_value,ord=ord,dim=dim,min_size=min_size, inverse_dims=inverse_dims)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        norm_value = NumberList(s['norm_value'] for s in settings)\n        ord, dim, min_size, inverse_dims = itemgetter('ord', 'dim', 'min_size', 'inverse_dims')(settings[0])\n\n        _clip_norm_(\n            tensors_ = TensorList(tensors),\n            min = None,\n            max = None,\n            norm_value = norm_value,\n            ord = ord,\n            dim = dim,\n            inverse_dims=inverse_dims,\n            min_size = min_size,\n        )\n\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.NormalizeByEMA","title":"NormalizeByEMA","text":"<p>               Bases: <code>torchzero.modules.clipping.ema_clipping.ClipNormByEMA</code></p> <p>Sets norm of the update to be the same as the norm of an exponential moving average of past updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for the exponential moving average. Defaults to 0.99.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>order of the norm. Defaults to 2.</p> </li> <li> <code>eps</code>               (<code>float</code>)           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.</p> </li> <li> <code>max_ema_growth</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.</p> </li> <li> <code>ema_init</code>               (<code>str</code>)           \u2013            <p>How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/ema_clipping.py</code> <pre><code>class NormalizeByEMA(ClipNormByEMA):\n    \"\"\"Sets norm of the update to be the same as the norm of an exponential moving average of past updates.\n\n    Args:\n        beta (float, optional): beta for the exponential moving average. Defaults to 0.99.\n        ord (float, optional): order of the norm. Defaults to 2.\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n        tensorwise (bool, optional):\n            if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.\n        max_ema_growth (float | None, optional):\n            if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.\n        ema_init (str, optional):\n            How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.\n    \"\"\"\n    NORMALIZE = True\n</code></pre>"},{"location":"API/all/#torchzero.modules.NormalizeByEMA.NORMALIZE","title":"NORMALIZE  <code>class-attribute</code>","text":"<pre><code>NORMALIZE = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.NystromPCG","title":"NystromPCG","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with a Nystr\u00f6m-preconditioned conjugate gradient solver.</p> Notes <ul> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> <li> <p>In most cases NystromPCG should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>size of the sketch for preconditioning, this many hessian-vector products will be evaluated before running the conjugate gradient solver. Larger value improves the preconditioning and speeds up conjugate gradient.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of iterations. By default this is set to the number of dimensions in the objective function, which is supposed to be enough for conjugate gradient to have guaranteed convergence. Setting this to a small value can still generate good enough directions. Defaults to None.</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>relative tolerance for conjugate gradient solver. Defaults to 1e-4.</p> </li> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>regularization parameter. Defaults to 1e-8.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules to apply hessian preconditioner to. Defaults to None.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random generator. Defaults to None.</p> </li> </ul> <p>Examples:</p> <p>NystromPCG with backtracking line search</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NystromPCG(10),\n    tz.m.Backtracking()\n)\n</code></pre> Reference <p>Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752. https://arxiv.org/abs/2110.02820</p> Source code in <code>torchzero/modules/second_order/nystrom.py</code> <pre><code>class NystromPCG(Transform):\n    \"\"\"Newton's method with a Nystr\u00f6m-preconditioned conjugate gradient solver.\n\n    Notes:\n        - This module requires the a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients for calculating HVPs.\n        The closure must accept a ``backward`` argument (refer to documentation).\n\n        - In most cases NystromPCG should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n    Args:\n        rank (int):\n            size of the sketch for preconditioning, this many hessian-vector products will be evaluated before\n            running the conjugate gradient solver. Larger value improves the preconditioning and speeds up\n            conjugate gradient.\n        maxiter (int | None, optional):\n            maximum number of iterations. By default this is set to the number of dimensions\n            in the objective function, which is supposed to be enough for conjugate gradient\n            to have guaranteed convergence. Setting this to a small value can still generate good enough directions.\n            Defaults to None.\n        tol (float, optional): relative tolerance for conjugate gradient solver. Defaults to 1e-4.\n        reg (float, optional): regularization parameter. Defaults to 1e-8.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        inner (Chainable | None, optional): modules to apply hessian preconditioner to. Defaults to None.\n        seed (int | None, optional): seed for random generator. Defaults to None.\n\n    Examples:\n\n    NystromPCG with backtracking line search\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NystromPCG(10),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Reference:\n        Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752. https://arxiv.org/abs/2110.02820\n\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 100,\n        maxiter=None,\n        tol=1e-8,\n        reg: float = 1e-6,\n        update_freq: int = 1, # here update_freq is within update_states\n        eigv_tol: float = 0,\n        orthogonalize_method: OrthogonalizeMethod = 'qr',\n        hvp_method: HVPMethod = \"batched_autograd\",\n        h=1e-3,\n        inner: Chainable | None = None,\n        seed: int | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        # ---------------------- Hessian vector product function --------------------- #\n        # this should run on every update_states\n        _, H_mv, H_mm = objective.tensor_Hvp_function(hvp_method=fs['hvp_method'], h=fs['h'], at_x0=True)\n        objective.temp = H_mv\n\n        # --------------------------- update preconditioner -------------------------- #\n        step = self.increment_counter(\"step\", 0)\n        if step % fs[\"update_freq\"] == 0:\n\n            ndim = sum(t.numel() for t in objective.params)\n            device = objective.params[0].device\n            dtype = objective.params[0].dtype\n            generator = self.get_generator(device, seed=fs['seed'])\n\n            try:\n                Omega = torch.randn(ndim, min(fs[\"rank\"], ndim), device=device, dtype=dtype, generator=generator)\n                HOmega = H_mm(orthogonalize(Omega, fs[\"orthogonalize_method\"]))\n                # compute the approximation\n                L, Q = nystrom_approximation(\n                    Omega=Omega,\n                    AOmega=HOmega,\n                    eigv_tol=fs[\"eigv_tol\"],\n                )\n\n                self.global_state[\"L\"] = L\n                self.global_state[\"Q\"] = Q\n\n            except torch.linalg.LinAlgError as e:\n                warnings.warn(f\"Nystrom approximation failed with: {e}\")\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        b = objective.get_updates()\n        H_mv = objective.poptemp()\n        fs = self.settings[objective.params[0]]\n\n        # ----------------------------------- solve ---------------------------------- #\n        if \"L\" not in self.global_state:\n            # fallback on cg\n            sol = cg(A_mv=H_mv, b=TensorList(b), tol=fs[\"tol\"], reg=fs[\"reg\"], maxiter=fs[\"maxiter\"])\n            objective.updates = sol.x\n            return objective\n\n        L = self.global_state[\"L\"]\n        Q = self.global_state[\"Q\"]\n\n        x = nystrom_pcg(L=L, Q=Q, A_mv=H_mv, b=torch.cat([t.ravel() for t in b]),\n                        reg=fs['reg'], tol=fs[\"tol\"], maxiter=fs[\"maxiter\"])\n\n        # -------------------------------- set update -------------------------------- #\n        objective.updates = vec_to_tensors(x, reference=objective.params)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.NystromSketchAndSolve","title":"NystromSketchAndSolve","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with a Nystr\u00f6m sketch-and-solve solver.</p> Notes <ul> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> <li> <p>In most cases NystromSketchAndSolve should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> <li> <p>If this is unstable, increase the <code>reg</code> parameter and tune the rank.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>size of the sketch, this many hessian-vector products will be evaluated per step.</p> </li> <li> <code>reg</code>               (<code>float | None</code>, default:                   <code>0.01</code> )           \u2013            <p>scale of identity matrix added to hessian. Note that if this is specified, nystrom sketch-and-solve is used to compute <code>(Q diag(L) Q.T + reg*I)x = b</code>. It is very unstable when <code>reg</code> is small, i.e. smaller than 1e-4. If this is None,<code>(Q diag(L) Q.T)x = b</code> is computed by simply taking reciprocal of eigenvalues. Defaults to 1e-3.</p> </li> <li> <code>eigv_tol</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>all eigenvalues smaller than largest eigenvalue times <code>eigv_tol</code> are removed. Defaults to None.</p> </li> <li> <code>truncate</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>keeps top <code>truncate</code> eigenvalues. Defaults to None.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>scalar added to eigenvalues. Defaults to 0.</p> </li> <li> <code>rdamping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>scalar multiplied by largest eigenvalue and added to eigenvalues. Defaults to 0.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating preconditioner. Defaults to 1.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules to apply hessian preconditioner to. Defaults to None.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random generator. Defaults to None.</p> </li> </ul> <p>Examples: NystromSketchAndSolve with backtracking line search</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NystromSketchAndSolve(100),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Trust region NystromSketchAndSolve</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquadt(tz.m.NystromSketchAndSolve(100)),\n)\n</code></pre> <p>References: - Frangella, Z., Rathore, P., Zhao, S., &amp; Udell, M. (2024). SketchySGD: Reliable Stochastic Optimization via Randomized Curvature Estimates. SIAM Journal on Mathematics of Data Science, 6(4), 1173-1204. - Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752</p> Source code in <code>torchzero/modules/second_order/nystrom.py</code> <pre><code>class NystromSketchAndSolve(Transform):\n    \"\"\"Newton's method with a Nystr\u00f6m sketch-and-solve solver.\n\n    Notes:\n        - This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n        - In most cases NystromSketchAndSolve should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n        - If this is unstable, increase the ``reg`` parameter and tune the rank.\n\n    Args:\n        rank (int): size of the sketch, this many hessian-vector products will be evaluated per step.\n        reg (float | None, optional):\n            scale of identity matrix added to hessian. Note that if this is specified, nystrom sketch-and-solve\n            is used to compute ``(Q diag(L) Q.T + reg*I)x = b``. It is very unstable when ``reg`` is small,\n            i.e. smaller than 1e-4. If this is None,``(Q diag(L) Q.T)x = b`` is computed by simply taking\n            reciprocal of eigenvalues. Defaults to 1e-3.\n        eigv_tol (float, optional):\n            all eigenvalues smaller than largest eigenvalue times ``eigv_tol`` are removed. Defaults to None.\n        truncate (int | None, optional):\n            keeps top ``truncate`` eigenvalues. Defaults to None.\n        damping (float, optional): scalar added to eigenvalues. Defaults to 0.\n        rdamping (float, optional): scalar multiplied by largest eigenvalue and added to eigenvalues. Defaults to 0.\n        update_freq (int, optional): frequency of updating preconditioner. Defaults to 1.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        inner (Chainable | None, optional): modules to apply hessian preconditioner to. Defaults to None.\n        seed (int | None, optional): seed for random generator. Defaults to None.\n\n\n    Examples:\n    NystromSketchAndSolve with backtracking line search\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NystromSketchAndSolve(100),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Trust region NystromSketchAndSolve\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquadt(tz.m.NystromSketchAndSolve(100)),\n    )\n    ```\n\n    References:\n    - [Frangella, Z., Rathore, P., Zhao, S., &amp; Udell, M. (2024). SketchySGD: Reliable Stochastic Optimization via Randomized Curvature Estimates. SIAM Journal on Mathematics of Data Science, 6(4), 1173-1204.](https://arxiv.org/pdf/2211.08597)\n    - [Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752](https://arxiv.org/abs/2110.02820)\n\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 100,\n        reg: float | None = 1e-2,\n        eigv_tol: float = 0,\n        truncate: int | None = None,\n        damping: float = 0,\n        rdamping: float = 0,\n        update_freq: int = 1,\n        orthogonalize_method: OrthogonalizeMethod = 'qr',\n        hvp_method: HVPMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n        seed: int | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"update_freq\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = TensorList(objective.params)\n        fs = settings[0]\n\n        # ---------------------- Hessian vector product function --------------------- #\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n        _, H_mv, H_mm = objective.tensor_Hvp_function(hvp_method=hvp_method, h=h, at_x0=True)\n\n        # ---------------------------------- sketch ---------------------------------- #\n        ndim = sum(t.numel() for t in objective.params)\n        device = params[0].device\n        dtype = params[0].dtype\n\n        generator = self.get_generator(params[0].device, seed=fs['seed'])\n        try:\n            Omega = torch.randn([ndim, min(fs[\"rank\"], ndim)], device=device, dtype=dtype, generator=generator)\n            Omega = orthogonalize(Omega, fs[\"orthogonalize_method\"])\n            HOmega = H_mm(Omega)\n\n            # compute the approximation\n            L, Q = nystrom_approximation(\n                Omega=Omega,\n                AOmega=HOmega,\n                eigv_tol=fs[\"eigv_tol\"],\n            )\n\n            # regularize\n            L, Q = regularize_eigh(\n                L=L,\n                Q=Q,\n                truncate=fs[\"truncate\"],\n                tol=fs[\"eigv_tol\"],\n                damping=fs[\"damping\"],\n                rdamping=fs[\"rdamping\"],\n            )\n\n            # store\n            if L is not None:\n                self.global_state[\"L\"] = L\n                self.global_state[\"Q\"] = Q\n\n        except torch.linalg.LinAlgError as e:\n            warnings.warn(f\"Nystrom approximation failed with: {e}\")\n\n    def apply_states(self, objective, states, settings):\n        if \"L\" not in self.global_state:\n            return objective\n\n        fs = settings[0]\n        updates = objective.get_updates()\n        b=torch.cat([t.ravel() for t in updates])\n\n        # ----------------------------------- solve ---------------------------------- #\n        L = self.global_state[\"L\"]\n        Q = self.global_state[\"Q\"]\n\n        if fs[\"reg\"] is None:\n            x = Q @ ((Q.mH @ b) / L)\n        else:\n            x = nystrom_sketch_and_solve(L=L, Q=Q, b=b, reg=fs[\"reg\"])\n\n        # -------------------------------- set update -------------------------------- #\n        objective.updates = vec_to_tensors(x, reference=objective.params)\n        return objective\n\n    def get_H(self, objective=...):\n        if \"L\" not in self.global_state:\n            return ScaledIdentity()\n\n        L = self.global_state[\"L\"]\n        Q = self.global_state[\"Q\"]\n        return Eigendecomposition(L, Q)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Ones","title":"Ones","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs ones</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Ones(Module):\n    \"\"\"Outputs ones\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.ones_like(p) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Online","title":"Online","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Allows certain modules to be used for mini-batch optimization.</p> <p>Examples:</p> <p>Online L-BFGS with Backtracking line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Online(tz.m.LBFGS()),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>Online L-BFGS trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.Online(tz.m.LBFGS()))\n)\n</code></pre></p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class Online(Module):\n    \"\"\"Allows certain modules to be used for mini-batch optimization.\n\n    Examples:\n\n    Online L-BFGS with Backtracking line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Online(tz.m.LBFGS()),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Online L-BFGS trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.Online(tz.m.LBFGS()))\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, module: Module,):\n        super().__init__()\n        self.set_child('module', module)\n\n    @torch.no_grad\n    def update(self, objective):\n        closure = objective.closure\n        if closure is None: raise ValueError(\"Closure must be passed for Online\")\n\n        step = self.increment_counter(\"step\", start = 0)\n\n        params = TensorList(objective.params)\n        p_cur = params.clone()\n        p_prev = self.get_state(params, 'p_prev', cls=TensorList)\n\n        module = self.children['module']\n        var_c = objective.clone(clone_updates=False)\n\n        # on 1st step just step and store previous params\n        if step == 0:\n            p_prev.copy_(params)\n\n            module.update(var_c)\n            objective.update_attrs_from_clone_(var_c)\n            return\n\n        # restore previous params and update\n        prev_objective = Objective(params=params, closure=closure, model=objective.model, current_step=objective.current_step)\n        params.set_(p_prev)\n        module.reset_for_online()\n        module.update(prev_objective)\n\n        # restore current params and update\n        params.set_(p_cur)\n        p_prev.copy_(params)\n        module.update(var_c)\n        objective.update_attrs_from_clone_(var_c)\n\n    @torch.no_grad\n    def apply(self, objective):\n        module = self.children['module']\n        return module.apply(objective.clone(clone_updates=False))\n\n    def get_H(self, objective):\n        return self.children['module'].get_H(objective)\n</code></pre>"},{"location":"API/all/#torchzero.modules.OrthoGrad","title":"OrthoGrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> <p>Parameters:</p> <ul> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon added to the denominator for numerical stability (default: 1e-30)</p> </li> <li> <code>renormalize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to graft projected gradient to original gradient norm. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/orthograd.py</code> <pre><code>class OrthoGrad(TensorTransform):\n    \"\"\"Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.\n\n    Args:\n        eps (float, optional): epsilon added to the denominator for numerical stability (default: 1e-30)\n        renormalize (bool, optional): whether to graft projected gradient to original gradient norm. Defaults to True.\n    \"\"\"\n    def __init__(self, eps: float = 1e-8, renormalize=True):\n        defaults = dict(eps=eps, renormalize=renormalize)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        eps = settings[0]['eps']\n        renormalize = settings[0]['renormalize']\n\n        params = TensorList(params)\n        target = TensorList(tensors)\n\n        scale = params.dot(target)/(params.dot(params) + eps)\n        if renormalize:\n            norm = target.global_vector_norm()\n            target -= params * scale\n            target *= (norm / target.global_vector_norm())\n            return target\n\n        target -= params * scale\n        return target\n</code></pre>"},{"location":"API/all/#torchzero.modules.Orthogonalize","title":"Orthogonalize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Uses Newton-Schulz iteration or SVD to compute the zeroth power / orthogonalization of update along first 2 dims.</p> <p>To disable orthogonalization for a parameter, put it into a parameter group with \"orthogonalize\" = False. The Muon page says that embeddings and classifier heads should not be orthogonalized. Usually only matrix parameters that are directly used in matmuls should be orthogonalized.</p> <p>To make Muon, use Split with Adam on 1d params</p> <p>Parameters:</p> <ul> <li> <code>adjust_lr</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Enables LR adjustment based on parameter size from \"Muon is Scalable for LLM Training\". Defaults to False.</p> </li> <li> <code>dual_norm_correction</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.</p> </li> <li> <code>method</code>               (<code>str</code>, default:                   <code>'newtonschulz'</code> )           \u2013            <p>Newton-Schulz is very fast, SVD is slow but can be more precise.</p> </li> <li> <code>channel_first</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions are considered batch dimensions.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Orthogonalize--examples","title":"Examples:","text":"<p>standard Muon with Adam fallback <pre><code>opt = tz.Optimizer(\n    model.head.parameters(),\n    tz.m.Split(\n        # apply muon only to 2D+ parameters\n        filter = lambda t: t.ndim &gt;= 2,\n        true = [\n            tz.m.HeavyBall(),\n            tz.m.Orthogonalize(),\n            tz.m.LR(1e-2),\n        ],\n        false = tz.m.Adam()\n    ),\n    tz.m.LR(1e-2)\n)\n</code></pre></p> Reference <p>Keller Jordan, Yuchen Jin, Vlado Boza, You Jiacheng, Franz Cesista, Laker Newhouse, Jeremy Bernstein - Muon: An optimizer for hidden layers in neural networks (2024) https://github.com/KellerJordan/Muon</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>class Orthogonalize(TensorTransform):\n    \"\"\"Uses Newton-Schulz iteration or SVD to compute the zeroth power / orthogonalization of update along first 2 dims.\n\n    To disable orthogonalization for a parameter, put it into a parameter group with \"orthogonalize\" = False.\n    The Muon page says that embeddings and classifier heads should not be orthogonalized.\n    Usually only matrix parameters that are directly used in matmuls should be orthogonalized.\n\n    To make Muon, use Split with Adam on 1d params\n\n    Args:\n        adjust_lr (bool, optional):\n            Enables LR adjustment based on parameter size from \"Muon is Scalable for LLM Training\". Defaults to False.\n        dual_norm_correction (bool, optional):\n            enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.\n        method (str, optional):\n            Newton-Schulz is very fast, SVD is slow but can be more precise.\n        channel_first (bool, optional):\n            if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions\n            are considered batch dimensions.\n\n    ## Examples:\n\n    standard Muon with Adam fallback\n    ```py\n    opt = tz.Optimizer(\n        model.head.parameters(),\n        tz.m.Split(\n            # apply muon only to 2D+ parameters\n            filter = lambda t: t.ndim &gt;= 2,\n            true = [\n                tz.m.HeavyBall(),\n                tz.m.Orthogonalize(),\n                tz.m.LR(1e-2),\n            ],\n            false = tz.m.Adam()\n        ),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    Reference:\n        Keller Jordan, Yuchen Jin, Vlado Boza, You Jiacheng, Franz Cesista, Laker Newhouse, Jeremy Bernstein - Muon: An optimizer for hidden layers in neural networks (2024) https://github.com/KellerJordan/Muon\n    \"\"\"\n    def __init__(self, adjust_lr=False, dual_norm_correction=False,\n                 method: OrthogonalizeMethod = 'newtonschulz', channel_first:bool=True):\n        defaults = dict(orthogonalize=True, dual_norm_correction=dual_norm_correction, adjust_lr=adjust_lr, method=method.lower(), channel_first=channel_first)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        orthogonalize, dual_norm_correction, adjust_lr, method, channel_first = itemgetter(\n            'orthogonalize', 'dual_norm_correction', 'adjust_lr', 'method', 'channel_first')(setting)\n\n        if not orthogonalize: return tensor\n\n        if _is_at_least_2d(tensor, channel_first=channel_first):\n\n            X = _orthogonalize_format(tensor, method, channel_first=channel_first)\n\n            if dual_norm_correction:\n                X = _dual_norm_correction(X, tensor, channel_first=channel_first)\n\n            if adjust_lr:\n                X.mul_(adjust_lr_for_muon(1, param.shape, channel_first=channel_first))\n\n            return X.view_as(param)\n\n        return tensor\n</code></pre>"},{"location":"API/all/#torchzero.modules.PSB","title":"PSB","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._HessianUpdateStrategyDefaults</code></p> <p>Powell's Symmetric Broyden Quasi-Newton method.</p> Note <p>a line search or a trust region is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class PSB(_HessianUpdateStrategyDefaults):\n    \"\"\"Powell's Symmetric Broyden Quasi-Newton method.\n\n    Note:\n        a line search or a trust region is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return psb_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.PSGDDenseNewton","title":"PSGDDenseNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Dense hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_norm</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips norm of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>dQ</code>               (<code>str</code>, default:                   <code>'Q0.5EQ1.5'</code> )           \u2013            <p>geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".</p> </li> <li> <code>hvp_method</code>               (<code>Literal</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to compute hessian-vector products. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>if <code>hvp_method</code> is <code>\"fd_central\"</code> or <code>\"fd_forward\"</code>, controls finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution for random vectors for hessian-vector products. Defaults to 'normal'.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.PSGDDenseNewton--examples","title":"Examples:","text":"<p>Pure Dense Newton PSGD: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.DenseNewton(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Applying preconditioner to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.DenseNewton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_dense_newton.py</code> <pre><code>class PSGDDenseNewton(Transform):\n    \"\"\"Dense hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional):\n            adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_norm (float, optional): clips norm of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        dQ (str, optional): geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".\n        hvp_method (HVPMethod, optional): how to compute hessian-vector products. Defaults to 'autograd'.\n        h (float, optional):\n            if ``hvp_method`` is ``\"fd_central\"`` or ``\"fd_forward\"``, controls finite difference step size.\n            Defaults to 1e-3.\n        distribution (Distributions, optional):\n            distribution for random vectors for hessian-vector products. Defaults to 'normal'.\n\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure Dense Newton PSGD:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.DenseNewton(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Applying preconditioner to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.DenseNewton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        init_scale: float | None = None,\n        lr_preconditioner=0.1,\n        betaL=0.9,\n        damping=1e-9,\n        grad_clip_max_norm=float(\"inf\"),\n        update_probability=1.0,\n        dQ: Literal[\"QUAD4P\", \"QUAD\", \"QEP\", \"EQ\", \"QEQ\", \"Q0p5EQ1p5\", \"Q0.5EQ1.5\"] = \"Q0.5EQ1.5\",\n\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        distribution: Distributions = 'normal',\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        # -------------------------------- initialize -------------------------------- #\n        if \"Q\" not in self.global_state:\n\n            p = objective.params[0]\n            dQ = fs[\"dQ\"]\n            init_scale = fs[\"init_scale\"]\n\n            if init_scale is None:\n                self.global_state[\"Q\"] = None\n\n            else:\n                n = sum(p.numel() for p in objective.params)\n                if dQ == \"QUAD4P\":\n                    init_scale *= init_scale\n                self.global_state[\"Q\"] = torch.eye(n, dtype=p.dtype, device=p.device) * init_scale\n\n            self.global_state[\"L\"] = lift2single(torch.zeros([], dtype=p.dtype, device=p.device)) # Lipschitz smoothness constant estimation for the psgd criterion\n\n            if dQ == \"QUAD4P\":\n                self.global_state[\"update_precond\"] = update_precond_dense_quad4p\n                self.global_state[\"precond_grad\"] = lambda Q, g: Q @ g\n                assert torch.finfo(p.dtype).eps &lt; 1e-6, \"Directly fitting P needs at least single precision\"\n\n            elif dQ == \"QUAD\":\n                self.global_state[\"update_precond\"] = update_precond_dense_quad\n                self.global_state[\"precond_grad\"] = lambda Q, g: Q @ (Q @ g) # Q is symmetric; just save one transpose\n\n            else:\n                self.global_state[\"precond_grad\"] = lambda Q, g: Q.T @ (Q @ g)\n                if dQ == \"QEP\":\n                    self.global_state[\"update_precond\"] = update_precond_dense_qep\n                elif dQ == \"EQ\":\n                    self.global_state[\"update_precond\"] = update_precond_dense_eq\n                elif dQ == \"QEQ\":\n                    self.global_state[\"update_precond\"] = update_precond_dense_qeq\n                else:\n                    assert (dQ == \"Q0p5EQ1p5\") or (dQ == \"Q0.5EQ1.5\"), f\"Invalid choice for dQ: '{dQ}'\"\n                    self.global_state[\"update_precond\"] = update_precond_dense_q0p5eq1p5\n\n        # ---------------------------------- update ---------------------------------- #\n        Q = self.global_state[\"Q\"]\n        if (torch.rand([]) &lt; fs[\"update_probability\"]) or Q is None:\n\n            # hessian-vector product\n            vs = TensorList(objective.params).sample_like(distribution=fs[\"distribution\"])\n            Hvs, _ = objective.hessian_vector_product(z=vs, rgrad=None, at_x0=True, hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n\n            v = torch.cat([t.ravel() for t in vs]).unsqueeze(1)\n            h = torch.cat([t.ravel() for t in Hvs]).unsqueeze(1)\n\n            # initialize on the fly\n            if Q is None:\n                scale = (torch.mean(v*v))**(1/4) * (torch.mean(h**4) + fs[\"damping\"]**4)**(-1/8)\n                if fs[\"dQ\"] == \"QUAD4P\": # Q actually is P in this case\n                    scale *= scale\n                Q = self.global_state[\"Q\"] = torch.eye(len(v), dtype=v.dtype, device=v.device) * scale\n\n            # update preconditioner\n            self.global_state[\"update_precond\"](\n                Q=Q,\n                L=self.global_state[\"L\"],\n                v=v,\n                h=h,\n                lr=fs[\"lr_preconditioner\"],\n                betaL=fs[\"betaL\"],\n                damping=fs[\"damping\"],\n            )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n\n        # cat grads\n        g = torch.cat([t.ravel() for t in updates]).unsqueeze(1) # column vec\n        pre_grad = self.global_state[\"precond_grad\"](self.global_state[\"Q\"], g)\n\n        # norm clipping\n        grad_clip_max_norm = settings[0][\"grad_clip_max_norm\"]\n        if grad_clip_max_norm &lt; float(\"inf\"): # clip preconditioned gradient\n            grad_norm = torch.linalg.vector_norm(pre_grad)\n            if grad_norm &gt; grad_clip_max_norm:\n                pre_grad *= grad_clip_max_norm / grad_norm\n\n        vec_to_tensors_(pre_grad, updates)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.PSGDKronNewton","title":"PSGDKronNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Kron hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.</p> </li> <li> <code>max_skew</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times <code>max_skew</code>, it uses a diagonal preconditioner. Defaults to 1.0.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_amp</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips amplitude of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>dQ</code>               (<code>str</code>, default:                   <code>'Q0.5EQ1.5'</code> )           \u2013            <p>geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".</p> </li> <li> <code>balance_probability</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.</p> </li> <li> <code>hvp_method</code>               (<code>Literal</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to compute hessian-vector products. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>if <code>hvp_method</code> is <code>\"fd_central\"</code> or <code>\"fd_forward\"</code>, controls finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution for random vectors for hessian-vector products. Defaults to 'normal'.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.PSGDKronNewton--examples","title":"Examples:","text":"<p>Pure PSGD Kron Newton: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronNewton(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Applying preconditioner to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronNewton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_kron_newton.py</code> <pre><code>class PSGDKronNewton(Transform):\n    \"\"\"Kron hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        max_dim (int, optional): dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.\n        max_skew (float, optional):\n            if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times ``max_skew``, it uses a diagonal preconditioner. Defaults to 1.0.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional): adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_amp (float, optional): clips amplitude of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        dQ (str, optional): geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".\n        balance_probability (float, optional):\n            probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.\n        hvp_method (HVPMethod, optional): how to compute hessian-vector products. Defaults to 'autograd'.\n        h (float, optional):\n            if ``hvp_method`` is ``\"fd_central\"`` or ``\"fd_forward\"``, controls finite difference step size.\n            Defaults to 1e-3.\n        distribution (Distributions, optional):\n            distribution for random vectors for hessian-vector products. Defaults to 'normal'.\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n\n    ###Examples:\n\n    Pure PSGD Kron Newton:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronNewton(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Applying preconditioner to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronNewton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        max_dim: int = 10_000,\n        max_skew: float = 1.0,\n        init_scale: float | None = None,\n        lr_preconditioner: float = 0.1,\n        betaL: float = 0.9,\n        damping: float = 1e-9,\n        grad_clip_max_amp: float = float(\"inf\"),\n        update_probability: float= 1.0,\n        dQ: Literal[\"QEP\", \"EQ\", \"QEQ\", \"QUAD\",  \"Q0.5EQ1.5\", \"Q0p5EQ1p5\", \"QUAD4P\"] = \"Q0.5EQ1.5\",\n        balance_probability: float = 0.01,\n\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        distribution: Distributions = 'normal',\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n\n    def _initialize_state(self, param, state, setting):\n        assert \"initialized\" not in state\n        state[\"initialized\"] = True\n\n        # initialize preconditioners\n        if setting[\"init_scale\"] is None:\n            warnings.warn(\"FYI: Will set the preconditioner initial scale on the fly. Recommend to set it manually.\")\n            state[\"QLs_exprs\"] = None\n        else:\n            state[\"QLs_exprs\"] = init_kron(\n                param.squeeze(),\n                Scale=setting[\"init_scale\"],\n                max_size=setting[\"max_dim\"],\n                max_skew=setting[\"max_skew\"],\n                dQ=setting[\"dQ\"],\n            )\n\n        dQ = setting[\"dQ\"]\n        if dQ == \"QUAD4P\":\n            assert torch.finfo(param.dtype).eps &lt; 1e-6, \"Directly fitting P needs at least single precision\"\n            state[\"update_precond\"] = update_precond_kron_newton_quad4p\n            state[\"precond_grad\"] = lambda QL, exprs, G: exprs[0](*QL[0], G) # it's exprA(*Q, G)\n\n        else:\n            state[\"precond_grad\"] = precond_grad_kron\n            if dQ == \"QEP\":\n                state[\"update_precond\"] = update_precond_kron_newton_quad\n            elif dQ == \"EQ\":\n                state[\"update_precond\"] = update_precond_kron_newton_qep\n            elif dQ == \"QEQ\":\n                state[\"update_precond\"] = update_precond_kron_newton_eq\n            elif dQ == \"QUAD\":\n                state[\"update_precond\"] = update_precond_kron_newton_qeq\n            else:\n                assert (dQ == \"Q0.5EQ1.5\") or (dQ == \"Q0p5EQ1p5\"), f\"Invalid choice for dQ: '{dQ}'\"\n                state[\"update_precond\"] = update_precond_kron_newton_q0p5eq1p5\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n\n        # initialize states\n        for param, state, setting in zip(objective.params, states, settings):\n            if \"initialized\" not in state:\n                self._initialize_state(param, state, setting)\n\n        fs = settings[0]\n\n        uninitialized = any(state[\"QLs_exprs\"] is None for state in states)\n        if (torch.rand([]) &lt; fs[\"update_probability\"]) or uninitialized:\n\n            # hessian-vector product\n            vs = TensorList(objective.params).sample_like(distribution=fs[\"distribution\"])\n            Hvs, _ = objective.hessian_vector_product(z=vs, rgrad=None, at_x0=True, hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n\n            # initialize on the fly (why does it use vs?)\n            if uninitialized:\n\n                scale = (sum([torch.sum(torch.abs(v)**2) for v in vs])/sum([v.numel() for v in vs])) ** (1/4) # (mean(|v|^2))^(1/4)\n\n                scale = scale * (max([torch.mean((torch.abs(h))**4) for h in Hvs]) + fs[\"damping\"]**4) ** (-1/8) # (mean(|v|^2))^(1/4) * (mean(|h|^4))^(-1/8)\n\n                for h, state, setting in zip(Hvs, states, settings):\n                    if state[\"QLs_exprs\"] is None:\n                        state[\"QLs_exprs\"] = init_kron(\n                            h.squeeze(),\n                            Scale=scale,\n                            max_size=setting[\"max_dim\"],\n                            max_skew=setting[\"max_skew\"],\n                            dQ=setting[\"dQ\"],\n                        )\n\n            # update preconditioner\n            for v, h, state, setting in zip(vs, Hvs, states, settings):\n                state[\"update_precond\"](\n                    *state[\"QLs_exprs\"],\n                    v.squeeze(),\n                    h.squeeze(),\n                    lr=setting[\"lr_preconditioner\"],\n                    betaL=setting[\"betaL\"],\n                    damping=setting[\"damping\"],\n                    balance_prob=setting[\"balance_probability\"]\n                )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n\n        params = objective.params\n        tensors = objective.get_updates()\n        pre_tensors = []\n\n        # precondition\n        for param, tensor, state in zip(params, tensors, states):\n            t = state[\"precond_grad\"](\n                *state[\"QLs_exprs\"],\n                tensor.squeeze(),\n            )\n            pre_tensors.append(t.view_as(param))\n\n        # norm clipping\n        grad_clip_max_amp = settings[0][\"grad_clip_max_amp\"]\n        if grad_clip_max_amp &lt; math.inf:\n            pre_tensors = TensorList(pre_tensors)\n            num_params = sum(t.numel() for t in pre_tensors)\n\n            avg_amp = pre_tensors.dot(pre_tensors.conj()).div(num_params).sqrt()\n\n            if avg_amp &gt; grad_clip_max_amp:\n                torch._foreach_mul_(pre_tensors, grad_clip_max_amp / avg_amp)\n\n        objective.updates = pre_tensors\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.PSGDKronWhiten","title":"PSGDKronWhiten","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Kron whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.</p> </li> <li> <code>max_skew</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times <code>max_skew</code>, it uses a diagonal preconditioner. Defaults to 1.0.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined from magnitude of the first gradient. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_amp</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips amplitude of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>dQ</code>               (<code>str</code>, default:                   <code>'Q0.5EQ1.5'</code> )           \u2013            <p>geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".</p> </li> <li> <code>balance_probability</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.PSGDKronWhiten--examples","title":"Examples:","text":"<p>Pure PSGD Kron: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Momentum into preconditioner (whitens momentum): <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.EMA(0.9),\n    tz.m.KronWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Updating the preconditioner from gradients and applying it to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronWhiten(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_kron_whiten.py</code> <pre><code>class PSGDKronWhiten(TensorTransform):\n    \"\"\"Kron whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        max_dim (int, optional): dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.\n        max_skew (float, optional):\n            if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times ``max_skew``, it uses a diagonal preconditioner. Defaults to 1.0.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined from magnitude of the first gradient. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional): adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_amp (float, optional): clips amplitude of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        dQ (str, optional): geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".\n        balance_probability (float, optional):\n            probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.\n\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure PSGD Kron:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Momentum into preconditioner (whitens momentum):\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.EMA(0.9),\n        tz.m.KronWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Updating the preconditioner from gradients and applying it to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronWhiten(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        max_dim: int = 10_000,\n        max_skew: float = 1.0,\n        init_scale: float | None = None,\n        lr_preconditioner: float = 0.1,\n        betaL: float = 0.9,\n        damping: float = 1e-9,\n        grad_clip_max_amp: float = float(\"inf\"),\n        update_probability: float= 1.0,\n        dQ: Literal[\"QEP\", \"EQ\", \"QEQ\", \"QUAD\",  \"Q0.5EQ1.5\", \"Q0p5EQ1p5\", \"QUAD4P\"] = \"Q0.5EQ1.5\",\n        balance_probability: float = 0.01,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        # initialize preconditioners\n        if setting[\"init_scale\"] is None:\n            # warnings.warn(\"FYI: Will set the preconditioner initial scale on the fly. Recommend to set it manually.\")\n            state[\"QLs_exprs\"] = None\n        else:\n            state[\"QLs_exprs\"] = init_kron(\n                param.squeeze(),\n                Scale=setting[\"init_scale\"],\n                max_size=setting[\"max_dim\"],\n                max_skew=setting[\"max_skew\"],\n                dQ=setting[\"dQ\"],\n            )\n\n        dQ = setting[\"dQ\"]\n        if dQ == \"QUAD4P\":\n            assert torch.finfo(param.dtype).eps &lt; 1e-6, \"Directly fitting P needs at least single precision\"\n            state[\"update_precond\"] = update_precond_kron_whiten_quad4p\n            state[\"precond_grad\"] = lambda QL, exprs, G: exprs[0](*QL[0], G) # it's exprA(*Q, G)\n\n        else:\n            state[\"precond_grad\"] = precond_grad_kron\n            if dQ == \"QEP\":\n                state[\"update_precond\"] = update_precond_kron_whiten_qep\n            elif dQ == \"EQ\":\n                state[\"update_precond\"] = update_precond_kron_whiten_eq\n            elif dQ == \"QEQ\":\n                state[\"update_precond\"] = update_precond_kron_whiten_qeq\n            elif dQ == \"QUAD\":\n                state[\"update_precond\"] = update_precond_kron_whiten_quad\n            else:\n                assert (dQ == \"Q0.5EQ1.5\") or (dQ == \"Q0p5EQ1p5\"), f\"Invalid choice for dQ: '{dQ}'\"\n                state[\"update_precond\"] = update_precond_kron_whiten_q0p5eq1p5\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n\n        # initialize on the fly if not initialized\n        if any(state[\"QLs_exprs\"] is None for state in states):\n\n            scale = max([torch.mean((torch.abs(g))**4) for g in tensors])\n            scale = (scale + settings[0][\"damping\"]**4)**(-1/8)\n\n            for param, state, setting in zip(params, states, settings):\n                if state[\"QLs_exprs\"] is None:\n                    state[\"QLs_exprs\"] = init_kron(\n                        param.squeeze(),\n                        Scale=scale,\n                        max_size=setting[\"max_dim\"],\n                        max_skew=setting[\"max_skew\"],\n                        dQ=setting[\"dQ\"],\n                    )\n\n\n        # update preconditioners\n        # (could also try per-parameter probability)\n        if torch.rand([]) &lt; settings[0][\"update_probability\"]: # update Q\n            for tensor, state, setting in zip(tensors, states, settings):\n                state[\"update_precond\"](\n                    *state[\"QLs_exprs\"],\n                    tensor.squeeze(),\n                    lr=setting[\"lr_preconditioner\"],\n                    betaL=setting[\"betaL\"],\n                    damping=setting[\"damping\"],\n                    balance_prob=setting[\"balance_probability\"]\n                )\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n\n        pre_tensors = []\n\n        # precondition\n        for param, tensor, state in zip(params, tensors, states):\n            t = state[\"precond_grad\"](\n                *state[\"QLs_exprs\"],\n                tensor.squeeze(),\n            )\n            pre_tensors.append(t.view_as(param))\n\n        # norm clipping\n        grad_clip_max_amp = settings[0][\"grad_clip_max_amp\"]\n        if grad_clip_max_amp &lt; math.inf:\n            pre_tensors = TensorList(pre_tensors)\n            num_params = sum(t.numel() for t in pre_tensors)\n\n            avg_amp = pre_tensors.dot(pre_tensors.conj()).div(num_params).sqrt()\n\n            if avg_amp &gt; grad_clip_max_amp:\n                torch._foreach_mul_(pre_tensors, grad_clip_max_amp / avg_amp)\n\n        return pre_tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.PSGDLRANewton","title":"PSGDLRANewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Low rank hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_norm</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips norm of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>hvp_method</code>               (<code>Literal</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to compute hessian-vector products. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>if <code>hvp_method</code> is <code>\"fd_central\"</code> or <code>\"fd_forward\"</code>, controls finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution for random vectors for hessian-vector products. Defaults to 'normal'.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.PSGDLRANewton--examples","title":"Examples:","text":"<p>Pure LRA Newton PSGD: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRANewton(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Applying preconditioner to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRANewton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_lra_newton.py</code> <pre><code>class PSGDLRANewton(Transform):\n    \"\"\"Low rank hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        rank (int, optional):\n            Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional):\n            adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_norm (float, optional): clips norm of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        hvp_method (HVPMethod, optional): how to compute hessian-vector products. Defaults to 'autograd'.\n        h (float, optional):\n            if ``hvp_method`` is ``\"fd_central\"`` or ``\"fd_forward\"``, controls finite difference step size.\n            Defaults to 1e-3.\n        distribution (Distributions, optional):\n            distribution for random vectors for hessian-vector products. Defaults to 'normal'.\n\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure LRA Newton PSGD:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRANewton(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Applying preconditioner to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRANewton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 10,\n        init_scale: float | None = None,\n        lr_preconditioner=0.1,\n        betaL=0.9,\n        damping=1e-9,\n        grad_clip_max_norm=float(\"inf\"),\n        update_probability=1.0,\n\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        distribution: Distributions = 'normal',\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        # initialize\n        if \"UVd\" not in self.global_state:\n            p = torch.cat([t.ravel() for t in objective.params])\n            _initialize_lra_state_(p, self.global_state, fs)\n\n        UVd = self.global_state[\"UVd\"]\n        if (torch.rand([]) &lt; fs[\"update_probability\"]) or (UVd[2] is None):\n\n            # hessian-vector product\n            vs = TensorList(objective.params).sample_like(distribution=fs[\"distribution\"])\n            Hvs, _ = objective.hessian_vector_product(z=vs, rgrad=None, at_x0=True, hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n\n            v = torch.cat([t.ravel() for t in vs]).unsqueeze(1)\n            h = torch.cat([t.ravel() for t in Hvs]).unsqueeze(1)\n\n            if UVd[2] is None:\n                UVd[2] = (torch.mean(v*v))**(1/4) * (torch.mean(h**4) + fs[\"damping\"]**4)**(-1/8) * torch.ones_like(v)\n\n            # update preconditioner\n            update_precond_lra_newton(UVd=UVd, Luvd=self.global_state[\"Luvd\"], v=v, h=h, lr=fs[\"lr_preconditioner\"], betaL=fs[\"betaL\"], damping=fs[\"damping\"])\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n\n        g = torch.cat([t.ravel() for t in updates]).unsqueeze(1) # column vec\n        pre_grad = precond_grad_lra(UVd=self.global_state[\"UVd\"], g=g)\n\n        # norm clipping\n        grad_clip_max_norm = settings[0][\"grad_clip_max_norm\"]\n        if grad_clip_max_norm &lt; float(\"inf\"): # clip preconditioned gradient\n            grad_norm = torch.linalg.vector_norm(pre_grad)\n            if grad_norm &gt; grad_clip_max_norm:\n                pre_grad *= grad_clip_max_norm / grad_norm\n\n        vec_to_tensors_(pre_grad, updates)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.PSGDLRAWhiten","title":"PSGDLRAWhiten","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Low rank whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_norm</code>               (<code>float</code>)           \u2013            <p>clips norm of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, treats all parameters as concatenated to a single vector. If False, each parameter is preconditioned separately. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.PSGDLRAWhiten--examples","title":"Examples:","text":"<p>Pure PSGD LRA: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRAWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Momentum into preconditioner (whitens momentum): <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.EMA(0.9),\n    tz.m.LRAWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Updating the preconditioner from gradients and applying it to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRAWhiten(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_lra_whiten.py</code> <pre><code>class PSGDLRAWhiten(TensorTransform):\n    \"\"\"Low rank whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        rank (int, optional):\n            Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional):\n            adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_norm (float, optional): clips norm of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        concat_params (bool, optional):\n            if True, treats all parameters as concatenated to a single vector.\n            If False, each parameter is preconditioned separately. Defaults to True.\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure PSGD LRA:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRAWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Momentum into preconditioner (whitens momentum):\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.EMA(0.9),\n        tz.m.LRAWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Updating the preconditioner from gradients and applying it to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRAWhiten(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 10,\n        init_scale: float | None = None,\n        lr_preconditioner=0.1,\n        betaL=0.9,\n        damping=1e-9,\n        grad_clip_max_amp=float(\"inf\"),\n        update_probability=1.0,\n\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, concat_params=concat_params, inner=inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        _initialize_lra_state_(tensor, state, setting)\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n\n        g = tensor.ravel().unsqueeze(1) # column vector\n\n        UVd = state[\"UVd\"]\n        if UVd[2] is None: # initialize d on the fly\n            UVd[2] = (torch.mean(g**4) + setting[\"damping\"]**4)**(-1/8) * torch.ones_like(g)\n\n        if torch.rand([]) &lt; setting[\"update_probability\"]:  # update preconditioner\n            update_precond_lra_whiten(\n                UVd=UVd,\n                Luvd=state[\"Luvd\"],\n                g=g,\n                lr=setting[\"lr_preconditioner\"],\n                betaL=setting[\"betaL\"],\n                damping=setting[\"damping\"],\n            )\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n\n        g = tensor.ravel().unsqueeze(1)\n        pre_grad = precond_grad_lra(UVd=state[\"UVd\"], g=g)\n\n        # norm clipping\n        grad_clip_max_amp = setting[\"grad_clip_max_amp\"]\n        if grad_clip_max_amp &lt; float(\"inf\"): # clip preconditioned gradient\n            amp = torch.sqrt(torch.mean(pre_grad * pre_grad))\n            if amp &gt; grad_clip_max_amp:\n                pre_grad *= grad_clip_max_amp/amp\n\n        return pre_grad.view_as(tensor)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Params","title":"Params","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs parameters</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Params(Module):\n    \"\"\"Outputs parameters\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [p.clone() for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Pearson","title":"Pearson","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Pearson's Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Pearson(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Pearson's Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return pearson_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.PerturbWeights","title":"PerturbWeights","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Changes the closure so that it evaluates loss and gradients at weights perturbed by a random perturbation.</p> <p>Can be disabled for a parameter by setting <code>perturb=False</code> in corresponding parameter group.</p> <p>Parameters:</p> <ul> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>multiplier for perturbation magnitude. Defaults to 0.1.</p> </li> <li> <code>relative</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to multiply perturbation by mean absolute value of the parameter. Defaults to True.</p> </li> <li> <code>distribution</code>               (<code>bool</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution of the random perturbation. Defaults to False.</p> </li> </ul> Source code in <code>torchzero/modules/misc/regularization.py</code> <pre><code>class PerturbWeights(Module):\n    \"\"\"\n    Changes the closure so that it evaluates loss and gradients at weights perturbed by a random perturbation.\n\n    Can be disabled for a parameter by setting ``perturb=False`` in corresponding parameter group.\n\n    Args:\n        alpha (float, optional): multiplier for perturbation magnitude. Defaults to 0.1.\n        relative (bool, optional): whether to multiply perturbation by mean absolute value of the parameter. Defaults to True.\n        distribution (bool, optional):\n            distribution of the random perturbation. Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = 0.1,\n        relative: bool = True,\n        distribution: Distributions = \"normal\",\n        metric: Metrics = \"mad\",\n    ):\n        defaults = dict(alpha=alpha, relative=relative, distribution=distribution, metric=metric, perturb=True)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def update(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError('WeightDropout requires closure')\n        params = TensorList(objective.params)\n\n        # create perturbations\n        perts = []\n        for p in params:\n            settings = self.settings[p]\n            if not settings['perturb']:\n                perts.append(torch.zeros_like(p))\n                continue\n\n            alpha = settings['alpha']\n            if settings['relative']:\n                alpha *= evaluate_metric(p, settings[\"metric\"])\n\n            distribution = self.settings[p]['distribution'].lower()\n            if distribution in ('normal', 'gaussian'):\n                perts.append(torch.randn_like(p).mul_(alpha))\n            elif distribution == 'uniform':\n                perts.append(torch.empty_like(p).uniform_(-alpha,alpha))\n            elif distribution == 'sphere':\n                r = torch.randn_like(p)\n                perts.append((r * alpha) / torch.linalg.vector_norm(r)) # pylint:disable=not-callable\n            else:\n                raise ValueError(distribution)\n\n        @torch.no_grad\n        def perturbed_closure(backward=True):\n            params.add_(perts)\n            if backward:\n                with torch.enable_grad(): loss = closure()\n            else:\n                loss = closure(False)\n            params.sub_(perts)\n            return loss\n\n        objective.closure = perturbed_closure\n</code></pre>"},{"location":"API/all/#torchzero.modules.PolakRibiere","title":"PolakRibiere","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Polak-Ribi\u00e8re-Polyak nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class PolakRibiere(ConguateGradientBase):\n    \"\"\"Polak-Ribi\u00e8re-Polyak nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, clip_beta=True, restart_interval: int | None | Literal['auto'] = 'auto', inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return polak_ribiere_beta(g, prev_g)\n</code></pre>"},{"location":"API/all/#torchzero.modules.PolyakStepSize","title":"PolyakStepSize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Polyak's subgradient method with known or unknown f*.</p> <p>Parameters:</p> <ul> <li> <code>f_star</code>               (<code>float | Mone</code>, default:                   <code>0</code> )           \u2013            <p>minimal possible value of the objective function. If not known, set to <code>None</code>. Defaults to 0.</p> </li> <li> <code>y</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>when <code>f_star</code> is set to None, it is calculated as <code>f_best - y</code>.</p> </li> <li> <code>y_decay</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p><code>y</code> is multiplied by <code>(1 - y_decay)</code> after each step. Defaults to 1e-3.</p> </li> <li> <code>max</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum possible step size. Defaults to None.</p> </li> <li> <code>use_grad</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, uses dot product of update and gradient to compute the step size. Otherwise, dot product of update with itself is used.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>multiplier to Polyak step-size. Defaults to 1.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class PolyakStepSize(TensorTransform):\n    \"\"\"Polyak's subgradient method with known or unknown f*.\n\n    Args:\n        f_star (float | Mone, optional):\n            minimal possible value of the objective function. If not known, set to ``None``. Defaults to 0.\n        y (float, optional):\n            when ``f_star`` is set to None, it is calculated as ``f_best - y``.\n        y_decay (float, optional):\n            ``y`` is multiplied by ``(1 - y_decay)`` after each step. Defaults to 1e-3.\n        max (float | None, optional): maximum possible step size. Defaults to None.\n        use_grad (bool, optional):\n            if True, uses dot product of update and gradient to compute the step size.\n            Otherwise, dot product of update with itself is used.\n        alpha (float, optional): multiplier to Polyak step-size. Defaults to 1.\n    \"\"\"\n    def __init__(self, f_star: float | None = 0, y: float = 1, y_decay: float = 1e-3, max: float | None = None, use_grad=True, alpha: float = 1, inner: Chainable | None = None):\n\n        defaults = dict(alpha=alpha, max=max, f_star=f_star, y=y, y_decay=y_decay)\n        super().__init__(defaults, uses_grad=use_grad, uses_loss=True, inner=inner)\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None and loss is not None\n        tensors = TensorList(tensors)\n        grads = TensorList(grads)\n\n        # load variables\n        max, f_star, y, y_decay = itemgetter('max', 'f_star', 'y', 'y_decay')(settings[0])\n        y_val = self.global_state.get('y_val', y)\n        f_best = self.global_state.get('f_best', None)\n\n        # gg\n        if self._uses_grad: gg = tensors.dot(grads)\n        else: gg = tensors.dot(tensors)\n\n        # store loss\n        if f_best is None or loss &lt; f_best: f_best = tofloat(loss)\n        if f_star is None: f_star = f_best - y_val\n\n        # calculate the step size\n        if gg &lt;= torch.finfo(gg.dtype).tiny * 2: alpha = 0 # converged\n        else: alpha = (loss - f_star) / gg\n\n        # clip\n        if max is not None:\n            if alpha &gt; max: alpha = max\n\n        # store state\n        self.global_state['f_best'] = f_best\n        self.global_state['y_val'] = y_val * (1 - y_decay)\n        self.global_state['alpha'] = alpha\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', 1)\n        if not _acceptable_alpha(alpha, tensors[0]): alpha = epsilon_step_size(TensorList(tensors))\n\n        torch._foreach_mul_(tensors, alpha * unpack_dicts(settings, 'alpha', cls=NumberList))\n        return tensors\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Pow","title":"Pow","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Take tensors to the power of <code>exponent</code>. <code>exponent</code> can be a number or a module.</p> <p>If <code>exponent</code> is a module, this calculates <code>tensors ^ exponent(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Pow(BinaryOperationBase):\n    \"\"\"Take tensors to the power of ``exponent``. ``exponent`` can be a number or a module.\n\n    If ``exponent`` is a module, this calculates ``tensors ^ exponent(tensors)``\n    \"\"\"\n    def __init__(self, exponent: Chainable | float):\n        super().__init__({}, exponent=exponent)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], exponent: float | list[torch.Tensor]):\n        torch._foreach_pow_(update, exponent)\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.PowModules","title":"PowModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input ** exponent</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class PowModules(MultiOperationBase):\n    \"\"\"Calculates ``input ** exponent``. ``input`` and ``other`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable | float, exponent: Chainable | float):\n        defaults = {}\n        super().__init__(defaults, input=input, exponent=exponent)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: float | list[torch.Tensor], exponent: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        if isinstance(input, (int,float)):\n            assert isinstance(exponent, list)\n            return input ** TensorList(exponent)\n\n        torch._foreach_div_(input, exponent)\n        return input\n</code></pre>"},{"location":"API/all/#torchzero.modules.PowellRestart","title":"PowellRestart","text":"<p>               Bases: <code>torchzero.modules.restarts.restars.RestartStrategyBase</code></p> <p>Powell's two restarting criterions for conjugate gradient methods.</p> <p>The restart clears all states of <code>modules</code>.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable | None</code>)           \u2013            <p>modules to reset. If None, resets all modules.</p> </li> <li> <code>cond1</code>               (<code>float | None</code>, default:                   <code>0.2</code> )           \u2013            <p>criterion that checks for nonconjugacy of the search directions. Restart is performed whenevr g^Tg_{k+1} &gt;= cond1*||g_{k+1}||^2. The default condition value of 0.2 is suggested by Powell. Can be None to disable that criterion.</p> </li> <li> <code>cond2</code>               (<code>float | None</code>, default:                   <code>0.2</code> )           \u2013            <p>criterion that checks if direction is not effectively downhill. Restart is performed if -1.2||g||^2 &lt; d^Tg &lt; -0.8||g||^2. Defaults to 0.2. Can be None to disable that criterion.</p> </li> </ul> Reference <p>Powell, Michael James David. \"Restart procedures for the conjugate gradient method.\" Mathematical programming 12.1 (1977): 241-254.</p> Source code in <code>torchzero/modules/restarts/restars.py</code> <pre><code>class PowellRestart(RestartStrategyBase):\n    \"\"\"Powell's two restarting criterions for conjugate gradient methods.\n\n    The restart clears all states of ``modules``.\n\n    Args:\n        modules (Chainable | None):\n            modules to reset. If None, resets all modules.\n        cond1 (float | None, optional):\n            criterion that checks for nonconjugacy of the search directions.\n            Restart is performed whenevr g^Tg_{k+1} &gt;= cond1*||g_{k+1}||^2.\n            The default condition value of 0.2 is suggested by Powell. Can be None to disable that criterion.\n        cond2 (float | None, optional):\n            criterion that checks if direction is not effectively downhill.\n            Restart is performed if -1.2||g||^2 &lt; d^Tg &lt; -0.8||g||^2.\n            Defaults to 0.2. Can be None to disable that criterion.\n\n    Reference:\n        Powell, Michael James David. \"Restart procedures for the conjugate gradient method.\" Mathematical programming 12.1 (1977): 241-254.\n    \"\"\"\n    def __init__(self, modules: Chainable | None, cond1:float | None = 0.2, cond2:float | None = 0.2):\n        defaults=dict(cond1=cond1, cond2=cond2)\n        super().__init__(defaults, modules)\n\n    def should_reset(self, objective):\n        g = TensorList(objective.get_grads())\n        cond1 = self.defaults['cond1']; cond2 = self.defaults['cond2']\n\n        # -------------------------------- initialize -------------------------------- #\n        if 'initialized' not in self.global_state:\n            self.global_state['initialized'] = 0\n            g_prev = self.get_state(objective.params, 'g_prev', init=g)\n            return False\n\n        g_g = g.dot(g)\n\n        reset = False\n        # ------------------------------- 1st condition ------------------------------ #\n        if cond1 is not None:\n            g_prev = self.get_state(objective.params, 'g_prev', must_exist=True, cls=TensorList)\n            g_g_prev = g_prev.dot(g)\n\n            if g_g_prev.abs() &gt;= cond1 * g_g:\n                reset = True\n\n        # ------------------------------- 2nd condition ------------------------------ #\n        if (cond2 is not None) and (not reset):\n            d_g = TensorList(objective.get_updates()).dot(g)\n            if (-1-cond2) * g_g &lt; d_g &lt; (-1 + cond2) * g_g:\n                reset = True\n\n        # ------------------------------ clear on reset ------------------------------ #\n        if reset:\n            self.global_state.clear()\n            self.clear_state_keys('g_prev')\n            return True\n\n        return False\n</code></pre>"},{"location":"API/all/#torchzero.modules.Previous","title":"Previous","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an update from n steps back, for example if n=1, returns previous update</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class Previous(TensorTransform):\n    \"\"\"Maintains an update from n steps back, for example if n=1, returns previous update\"\"\"\n    def __init__(self, n=1):\n        defaults = dict(n=n)\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        n = setting['n']\n\n        if 'history' not in state:\n            state['history'] = deque(maxlen=n+1)\n\n        state['history'].append(tensor)\n\n        return state['history'][0]\n</code></pre>"},{"location":"API/all/#torchzero.modules.PrintLoss","title":"PrintLoss","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints var.get_loss().</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintLoss(Module):\n    \"\"\"Prints var.get_loss().\"\"\"\n    def __init__(self, text = 'loss = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{objective.get_loss(False)}')\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.PrintParams","title":"PrintParams","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints current update.</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintParams(Module):\n    \"\"\"Prints current update.\"\"\"\n    def __init__(self, text = 'params = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{objective.params}')\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.PrintShape","title":"PrintShape","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints shapes of the update.</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintShape(Module):\n    \"\"\"Prints shapes of the update.\"\"\"\n    def __init__(self, text = 'shapes = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        shapes = [u.shape for u in objective.updates] if objective.updates is not None else None\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{shapes}')\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.PrintUpdate","title":"PrintUpdate","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints current update.</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintUpdate(Module):\n    \"\"\"Prints current update.\"\"\"\n    def __init__(self, text = 'update = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{objective.updates}')\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Prod","title":"Prod","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs product of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class Prod(ReduceOperationBase):\n    \"\"\"Outputs product of ``inputs`` that can be modules or numbers.\"\"\"\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        prod = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_mul_(prod, v)\n\n        return prod\n</code></pre>"},{"location":"API/all/#torchzero.modules.ProjectedGradientMethod","title":"ProjectedGradientMethod","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Projected gradient method. Directly projects the gradient onto subspace conjugate to past directions.</p> Notes <ul> <li>This method uses N^2 memory.</li> <li>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</li> <li>This is not the same as projected gradient descent.</li> </ul> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.  (algorithm 5 in section 6)</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class ProjectedGradientMethod(HessianUpdateStrategy): # this doesn't maintain hessian\n    \"\"\"Projected gradient method. Directly projects the gradient onto subspace conjugate to past directions.\n\n    Notes:\n        - This method uses N^2 memory.\n        - This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n        - This is not the same as projected gradient descent.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.  (algorithm 5 in section 6)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        init_scale: float | Literal[\"auto\"] = 1,\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = 'auto',\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        # inverse: bool = True,\n        inner: Chainable | None = None,\n    ):\n        super().__init__(\n            defaults=None,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return projected_gradient_(H=H, y=y)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ProjectedNewtonRaphson","title":"ProjectedNewtonRaphson","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Projected Newton Raphson method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.</p> <p>This one is Algorithm 7.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ProjectedNewtonRaphson(HessianUpdateStrategy):\n    \"\"\"\n    Projected Newton Raphson method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.\n\n        This one is Algorithm 7.\n    \"\"\"\n    def __init__(\n        self,\n        init_scale: float | Literal[\"auto\"] = 'auto',\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = 'auto',\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        super().__init__(\n            init_scale=init_scale,\n            tol=tol,\n            ptol = ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        if 'R' not in state: state['R'] = torch.eye(H.size(-1), device=H.device, dtype=H.dtype)\n        H, R = projected_newton_raphson_H_(H=H, R=state['R'], s=s, y=y)\n        state[\"R\"] = R\n        return H\n\n    def reset_P(self, P, s, y, inverse, init_scale, state):\n        assert inverse\n        if 'R' not in state: state['R'] = torch.eye(P.size(-1), device=P.device, dtype=P.dtype)\n        P.copy_(state[\"R\"])\n</code></pre>"},{"location":"API/all/#torchzero.modules.ProjectionBase","title":"ProjectionBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for projections. This is an abstract class, to use it, subclass it and override <code>project</code> and <code>unproject</code>.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable</code>)           \u2013            <p>modules that will be applied in the projected domain.</p> </li> <li> <code>project_update</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to project the update. Defaults to True.</p> </li> <li> <code>project_params</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to project the params. This is necessary for modules that use closure. Defaults to False.</p> </li> <li> <code>project_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to project the gradients (separately from update). Defaults to False.</p> </li> <li> <code>defaults</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>dictionary with defaults. Defaults to None.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>project</code>             \u2013              <p>projects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> </li> <li> <code>unproject</code>             \u2013              <p>unprojects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> </li> </ul> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>class ProjectionBase(Module, ABC):\n    \"\"\"\n    Base class for projections.\n    This is an abstract class, to use it, subclass it and override ``project`` and ``unproject``.\n\n    Args:\n        modules (Chainable): modules that will be applied in the projected domain.\n        project_update (bool, optional): whether to project the update. Defaults to True.\n        project_params (bool, optional):\n            whether to project the params. This is necessary for modules that use closure. Defaults to False.\n        project_grad (bool, optional): whether to project the gradients (separately from update). Defaults to False.\n        defaults (dict[str, Any] | None, optional): dictionary with defaults. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        modules: Chainable,\n        project_update=True,\n        project_params=False,\n        project_grad=False,\n        defaults: dict[str, Any] | None = None,\n    ):\n        super().__init__(defaults)\n        self.set_child('modules', modules)\n        self.global_state['current_step'] = 0\n        self._project_update = project_update\n        self._project_params = project_params\n        self._project_grad = project_grad\n        self._projected_params = None\n\n        self._states: dict[str, list[dict[str, Any]]] = {}\n        \"\"\"per-parameter states for each projection target\"\"\"\n\n    @abstractmethod\n    def project(\n        self,\n        tensors: list[torch.Tensor],\n        params: list[torch.Tensor],\n        grads: list[torch.Tensor] | None,\n        loss: torch.Tensor | None,\n        states: list[dict[str, Any]],\n        settings: list[ChainMap[str, Any]],\n        current: str,\n    ) -&gt; Iterable[torch.Tensor]:\n        \"\"\"projects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\"\"\"\n\n    @abstractmethod\n    def unproject(\n        self,\n        projected_tensors: list[torch.Tensor],\n        params: list[torch.Tensor],\n        grads: list[torch.Tensor] | None,\n        loss: torch.Tensor | None,\n        states: list[dict[str, Any]],\n        settings: list[ChainMap[str, Any]],\n        current: str,\n    ) -&gt; Iterable[torch.Tensor]:\n        \"\"\"unprojects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\n\n        Args:\n            projected_tensors (list[torch.Tensor]): projected tensors to unproject.\n            params (list[torch.Tensor]): original, unprojected parameters.\n            grads (list[torch.Tensor] | None): original, unprojected gradients\n            loss (torch.Tensor | None): loss at initial point.\n            states (list[dict[str, Any]]): list of state dictionaries per each UNPROJECTED tensor.\n            settings (list[ChainMap[str, Any]]): list of setting dictionaries per each UNPROJECTED tensor.\n            current (str): string representing what is being unprojected, e.g. \"params\", \"grads\" or \"update\".\n\n        Returns:\n            Iterable[torch.Tensor]: unprojected tensors of the same shape as params\n        \"\"\"\n\n    def update(self, objective: Objective): raise RuntimeError(\"projections don't support update/apply\")\n    def apply(self, objective: Objective): raise RuntimeError(\"projections don't support update/apply\")\n\n    @torch.no_grad\n    def step(self, objective: Objective):\n        params = objective.params\n        settings = [self.settings[p] for p in params]\n\n        def _project(tensors: list[torch.Tensor], current: Literal['params', 'grads', 'update']):\n            states = self._states.setdefault(current, [{} for _ in params])\n            return list(self.project(\n                tensors=tensors,\n                params=params,\n                grads=objective.grads,\n                loss=objective.loss,\n                states=states,\n                settings=settings,\n                current=current,\n            ))\n\n        projected_obj = objective.clone(clone_updates=False, parent=objective)\n\n        closure = objective.closure\n\n        # if this is True, update and grad were projected simultaneously under current=\"grads\"\n        # so update will have to be unprojected with current=\"grads\"\n        update_is_grad = False\n\n        # if closure is provided and project_params=True, make new closure that evaluates projected params\n        # that also means projected modules can evaluate grad/update at will, it shouldn't be computed here\n        # but if it has already been computed, it should be projected\n        if self._project_params and closure is not None:\n\n            if self._project_update and objective.updates is not None:\n                # project update only if it already exists\n                projected_obj.updates = _project(objective.updates, current='update')\n\n            else:\n                # update will be set to gradients on var.get_grad()\n                # therefore projection will happen with current=\"grads\"\n                update_is_grad = True\n\n            # project grad only if it already exists\n            if self._project_grad and objective.grads is not None:\n                projected_obj.grads = _project(objective.grads, current='grads')\n\n        # otherwise update/grad needs to be calculated and projected here\n        else:\n            if self._project_update:\n                if objective.updates is None:\n                    # update is None, meaning it will be set to `grad`.\n                    # we can project grad and use it for update\n                    grad = objective.get_grads()\n                    projected_obj.grads = _project(grad, current='grads')\n                    projected_obj.updates = [g.clone() for g in projected_obj.grads]\n                    del objective.updates\n                    update_is_grad = True\n\n                else:\n                    # update exists so it needs to be projected\n                    update = objective.get_updates()\n                    projected_obj.updates = _project(update, current='update')\n                    del update, objective.updates\n\n            if self._project_grad and projected_obj.grads is None:\n                # projected_vars.grad may have been projected simultaneously with update\n                # but if that didn't happen, it is projected here\n                grad = objective.get_grads()\n                projected_obj.grads = _project(grad, current='grads')\n\n\n        original_params = None\n        if self._project_params:\n            original_params = [p.clone() for p in objective.params]\n            projected_params = _project(objective.params, current='params')\n\n        else:\n            # make fake params for correct shapes and state storage\n            # they reuse update or grad storage for memory efficiency\n            projected_params = projected_obj.updates if projected_obj.updates is not None else projected_obj.grads\n            assert projected_params is not None\n\n        if self._projected_params is None:\n            # 1st step - create objects for projected_params. They have to remain the same python objects\n            # to support per-parameter states which are stored by ids.\n            self._projected_params = [p.view_as(p).requires_grad_() for p in projected_params]\n        else:\n            # set storage to new fake params while ID remains the same\n            for empty_p, new_p in zip(self._projected_params, projected_params):\n                empty_p.set_(new_p.view_as(new_p).requires_grad_()) # pyright: ignore[reportArgumentType]\n\n        projected_params = self._projected_params\n        # projected_settings = [self.settings[p] for p in projected_params]\n\n        def _unproject(projected_tensors: list[torch.Tensor], current: Literal['params', 'grads', 'update']):\n            states = self._states.setdefault(current, [{} for _ in params])\n            return list(self.unproject(\n                projected_tensors=projected_tensors,\n                params=params,\n                grads=objective.grads,\n                loss=objective.loss,\n                states=states,\n                settings=settings,\n                current=current,\n            ))\n\n        # project closure\n        if self._project_params:\n            projected_obj.closure = _make_projected_closure(closure, project_fn=_project, unproject_fn=_unproject,\n                                                            params=params, projected_params=projected_params)\n\n        elif closure is not None:\n            projected_obj.closure = _FakeProjectedClosure(closure, project_fn=_project,\n                                                          params=params, fake_params=projected_params)\n\n        else:\n            projected_obj.closure = None\n\n        # ----------------------------------- step ----------------------------------- #\n        projected_obj.params = projected_params\n        projected_obj = self.children['modules'].step(projected_obj)\n\n        # empty fake params storage\n        # this doesn't affect update/grad because it is a different python object, set_ changes storage on an object\n        if not self._project_params:\n            for p in self._projected_params:\n                set_storage_(p, torch.empty(0, device=p.device, dtype=p.dtype))\n\n        # --------------------------------- unproject -------------------------------- #\n        unprojected_obj = projected_obj.clone(clone_updates=False)\n        unprojected_obj.closure = objective.closure\n        unprojected_obj.params = objective.params\n        unprojected_obj.grads = objective.grads # this may also be set by projected_var since it has var as parent\n\n        if self._project_update:\n            assert projected_obj.updates is not None\n            unprojected_obj.updates = _unproject(projected_obj.updates, current='grads' if update_is_grad else 'update')\n            del projected_obj.updates\n\n        del projected_obj\n\n        # original params are stored if params are projected\n        if original_params is not None:\n            for p, o in zip(unprojected_obj.params, original_params):\n                p.set_(o) # pyright: ignore[reportArgumentType]\n\n        return unprojected_obj\n</code></pre>"},{"location":"API/all/#torchzero.modules.ProjectionBase.project","title":"project","text":"<pre><code>project(tensors: list[Tensor], params: list[Tensor], grads: list[Tensor] | None, loss: Tensor | None, states: list[dict[str, Any]], settings: list[ChainMap[str, Any]], current: str) -&gt; Iterable[Tensor]\n</code></pre> <p>projects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>@abstractmethod\ndef project(\n    self,\n    tensors: list[torch.Tensor],\n    params: list[torch.Tensor],\n    grads: list[torch.Tensor] | None,\n    loss: torch.Tensor | None,\n    states: list[dict[str, Any]],\n    settings: list[ChainMap[str, Any]],\n    current: str,\n) -&gt; Iterable[torch.Tensor]:\n    \"\"\"projects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.ProjectionBase.unproject","title":"unproject","text":"<pre><code>unproject(projected_tensors: list[Tensor], params: list[Tensor], grads: list[Tensor] | None, loss: Tensor | None, states: list[dict[str, Any]], settings: list[ChainMap[str, Any]], current: str) -&gt; Iterable[Tensor]\n</code></pre> <p>unprojects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> <p>Parameters:</p> <ul> <li> <code>projected_tensors</code>               (<code>list[Tensor]</code>)           \u2013            <p>projected tensors to unproject.</p> </li> <li> <code>params</code>               (<code>list[Tensor]</code>)           \u2013            <p>original, unprojected parameters.</p> </li> <li> <code>grads</code>               (<code>list[Tensor] | None</code>)           \u2013            <p>original, unprojected gradients</p> </li> <li> <code>loss</code>               (<code>Tensor | None</code>)           \u2013            <p>loss at initial point.</p> </li> <li> <code>states</code>               (<code>list[dict[str, Any]]</code>)           \u2013            <p>list of state dictionaries per each UNPROJECTED tensor.</p> </li> <li> <code>settings</code>               (<code>list[ChainMap[str, Any]]</code>)           \u2013            <p>list of setting dictionaries per each UNPROJECTED tensor.</p> </li> <li> <code>current</code>               (<code>str</code>)           \u2013            <p>string representing what is being unprojected, e.g. \"params\", \"grads\" or \"update\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterable[Tensor]</code>           \u2013            <p>Iterable[torch.Tensor]: unprojected tensors of the same shape as params</p> </li> </ul> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>@abstractmethod\ndef unproject(\n    self,\n    projected_tensors: list[torch.Tensor],\n    params: list[torch.Tensor],\n    grads: list[torch.Tensor] | None,\n    loss: torch.Tensor | None,\n    states: list[dict[str, Any]],\n    settings: list[ChainMap[str, Any]],\n    current: str,\n) -&gt; Iterable[torch.Tensor]:\n    \"\"\"unprojects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\n\n    Args:\n        projected_tensors (list[torch.Tensor]): projected tensors to unproject.\n        params (list[torch.Tensor]): original, unprojected parameters.\n        grads (list[torch.Tensor] | None): original, unprojected gradients\n        loss (torch.Tensor | None): loss at initial point.\n        states (list[dict[str, Any]]): list of state dictionaries per each UNPROJECTED tensor.\n        settings (list[ChainMap[str, Any]]): list of setting dictionaries per each UNPROJECTED tensor.\n        current (str): string representing what is being unprojected, e.g. \"params\", \"grads\" or \"update\".\n\n    Returns:\n        Iterable[torch.Tensor]: unprojected tensors of the same shape as params\n    \"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.RCopySign","title":"RCopySign","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RCopySign(BinaryOperationBase):\n    \"\"\"Returns ``other(tensors)`` with sign copied from tensors.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        return [o.copysign_(u) for u, o in zip(update, other)]\n</code></pre>"},{"location":"API/all/#torchzero.modules.RDSA","title":"RDSA","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Gradient approximation via Random-direction stochastic approximation (RDSA) method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central2'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution. Defaults to \"gaussian\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class RDSA(RandomizedFDM):\n    \"\"\"\n    Gradient approximation via Random-direction stochastic approximation (RDSA) method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"gaussian\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771\n\n    \"\"\"\n    def __init__(\n        self,\n        h: float = 1e-3,\n        n_samples: int = 1,\n        formula: _FD_Formula = \"central2\",\n        distribution: Distributions = \"gaussian\",\n        pre_generate: bool = True,\n        return_approx_loss: bool = False,\n        target: GradTarget = \"closure\",\n        seed: int | None | torch.Generator = None,\n    ):\n        super().__init__(h=h, n_samples=n_samples,formula=formula,distribution=distribution,pre_generate=pre_generate,target=target,seed=seed, return_approx_loss=return_approx_loss)\n</code></pre>"},{"location":"API/all/#torchzero.modules.RDiv","title":"RDiv","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Divide <code>other</code> by tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>other(tensors) / tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RDiv(BinaryOperationBase):\n    \"\"\"Divide ``other`` by tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``other(tensors) / tensors``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        return other / TensorList(update)\n</code></pre>"},{"location":"API/all/#torchzero.modules.RMSprop","title":"RMSprop","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Divides graient by EMA of gradient squares.</p> <p>This implementation is identical to :code:<code>torch.optim.RMSprop</code>.</p> <p>Parameters:</p> <ul> <li> <code>smoothing</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for exponential moving average of gradient squares. Defaults to 0.99.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for division. Defaults to 1e-8.</p> </li> <li> <code>centered</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to center EMA of gradient squares using an additional EMA. Defaults to False.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>applies Adam debiasing. Defaults to False.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>)           \u2013            <p>power used in second momentum power and root. Defaults to 2.</p> </li> <li> <code>init</code>               (<code>str</code>, default:                   <code>'zeros'</code> )           \u2013            <p>how to initialize EMA, either \"update\" to use first update or \"zeros\". Defaults to \"update\".</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>Inner modules that are applied after updating EMA and before preconditioning. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/rmsprop.py</code> <pre><code>class RMSprop(TensorTransform):\n    \"\"\"Divides graient by EMA of gradient squares.\n\n    This implementation is identical to :code:`torch.optim.RMSprop`.\n\n    Args:\n        smoothing (float, optional): beta for exponential moving average of gradient squares. Defaults to 0.99.\n        eps (float, optional): epsilon for division. Defaults to 1e-8.\n        centered (bool, optional): whether to center EMA of gradient squares using an additional EMA. Defaults to False.\n        debias (bool, optional): applies Adam debiasing. Defaults to False.\n        amsgrad (bool, optional): Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.\n        pow (float, optional): power used in second momentum power and root. Defaults to 2.\n        init (str, optional): how to initialize EMA, either \"update\" to use first update or \"zeros\". Defaults to \"update\".\n        inner (Chainable | None, optional):\n            Inner modules that are applied after updating EMA and before preconditioning. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        smoothing: float = 0.99,\n        eps: float = 1e-8,\n        centered: bool = False,\n        debias: bool = False,\n        amsgrad: bool = False,\n        init: Literal[\"zeros\", \"update\"] = \"zeros\",\n\n        inner: Chainable | None = None,\n        exp_avg_sq_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"inner\"], defaults[\"exp_avg_sq_tfm\"]\n        super().__init__(defaults, inner=inner)\n\n        self.set_child('exp_avg_sq', exp_avg_sq_tfm)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"exp_avg_sq_max\")\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        if setting[\"init\"] == \"zeros\":\n            state[\"exp_avg_sq\"] = torch.zeros_like(tensor)\n            if setting[\"centered\"]: state[\"exp_avg\"] = torch.zeros_like(tensor)\n            if setting[\"amsgrad\"]: state[\"amsgrad\"] = torch.zeros_like(tensor)\n\n        else:\n            state[\"exp_avg_sq\"] = tensor ** 2\n            if setting[\"centered\"]: state[\"exp_avg\"] = tensor.clone()\n            if setting[\"amsgrad\"]: state[\"amsgrad\"] = tensor ** 2\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        self.increment_counter(\"step\", start = 0)\n        fs = settings[0]\n\n        exp_avg_sq = unpack_states(states, tensors, \"exp_avg_sq\", cls=TensorList)\n\n        # update exponential average\n        smoothing = NumberList(s[\"smoothing\"] for s in settings)\n        exp_avg_sq.mul_(smoothing).addcmul_(tensors, tensors, value=1-smoothing)\n\n        # update mean estimate if centered\n        if fs[\"centered\"]:\n            exp_avg = unpack_states(states, tensors, \"exp_avg\", cls=TensorList)\n            exp_avg.lerp_(tensors, 1-smoothing)\n\n        # amsgrad\n        if fs[\"amsgrad\"]:\n            exp_avg_sq_max = unpack_states(states, tensors, \"exp_avg_sq_max\", cls=TensorList)\n            exp_avg_sq_max.maximum_(exp_avg_sq)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        step = self.global_state[\"step\"] # 0 on 1st step\n        eps = NumberList(s[\"eps\"] for s in settings)\n        fs = settings[0]\n\n        if fs[\"amsgrad\"]: key = \"max_exp_avg_sq\"\n        else: key = \"exp_avg_sq\"\n        exp_avg_sq = TensorList(s[key] for s in states)\n\n        # load mean estimate if centered\n        exp_avg = None\n        if fs['centered']:\n            exp_avg = TensorList(s[\"exp_avg\"] for s in states)\n\n        # debias exp_avg_sq and exp_avg\n        if fs[\"debias\"]:\n            smoothing = NumberList(s[\"smoothing\"] for s in settings)\n            bias_correction = 1 - (smoothing ** (step + 1))\n            exp_avg_sq = exp_avg_sq / bias_correction\n\n            if fs['centered']:\n                assert exp_avg is not None\n                exp_avg = exp_avg / bias_correction\n\n        # apply transform to potentially debiased exp_avg_sq\n        exp_avg_sq = TensorList(self.inner_step_tensors(\n            \"exp_avg_sq\", exp_avg_sq, params=params, grads=grads, loss=loss, clone=True, must_exist=False\n        ))\n\n        # center\n        if fs[\"centered\"]:\n            assert exp_avg is not None\n            exp_avg_sq = exp_avg_sq.addcmul(exp_avg, exp_avg, value=-1)\n\n        return tensors.div_(exp_avg_sq.sqrt().add_(eps))\n</code></pre>"},{"location":"API/all/#torchzero.modules.RPow","title":"RPow","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Take <code>other</code> to the power of tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>other(tensors) ^ tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RPow(BinaryOperationBase):\n    \"\"\"Take ``other`` to the power of tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``other(tensors) ^ tensors``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        if isinstance(other, (int, float)): return torch._foreach_pow(other, update) # no in-place\n        torch._foreach_pow_(other, update)\n        return other\n</code></pre>"},{"location":"API/all/#torchzero.modules.RSub","title":"RSub","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Subtract tensors from <code>other</code>. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>other(tensors) - tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RSub(BinaryOperationBase):\n    \"\"\"Subtract tensors from ``other``. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``other(tensors) - tensors``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        return other - TensorList(update)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Randn","title":"Randn","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with random numbers from a normal distribution with mean 0 and variance 1.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Randn(Module):\n    \"\"\"Outputs tensors filled with random numbers from a normal distribution with mean 0 and variance 1.\"\"\"\n    def __init__(self):\n        super().__init__({})\n\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.randn_like(p) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.RandomHvp","title":"RandomHvp","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Returns a hessian-vector product with a random vector, optionally times vector</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class RandomHvp(Module):\n    \"\"\"Returns a hessian-vector product with a random vector, optionally times vector\"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 1,\n        distribution: Distributions = \"normal\",\n        update_freq: int = 1,\n        zHz: bool = False,\n        hvp_method: Literal[\"autograd\", \"fd_forward\", \"central\"] = \"autograd\",\n        h=1e-3,\n        seed: int | None = None\n    ):\n        defaults = locals().copy()\n        del defaults['self']\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        params = TensorList(objective.params)\n\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        D = None\n        update_freq = self.defaults['update_freq']\n        if step % update_freq == 0:\n\n            D, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = self.defaults['n_samples'],\n                distribution = self.defaults['distribution'],\n                hvp_method = self.defaults['hvp_method'],\n                h = self.defaults['h'],\n                zHz = self.defaults[\"zHz\"],\n                generator = self.get_generator(params[0].device, self.defaults[\"seed\"]),\n            )\n\n            if update_freq != 1:\n                assert D is not None\n                D_buf = self.get_state(params, \"D\", cls=TensorList)\n                D_buf.set_(D)\n\n        if D is None:\n            D = self.get_state(params, \"D\", cls=TensorList)\n\n        objective.updates = list(D)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.RandomReinitialize","title":"RandomReinitialize","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>On each step with probability <code>p_reinit</code> trigger reinitialization, whereby <code>p_weights</code> weights are reset to their initial values.</p> <p>This modifies the parameters directly. Place it as the first module.</p> <p>Parameters:</p> <ul> <li> <code>p_reinit</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>probability to trigger reinitialization on each step. Defaults to 0.01.</p> </li> <li> <code>p_weights</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>probability for each weight to be set to initial value when reinitialization is triggered. Defaults to 0.1.</p> </li> <li> <code>store_every</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>if set, stores new initial values every this many steps. Defaults to None.</p> </li> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>whenever <code>store_every</code> is triggered, uses linear interpolation with this beta. If <code>store_every=1</code>, this can be set to some value close to 1 such as 0.999 to reinitialize to slow parameter EMA. Defaults to 0.</p> </li> <li> <code>reset</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to reset states of other modules on reinitialization. Defaults to False.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>random seed.</p> </li> </ul> Source code in <code>torchzero/modules/weight_decay/reinit.py</code> <pre><code>class RandomReinitialize(Module):\n    \"\"\"On each step with probability ``p_reinit`` trigger reinitialization,\n    whereby ``p_weights`` weights are reset to their initial values.\n\n    This modifies the parameters directly. Place it as the first module.\n\n    Args:\n        p_reinit (float, optional): probability to trigger reinitialization on each step. Defaults to 0.01.\n        p_weights (float, optional): probability for each weight to be set to initial value when reinitialization is triggered. Defaults to 0.1.\n        store_every (int | None, optional): if set, stores new initial values every this many steps. Defaults to None.\n        beta (float, optional):\n            whenever ``store_every`` is triggered, uses linear interpolation with this beta.\n            If ``store_every=1``, this can be set to some value close to 1 such as 0.999\n            to reinitialize to slow parameter EMA. Defaults to 0.\n        reset (bool, optional): whether to reset states of other modules on reinitialization. Defaults to False.\n        seed (int | None, optional): random seed.\n    \"\"\"\n\n    def __init__(\n        self,\n        p_reinit: float = 0.01,\n        p_weights: float = 0.1,\n        store_every: int | None = None,\n        beta: float = 0,\n        reset: bool = False,\n        seed: int | None = None,\n    ):\n        defaults = dict(p_weights=p_weights, p_reinit=p_reinit, store_every=store_every, beta=beta, reset=reset, seed=seed)\n        super().__init__(defaults)\n\n    def update(self, objective):\n        # this stores initial values to per-parameter states\n        p_init = self.get_state(objective.params, \"p_init\", init=\"params\", cls=TensorList)\n\n        # store new params every store_every steps\n        step = self.global_state.get(\"step\", 0)\n        self.global_state[\"step\"] = step + 1\n\n        store_every = self.defaults[\"store_every\"]\n        if (store_every is not None and step % store_every == 0):\n            beta = self.get_settings(objective.params, \"beta\", cls=NumberList)\n            p_init.lerp_(objective.params, weight=(1 - beta))\n\n    @torch.no_grad\n    def apply(self, objective):\n        p_reinit = self.defaults[\"p_reinit\"]\n        device = objective.params[0].device\n        generator = self.get_generator(device, self.defaults[\"seed\"])\n\n        # determine whether to trigger reinitialization\n        reinitialize = torch.rand(1, generator=generator, device=device) &lt; p_reinit\n\n        # reinitialize\n        if reinitialize:\n            params = TensorList(objective.params)\n            p_init = self.get_state(params, \"p_init\", init=params)\n\n\n            # mask with p_weights entries being True\n            p_weights = self.get_settings(params, \"p_weights\")\n            mask = params.bernoulli_like(p_weights, generator=generator).as_bool()\n\n            # set weights at mask to their initialization\n            params.masked_set_(mask, p_init)\n\n            # reset\n            if self.defaults[\"reset\"]:\n                objective.post_step_hooks.append(partial(_reset_except_self, self=self))\n\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.RandomSample","title":"RandomSample","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with random numbers from distribution depending on value of <code>distribution</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class RandomSample(Module):\n    \"\"\"Outputs tensors filled with random numbers from distribution depending on value of ``distribution``.\"\"\"\n    def __init__(self, distribution: Distributions = 'normal', variance:float | None = None):\n        defaults = dict(distribution=distribution, variance=variance)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        distribution = self.defaults['distribution']\n        variance = self.get_settings(objective.params, 'variance')\n        objective.updates = TensorList(objective.params).sample_like(distribution=distribution, variance=variance)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.RandomStepSize","title":"RandomStepSize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Uses random global or layer-wise step size from <code>low</code> to <code>high</code>.</p> <p>Parameters:</p> <ul> <li> <code>low</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>minimum learning rate. Defaults to 0.</p> </li> <li> <code>high</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>maximum learning rate. Defaults to 1.</p> </li> <li> <code>parameterwise</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, generate random step size for each parameter separately, if False generate one global random step size. Defaults to False.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class RandomStepSize(TensorTransform):\n    \"\"\"Uses random global or layer-wise step size from ``low`` to ``high``.\n\n    Args:\n        low (float, optional): minimum learning rate. Defaults to 0.\n        high (float, optional): maximum learning rate. Defaults to 1.\n        parameterwise (bool, optional):\n            if True, generate random step size for each parameter separately,\n            if False generate one global random step size. Defaults to False.\n    \"\"\"\n    def __init__(self, low: float = 0, high: float = 1, parameterwise=False, seed:int|None=None):\n        defaults = dict(low=low, high=high, parameterwise=parameterwise,seed=seed)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        s = settings[0]\n        parameterwise = s['parameterwise']\n\n        seed = s['seed']\n        if 'generator' not in self.global_state:\n            self.global_state['generator'] = random.Random(seed)\n        generator: random.Random = self.global_state['generator']\n\n        if parameterwise:\n            low, high = unpack_dicts(settings, 'low', 'high')\n            lr = [generator.uniform(l, h) for l, h in zip(low, high)]\n        else:\n            low = s['low']\n            high = s['high']\n            lr = generator.uniform(low, high)\n\n        torch._foreach_mul_(tensors, lr)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.RandomizedFDM","title":"RandomizedFDM","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>Gradient approximation via a randomized finite-difference method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'rademacher'</code> )           \u2013            <p>distribution. Defaults to \"rademacher\". If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> <p>Examples:</p>"},{"location":"API/all/#torchzero.modules.RandomizedFDM--simultaneous-perturbation-stochastic-approximation-spsa-method","title":"Simultaneous perturbation stochastic approximation (SPSA) method","text":"<p>SPSA is randomized FDM with rademacher distribution and central formula. <pre><code>spsa = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"rademacher\"),\n    tz.m.LR(1e-2)\n)\n</code></pre></p>"},{"location":"API/all/#torchzero.modules.RandomizedFDM--random-direction-stochastic-approximation-rdsa-method","title":"Random-direction stochastic approximation (RDSA) method","text":"<p>RDSA is randomized FDM with usually gaussian distribution and central formula. <pre><code>rdsa = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"gaussian\"),\n    tz.m.LR(1e-2)\n)\n</code></pre></p>"},{"location":"API/all/#torchzero.modules.RandomizedFDM--gaussian-smoothing-method","title":"Gaussian smoothing method","text":"<p>GS uses many gaussian samples with possibly a larger finite difference step size. <pre><code>gs = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(n_samples=100, distribution=\"gaussian\", formula=\"forward2\", h=1e-1),\n    tz.m.NewtonCG(hvp_method=\"forward\"),\n    tz.m.Backtracking()\n)\n</code></pre></p>"},{"location":"API/all/#torchzero.modules.RandomizedFDM--randomizedfdm-with-momentum","title":"RandomizedFDM with momentum","text":"<p>Momentum might help by reducing the variance of the estimated gradients. <pre><code>momentum_spsa = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(),\n    tz.m.HeavyBall(0.9),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class RandomizedFDM(GradApproximator):\n    \"\"\"Gradient approximation via a randomized finite-difference method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"rademacher\".\n            If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    Examples:\n    #### Simultaneous perturbation stochastic approximation (SPSA) method\n\n    SPSA is randomized FDM with rademacher distribution and central formula.\n    ```py\n    spsa = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"rademacher\"),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    #### Random-direction stochastic approximation (RDSA) method\n\n    RDSA is randomized FDM with usually gaussian distribution and central formula.\n    ```\n    rdsa = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"gaussian\"),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    #### Gaussian smoothing method\n\n    GS uses many gaussian samples with possibly a larger finite difference step size.\n    ```\n    gs = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(n_samples=100, distribution=\"gaussian\", formula=\"forward2\", h=1e-1),\n        tz.m.NewtonCG(hvp_method=\"forward\"),\n        tz.m.Backtracking()\n    )\n    ```\n\n    #### RandomizedFDM with momentum\n\n    Momentum might help by reducing the variance of the estimated gradients.\n    ```\n    momentum_spsa = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(),\n        tz.m.HeavyBall(0.9),\n        tz.m.LR(1e-3)\n    )\n    ```\n    \"\"\"\n    PRE_MULTIPLY_BY_H = True\n    def __init__(\n        self,\n        h: float = 1e-3,\n        n_samples: int = 1,\n        formula: _FD_Formula = \"central\",\n        distribution: Distributions = \"rademacher\",\n        pre_generate: bool = True,\n        return_approx_loss: bool = False,\n        seed: int | None | torch.Generator = None,\n        target: GradTarget = \"closure\",\n    ):\n        defaults = dict(h=h, formula=formula, n_samples=n_samples, distribution=distribution, pre_generate=pre_generate, seed=seed)\n        super().__init__(defaults, return_approx_loss=return_approx_loss, target=target)\n\n\n    def pre_step(self, objective):\n        h = self.get_settings(objective.params, 'h')\n        pre_generate = self.defaults['pre_generate']\n\n        if pre_generate:\n            n_samples = self.defaults['n_samples']\n            distribution = self.defaults['distribution']\n\n            params = TensorList(objective.params)\n            generator = self.get_generator(params[0].device, self.defaults['seed'])\n            perturbations = [params.sample_like(distribution=distribution, variance=1, generator=generator) for _ in range(n_samples)]\n\n            # this is false for ForwardGradient where h isn't used and it subclasses this\n            if self.PRE_MULTIPLY_BY_H:\n                torch._foreach_mul_([p for l in perturbations for p in l], [v for vv in h for v in [vv]*n_samples])\n\n            for param, prt in zip(params, zip(*perturbations)):\n                self.state[param]['perturbations'] = prt\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        params = TensorList(params)\n        loss_approx = None\n\n        h = NumberList(self.settings[p]['h'] for p in params)\n        n_samples = self.defaults['n_samples']\n        distribution = self.defaults['distribution']\n        fd_fn = _RFD_FUNCS[self.defaults['formula']]\n\n        default = [None]*n_samples\n        perturbations = list(zip(*(self.state[p].get('perturbations', default) for p in params)))\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n        grad = None\n        for i in range(n_samples):\n            prt = perturbations[i]\n\n            if prt[0] is None:\n                prt = params.sample_like(distribution=distribution, generator=generator, variance=1).mul_(h)\n\n            else: prt = TensorList(prt)\n\n            loss, loss_approx, d = fd_fn(closure=closure, params=params, p_fn=lambda: prt, h=h, f_0=loss)\n            # here `d` is a numberlist of directional derivatives, due to per parameter `h` values.\n\n            # support for per-sample values which gives better estimate\n            if d[0].numel() &gt; 1: d = d.map(torch.mean)\n\n            if grad is None: grad = prt * d\n            else: grad += prt * d\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n\n        # mean if got per-sample values\n        if loss is not None:\n            if loss.numel() &gt; 1:\n                loss = loss.mean()\n\n        if loss_approx is not None:\n            if loss_approx.numel() &gt; 1:\n                loss_approx = loss_approx.mean()\n\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/all/#torchzero.modules.RandomizedFDM.PRE_MULTIPLY_BY_H","title":"PRE_MULTIPLY_BY_H  <code>class-attribute</code>","text":"<pre><code>PRE_MULTIPLY_BY_H = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.Reciprocal","title":"Reciprocal","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>1 / input</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Reciprocal(TensorTransform):\n    \"\"\"Returns ``1 / input``\"\"\"\n    def __init__(self, eps = 0):\n        defaults = dict(eps = eps)\n        super().__init__(defaults)\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        eps = [s['eps'] for s in settings]\n        if any(e != 0 for e in eps): torch._foreach_add_(tensors, eps)\n        torch._foreach_reciprocal_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.ReduceOperationBase","title":"ReduceOperationBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for reduction operations like Sum, Prod, Maximum. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> <p>Methods:</p> <ul> <li> <code>transform</code>             \u2013              <p>applies the operation to operands</p> </li> </ul> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class ReduceOperationBase(Module, ABC):\n    \"\"\"Base class for reduction operations like Sum, Prod, Maximum. This is an abstract class, subclass it and override `transform` method to use it.\"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, *operands: Chainable | Any):\n        super().__init__(defaults=defaults)\n\n        self.operands = []\n        for i, v in enumerate(operands):\n\n            if isinstance(v, (Module, Sequence)):\n                self.set_child(f'operand_{i}', v)\n                self.operands.append(self.children[f'operand_{i}'])\n            else:\n                self.operands.append(v)\n\n        if not self.children:\n            raise ValueError('At least one operand must be a module')\n\n    @abstractmethod\n    def transform(self, objective: Objective, *operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        \"\"\"applies the operation to operands\"\"\"\n        raise NotImplementedError\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective: Objective) -&gt; Objective:\n        # pass cloned update to all module operands\n        processed_operands: list[Any | list[torch.Tensor]] = self.operands.copy()\n\n        for i, v in enumerate(self.operands):\n            if f'operand_{i}' in self.children:\n                v: Module\n                updated_obj = v.step(objective.clone(clone_updates=True))\n                processed_operands[i] = updated_obj.get_updates()\n                objective.update_attrs_from_clone_(updated_obj) # update loss, grad, etc if this module calculated them\n\n        transformed = self.transform(objective, *processed_operands)\n        objective.updates = transformed\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.ReduceOperationBase.transform","title":"transform","text":"<pre><code>transform(objective: Objective, *operands: Any | list[Tensor]) -&gt; list[Tensor]\n</code></pre> <p>applies the operation to operands</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>@abstractmethod\ndef transform(self, objective: Objective, *operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n    \"\"\"applies the operation to operands\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"API/all/#torchzero.modules.Relative","title":"Relative","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies update by absolute parameter values to make it relative to their magnitude, <code>min_value</code> is minimum allowed value to avoid getting stuck at 0.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class Relative(TensorTransform):\n    \"\"\"Multiplies update by absolute parameter values to make it relative to their magnitude, ``min_value`` is minimum allowed value to avoid getting stuck at 0.\"\"\"\n    def __init__(self, min_value:float = 1e-4):\n        defaults = dict(min_value=min_value)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        mul = TensorList(params).abs().clamp_([s['min_value'] for s in settings])\n        torch._foreach_mul_(tensors, mul)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.RelativeWeightDecay","title":"RelativeWeightDecay","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Weight decay relative to the mean absolute value of update, gradient or parameters depending on value of <code>norm_input</code> argument.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>relative weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> <li> <code>norm_input</code>               (<code>str</code>, default:                   <code>'update'</code> )           \u2013            <p>determines what should weight decay be relative to. \"update\", \"grad\" or \"params\". Defaults to \"update\".</p> </li> <li> <code>metric</code>               (<code>Ords</code>, default:                   <code>'mad'</code> )           \u2013            <p>metric (norm, etc) that weight decay should be relative to. defaults to 'mad' (mean absolute deviation).</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.RelativeWeightDecay--examples","title":"Examples:","text":"<p>Adam with non-decoupled relative weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.RelativeWeightDecay(1e-1),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with decoupled relative weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.RelativeWeightDecay(1e-1),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class RelativeWeightDecay(TensorTransform):\n    \"\"\"Weight decay relative to the mean absolute value of update, gradient or parameters depending on value of ``norm_input`` argument.\n\n    Args:\n        weight_decay (float): relative weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n        norm_input (str, optional):\n            determines what should weight decay be relative to. \"update\", \"grad\" or \"params\".\n            Defaults to \"update\".\n        metric (Ords, optional):\n            metric (norm, etc) that weight decay should be relative to.\n            defaults to 'mad' (mean absolute deviation).\n        target (Target, optional): what to set on var. Defaults to 'update'.\n\n    ### Examples:\n\n    Adam with non-decoupled relative weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.RelativeWeightDecay(1e-1),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with decoupled relative weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.RelativeWeightDecay(1e-1),\n        tz.m.LR(1e-3)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        weight_decay: float = 0.1,\n        ord: int  = 2,\n        norm_input: Literal[\"update\", \"grad\", \"params\"] = \"update\",\n        metric: Metrics = 'mad',\n        cautious: bool = False,\n    ):\n        defaults = dict(weight_decay=weight_decay, ord=ord, norm_input=norm_input, metric=metric, cautious=cautious)\n        super().__init__(defaults, uses_grad=norm_input == 'grad')\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        weight_decay = NumberList(s['weight_decay'] for s in settings)\n\n        fs = settings[0]\n        norm_input = fs['norm_input']\n\n        if norm_input == 'update': src = TensorList(tensors)\n        elif norm_input == 'grad':\n            assert grads is not None\n            src = TensorList(grads)\n        elif norm_input == 'params':\n            src = TensorList(params)\n        else:\n            raise ValueError(norm_input)\n\n        norm = src.global_metric(fs['metric'])\n\n        if fs[\"cautious\"]:\n            wd_ = cautious_weight_decay_\n        else:\n            wd_ = weight_decay_\n        return wd_(as_tensorlist(tensors), as_tensorlist(params), weight_decay * norm, fs[\"ord\"])\n</code></pre>"},{"location":"API/all/#torchzero.modules.RestartEvery","title":"RestartEvery","text":"<p>               Bases: <code>torchzero.modules.restarts.restars.RestartStrategyBase</code></p> <p>Resets the state every n steps</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable | None</code>)           \u2013            <p>modules to reset. If None, resets all modules.</p> </li> <li> <code>steps</code>               (<code>int | Literal['ndim']</code>)           \u2013            <p>number of steps between resets. \"ndim\" to use number of parameters.</p> </li> </ul> Source code in <code>torchzero/modules/restarts/restars.py</code> <pre><code>class RestartEvery(RestartStrategyBase):\n    \"\"\"Resets the state every n steps\n\n    Args:\n        modules (Chainable | None):\n            modules to reset. If None, resets all modules.\n        steps (int | Literal[\"ndim\"]):\n            number of steps between resets. \"ndim\" to use number of parameters.\n    \"\"\"\n    def __init__(self, modules: Chainable | None, steps: int | Literal['ndim']):\n        defaults = dict(steps=steps)\n        super().__init__(defaults, modules)\n\n    def should_reset(self, objective):\n        step = self.global_state.get('step', 0) + 1\n        self.global_state['step'] = step\n\n        n = self.defaults['steps']\n        if isinstance(n, str): n = sum(p.numel() for p in objective.params if p.requires_grad)\n\n        # reset every n steps\n        if step % n == 0:\n            self.global_state.clear()\n            return True\n\n        return False\n</code></pre>"},{"location":"API/all/#torchzero.modules.RestartOnStuck","title":"RestartOnStuck","text":"<p>               Bases: <code>torchzero.modules.restarts.restars.RestartStrategyBase</code></p> <p>Resets the state when update (difference in parameters) is zero for multiple steps in a row.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable | None</code>)           \u2013            <p>modules to reset. If None, resets all modules.</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>step is considered failed when maximum absolute parameter difference is smaller than this. Defaults to None (uses twice the smallest respresentable number)</p> </li> <li> <code>n_tol</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>number of failed consequtive steps required to trigger a reset. Defaults to 10.</p> </li> </ul> Source code in <code>torchzero/modules/restarts/restars.py</code> <pre><code>class RestartOnStuck(RestartStrategyBase):\n    \"\"\"Resets the state when update (difference in parameters) is zero for multiple steps in a row.\n\n    Args:\n        modules (Chainable | None):\n            modules to reset. If None, resets all modules.\n        tol (float, optional):\n            step is considered failed when maximum absolute parameter difference is smaller than this. Defaults to None (uses twice the smallest respresentable number)\n        n_tol (int, optional):\n            number of failed consequtive steps required to trigger a reset. Defaults to 10.\n\n    \"\"\"\n    def __init__(self, modules: Chainable | None, tol: float | None = None, n_tol: int = 10):\n        defaults = dict(tol=tol, n_tol=n_tol)\n        super().__init__(defaults, modules)\n\n    @torch.no_grad\n    def should_reset(self, objective):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        params = TensorList(objective.params)\n        tol = self.defaults['tol']\n        if tol is None: tol = torch.finfo(params[0].dtype).tiny * 2\n        n_tol = self.defaults['n_tol']\n        n_bad = self.global_state.get('n_bad', 0)\n\n        # calculate difference in parameters\n        prev_params = self.get_state(params, 'prev_params', cls=TensorList)\n        update = params - prev_params\n        prev_params.copy_(params)\n\n        # if update is too small, it is considered bad, otherwise n_bad is reset to 0\n        if step &gt; 0:\n            if update.abs().global_max() &lt;= tol:\n                n_bad += 1\n\n            else:\n                n_bad = 0\n\n        self.global_state['n_bad'] = n_bad\n\n        # no progress, reset\n        if n_bad &gt;= n_tol:\n            self.global_state.clear()\n            return True\n\n        return False\n</code></pre>"},{"location":"API/all/#torchzero.modules.RestartStrategyBase","title":"RestartStrategyBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for restart strategies.</p> <p>On each <code>update</code>/<code>step</code> this checks reset condition and if it is satisfied, resets the modules before updating or stepping.</p> <p>Methods:</p> <ul> <li> <code>should_reset</code>             \u2013              <p>returns whether reset should occur</p> </li> </ul> Source code in <code>torchzero/modules/restarts/restars.py</code> <pre><code>class RestartStrategyBase(Module, ABC):\n    \"\"\"Base class for restart strategies.\n\n    On each ``update``/``step`` this checks reset condition and if it is satisfied,\n    resets the modules before updating or stepping.\n    \"\"\"\n    def __init__(self, defaults: dict | None = None, modules: Chainable | None = None):\n        if defaults is None: defaults = {}\n        super().__init__(defaults)\n        if modules is not None:\n            self.set_child('modules', modules)\n\n    @abstractmethod\n    def should_reset(self, objective: Objective) -&gt; bool:\n        \"\"\"returns whether reset should occur\"\"\"\n\n    def _reset_on_condition(self, objective: Objective):\n        modules = self.children.get('modules', None)\n\n        if self.should_reset(objective):\n            if modules is None:\n                objective.post_step_hooks.append(partial(_reset_except_self, self=self))\n            else:\n                modules.reset()\n\n        return modules\n\n    @final\n    def update(self, objective):\n        modules = self._reset_on_condition(objective)\n        if modules is not None:\n            modules.update(objective)\n\n    @final\n    def apply(self, objective):\n        # don't check here because it was check in `update`\n        modules = self.children.get('modules', None)\n        if modules is None: return objective\n        return modules.apply(objective.clone(clone_updates=False))\n\n    @final\n    def step(self, objective):\n        modules = self._reset_on_condition(objective)\n        if modules is None: return objective\n        return modules.step(objective.clone(clone_updates=False))\n</code></pre>"},{"location":"API/all/#torchzero.modules.RestartStrategyBase.should_reset","title":"should_reset","text":"<pre><code>should_reset(objective: Objective) -&gt; bool\n</code></pre> <p>returns whether reset should occur</p> Source code in <code>torchzero/modules/restarts/restars.py</code> <pre><code>@abstractmethod\ndef should_reset(self, objective: Objective) -&gt; bool:\n    \"\"\"returns whether reset should occur\"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.Rprop","title":"Rprop","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Resilient propagation. The update magnitude gets multiplied by <code>nplus</code> if gradient didn't change the sign, or <code>nminus</code> if it did. Then the update is applied with the sign of the current gradient.</p> <p>Additionally, if gradient changes sign, the update for that weight is reverted. Next step, magnitude for that weight won't change.</p> <p>Compared to pytorch this also implements backtracking update when sign changes.</p> <p>This implementation is identical to <code>torch.optim.Rprop</code> if <code>backtrack</code> is set to False.</p> <p>Parameters:</p> <ul> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>1.2</code> )           \u2013            <p>multiplicative increase factor for when ascent didn't change sign (default: 1.2).</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplicative decrease factor for when ascent changed sign (default: 0.5).</p> </li> <li> <code>lb</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>minimum step size, can be None (default: 1e-6)</p> </li> <li> <code>ub</code>               (<code>float</code>, default:                   <code>50</code> )           \u2013            <p>maximum step size, can be None (default: 50)</p> </li> <li> <code>backtrack</code>               (<code>float</code>, default:                   <code>True</code> )           \u2013            <p>if True, when ascent sign changes, undoes last weight update, otherwise sets update to 0. When this is False, this exactly matches pytorch Rprop. (default: True)</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>initial per-parameter learning rate (default: 1).</p> </li> </ul> <p>reference     Riedmiller, M., &amp; Braun, H. (1993, March). A direct adaptive method for faster backpropagation learning:     The RPROP algorithm. In IEEE international conference on neural networks (pp. 586-591). IEEE.</p> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class Rprop(TensorTransform):\n    \"\"\"\n    Resilient propagation. The update magnitude gets multiplied by ``nplus`` if gradient didn't change the sign,\n    or ``nminus`` if it did. Then the update is applied with the sign of the current gradient.\n\n    Additionally, if gradient changes sign, the update for that weight is reverted.\n    Next step, magnitude for that weight won't change.\n\n    Compared to pytorch this also implements backtracking update when sign changes.\n\n    This implementation is identical to ``torch.optim.Rprop`` if ``backtrack`` is set to False.\n\n    Args:\n        nplus (float): multiplicative increase factor for when ascent didn't change sign (default: 1.2).\n        nminus (float): multiplicative decrease factor for when ascent changed sign (default: 0.5).\n        lb (float): minimum step size, can be None (default: 1e-6)\n        ub (float): maximum step size, can be None (default: 50)\n        backtrack (float):\n            if True, when ascent sign changes, undoes last weight update, otherwise sets update to 0.\n            When this is False, this exactly matches pytorch Rprop. (default: True)\n        alpha (float): initial per-parameter learning rate (default: 1).\n\n    reference\n        *Riedmiller, M., &amp; Braun, H. (1993, March). A direct adaptive method for faster backpropagation learning:\n        The RPROP algorithm. In IEEE international conference on neural networks (pp. 586-591). IEEE.*\n    \"\"\"\n    def __init__(\n        self,\n        nplus: float = 1.2,\n        nminus: float = 0.5,\n        lb: float = 1e-6,\n        ub: float = 50,\n        backtrack=True,\n        alpha: float = 1,\n    ):\n        defaults = dict(nplus = nplus, nminus = nminus, alpha = alpha, lb = lb, ub = ub, backtrack=backtrack)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        nplus, nminus, lb, ub, alpha = unpack_dicts(settings, 'nplus', 'nminus', 'lb', 'ub', 'alpha', cls=NumberList)\n        prev, allowed, magnitudes = unpack_states(\n            states, tensors,\n            'prev','allowed','magnitudes',\n            init=[torch.zeros_like, _bool_ones_like, torch.zeros_like],\n            cls = TensorList,\n        )\n\n        tensors = rprop_(\n            tensors_ = TensorList(tensors),\n            prev_ = prev,\n            allowed_ = allowed,\n            magnitudes_ = magnitudes,\n            nplus = nplus,\n            nminus = nminus,\n            lb = lb,\n            ub = ub,\n            alpha = alpha,\n            backtrack=settings[0]['backtrack'],\n            step=step,\n        )\n\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.SAM","title":"SAM","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Sharpness-Aware Minimization from https://arxiv.org/pdf/2010.01412</p> <p>SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value. It performs two forward and backward passes per step.</p> <p>This implementation modifies the closure to return loss and calculate gradients of the SAM objective. All modules after this will use the modified objective.</p> <p>.. note::     This module requires a closure passed to the optimizer step,     as it needs to re-evaluate the loss and gradients at two points on each step.</p> <p>Parameters:</p> <ul> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.05</code> )           \u2013            <p>Neighborhood size. Defaults to 0.05.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm of the SAM objective. Defaults to 2.</p> </li> <li> <code>asam</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>enables ASAM variant which makes perturbation relative to weight magnitudes. ASAM requires a much larger <code>rho</code>, like 0.5 or 1. The <code>tz.m.ASAM</code> class is idential to setting this argument to True, but it has larger <code>rho</code> by default.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.SAM--examples","title":"Examples:","text":"<p>SAM-SGD:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SAM(),\n    tz.m.LR(1e-2)\n)\n</code></pre> <p>SAM-Adam:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SAM(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2)\n)\n</code></pre> References <p>Foret, P., Kleiner, A., Mobahi, H., &amp; Neyshabur, B. (2020). Sharpness-aware minimization for efficiently improving generalization. arXiv preprint arXiv:2010.01412.</p> Source code in <code>torchzero/modules/adaptive/sam.py</code> <pre><code>class SAM(Transform):\n    \"\"\"Sharpness-Aware Minimization from https://arxiv.org/pdf/2010.01412\n\n    SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value.\n    It performs two forward and backward passes per step.\n\n    This implementation modifies the closure to return loss and calculate gradients\n    of the SAM objective. All modules after this will use the modified objective.\n\n    .. note::\n        This module requires a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients at two points on each step.\n\n    Args:\n        rho (float, optional): Neighborhood size. Defaults to 0.05.\n        p (float, optional): norm of the SAM objective. Defaults to 2.\n        asam (bool, optional):\n            enables ASAM variant which makes perturbation relative to weight magnitudes.\n            ASAM requires a much larger ``rho``, like 0.5 or 1.\n            The ``tz.m.ASAM`` class is idential to setting this argument to True, but\n            it has larger ``rho`` by default.\n\n    ### Examples:\n\n    SAM-SGD:\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SAM(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    SAM-Adam:\n\n    ```\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SAM(),\n        tz.m.Adam(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    References:\n        [Foret, P., Kleiner, A., Mobahi, H., &amp; Neyshabur, B. (2020). Sharpness-aware minimization for efficiently improving generalization. arXiv preprint arXiv:2010.01412.](https://arxiv.org/abs/2010.01412#page=3.16)\n    \"\"\"\n    def __init__(self, rho: float = 0.05, p: float = 2, eps=1e-10, asam=False):\n        defaults = dict(rho=rho, p=p, eps=eps, asam=asam)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n\n        params = objective.params\n        closure = objective.closure\n        zero_grad = objective.zero_grad\n        if closure is None: raise RuntimeError(\"SAM requires a closure passed to the optimizer step\")\n        p, rho = unpack_dicts(settings, 'p', 'rho', cls=NumberList)\n        fs = settings[0]\n        eps = fs['eps']\n        asam = fs['asam']\n\n        # 1/p + 1/q = 1\n        # okay, authors of SAM paper, I will manually solve your equation\n        # so q = -p/(1-p)\n        q = -p / (1-p)\n        # as a validation for 2 it is -2 / -1 = 2\n\n        @torch.no_grad\n        def sam_closure(backward=True):\n            orig_grads = None\n            if not backward:\n                # if backward is False, make sure this doesn't modify gradients\n                # to avoid issues\n                orig_grads = [p.grad for p in params]\n\n            # gradient at initial parameters\n            zero_grad()\n            with torch.enable_grad():\n                closure()\n\n            grad = TensorList(p.grad if p.grad is not None else torch.zeros_like(p) for p in params)\n            grad_abs = grad.abs()\n\n            # compute e\n            term1 = grad.sign().mul_(rho)\n            term2 = grad_abs.pow(q-1)\n\n            if asam:\n                grad_abs.mul_(torch._foreach_abs(params))\n\n            denom = grad_abs.pow_(q).sum().pow(1/p)\n\n            e = term1.mul_(term2).div_(denom.clip(min=eps))\n\n            if asam:\n                e.mul_(torch._foreach_pow(params, 2))\n\n            # calculate loss and gradient approximation of inner problem\n            torch._foreach_add_(params, e)\n            if backward:\n                zero_grad()\n                with torch.enable_grad():\n                    # this sets .grad attributes\n                    sam_loss = closure()\n\n            else:\n                sam_loss = closure(False)\n\n            # and restore initial parameters\n            torch._foreach_sub_(params, e)\n\n            if orig_grads is not None:\n                for param,orig_grad in zip(params, orig_grads):\n                    param.grad = orig_grad\n\n            return sam_loss\n\n        objective.closure = sam_closure\n</code></pre>"},{"location":"API/all/#torchzero.modules.SG2","title":"SG2","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>second-order stochastic gradient</p> <p>2SPSA (second-order SPSA) <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SPSA(),\n    tz.m.SG2(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>SG2 with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SG2(),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>SG2 with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.SG2(beta=0.75. n_samples=4)),\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/sg2.py</code> <pre><code>class SG2(Transform):\n    \"\"\"second-order stochastic gradient\n\n    2SPSA (second-order SPSA)\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SPSA(),\n        tz.m.SG2(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    SG2 with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SG2(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    SG2 with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.SG2(beta=0.75. n_samples=4)),\n    )\n    ```\n\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 1,\n        n_first_step_samples: int = 10,\n        start_step: int = 10,\n        beta: float | None = None,\n        damping: float = 1e-4,\n        h: float = 1e-2,\n        seed=None,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(n_samples=n_samples, h=h, beta=beta, damping=damping, seed=seed, start_step=start_step, n_first_step_samples=n_first_step_samples)\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        k = self.increment_counter(\"step\", 0)\n\n        params = TensorList(objective.params)\n        closure = objective.closure\n        if closure is None:\n            raise RuntimeError(\"closure is required for SG2\")\n        generator = self.get_generator(params[0].device, self.defaults[\"seed\"])\n\n        h = unpack_dicts(settings, \"h\")\n        x_0 = params.clone()\n        n_samples = fs[\"n_samples\"]\n        if k == 0: n_samples = fs[\"n_first_step_samples\"]\n        H_hat = None\n\n        # compute new approximation\n        for i in range(n_samples):\n            # generate perturbation\n            cd = params.rademacher_like(generator=generator).mul_(h)\n\n            # two sided hessian approximation\n            params.add_(cd)\n            closure()\n            g_p = params.grad.fill_none_(params)\n\n            params.copy_(x_0)\n            params.sub_(cd)\n            closure()\n            g_n = params.grad.fill_none_(params)\n\n            delta_g = g_p - g_n\n\n            # restore params\n            params.set_(x_0)\n\n            # compute H hat\n            H_i = sg2_(\n                delta_g = delta_g.to_vec(),\n                cd = cd.to_vec(),\n            )\n\n            if H_hat is None: H_hat = H_i\n            else: H_hat += H_i\n\n        assert H_hat is not None\n        if n_samples &gt; 1: H_hat /= n_samples\n\n        # add damping\n        if fs[\"damping\"] != 0:\n            reg = torch.eye(H_hat.size(0), device=H_hat.device, dtype=H_hat.dtype).mul_(fs[\"damping\"])\n            H_hat += reg\n\n        # update H\n        H = self.global_state.get(\"H\", None)\n        if H is None: H = H_hat\n        else:\n            beta = fs[\"beta\"]\n            if beta is None: beta = (k+1) / (k+2)\n            H.lerp_(H_hat, 1-beta)\n\n        self.global_state[\"H\"] = H\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        fs = settings[0]\n        updates = objective.get_updates()\n\n        H: torch.Tensor = self.global_state[\"H\"]\n        k = self.global_state[\"step\"]\n        if k &lt; fs[\"start_step\"]:\n            # don't precondition yet\n            # I guess we can try using trace to scale the update\n            # because it will have horrible scaling otherwise\n            torch._foreach_div_(updates, H.trace())\n            return objective\n\n        b = torch.cat([t.ravel() for t in updates])\n        sol = torch.linalg.lstsq(H, b).solution # pylint:disable=not-callable\n\n        vec_to_tensors_(sol, updates)\n        return objective\n\n    def get_H(self, objective=...):\n        return Dense(self.global_state[\"H\"])\n</code></pre>"},{"location":"API/all/#torchzero.modules.SOAP","title":"SOAP","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>SOAP (ShampoO with Adam in the Preconditioner's eigenbasis from https://arxiv.org/abs/2409.11321).</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.95</code> )           \u2013            <p>beta for first momentum. Defaults to 0.95.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.95</code> )           \u2013            <p>beta for second momentum. Defaults to 0.95.</p> </li> <li> <code>shampoo_beta</code>               (<code>float | None</code>, default:                   <code>0.95</code> )           \u2013            <p>beta for covariance matrices accumulators. Can be None, then it just sums them like Adagrad (which works worse). Defaults to 0.95.</p> </li> <li> <code>precond_freq</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>How often to update the preconditioner. Defaults to 10.</p> </li> <li> <code>merge_small</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to merge small dims. Defaults to True.</p> </li> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>4096</code> )           \u2013            <p>Won't precondition dims larger than this. Defaults to 10_000.</p> </li> <li> <code>precondition_1d</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to precondition 1d params (SOAP paper sets this to False). Defaults to True.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for dividing first momentum by second. Defaults to 1e-8.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>enables adam bias correction. Defaults to True.</p> </li> <li> <code>proj_exp_avg</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, maintains exponential average of gradients (momentum) in projected space. If False - in original space Defaults to True.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>learning rate. Defaults to 1.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>output of this module is projected and Adam will run on it, but preconditioners are updated from original gradients.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.SOAP--examples","title":"Examples:","text":"<p>SOAP:</p> <p><pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAP(),\n    tz.m.LR(1e-3)\n)\n</code></pre> Stabilized SOAP:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAP(),\n    tz.m.NormalizeByEMA(max_ema_growth=1.2),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/soap.py</code> <pre><code>class SOAP(TensorTransform):\n    \"\"\"SOAP (ShampoO with Adam in the Preconditioner's eigenbasis from https://arxiv.org/abs/2409.11321).\n\n    Args:\n        beta1 (float, optional): beta for first momentum. Defaults to 0.95.\n        beta2 (float, optional): beta for second momentum. Defaults to 0.95.\n        shampoo_beta (float | None, optional):\n            beta for covariance matrices accumulators. Can be None, then it just sums them like Adagrad (which works worse). Defaults to 0.95.\n        precond_freq (int, optional): How often to update the preconditioner. Defaults to 10.\n        merge_small (bool, optional): Whether to merge small dims. Defaults to True.\n        max_dim (int, optional): Won't precondition dims larger than this. Defaults to 10_000.\n        precondition_1d (bool, optional):\n            Whether to precondition 1d params (SOAP paper sets this to False). Defaults to True.\n        eps (float, optional):\n            epsilon for dividing first momentum by second. Defaults to 1e-8.\n        debias (bool, optional):\n            enables adam bias correction. Defaults to True.\n        proj_exp_avg (bool, optional):\n            if True, maintains exponential average of gradients (momentum) in projected space.\n            If False - in original space Defaults to True.\n        alpha (float, optional):\n            learning rate. Defaults to 1.\n        inner (Chainable | None, optional):\n            output of this module is projected and Adam will run on it, but preconditioners are updated\n            from original gradients.\n\n    ### Examples:\n    SOAP:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SOAP(),\n        tz.m.LR(1e-3)\n    )\n    ```\n    Stabilized SOAP:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SOAP(),\n        tz.m.NormalizeByEMA(max_ema_growth=1.2),\n        tz.m.LR(1e-2)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.95,\n        beta2: float = 0.95,\n        shampoo_beta: float | None = 0.95,\n        precond_freq: int = 10,\n        merge_small: bool = True,\n        max_dim: int = 4096,\n        precondition_1d: bool = True,\n        eps: float = 1e-8,\n        debias: bool = True,\n        proj_exp_avg: bool = True,\n        alpha: float = 1,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"inner\"]\n\n        super().__init__(defaults)\n        self.set_child(\"inner\", inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        if setting[\"merge_small\"]:\n            tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n        state[\"exp_avg_proj\"] = torch.zeros_like(tensor)\n        state[\"exp_avg_sq_proj\"] = torch.zeros_like(tensor)\n\n        if tensor.ndim &lt;= 1 and not setting[\"precondition_1d\"]:\n            state['GG'] = []\n\n        else:\n            max_dim = setting[\"max_dim\"]\n            state['GG'] = [\n                torch.zeros(s, s, dtype=tensor.dtype, device=tensor.device) if 1&lt;s&lt;max_dim else None for s in tensor.shape\n            ]\n\n        # either scalar parameter, 1d with precondition_1d=False, or all dims are too big.\n        if len([i is not None for i in state['GG']]) == 0:\n            state['GG'] = None\n\n        # first covariance accumulation\n        if state['GG'] is not None:\n            update_soap_covariances_(tensor, GGs_=state['GG'], beta=setting[\"shampoo_beta\"])\n\n            # get projection matrix with first gradients with eigh\n            try: state['Q'] = get_orthogonal_matrix(state['GG'])\n            except torch.linalg.LinAlgError as e:\n                warnings.warn(f\"torch.linalg.eigh raised an error when initializing SOAP Q matrices on 1st step, diagonal preconditioning will be used for this parameter. The error was:\\n{e}\")\n                state[\"GG\"] = None\n\n        state['step'] = 0\n\n\n    # no update to avoid running merge_dims twice\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        # note\n        # do not modify tensors in-place\n        # because they are used to update preconditioner at the end\n\n        steps = [s[\"step\"] for s in states]\n        if any(s == 0 for s in steps):\n            # skip 1st update so to avoid using current gradient in the projection\n            # I scale it instead to avoid issues with further modules\n            for s in states: s[\"step\"] += 1\n            return TensorList(tensors).clamp(-0.1, 0.1)\n            # return TensorList(tensors).zero_()\n\n        fs = settings[0]\n        merged_updates = [] # for when exp_avg is maintained unprojected\n        merged_grads = [] # this doesn't go into preconditioner\n        projected = []\n\n        # -------------------------------- inner step -------------------------------- #\n        updates = tensors\n        has_inner = \"inner\" in self.children\n        if has_inner:\n            updates = self.inner_step_tensors(\"inner\", updates, clone=True,\n                                              params=params, grads=grads, loss=loss)\n\n        # ---------------------------------- project --------------------------------- #\n        for grad, update, state, setting in zip(tensors, updates, states, settings):\n            if setting[\"merge_small\"]:\n                update, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(update, setting[\"max_dim\"])\n                if has_inner: # grad is a different tensor, merge it too\n                    grad, _, _ = _merge_small_dims(grad, setting[\"max_dim\"])\n                else: # in this case update is still just grad\n                    grad = update\n\n            merged_updates.append(update)\n            merged_grads.append(grad)\n\n            if state['GG'] is not None:\n                update = project(update, state['Q'])\n\n            projected.append(update)\n\n\n        # ------------------------ run adam in projected space ----------------------- #\n        exp_avg_proj, exp_avg_sq_proj = unpack_states(states, projected, \"exp_avg_proj\", \"exp_avg_sq_proj\", must_exist=True, cls=TensorList)\n        alpha, beta1, beta2, eps = unpack_dicts(settings, \"alpha\", \"beta1\", \"beta2\", \"eps\", cls=NumberList)\n\n        # lerp exp_avg in projected space\n        if fs[\"proj_exp_avg\"]:\n            exp_avg_proj.lerp_(projected, weight=1-beta1)\n\n        # or lerp in original space and project\n        else:\n            exp_avg = exp_avg_proj\n            exp_avg.lerp_(merged_updates, weight=1-beta1)\n            exp_avg_proj = []\n            for t, state, setting in zip(exp_avg, states, settings):\n                if state['GG'] is not None:\n                    t = project(t, state[\"Q\"])\n                exp_avg_proj.append(t)\n\n        # lerp exp_avg_sq\n        exp_avg_sq_proj.mul_(beta2).addcmul_(projected, projected, value=1-beta2)\n\n        # adam direction\n        denom = exp_avg_sq_proj.sqrt().add_(eps)\n        dirs_proj = exp_avg_proj / denom\n\n        # ------------------------------- project back ------------------------------- #\n        dirs: list[torch.Tensor] = []\n        for dir, state, setting in zip(dirs_proj, states, settings):\n            if state['GG'] is not None:\n                dir = project_back(dir, state['Q'])\n\n            if setting[\"merge_small\"]:\n                dir = _unmerge_small_dims(dir, state['flat_sizes'], state['sort_idxs'])\n\n            dirs.append(dir)\n\n        # -------------------------- update preconditioners -------------------------- #\n        # Update is done after the gradient step to avoid using current gradients in the projection.\n\n        for grad, state, setting in zip(merged_grads, states, settings):\n            if state['GG'] is not None:\n\n                # lerp covariances\n                update_soap_covariances_(grad, state['GG'], beta=setting[\"shampoo_beta\"])\n\n                # (state['step'] - 1) since we start updating on 2nd step\n                if (state['step'] - 1) % setting['precond_freq'] == 0:\n\n                    # unproject exp_avg before updating if it is maintained projected\n                    exp_avg = None\n                    if fs[\"proj_exp_avg\"]:\n                        exp_avg = project_back(state[\"exp_avg_proj\"], state[\"Q\"])\n\n                    # update projection matrix and exp_avg_sq_proj\n                    try:\n                        state['Q'], state['exp_avg_sq_proj'] = get_orthogonal_matrix_QR(\n                            state[\"exp_avg_sq_proj\"], state['GG'], state['Q'])\n\n                        # re-project exp_avg if it is maintained projected\n                        if fs[\"proj_exp_avg\"]:\n                            assert exp_avg is not None\n                            state[\"exp_avg_proj\"] = project(exp_avg, state[\"Q\"])\n\n                    except torch.linalg.LinAlgError:\n                        pass\n\n            state[\"step\"] += 1\n\n\n        # ------------------------- bias-corrected step size ------------------------- #\n        if fs[\"debias\"]:\n            steps1 = [s+1 for s in steps]\n            bias_correction1 = 1.0 - beta1 ** steps1\n            bias_correction2 = 1.0 - beta2 ** steps1\n            alpha = alpha * (bias_correction2 ** .5) / bias_correction1\n\n        torch._foreach_mul_(dirs, alpha)\n        return dirs\n</code></pre>"},{"location":"API/all/#torchzero.modules.SOAPBasis","title":"SOAPBasis","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Run another optimizer in Shampoo eigenbases.</p> Note <p>the buffers of the <code>basis_opt</code> are re-projected whenever basis changes. The reprojection logic is not implemented on all modules. Some supported modules are:</p> <p><code>Adagrad</code>, <code>Adam</code>, <code>Adan</code>, <code>Lion</code>, <code>MARSCorrection</code>, <code>MSAMMomentum</code>, <code>RMSprop</code>, <code>EMA</code>, <code>HeavyBall</code>, <code>NAG</code>, <code>ClipNormByEMA</code>, <code>ClipValueByEMA</code>, <code>NormalizeByEMA</code>, <code>ClipValueGrowth</code>, <code>CoordinateMomentum</code>, <code>CubicAdam</code>.</p> <p>Additionally most modules with no internal buffers are supported, e.g. <code>Cautious</code>, <code>Sign</code>, <code>ClipNorm</code>, <code>Orthogonalize</code>, etc. However modules that use weight values, such as <code>WeighDecay</code> can't be supported, as weights can't be projected.</p> <p>Also, if you say use <code>EMA</code> on output of <code>Pow(2)</code>, the exponential average will be reprojected as gradient and not as squared gradients. Use modules like <code>EMASquared</code>, <code>SqrtEMASquared</code> to get correct reprojections.</p> <p>Parameters:</p> <ul> <li> <code>basis_opt</code>               (<code>Chainable</code>)           \u2013            <p>module or modules to run in Shampoo eigenbases.</p> </li> <li> <code>shampoo_beta</code>               (<code>float | None</code>, default:                   <code>0.95</code> )           \u2013            <p>beta for covariance matrices accumulators. Can be None, then it just sums them like Adagrad (which works worse). Defaults to 0.95.</p> </li> <li> <code>precond_freq</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>How often to update the preconditioner. Defaults to 10.</p> </li> <li> <code>merge_small</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to merge small dims. Defaults to True.</p> </li> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>4096</code> )           \u2013            <p>Won't precondition dims larger than this. Defaults to 10_000.</p> </li> <li> <code>precondition_1d</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to precondition 1d params (SOAP paper sets this to False). Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>output of this module is projected and <code>basis_opt</code> will run on it, but preconditioners are updated from original gradients.</p> </li> </ul> <p>Examples: SOAP with MARS and AMSGrad: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAPBasis([tz.m.MARSCorrection(0.95), tz.m.Adam(0.95, 0.95, amsgrad=True)]),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>LaProp in Shampoo eigenbases (SOLP): <pre><code># we define LaProp through other modules, moved it out for brevity\nlaprop = (\n    tz.m.RMSprop(0.95),\n    tz.m.Debias(beta1=None, beta2=0.95),\n    tz.m.EMA(0.95),\n    tz.m.Debias(beta1=0.95, beta2=None),\n)\n\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAPBasis(laprop),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Lion in Shampoo eigenbases (works kinda well): <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAPBasis(tz.m.Lion()),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Source code in <code>torchzero/modules/basis/soap_basis.py</code> <pre><code>class SOAPBasis(TensorTransform):\n    \"\"\"\n    Run another optimizer in Shampoo eigenbases.\n\n    Note:\n        the buffers of the ``basis_opt`` are re-projected whenever basis changes. The reprojection logic is not implemented on all modules. Some supported modules are:\n\n        ``Adagrad``, ``Adam``, ``Adan``, ``Lion``, ``MARSCorrection``, ``MSAMMomentum``, ``RMSprop``, ``EMA``, ``HeavyBall``, ``NAG``, ``ClipNormByEMA``, ``ClipValueByEMA``, ``NormalizeByEMA``, ``ClipValueGrowth``, ``CoordinateMomentum``, ``CubicAdam``.\n\n        Additionally most modules with no internal buffers are supported, e.g. ``Cautious``, ``Sign``, ``ClipNorm``, ``Orthogonalize``, etc. However modules that use weight values, such as ``WeighDecay`` can't be supported, as weights can't be projected.\n\n        Also, if you say use ``EMA`` on output of ``Pow(2)``, the exponential average will be reprojected as gradient and not as squared gradients. Use modules like ``EMASquared``, ``SqrtEMASquared`` to get correct reprojections.\n\n    Args:\n        basis_opt (Chainable): module or modules to run in Shampoo eigenbases.\n        shampoo_beta (float | None, optional):\n            beta for covariance matrices accumulators. Can be None, then it just sums them like Adagrad (which works worse). Defaults to 0.95.\n        precond_freq (int, optional): How often to update the preconditioner. Defaults to 10.\n        merge_small (bool, optional): Whether to merge small dims. Defaults to True.\n        max_dim (int, optional): Won't precondition dims larger than this. Defaults to 10_000.\n        precondition_1d (bool, optional):\n            Whether to precondition 1d params (SOAP paper sets this to False). Defaults to True.\n        inner (Chainable | None, optional):\n            output of this module is projected and ``basis_opt`` will run on it, but preconditioners are updated\n            from original gradients.\n\n    Examples:\n    SOAP with MARS and AMSGrad:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SOAPBasis([tz.m.MARSCorrection(0.95), tz.m.Adam(0.95, 0.95, amsgrad=True)]),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    LaProp in Shampoo eigenbases (SOLP):\n    ```python\n\n    # we define LaProp through other modules, moved it out for brevity\n    laprop = (\n        tz.m.RMSprop(0.95),\n        tz.m.Debias(beta1=None, beta2=0.95),\n        tz.m.EMA(0.95),\n        tz.m.Debias(beta1=0.95, beta2=None),\n    )\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SOAPBasis(laprop),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Lion in Shampoo eigenbases (works kinda well):\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SOAPBasis(tz.m.Lion()),\n        tz.m.LR(1e-3)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        basis_opt: Chainable,\n        shampoo_beta: float | None = 0.95,\n        precond_freq: int = 10,\n        merge_small: bool = True,\n        max_dim: int = 4096,\n        precondition_1d: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"inner\"], defaults[\"basis_opt\"]\n\n        super().__init__(defaults)\n        self.set_child(\"inner\", inner)\n        self.set_child(\"basis_opt\", basis_opt)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        if setting[\"merge_small\"]:\n            tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n        state[\"exp_avg_proj\"] = torch.zeros_like(tensor)\n        state[\"exp_avg_sq_proj\"] = torch.zeros_like(tensor)\n\n        if tensor.ndim &lt;= 1 and not setting[\"precondition_1d\"]:\n            state['GG'] = []\n\n        else:\n            max_dim = setting[\"max_dim\"]\n            state['GG'] = [\n                torch.zeros(s, s, dtype=tensor.dtype, device=tensor.device) if 1&lt;s&lt;max_dim else None for s in tensor.shape\n            ]\n\n        # either scalar parameter, 1d with precondition_1d=False, or all dims are too big.\n        if len([i is not None for i in state['GG']]) == 0:\n            state['GG'] = None\n\n        # first covariance accumulation\n        if state['GG'] is not None:\n            update_soap_covariances_(tensor, GGs_=state['GG'], beta=setting[\"shampoo_beta\"])\n\n            # get projection matrix with first gradients with eigh\n            try: state['Q'] = get_orthogonal_matrix(state['GG'])\n            except torch.linalg.LinAlgError as e:\n                warnings.warn(f\"torch.linalg.eigh raised an error when initializing SOAP Q matrices on 1st step, diagonal preconditioning will be used for this parameter. The error was:\\n{e}\")\n                state[\"GG\"] = None\n\n        state['step'] = 0\n\n\n    # no update to avoid running merge_dims twice\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        # note\n        # do not modify tensors in-place\n        # because they are used to update preconditioner at the end\n\n        steps = [s[\"step\"] for s in states]\n        if any(s == 0 for s in steps):\n            # skip 1st update so to avoid using current gradient in the projection\n            # I scale it instead to avoid issues with further modules\n            for s in states: s[\"step\"] += 1\n            return TensorList(tensors).clamp(-0.1, 0.1)\n            # return TensorList(tensors).zero_()\n\n        merged_updates = [] # for when exp_avg is maintained unprojected\n        merged_grads = [] # this doesn't go into preconditioner\n        projected = []\n\n        # -------------------------------- inner step -------------------------------- #\n        updates = tensors\n        has_inner = \"inner\" in self.children\n        if has_inner:\n            updates = self.inner_step_tensors(\"inner\", updates, clone=True,\n                                              params=params, grads=grads, loss=loss)\n\n        # ---------------------------------- project --------------------------------- #\n        for grad, update, state, setting in zip(tensors, updates, states, settings):\n            if setting[\"merge_small\"]:\n                update, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(update, setting[\"max_dim\"])\n                if has_inner: # grad is a different tensor, merge it too\n                    grad, _, _ = _merge_small_dims(grad, setting[\"max_dim\"])\n                else: # in this case update is still just grad\n                    grad = update\n\n            merged_updates.append(update)\n            merged_grads.append(grad)\n\n            if state['GG'] is not None:\n                update = project(update, state['Q'])\n\n            projected.append(update)\n\n\n        # ------------------------ run opt in projected space ----------------------- #\n        dirs_proj = self.inner_step_tensors(\"basis_opt\", tensors=projected, clone=True, grads=projected)\n\n        # ------------------------------- project back ------------------------------- #\n        dirs: list[torch.Tensor] = []\n        for dir, state, setting in zip(dirs_proj, states, settings):\n            if state['GG'] is not None:\n                dir = project_back(dir, state['Q'])\n\n            if setting[\"merge_small\"]:\n                dir = _unmerge_small_dims(dir, state['flat_sizes'], state['sort_idxs'])\n\n            dirs.append(dir)\n\n        # -------------------------- update preconditioners -------------------------- #\n        # Update is done after the gradient step to avoid using current gradients in the projection.\n\n        grad_buffs = self.get_child_projected_buffers(\"basis_opt\", \"grad\")\n        grad_sq_buffs = self.get_child_projected_buffers(\"basis_opt\", [\"grad_sq\", \"grad_cu\"])\n\n        for i, (grad, state, setting) in enumerate(zip(merged_grads, states, settings)):\n            if state['GG'] is not None:\n\n                # lerp covariances\n                update_soap_covariances_(grad, state['GG'], beta=setting[\"shampoo_beta\"])\n\n                # (state['step'] - 1) since we start updating on 2nd step\n                if (state['step'] - 1) % setting['precond_freq'] == 0:\n                    g_buffs = [b[i] for b in grad_buffs]\n                    g_sq_buffs = [b[i] for b in grad_sq_buffs]\n\n                    # unproject grad buffers before updating\n                    g_buffs_unproj = [project_back(buff, state[\"Q\"]) for buff in g_buffs]\n\n                    # update projection matrix and exp_avg_sq_proj\n                    try:\n                        state['Q'], g_sq_buffs_new = get_orthogonal_matrix_QR(\n                            g_sq_buffs, state['GG'], state['Q'])\n\n                        for b_old, b_new in zip(g_sq_buffs, g_sq_buffs_new):\n                            set_storage_(b_old, b_new)\n\n                        # re-project grad buffers\n                        for b_proj, b_unproj in zip(g_buffs, g_buffs_unproj):\n                            set_storage_(b_proj, project(b_unproj, state[\"Q\"]))\n\n                    except torch.linalg.LinAlgError:\n                        pass\n\n            state[\"step\"] += 1\n\n        return dirs\n</code></pre>"},{"location":"API/all/#torchzero.modules.SPSA","title":"SPSA","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Gradient approximation via Simultaneous perturbation stochastic approximation (SPSA) method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'rademacher'</code> )           \u2013            <p>distribution. Defaults to \"rademacher\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class SPSA(RandomizedFDM):\n    \"\"\"\n    Gradient approximation via Simultaneous perturbation stochastic approximation (SPSA) method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"rademacher\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771\n    \"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.SPSA1","title":"SPSA1","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>One-measurement variant of SPSA. Unlike standard two-measurement SPSA, the estimated gradient often won't be a descent direction, however the expectation is biased towards the descent direction. Therefore this variant of SPSA is only recommended for a specific class of problems where the objective function changes on each evaluation, for example feedback control problems.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size, recommended to set to same value as learning rate. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random samples. Defaults to 1.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>measurement noise estimate. Defaults to 1e-8.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>random seed. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on closure. Defaults to \"closure\".</p> </li> </ul> Reference <p>SPALL, JAMES C. \"A One-measurement Form of Simultaneous Stochastic Approximation.\"</p> Source code in <code>torchzero/modules/grad_approximation/spsa1.py</code> <pre><code>class SPSA1(GradApproximator):\n    \"\"\"One-measurement variant of SPSA. Unlike standard two-measurement SPSA, the estimated\n    gradient often won't be a descent direction, however the expectation is biased towards\n    the descent direction. Therefore this variant of SPSA is only recommended for a specific\n    class of problems where the objective function changes on each evaluation,\n    for example feedback control problems.\n\n    Args:\n        h (float, optional):\n            finite difference step size, recommended to set to same value as learning rate. Defaults to 1e-3.\n        n_samples (int, optional): number of random samples. Defaults to 1.\n        eps (float, optional): measurement noise estimate. Defaults to 1e-8.\n        seed (int | None | torch.Generator, optional): random seed. Defaults to None.\n        target (GradTarget, optional): what to set on closure. Defaults to \"closure\".\n\n    Reference:\n        [SPALL, JAMES C. \"A One-measurement Form of Simultaneous Stochastic Approximation](https://www.jhuapl.edu/spsa/PDF-SPSA/automatica97_one_measSPSA.pdf).\"\n    \"\"\"\n\n    def __init__(\n        self,\n        h: float = 1e-3,\n        n_samples: int = 1,\n        eps: float = 1e-8, # measurement noise\n        pre_generate = False,\n        seed: int | None | torch.Generator = None,\n        target: GradTarget = \"closure\",\n    ):\n        defaults = dict(h=h, eps=eps, n_samples=n_samples, pre_generate=pre_generate, seed=seed)\n        super().__init__(defaults, target=target)\n\n\n    def pre_step(self, objective):\n\n        if self.defaults['pre_generate']:\n\n            params = TensorList(objective.params)\n            generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n            n_samples = self.defaults['n_samples']\n            h = self.get_settings(objective.params, 'h')\n\n            perturbations = [params.rademacher_like(generator=generator) for _ in range(n_samples)]\n            torch._foreach_mul_([p for l in perturbations for p in l], [v for vv in h for v in [vv]*n_samples])\n\n            for param, prt in zip(params, zip(*perturbations)):\n                self.state[param]['perturbations'] = prt\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n        params = TensorList(params)\n        orig_params = params.clone() # store to avoid small changes due to float imprecision\n        loss_approx = None\n\n        h, eps = self.get_settings(params, \"h\", \"eps\", cls=NumberList)\n        n_samples = self.defaults['n_samples']\n\n        default = [None]*n_samples\n        # perturbations are pre-multiplied by h\n        perturbations = list(zip(*(self.state[p].get('perturbations', default) for p in params)))\n\n        grad = None\n        for i in range(n_samples):\n            prt = perturbations[i]\n\n            if prt[0] is None:\n                prt = params.rademacher_like(generator=generator).mul_(h)\n\n            else: prt = TensorList(prt)\n\n            params += prt\n            L = closure(False)\n            params.copy_(orig_params)\n\n            sample = prt * ((L + eps) / h)\n            if grad is None: grad = sample\n            else: grad += sample\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n\n        # mean if got per-sample values\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/all/#torchzero.modules.SR1","title":"SR1","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Symmetric Rank 1. This works best with a trust region: <pre><code>tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False))\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>init_scale</code>               (<code>float | Literal['auto']</code>, default:                   <code>'auto'</code> )           \u2013            <p>initial hessian matrix is set to identity times this.</p> <p>\"auto\" corresponds to a heuristic from [1] p.142-143.</p> <p>Defaults to \"auto\".</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-32</code> )           \u2013            <p>tolerance for denominator in SR1 update rule as in [1] p.146. Defaults to 1e-32.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips update if maximum difference between current and previous gradients is less than this, to avoid instability. Defaults to 1e-32.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.</p> </li> <li> <code>restart_interval</code>               (<code>int | None | Literal['auto']</code>, default:                   <code>None</code> )           \u2013            <p>interval between resetting the hessian approximation.</p> <p>\"auto\" corresponds to number of decision variables + 1.</p> <p>None - no resets.</p> <p>Defaults to None.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>momentum on H or B. Defaults to None.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating H or B. Defaults to 1.</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to downscale first step before hessian approximation becomes available. Defaults to True.</p> </li> <li> <code>scale_second</code>               (<code>bool</code>)           \u2013            <p>whether to downscale second step. Defaults to False.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If true, all parameters are treated as a single vector. If False, the update rule is applied to each parameter separately. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to the output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.SR1--examples","title":"Examples:","text":"<p>SR1 with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n)\n</code></pre></p>"},{"location":"API/all/#torchzero.modules.SR1--references","title":"References:","text":"<pre><code>[1]. Nocedal. Stephen J. Wright. Numerical Optimization\n</code></pre> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class SR1(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Symmetric Rank 1. This works best with a trust region:\n    ```python\n    tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False))\n    ```\n\n    Args:\n        init_scale (float | Literal[\"auto\"], optional):\n            initial hessian matrix is set to identity times this.\n\n            \"auto\" corresponds to a heuristic from [1] p.142-143.\n\n            Defaults to \"auto\".\n        tol (float, optional):\n            tolerance for denominator in SR1 update rule as in [1] p.146. Defaults to 1e-32.\n        ptol (float | None, optional):\n            skips update if maximum difference between current and previous gradients is less than this, to avoid instability.\n            Defaults to 1e-32.\n        ptol_restart (bool, optional): whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.\n        restart_interval (int | None | Literal[\"auto\"], optional):\n            interval between resetting the hessian approximation.\n\n            \"auto\" corresponds to number of decision variables + 1.\n\n            None - no resets.\n\n            Defaults to None.\n        beta (float | None, optional): momentum on H or B. Defaults to None.\n        update_freq (int, optional): frequency of updating H or B. Defaults to 1.\n        scale_first (bool, optional):\n            whether to downscale first step before hessian approximation becomes available. Defaults to True.\n        scale_second (bool, optional): whether to downscale second step. Defaults to False.\n        concat_params (bool, optional):\n            If true, all parameters are treated as a single vector.\n            If False, the update rule is applied to each parameter separately. Defaults to True.\n        inner (Chainable | None, optional): preconditioning is applied to the output of this module. Defaults to None.\n\n    ### Examples:\n\n    SR1 with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n    )\n    ```\n\n    ###  References:\n        [1]. Nocedal. Stephen J. Wright. Numerical Optimization\n    \"\"\"\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return sr1_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return sr1_(H=B, s=y, y=s, tol=setting['tol'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.SSVM","title":"SSVM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Self-scaling variable metric Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Oren, S. S., &amp; Spedicato, E. (1976). Optimal conditioning of self-scaling variable Metric algorithms. Mathematical Programming, 10(1), 70\u201390. doi:10.1007/bf01580654</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class SSVM(HessianUpdateStrategy):\n    \"\"\"\n    Self-scaling variable metric Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Oren, S. S., &amp; Spedicato, E. (1976). Optimal conditioning of self-scaling variable Metric algorithms. Mathematical Programming, 10(1), 70\u201390. doi:10.1007/bf01580654\n    \"\"\"\n    def __init__(\n        self,\n        switch: tuple[float,float] | Literal[1,2,3,4] = 3,\n        init_scale: float | Literal[\"auto\"] = 'auto',\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(switch=switch)\n        super().__init__(\n            defaults=defaults,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return ssvm_H_(H=H, s=s, y=y, g=g, switch=setting['switch'], tol=setting['tol'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.SVRG","title":"SVRG","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Stochastic variance reduced gradient method (SVRG).</p> <p>To use, put SVRG as the first module, it can be used with any other modules. To reduce variance of a gradient estimator, put the gradient estimator before SVRG.</p> <p>First it uses first <code>accum_steps</code> batches to compute full gradient at initial parameters using gradient accumulation, the model will not be updated during this.</p> <p>Then it performs <code>svrg_steps</code> SVRG steps, each requires two forward and backward passes.</p> <p>After <code>svrg_steps</code>, it goes back to full gradient computation step step.</p> <p>As an alternative to gradient accumulation you can pass \"full_closure\" argument to the <code>step</code> method, which should compute full gradients, set them to <code>.grad</code> attributes of the parameters, and return full loss.</p> <p>Parameters:</p> <ul> <li> <code>svrg_steps</code>               (<code>int</code>)           \u2013            <p>number of steps before calculating full gradient. This can be set to length of the dataloader.</p> </li> <li> <code>accum_steps</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>number of steps to accumulate the gradient for. Not used if \"full_closure\" is passed to the <code>step</code> method. If None, uses value of <code>svrg_steps</code>. Defaults to None.</p> </li> <li> <code>reset_before_accum</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to reset all other modules when re-calculating full gradient. Defaults to True.</p> </li> <li> <code>svrg_loss</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to replace loss with SVRG loss (calculated by same formula as SVRG gradient). Defaults to True.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>multiplier to <code>g_full(x_0) - g_batch(x_0)</code> term, can be annealed linearly from 1 to 0 as suggested in https://arxiv.org/pdf/2311.05589#page=6</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.SVRG--examples","title":"Examples:","text":"<p>SVRG-LBFGS <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SVRG(len(dataloader)),\n    tz.m.LBFGS(),\n    tz.m.Backtracking(),\n)\n</code></pre></p> <p>For extra variance reduction one can use Online versions of algorithms, although it won't always help. <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SVRG(len(dataloader)),\n    tz.m.Online(tz.m.LBFGS()),\n    tz.m.Backtracking(),\n)\n\nVariance reduction can also be applied to gradient estimators.\n```python\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SPSA(),\n    tz.m.SVRG(100),\n    tz.m.LR(1e-2),\n)\n</code></pre></p>"},{"location":"API/all/#torchzero.modules.SVRG--notes","title":"Notes","text":"<p>The SVRG gradient is computed as <code>g_b(x) - alpha * (g_b(x_0) - g_f(x_0))</code>, where: - <code>x</code> is current parameters - <code>x_0</code> is initial parameters, where full gradient was computed - <code>g_b</code> refers to mini-batch gradient at <code>x</code> or <code>x_0</code> - <code>g_f</code> refers to full gradient at <code>x_0</code>.</p> <p>The SVRG loss is computed using the same formula.</p> Source code in <code>torchzero/modules/variance_reduction/svrg.py</code> <pre><code>class SVRG(Module):\n    \"\"\"Stochastic variance reduced gradient method (SVRG).\n\n    To use, put SVRG as the first module, it can be used with any other modules.\n    To reduce variance of a gradient estimator, put the gradient estimator before SVRG.\n\n    First it uses first ``accum_steps`` batches to compute full gradient at initial\n    parameters using gradient accumulation, the model will not be updated during this.\n\n    Then it performs ``svrg_steps`` SVRG steps, each requires two forward and backward passes.\n\n    After ``svrg_steps``, it goes back to full gradient computation step step.\n\n    As an alternative to gradient accumulation you can pass \"full_closure\" argument to the ``step`` method,\n    which should compute full gradients, set them to ``.grad`` attributes of the parameters,\n    and return full loss.\n\n    Args:\n        svrg_steps (int): number of steps before calculating full gradient. This can be set to length of the dataloader.\n        accum_steps (int | None, optional):\n            number of steps to accumulate the gradient for. Not used if \"full_closure\" is passed to the ``step`` method. If None, uses value of ``svrg_steps``. Defaults to None.\n        reset_before_accum (bool, optional):\n            whether to reset all other modules when re-calculating full gradient. Defaults to True.\n        svrg_loss (bool, optional):\n            whether to replace loss with SVRG loss (calculated by same formula as SVRG gradient). Defaults to True.\n        alpha (float, optional):\n            multiplier to ``g_full(x_0) - g_batch(x_0)`` term, can be annealed linearly from 1 to 0 as suggested in https://arxiv.org/pdf/2311.05589#page=6\n\n    ## Examples:\n    SVRG-LBFGS\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SVRG(len(dataloader)),\n        tz.m.LBFGS(),\n        tz.m.Backtracking(),\n    )\n    ```\n\n    For extra variance reduction one can use Online versions of algorithms, although it won't always help.\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SVRG(len(dataloader)),\n        tz.m.Online(tz.m.LBFGS()),\n        tz.m.Backtracking(),\n    )\n\n    Variance reduction can also be applied to gradient estimators.\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SPSA(),\n        tz.m.SVRG(100),\n        tz.m.LR(1e-2),\n    )\n    ```\n    ## Notes\n\n    The SVRG gradient is computed as ``g_b(x) - alpha * (g_b(x_0) - g_f(x_0))``, where:\n    - ``x`` is current parameters\n    - ``x_0`` is initial parameters, where full gradient was computed\n    - ``g_b`` refers to mini-batch gradient at ``x`` or ``x_0``\n    - ``g_f`` refers to full gradient at ``x_0``.\n\n    The SVRG loss is computed using the same formula.\n    \"\"\"\n    def __init__(self, svrg_steps: int, accum_steps: int | None = None, reset_before_accum:bool=True, svrg_loss:bool=True, alpha:float=1):\n        defaults = dict(svrg_steps = svrg_steps, accum_steps=accum_steps, reset_before_accum=reset_before_accum, svrg_loss=svrg_loss, alpha=alpha)\n        super().__init__(defaults)\n\n\n    @torch.no_grad\n    def update(self, objective):\n        params = objective.params\n        closure = objective.closure\n        assert closure is not None\n\n        if \"full_grad\" not in self.global_state:\n\n            # -------------------------- calculate full gradient ------------------------- #\n            if \"full_closure\" in objective.storage:\n                full_closure = objective.storage['full_closure']\n                with torch.enable_grad():\n                    full_loss = full_closure()\n                    if all(p.grad is None for p in params):\n                        warnings.warn(\"all gradients are None after evaluating full_closure.\")\n\n                    full_grad = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n                    self.global_state[\"full_loss\"] = full_loss\n                    self.global_state[\"full_grad\"] = full_grad\n                    self.global_state['x_0'] = [p.clone() for p in params]\n\n                # current batch will be used for svrg update\n\n            else:\n                # accumulate gradients over n steps\n                accum_steps = self.defaults['accum_steps']\n                if accum_steps is None: accum_steps = self.defaults['svrg_steps']\n\n                current_accum_step = self.global_state.get('current_accum_step', 0) + 1\n                self.global_state['current_accum_step'] = current_accum_step\n\n                # accumulate grads\n                accumulator = self.get_state(params, 'accumulator')\n                grad = objective.get_grads()\n                torch._foreach_add_(accumulator, grad)\n\n                # accumulate loss\n                loss_accumulator = self.global_state.get('loss_accumulator', 0)\n                loss_accumulator += tofloat(objective.loss)\n                self.global_state['loss_accumulator'] = loss_accumulator\n\n                # on nth step, use the accumulated gradient\n                if current_accum_step &gt;= accum_steps:\n                    torch._foreach_div_(accumulator, accum_steps)\n                    self.global_state[\"full_grad\"] = accumulator\n                    self.global_state[\"full_loss\"] = loss_accumulator / accum_steps\n\n                    self.global_state['x_0'] = [p.clone() for p in params]\n                    self.clear_state_keys('accumulator')\n                    del self.global_state['current_accum_step']\n\n                # otherwise skip update until enough grads are accumulated\n                else:\n                    objective.updates = None\n                    objective.stop = True\n                    objective.skip_update = True\n                    return\n\n\n        svrg_steps = self.defaults['svrg_steps']\n        current_svrg_step = self.global_state.get('current_svrg_step', 0) + 1\n        self.global_state['current_svrg_step'] = current_svrg_step\n\n        # --------------------------- SVRG gradient closure -------------------------- #\n        x0 = self.global_state['x_0']\n        gf_x0 = self.global_state[\"full_grad\"]\n        ff_x0 = self.global_state['full_loss']\n        use_svrg_loss = self.defaults['svrg_loss']\n        alpha = self.get_settings(params, 'alpha')\n        alpha_0 = alpha[0]\n        if all(a == 1 for a in alpha): alpha = None\n\n        def svrg_closure(backward=True):\n            # g_b(x) - \u03b1 * (g_f(x_0) - g_b(x_0)) and same for loss\n            with torch.no_grad():\n                x = [p.clone() for p in params]\n\n                if backward:\n                    # f and g at x\n                    with torch.enable_grad(): fb_x = closure()\n                    gb_x = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n\n                    # f and g at x_0\n                    torch._foreach_copy_(params, x0)\n                    with torch.enable_grad(): fb_x0 = closure()\n                    gb_x0 = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n                    torch._foreach_copy_(params, x)\n\n                    # g_svrg = gb_x - alpha * (gf_x0 - gb_x0)\n                    correction = torch._foreach_sub(gb_x0, gf_x0)\n                    if alpha is not None: torch._foreach_mul_(correction, alpha)\n                    g_svrg = torch._foreach_sub(gb_x, correction)\n\n                    f_svrg = fb_x - alpha_0 * (fb_x0 - ff_x0)\n                    for p, g in zip(params, g_svrg):\n                        p.grad = g\n\n                    if use_svrg_loss: return f_svrg\n                    return fb_x\n\n            # no backward\n            if use_svrg_loss:\n                fb_x = closure(False)\n                torch._foreach_copy_(params, x0)\n                fb_x0 = closure(False)\n                torch._foreach_copy_(params, x)\n                f_svrg = fb_x - alpha_0 * (fb_x0 - ff_x0)\n                return f_svrg\n\n            return closure(False)\n\n        objective.closure = svrg_closure\n\n        # --- after svrg_steps steps reset so that new full gradient is calculated on next step --- #\n        if current_svrg_step &gt;= svrg_steps:\n            del self.global_state['current_svrg_step']\n            del self.global_state['full_grad']\n            del self.global_state['full_loss']\n            del self.global_state['x_0']\n            if self.defaults['reset_before_accum']:\n                objective.post_step_hooks.append(partial(_reset_except_self, self=self))\n\n    def apply(self, objective): return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.SaveBest","title":"SaveBest","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Saves best parameters found so far, ones that have lowest loss. Put this as the last module.</p> <p>Adds the following attrs:</p> <ul> <li><code>best_params</code> - a list of tensors with best parameters.</li> <li><code>best_loss</code> - loss value with <code>best_params</code>.</li> <li><code>load_best_parameters</code> - a function that sets parameters to the best parameters./</li> </ul>"},{"location":"API/all/#torchzero.modules.SaveBest--examples","title":"Examples","text":"<p>```python def rosenbrock(x, y):     return (1 - x)2 + (100 * (y - x2))**2</p> <p>xy = torch.tensor((-1.1, 2.5), requires_grad=True) opt = tz.Optimizer(     [xy],     tz.m.NAG(0.999),     tz.m.LR(1e-6),     tz.m.SaveBest() )</p>"},{"location":"API/all/#torchzero.modules.SaveBest--optimize-for-1000-steps","title":"optimize for 1000 steps","text":"<p>for i in range(1000):     loss = rosenbrock(*xy)     opt.zero_grad()     loss.backward()     opt.step(loss=loss) # SaveBest needs closure or loss</p>"},{"location":"API/all/#torchzero.modules.SaveBest--nag-overshot-but-we-saved-the-best-params","title":"NAG overshot, but we saved the best params","text":"<p>print(f'{rosenbrock(*xy) = }') # &gt;&gt; 3.6583 print(f\"{opt.attrs['best_loss'] = }\") # &gt;&gt; 0.000627</p>"},{"location":"API/all/#torchzero.modules.SaveBest--load-best-parameters","title":"load best parameters","text":"<p>opt.attrs'load_best_params' print(f'{rosenbrock(*xy) = }') # &gt;&gt; 0.000627</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class SaveBest(Module):\n    \"\"\"Saves best parameters found so far, ones that have lowest loss. Put this as the last module.\n\n    Adds the following attrs:\n\n    - ``best_params`` - a list of tensors with best parameters.\n    - ``best_loss`` - loss value with ``best_params``.\n    - ``load_best_parameters`` - a function that sets parameters to the best parameters./\n\n    ## Examples\n    ```python\n    def rosenbrock(x, y):\n        return (1 - x)**2 + (100 * (y - x**2))**2\n\n    xy = torch.tensor((-1.1, 2.5), requires_grad=True)\n    opt = tz.Optimizer(\n        [xy],\n        tz.m.NAG(0.999),\n        tz.m.LR(1e-6),\n        tz.m.SaveBest()\n    )\n\n    # optimize for 1000 steps\n    for i in range(1000):\n        loss = rosenbrock(*xy)\n        opt.zero_grad()\n        loss.backward()\n        opt.step(loss=loss) # SaveBest needs closure or loss\n\n    # NAG overshot, but we saved the best params\n    print(f'{rosenbrock(*xy) = }') # &gt;&gt; 3.6583\n    print(f\"{opt.attrs['best_loss'] = }\") # &gt;&gt; 0.000627\n\n    # load best parameters\n    opt.attrs['load_best_params']()\n    print(f'{rosenbrock(*xy) = }') # &gt;&gt; 0.000627\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    @torch.no_grad\n    def apply(self, objective):\n        loss = tofloat(objective.get_loss(False))\n        lowest_loss = self.global_state.get('lowest_loss', float(\"inf\"))\n\n        if loss &lt; lowest_loss:\n            self.global_state['lowest_loss'] = loss\n            best_params = objective.attrs['best_params'] = [p.clone() for p in objective.params]\n            objective.attrs['best_loss'] = loss\n            objective.attrs['load_best_params'] = partial(_load_best_parameters, params=objective.params, best_params=best_params)\n\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.ScalarProjection","title":"ScalarProjection","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>projetion that splits all parameters into individual scalars</p> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>class ScalarProjection(ProjectionBase):\n    \"\"\"projetion that splits all parameters into individual scalars\"\"\"\n    def __init__(\n        self,\n        modules: Chainable,\n        project_update=True,\n        project_params=True,\n        project_grad=True,\n    ):\n        super().__init__(modules, project_update=project_update, project_params=project_params, project_grad=project_grad)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        return [s for t in tensors for s in t.ravel().unbind(0)]\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        return vec_to_tensors(vec=torch.stack(projected_tensors), reference=params)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ScaleByGradCosineSimilarity","title":"ScaleByGradCosineSimilarity","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies the update by cosine similarity with gradient. If cosine similarity is negative, naturally the update will be negated as well.</p> <p>Parameters:</p> <ul> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.ScaleByGradCosineSimilarity--examples","title":"Examples:","text":"<p>Scaled Adam <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.Adam(),\n    tz.m.ScaleByGradCosineSimilarity(),\n    tz.m.LR(1e-2)\n)\n</code></pre></p> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class ScaleByGradCosineSimilarity(TensorTransform):\n    \"\"\"Multiplies the update by cosine similarity with gradient.\n    If cosine similarity is negative, naturally the update will be negated as well.\n\n    Args:\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n\n    ## Examples:\n\n    Scaled Adam\n    ```python\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.Adam(),\n        tz.m.ScaleByGradCosineSimilarity(),\n        tz.m.LR(1e-2)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        eps: float = 1e-6,\n    ):\n        defaults = dict(eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        eps = settings[0]['eps']\n        tensors = TensorList(tensors)\n        grads = TensorList(grads)\n        cos_sim = tensors.dot(grads) / (tensors.global_vector_norm() * grads.global_vector_norm()).clip(min=eps)\n\n        return tensors.mul_(cos_sim)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ScaleLRBySignChange","title":"ScaleLRBySignChange","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>learning rate gets multiplied by <code>nplus</code> if ascent/gradient didn't change the sign, or <code>nminus</code> if it did.</p> <p>This is part of RProp update rule.</p> <p>Parameters:</p> <ul> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>1.2</code> )           \u2013            <p>learning rate gets multiplied by <code>nplus</code> if ascent/gradient didn't change the sign</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>learning rate gets multiplied by <code>nminus</code> if ascent/gradient changed the sign</p> </li> <li> <code>lb</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>lower bound for lr.</p> </li> <li> <code>ub</code>               (<code>float</code>, default:                   <code>50.0</code> )           \u2013            <p>upper bound for lr.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial learning rate.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class ScaleLRBySignChange(TensorTransform):\n    \"\"\"\n    learning rate gets multiplied by ``nplus`` if ascent/gradient didn't change the sign,\n    or ``nminus`` if it did.\n\n    This is part of RProp update rule.\n\n    Args:\n        nplus (float): learning rate gets multiplied by ``nplus`` if ascent/gradient didn't change the sign\n        nminus (float): learning rate gets multiplied by ``nminus`` if ascent/gradient changed the sign\n        lb (float): lower bound for lr.\n        ub (float): upper bound for lr.\n        alpha (float): initial learning rate.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        nplus: float = 1.2,\n        nminus: float = 0.5,\n        lb=1e-6,\n        ub=50.0,\n        alpha=1.0,\n        use_grad=False,\n    ):\n        defaults = dict(nplus=nplus, nminus=nminus, alpha=alpha, lb=lb, ub=ub, use_grad=use_grad)\n        super().__init__(defaults, uses_grad=use_grad)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        tensors = TensorList(tensors)\n        if self._uses_grad:\n            assert grads is not None\n            cur = TensorList(grads)\n        else: cur = tensors\n\n        nplus, nminus, lb, ub = unpack_dicts(settings, 'nplus', 'nminus', 'lb', 'ub', cls=NumberList)\n        prev, lrs = unpack_states(states, tensors, 'prev', 'lrs', cls=TensorList)\n\n        if step == 0:\n            lrs.set_(tensors.full_like([s['alpha'] for s in settings]))\n\n        tensors = scale_by_sign_change_(\n            tensors_ = tensors,\n            cur = cur,\n            prev_ = prev,\n            lrs_ = lrs,\n            nplus = nplus,\n            nminus = nminus,\n            lb = lb,\n            ub = ub,\n            step = step,\n        )\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.ScaleModulesByCosineSimilarity","title":"ScaleModulesByCosineSimilarity","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Scales the output of <code>main</code> module by it's cosine similarity to the output of <code>compare</code> module.</p> <p>Parameters:</p> <ul> <li> <code>main</code>               (<code>Chainable</code>)           \u2013            <p>main module or sequence of modules whose update will be scaled.</p> </li> <li> <code>compare</code>               (<code>Chainable</code>)           \u2013            <p>module or sequence of modules to compare to</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.ScaleModulesByCosineSimilarity--examples","title":"Examples:","text":"<p>Adam scaled by similarity to RMSprop <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.ScaleModulesByCosineSimilarity(\n        main = tz.m.Adam(),\n        compare = tz.m.RMSprop(0.999, debiased=True),\n    ),\n    tz.m.LR(1e-2)\n)\n</code></pre></p> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class ScaleModulesByCosineSimilarity(Module):\n    \"\"\"Scales the output of ``main`` module by it's cosine similarity to the output\n    of ``compare`` module.\n\n    Args:\n        main (Chainable): main module or sequence of modules whose update will be scaled.\n        compare (Chainable): module or sequence of modules to compare to\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n\n    ## Examples:\n\n    Adam scaled by similarity to RMSprop\n    ```python\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.ScaleModulesByCosineSimilarity(\n            main = tz.m.Adam(),\n            compare = tz.m.RMSprop(0.999, debiased=True),\n        ),\n        tz.m.LR(1e-2)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        main: Chainable,\n        compare: Chainable,\n        eps=1e-6,\n    ):\n        defaults = dict(eps=eps)\n        super().__init__(defaults)\n\n        self.set_child('main', main)\n        self.set_child('compare', compare)\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective):\n        main = self.children['main']\n        compare = self.children['compare']\n\n        main_var = main.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(main_var)\n\n        compare_var = compare.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(compare_var)\n\n        m = TensorList(main_var.get_updates())\n        c = TensorList(compare_var.get_updates())\n        eps = self.defaults['eps']\n\n        cos_sim = m.dot(c) / (m.global_vector_norm() * c.global_vector_norm()).clip(min=eps)\n\n        objective.updates = m.mul_(cos_sim)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.ScipyMinimizeScalar","title":"ScipyMinimizeScalar","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Line search via :code:<code>scipy.optimize.minimize_scalar</code> which implements brent, golden search and bounded brent methods.</p> <p>Parameters:</p> <ul> <li> <code>method</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>\"brent\", \"golden\" or \"bounded\". Defaults to None.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of function evaluations the line search is allowed to perform. Defaults to None.</p> </li> <li> <code>bracket</code>               (<code>Sequence | None</code>, default:                   <code>None</code> )           \u2013            <p>Either a triple (xa, xb, xc) satisfying xa &lt; xb &lt; xc and func(xb) &lt; func(xa) and  func(xb) &lt; func(xc), or a pair (xa, xb) to be used as initial points for a downhill bracket search. Defaults to None.</p> </li> <li> <code>bounds</code>               (<code>Sequence | None</code>, default:                   <code>None</code> )           \u2013            <p>For method \u2018bounded\u2019, bounds is mandatory and must have two finite items corresponding to the optimization bounds. Defaults to None.</p> </li> <li> <code>tol</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Tolerance for termination. Defaults to None.</p> </li> <li> <code>prev_init</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>uses previous step size as initial guess for the line search.</p> </li> <li> <code>options</code>               (<code>dict | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary of solver options. Defaults to None.</p> </li> </ul> <p>For more details on methods and arguments refer to https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize_scalar.html</p> Source code in <code>torchzero/modules/line_search/scipy.py</code> <pre><code>class ScipyMinimizeScalar(LineSearchBase):\n    \"\"\"Line search via :code:`scipy.optimize.minimize_scalar` which implements brent, golden search and bounded brent methods.\n\n    Args:\n        method (str | None, optional): \"brent\", \"golden\" or \"bounded\". Defaults to None.\n        maxiter (int | None, optional): maximum number of function evaluations the line search is allowed to perform. Defaults to None.\n        bracket (Sequence | None, optional):\n            Either a triple (xa, xb, xc) satisfying xa &lt; xb &lt; xc and func(xb) &lt; func(xa) and  func(xb) &lt; func(xc), or a pair (xa, xb) to be used as initial points for a downhill bracket search. Defaults to None.\n        bounds (Sequence | None, optional):\n            For method \u2018bounded\u2019, bounds is mandatory and must have two finite items corresponding to the optimization bounds. Defaults to None.\n        tol (float | None, optional): Tolerance for termination. Defaults to None.\n        prev_init (bool, optional): uses previous step size as initial guess for the line search.\n        options (dict | None, optional): A dictionary of solver options. Defaults to None.\n\n    For more details on methods and arguments refer to https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize_scalar.html\n\n    \"\"\"\n    def __init__(\n        self,\n        method: str | None = None,\n        maxiter: int | None = None,\n        bracket=None,\n        bounds=None,\n        tol: float | None = None,\n        prev_init: bool = False,\n        options=None,\n    ):\n        defaults = dict(method=method,bracket=bracket,bounds=bounds,tol=tol,options=options,maxiter=maxiter, prev_init=prev_init)\n        super().__init__(defaults)\n\n        import scipy.optimize\n        self.scopt = scipy.optimize\n\n\n    @torch.no_grad\n    def search(self, update, var):\n        objective = self.make_objective(var=var)\n        method, bracket, bounds, tol, options, maxiter = itemgetter(\n            'method', 'bracket', 'bounds', 'tol', 'options', 'maxiter')(self.defaults)\n\n        if maxiter is not None:\n            options = dict(options) if isinstance(options, Mapping) else {}\n            options['maxiter'] = maxiter\n\n        if self.defaults[\"prev_init\"] and \"x_prev\" in self.global_state:\n            if bracket is None: bracket = (0, 1)\n            bracket = (*bracket[:-1], self.global_state[\"x_prev\"])\n\n        x = self.scopt.minimize_scalar(objective, method=method, bracket=bracket, bounds=bounds, tol=tol, options=options).x # pyright:ignore[reportAttributeAccessIssue]\n\n        max = torch.finfo(var.params[0].dtype).max / 2\n        if (not math.isfinite(x)) or abs(x) &gt;= max: x = 0\n\n        self.global_state['x_prev'] = x\n        return x\n</code></pre>"},{"location":"API/all/#torchzero.modules.Sequential","title":"Sequential","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>On each step, this sequentially steps with <code>modules</code> <code>steps</code> times.</p> <p>The update is taken to be the parameter difference between parameters before and after the inner loop.</p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class Sequential(Module):\n    \"\"\"On each step, this sequentially steps with ``modules`` ``steps`` times.\n\n    The update is taken to be the parameter difference between parameters before and after the inner loop.\"\"\"\n    def __init__(self, modules: Iterable[Chainable], steps: int=1):\n        defaults = dict(steps=steps)\n        super().__init__(defaults)\n        self.set_children_sequence(modules)\n\n    @torch.no_grad\n    def apply(self, objective):\n        return _sequential_step(self, objective, sequential=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Shampoo","title":"Shampoo","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Shampoo from Preconditioned Stochastic Tensor Optimization (https://arxiv.org/abs/1802.09568).</p> Notes <p>Shampoo is usually grafted to another optimizer like Adam, otherwise it can be unstable. An example of how to do grafting is given below in the Examples section.</p> <p>Shampoo is a very computationally expensive optimizer, increase <code>update_freq</code> if it is too slow.</p> <p>SOAP optimizer usually outperforms Shampoo and is also not as computationally expensive. SOAP implementation is available as <code>tz.m.SOAP</code>.</p> <p>Parameters:</p> <ul> <li> <code>update_freq</code>               (<code>int</code>)           \u2013            <p>preconditioner update frequency. Defaults to 10.</p> </li> <li> <code>matrix_power</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>overrides matrix exponent. By default uses <code>-1/grad.ndim</code>. Defaults to None.</p> </li> <li> <code>merge_small</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to merge small dims on tensors. Defaults to True.</p> </li> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>maximum dimension size for preconditioning. Defaults to 10_000.</p> </li> <li> <code>precondition_1d</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to precondition 1d tensors. Defaults to True.</p> </li> <li> <code>adagrad_eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for adagrad division for tensors where shampoo can't be applied. Defaults to 1e-8.</p> </li> <li> <code>matrix_power_method</code>               (<code>Literal</code>, default:                   <code>'eigh_abs'</code> )           \u2013            <p>how to compute matrix power.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>if None calculates sum as in standard Shampoo, otherwise uses EMA of preconditioners. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>module applied after updating preconditioners and before applying preconditioning. For example if beta\u22480.999 and <code>inner=tz.m.EMA(0.9)</code>, this becomes Adam with shampoo preconditioner (ignoring debiasing). Defaults to None.</p> </li> </ul> <p>Examples: Shampoo grafted to Adam</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GraftModules(\n        direction = tz.m.Shampoo(),\n        magnitude = tz.m.Adam(),\n    ),\n    tz.m.LR(1e-3)\n)\n</code></pre> <p>Adam with Shampoo preconditioner</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Shampoo(beta=0.999, inner=tz.m.EMA(0.9)),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.LR(1e-3)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/shampoo.py</code> <pre><code>class Shampoo(TensorTransform):\n    \"\"\"Shampoo from Preconditioned Stochastic Tensor Optimization (https://arxiv.org/abs/1802.09568).\n\n    Notes:\n        Shampoo is usually grafted to another optimizer like Adam, otherwise it can be unstable. An example of how to do grafting is given below in the Examples section.\n\n        Shampoo is a very computationally expensive optimizer, increase ``update_freq`` if it is too slow.\n\n        SOAP optimizer usually outperforms Shampoo and is also not as computationally expensive. SOAP implementation is available as ``tz.m.SOAP``.\n\n    Args:\n        update_freq (int, optional): preconditioner update frequency. Defaults to 10.\n        matrix_power (float | None, optional): overrides matrix exponent. By default uses ``-1/grad.ndim``. Defaults to None.\n        merge_small (bool, optional): whether to merge small dims on tensors. Defaults to True.\n        max_dim (int, optional): maximum dimension size for preconditioning. Defaults to 10_000.\n        precondition_1d (bool, optional): whether to precondition 1d tensors. Defaults to True.\n        adagrad_eps (float, optional): epsilon for adagrad division for tensors where shampoo can't be applied. Defaults to 1e-8.\n        matrix_power_method (MatrixPowerMethod, optional): how to compute matrix power.\n        beta (float | None, optional):\n            if None calculates sum as in standard Shampoo, otherwise uses EMA of preconditioners. Defaults to None.\n        inner (Chainable | None, optional):\n            module applied after updating preconditioners and before applying preconditioning.\n            For example if beta\u22480.999 and `inner=tz.m.EMA(0.9)`, this becomes Adam with shampoo preconditioner (ignoring debiasing).\n            Defaults to None.\n\n    Examples:\n    Shampoo grafted to Adam\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GraftModules(\n            direction = tz.m.Shampoo(),\n            magnitude = tz.m.Adam(),\n        ),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with Shampoo preconditioner\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Shampoo(beta=0.999, inner=tz.m.EMA(0.9)),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.LR(1e-3)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        reg: float = 1e-12,\n        precond_freq: int = 10,\n        matrix_power: float | None = None,\n        merge_small: bool = True,\n        max_dim: int = 10_000,\n        precondition_1d: bool = True,\n        adagrad_eps: float = 1e-8,\n        matrix_power_method: MatrixPowerMethod = \"eigh_abs\",\n        beta: float | None = None,\n        beta_debias: bool = True,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"inner\"]\n\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        if setting[\"merge_small\"]:\n            tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n        if tensor.ndim &lt;= 1 and not setting[\"precondition_1d\"]:\n            state[\"accumulators\"] = []\n\n        else:\n            max_dim = setting[\"max_dim\"]\n            state['accumulators'] = [\n                torch.eye(s, dtype=tensor.dtype, device=tensor.device) if 1&lt;s&lt;max_dim else None for s in tensor.shape\n            ]\n            state['preconditioners'] = [\n                torch.eye(s, dtype=tensor.dtype, device=tensor.device) if 1&lt;s&lt;max_dim else None for s in tensor.shape\n            ]\n\n        # either scalar parameter, 1d with precondition_1d=False, or too big, then diagonal preconditioner is used.\n        if len([i is not None for i in state['accumulators']]) == 0:\n            state['diagonal_accumulator'] = torch.zeros_like(tensor)\n\n        state['step'] = 0\n        state[\"num_GTG\"] = 0\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n        if setting[\"merge_small\"]:\n            tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n            if \"inner\" not in self.children:\n                state[\"merged\"] = tensor\n\n        if 'diagonal_accumulator' in state:\n            update_diagonal_(tensor, state['diagonal_accumulator'], beta=setting[\"beta\"])\n        else:\n            update_shampoo_preconditioner_(\n                tensor,\n                accumulators_=state['accumulators'],\n                preconditioners_=state['preconditioners'],\n                step=state['step'],\n                precond_freq=setting[\"precond_freq\"],\n                matrix_power=setting[\"matrix_power\"],\n                beta=setting[\"beta\"],\n                reg=setting[\"reg\"],\n                matrix_power_method=setting[\"matrix_power_method\"],\n            )\n\n        if state[\"step\"] % setting[\"precond_freq\"] == 0:\n            state[\"num_GTG\"] += 1\n\n        state[\"step\"] += 1\n\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n\n        if setting[\"merge_small\"]:\n            if \"inner\" not in self.children:\n                tensor = state.pop(\"merged\")\n            else:\n                tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n        if 'diagonal_accumulator' in state:\n            dir = apply_diagonal_(tensor, state['diagonal_accumulator'], eps=setting[\"adagrad_eps\"])\n        else:\n            dir = apply_shampoo_preconditioner(tensor, preconditioners_=state['preconditioners'])\n\n        if setting[\"merge_small\"]:\n            dir = _unmerge_small_dims(dir, state['flat_sizes'], state['sort_idxs'])\n\n        if setting['beta_debias'] and setting[\"beta\"] is not None:\n            bias_correction = 1 - (setting[\"beta\"] ** state[\"num_GTG\"])\n            dir *= bias_correction ** 0.5\n\n        return dir\n</code></pre>"},{"location":"API/all/#torchzero.modules.ShorR","title":"ShorR","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Shor\u2019s r-algorithm.</p> Note <ul> <li> <p>A line search such as <code>[tz.m.StrongWolfe(a_init=\"quadratic\", fallback=True), tz.m.Mul(1.2)]</code> is required. Similarly to conjugate gradient, ShorR doesn't have an automatic step size scaling, so setting <code>a_init</code> in the line search is recommended.</p> </li> <li> <p>The line search should try to overstep by a little, therefore it can help to multiply direction given by a line search by some value slightly larger than 1 such as 1.2.</p> </li> </ul> References <p>Those are the original references, but neither seem to be available online:     - Shor, N. Z., Utilization of the Operation of Space Dilatation in the Minimization of Convex Functions, Kibernetika, No. 1, pp. 6-12, 1970.</p> <pre><code>- Skokov, V. A., Note on Minimization Methods Employing Space Stretching, Kibernetika, No. 4, pp. 115-117, 1974.\n</code></pre> <p>An overview is available in Burke, James V., Adrian S. Lewis, and Michael L. Overton. \"The Speed of Shor's R-algorithm.\" IMA Journal of numerical analysis 28.4 (2008): 711-720.</p> <p>Reference by Skokov, V. A. describes a more efficient formula which can be found here Ansari, Zafar A. Limited Memory Space Dilation and Reduction Algorithms. Diss. Virginia Tech, 1998.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ShorR(HessianUpdateStrategy):\n    \"\"\"Shor\u2019s r-algorithm.\n\n    Note:\n        - A line search such as ``[tz.m.StrongWolfe(a_init=\"quadratic\", fallback=True), tz.m.Mul(1.2)]`` is required. Similarly to conjugate gradient, ShorR doesn't have an automatic step size scaling, so setting ``a_init`` in the line search is recommended.\n\n        - The line search should try to overstep by a little, therefore it can help to multiply direction given by a line search by some value slightly larger than 1 such as 1.2.\n\n    References:\n        Those are the original references, but neither seem to be available online:\n            - Shor, N. Z., Utilization of the Operation of Space Dilatation in the Minimization of Convex Functions, Kibernetika, No. 1, pp. 6-12, 1970.\n\n            - Skokov, V. A., Note on Minimization Methods Employing Space Stretching, Kibernetika, No. 4, pp. 115-117, 1974.\n\n        An overview is available in [Burke, James V., Adrian S. Lewis, and Michael L. Overton. \"The Speed of Shor's R-algorithm.\" IMA Journal of numerical analysis 28.4 (2008): 711-720](https://sites.math.washington.edu/~burke/papers/reprints/60-speed-Shor-R.pdf).\n\n        Reference by Skokov, V. A. describes a more efficient formula which can be found here [Ansari, Zafar A. Limited Memory Space Dilation and Reduction Algorithms. Diss. Virginia Tech, 1998.](https://camo.ici.ro/books/thesis/th.pdf)\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha=0.5,\n        init_scale: float | Literal[\"auto\"] = 1,\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        # inverse: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(alpha=alpha)\n        super().__init__(\n            defaults=defaults,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return shor_r_(H=H, y=y, alpha=setting['alpha'])\n</code></pre>"},{"location":"API/all/#torchzero.modules.Sign","title":"Sign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>sign(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Sign(TensorTransform):\n    \"\"\"Returns ``sign(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_sign_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.SignConsistencyLRs","title":"SignConsistencyLRs","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs per-weight learning rates based on consecutive sign consistency.</p> <p>The learning rate for a weight is multiplied by <code>nplus</code> when two consecutive update signs are the same, otherwise it is multiplied by <code>nplus</code>. The learning rates are bounded to be in <code>(lb, ub)</code> range.</p>"},{"location":"API/all/#torchzero.modules.SignConsistencyLRs--examples","title":"Examples:","text":"<p>GD scaled by consecutive gradient sign consistency</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Mul(tz.m.SignConsistencyLRs()),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class SignConsistencyLRs(TensorTransform):\n    \"\"\"Outputs per-weight learning rates based on consecutive sign consistency.\n\n    The learning rate for a weight is multiplied by ``nplus`` when two consecutive update signs are the same, otherwise it is multiplied by ``nplus``. The learning rates are bounded to be in ``(lb, ub)`` range.\n\n    ### Examples:\n\n    GD scaled by consecutive gradient sign consistency\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Mul(tz.m.SignConsistencyLRs()),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n\"\"\"\n    def __init__(\n        self,\n        nplus: float = 1.2,\n        nminus: float = 0.5,\n        lb: float | None = 1e-6,\n        ub: float | None = 50,\n        alpha: float = 1,\n    ):\n        defaults = dict(nplus = nplus, nminus = nminus, alpha = alpha, lb = lb, ub = ub)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        target = TensorList(tensors)\n        nplus, nminus, lb, ub = unpack_dicts(settings, 'nplus', 'nminus', 'lb', 'ub', cls=NumberList)\n        prev, lrs = unpack_states(states, tensors, 'prev', 'lrs', cls=TensorList)\n\n        if step == 0:\n            lrs.set_(target.full_like([s['alpha'] for s in settings]))\n\n        target = sign_consistency_lrs_(\n            tensors = target,\n            prev_ = prev,\n            lrs_ = lrs,\n            nplus = nplus,\n            nminus = nminus,\n            lb = lb,\n            ub = ub,\n            step = step,\n        )\n        return target.clone()\n</code></pre>"},{"location":"API/all/#torchzero.modules.SignConsistencyMask","title":"SignConsistencyMask","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs a mask of sign consistency of current and previous inputs.</p> <p>The output is 0 for weights where input sign changed compared to previous input, 1 otherwise.</p>"},{"location":"API/all/#torchzero.modules.SignConsistencyMask--examples","title":"Examples:","text":"<p>GD that skips update for weights where gradient sign changed compared to previous gradient.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Mul(tz.m.SignConsistencyMask()),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class SignConsistencyMask(TensorTransform):\n    \"\"\"\n    Outputs a mask of sign consistency of current and previous inputs.\n\n    The output is 0 for weights where input sign changed compared to previous input, 1 otherwise.\n\n    ### Examples:\n\n    GD that skips update for weights where gradient sign changed compared to previous gradient.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Mul(tz.m.SignConsistencyMask()),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', cls=TensorList)\n        mask = prev.mul_(tensors).gt_(0)\n        prev.copy_(tensors)\n        return mask\n</code></pre>"},{"location":"API/all/#torchzero.modules.SixthOrder3P","title":"SixthOrder3P","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>Sixth-order iterative method.</p> <p>Abro, Hameer Akhtar, and Muhammad Mujtaba Shaikh. \"A new time-efficient and convergent nonlinear solver.\" Applied Mathematics and Computation 355 (2019): 516-536.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class SixthOrder3P(HigherOrderMethodBase):\n    \"\"\"Sixth-order iterative method.\n\n    Abro, Hameer Akhtar, and Muhammad Mujtaba Shaikh. \"A new time-efficient and convergent nonlinear solver.\" Applied Mathematics and Computation 355 (2019): 516-536.\n    \"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f(x): return evaluate(x, 1)[1]\n        def f_j(x): return evaluate(x, 2)[1:]\n        x_star = sixth_order_3p(x, f, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/all/#torchzero.modules.SixthOrder3PM2","title":"SixthOrder3PM2","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>Wang, Xiaofeng, and Yang Li. \"An efficient sixth-order Newton-type method for solving nonlinear systems.\" Algorithms 10.2 (2017): 45.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class SixthOrder3PM2(HigherOrderMethodBase):\n    \"\"\"Wang, Xiaofeng, and Yang Li. \"An efficient sixth-order Newton-type method for solving nonlinear systems.\" Algorithms 10.2 (2017): 45.\"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f_j(x): return evaluate(x, 2)[1:]\n        def f(x): return evaluate(x, 1)[1]\n        x_star = sixth_order_3pm2(x, f, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/all/#torchzero.modules.SixthOrder5P","title":"SixthOrder5P","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>Argyros, Ioannis K., et al. \"Extended convergence for two sixth order methods under the same weak conditions.\" Foundations 3.1 (2023): 127-139.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class SixthOrder5P(HigherOrderMethodBase):\n    \"\"\"Argyros, Ioannis K., et al. \"Extended convergence for two sixth order methods under the same weak conditions.\" Foundations 3.1 (2023): 127-139.\"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f_j(x): return evaluate(x, 2)[1:]\n        x_star = sixth_order_5p(x, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/all/#torchzero.modules.SophiaH","title":"SophiaH","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>SophiaH optimizer from https://arxiv.org/abs/2305.14342</p> <p>This is similar to Adam, but the second momentum is replaced by an exponential moving average of randomized hessian diagonal estimates, and the update is agressively clipped.</p> Notes <ul> <li> <p>In most cases SophiaH should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply SophiaH preconditioning to another module's output.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.96</code> )           \u2013            <p>first momentum. Defaults to 0.96.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum for hessian diagonal estimate. Defaults to 0.99.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>frequency of updating hessian diagonal estimate via a hessian-vector product. Defaults to 10.</p> </li> <li> <code>precond_scale</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>scale of the preconditioner. Defaults to 1.</p> </li> <li> <code>clip</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>clips update to (-clip, clip). Defaults to 1.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-12</code> )           \u2013            <p>clips hessian diagonal esimate to be no less than this value. Defaults to 1e-12.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to <code>\"autograd\"</code>. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of hessian-vector products with random vectors to evaluate each time when updating the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random vectors. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>)           \u2013            <p>preconditioning is applied to the output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.SophiaH--examples","title":"Examples:","text":"<p>Using SophiaH:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SophiaH(),\n    tz.m.LR(0.1)\n)\n</code></pre> <p>SophiaH preconditioner can be applied to any other module by passing it to the <code>inner</code> argument. Turn off SophiaH's first momentum to get just the preconditioning. Here is an example of applying SophiaH preconditioning to nesterov momentum (<code>tz.m.NAG</code>):</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SophiaH(beta1=0, inner=tz.m.NAG(0.96)),\n    tz.m.LR(0.1)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/sophia_h.py</code> <pre><code>class SophiaH(Transform):\n    \"\"\"SophiaH optimizer from https://arxiv.org/abs/2305.14342\n\n    This is similar to Adam, but the second momentum is replaced by an exponential moving average of randomized hessian diagonal estimates, and the update is agressively clipped.\n\n    Notes:\n        - In most cases SophiaH should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply SophiaH preconditioning to another module's output.\n\n        - This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        beta1 (float, optional): first momentum. Defaults to 0.96.\n        beta2 (float, optional): momentum for hessian diagonal estimate. Defaults to 0.99.\n        update_freq (int, optional):\n            frequency of updating hessian diagonal estimate via a hessian-vector product. Defaults to 10.\n        precond_scale (float, optional):\n            scale of the preconditioner. Defaults to 1.\n        clip (float, optional):\n            clips update to (-clip, clip). Defaults to 1.\n        eps (float, optional):\n            clips hessian diagonal esimate to be no less than this value. Defaults to 1e-12.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        n_samples (int, optional):\n            number of hessian-vector products with random vectors to evaluate each time when updating\n            the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n        seed (int | None, optional): seed for random vectors. Defaults to None.\n        inner (Chainable | None, optional): preconditioning is applied to the output of this module. Defaults to None.\n\n    ### Examples:\n\n    Using SophiaH:\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SophiaH(),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    SophiaH preconditioner can be applied to any other module by passing it to the ``inner`` argument.\n    Turn off SophiaH's first momentum to get just the preconditioning. Here is an example of applying\n    SophiaH preconditioning to nesterov momentum (``tz.m.NAG``):\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SophiaH(beta1=0, inner=tz.m.NAG(0.96)),\n        tz.m.LR(0.1)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.96,\n        beta2: float = 0.99,\n        update_freq: int = 10,\n        precond_scale: float = 1,\n        clip: float = 1,\n        eps: float = 1e-12,\n        hvp_method: HVPMethod = 'autograd',\n        distribution: Distributions = 'gaussian',\n        h: float = 1e-3,\n        n_samples = 1,\n        zHz: bool = True,\n        debias: bool = False,\n        seed: int | None = None,\n\n        exp_avg_tfm: Chainable | None = None,\n        D_exp_avg_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['exp_avg_tfm'], defaults[\"D_exp_avg_tfm\"]\n        super().__init__(defaults)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.set_child('D_exp_avg', D_exp_avg_tfm)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2 = unpack_dicts(settings, 'beta1', 'beta2', cls=NumberList)\n\n        exp_avg, D_exp_avg = unpack_states(states, params, 'exp_avg', 'D_exp_avg', cls=TensorList)\n\n        step = self.increment_counter(\"step\", start=0) # 0 on 1st update\n\n        # ---------------------------- hutchinson hessian ---------------------------- #\n        fs = settings[0]\n        update_freq = fs['update_freq']\n\n        if step % update_freq == 0:\n            self.increment_counter(\"num_Ds\", start=1)\n\n            D, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = fs['n_samples'],\n                distribution = fs['distribution'],\n                hvp_method = fs['hvp_method'],\n                h = fs['h'],\n                zHz = fs[\"zHz\"],\n                generator = self.get_generator(params[0].device, fs[\"seed\"]),\n            )\n\n            D_exp_avg.lerp_(D, weight=1-beta2)\n\n        # --------------------------------- momentum --------------------------------- #\n        tensors = objective.get_updates() # do this after hutchinson to not disturb autograd\n        exp_avg.lerp_(tensors, 1-beta1)\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2, eps, precond_scale, clip = unpack_dicts(\n            settings, 'beta1', 'beta2', 'eps', 'precond_scale', 'clip', cls=NumberList)\n\n        exp_avg, D_exp_avg = unpack_states(states, params, 'exp_avg', 'D_exp_avg')\n\n        # ---------------------------------- debias ---------------------------------- #\n        if settings[0][\"debias\"]:\n            bias_correction1 = 1.0 - (beta1 ** (self.global_state[\"step\"] + 1))\n            bias_correction2 = 1.0 - (beta2 ** self.global_state[\"num_Ds\"])\n\n            exp_avg = exp_avg / bias_correction1\n            D_exp_avg = D_exp_avg / bias_correction2\n\n        # -------------------------------- transforms -------------------------------- #\n        exp_avg = TensorList(self.inner_step_tensors(\n            \"exp_avg\", tensors=exp_avg, clone=True, objective=objective, must_exist=False))\n\n        D_exp_avg = TensorList(self.inner_step_tensors(\n            \"D_exp_avg\", tensors=D_exp_avg, clone=True, objective=objective, must_exist=False))\n\n        # ------------------------------ compute update ------------------------------ #\n        denom = D_exp_avg.lazy_mul(precond_scale).clip(min=eps)\n        objective.updates = (exp_avg / denom).clip_(-clip, clip)\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Split","title":"Split","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Apply <code>true</code> modules to all parameters filtered by <code>filter</code>, apply <code>false</code> modules to all other parameters.</p> <p>Parameters:</p> <ul> <li> <code>filter</code>               (<code>Filter, bool]</code>)           \u2013            <p>a filter that selects tensors to be optimized by <code>true</code>. - tensor or iterable of tensors (e.g. <code>encoder.parameters()</code>). - function that takes in tensor and outputs a bool (e.g. <code>lambda x: x.ndim &gt;= 2</code>). - a sequence of above (acts as \"or\", so returns true if any of them is true).</p> </li> <li> <code>true</code>               (<code>Chainable | None</code>)           \u2013            <p>modules that are applied to tensors where <code>filter</code> is <code>True</code>.</p> </li> <li> <code>false</code>               (<code>Chainable | None</code>)           \u2013            <p>modules that are applied to tensors where <code>filter</code> is <code>False</code>.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Split--examples","title":"Examples:","text":"<p>Muon with Adam fallback using same hyperparams as https://github.com/KellerJordan/Muon</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NAG(0.95),\n    tz.m.Split(\n        lambda p: p.ndim &gt;= 2,\n        true = tz.m.Orthogonalize(),\n        false = [tz.m.Adam(0.9, 0.95), tz.m.Mul(1/66)],\n    ),\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/misc/split.py</code> <pre><code>class Split(Module):\n    \"\"\"Apply ``true`` modules to all parameters filtered by ``filter``, apply ``false`` modules to all other parameters.\n\n    Args:\n        filter (Filter, bool]):\n            a filter that selects tensors to be optimized by ``true``.\n            - tensor or iterable of tensors (e.g. ``encoder.parameters()``).\n            - function that takes in tensor and outputs a bool (e.g. ``lambda x: x.ndim &gt;= 2``).\n            - a sequence of above (acts as \"or\", so returns true if any of them is true).\n\n        true (Chainable | None): modules that are applied to tensors where ``filter`` is ``True``.\n        false (Chainable | None): modules that are applied to tensors where ``filter`` is ``False``.\n\n    ### Examples:\n\n    Muon with Adam fallback using same hyperparams as https://github.com/KellerJordan/Muon\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NAG(0.95),\n        tz.m.Split(\n            lambda p: p.ndim &gt;= 2,\n            true = tz.m.Orthogonalize(),\n            false = [tz.m.Adam(0.9, 0.95), tz.m.Mul(1/66)],\n        ),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(self, filter: Filter, true: Chainable | None, false: Chainable | None):\n        defaults = dict(filter=filter)\n        super().__init__(defaults)\n\n        if true is not None: self.set_child('true', true)\n        if false is not None: self.set_child('false', false)\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    def step(self, objective):\n\n        params = objective.params\n        filter = _make_filter(self.settings[params[0]]['filter'])\n\n        true_idxs = []\n        false_idxs = []\n        for i,p in enumerate(params):\n            if filter(p): true_idxs.append(i)\n            else: false_idxs.append(i)\n\n        if 'true' in self.children and len(true_idxs) &gt; 0:\n            true = self.children['true']\n            objective = _split(true, idxs=true_idxs, params=params, objective=objective)\n\n        if 'false' in self.children and len(false_idxs) &gt; 0:\n            false = self.children['false']\n            objective = _split(false, idxs=false_idxs, params=params, objective=objective)\n\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Sqrt","title":"Sqrt","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>sqrt(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Sqrt(TensorTransform):\n    \"\"\"Returns ``sqrt(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_sqrt_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.SqrtEMASquared","title":"SqrtEMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an exponential moving average of squared updates, outputs optionally debiased square root.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>debiased</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to multiply the output by a debiasing term from the Adam method. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>SQRT_EMA_SQ_FN</code>             \u2013              <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code> and calculates it's square root,</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class SqrtEMASquared(TensorTransform):\n    \"\"\"Maintains an exponential moving average of squared updates, outputs optionally debiased square root.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        debiased (bool, optional): whether to multiply the output by a debiasing term from the Adam method. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    SQRT_EMA_SQ_FN: staticmethod = staticmethod(sqrt_ema_sq_)\n    def __init__(self, beta:float=0.999, amsgrad=False, debiased: bool = False, pow:float=2,):\n        defaults = dict(beta=beta,pow=pow,amsgrad=amsgrad,debiased=debiased)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        amsgrad, pow, debiased = itemgetter('amsgrad', 'pow', 'debiased')(settings[0])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return self.SQRT_EMA_SQ_FN(\n            TensorList(tensors),\n            exp_avg_sq_=exp_avg_sq,\n            beta=beta,\n            max_exp_avg_sq_=max_exp_avg_sq,\n            debiased=debiased,\n            step=step,\n            pow=pow,\n        )\n</code></pre>"},{"location":"API/all/#torchzero.modules.SqrtEMASquared.SQRT_EMA_SQ_FN","title":"SQRT_EMA_SQ_FN","text":"<pre><code>SQRT_EMA_SQ_FN(tensors: TensorList, exp_avg_sq_: TensorList, beta: float | NumberList, max_exp_avg_sq_: TensorList | None, debiased: bool, step: int, pow: float = 2, ema_sq_fn: Callable = ema_sq_)\n</code></pre> <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code> and calculates it's square root, with optional AMSGrad and debiasing.</p> <p>Returns new tensors.</p> Source code in <code>torchzero/modules/opt_utils.py</code> <pre><code>def sqrt_ema_sq_(\n    tensors: TensorList,\n    exp_avg_sq_: TensorList,\n    beta: float | NumberList,\n    max_exp_avg_sq_: TensorList | None,\n    debiased: bool,\n    step: int,\n    pow: float = 2,\n    ema_sq_fn: Callable = ema_sq_,\n):\n    \"\"\"\n    Updates `exp_avg_sq_` with EMA of squared `tensors` and calculates it's square root,\n    with optional AMSGrad and debiasing.\n\n    Returns new tensors.\n    \"\"\"\n    exp_avg_sq_=ema_sq_fn(\n        tensors=tensors,\n        exp_avg_sq_=exp_avg_sq_,\n        beta=beta,\n        max_exp_avg_sq_=max_exp_avg_sq_,\n        pow=pow,\n    )\n\n    sqrt_exp_avg_sq = root(exp_avg_sq_, pow, inplace=False)\n\n    if debiased: sqrt_exp_avg_sq = debias_second_momentum(sqrt_exp_avg_sq, step=step, beta=beta, pow=pow, inplace=True)\n    return sqrt_exp_avg_sq\n</code></pre>"},{"location":"API/all/#torchzero.modules.SqrtHomotopy","title":"SqrtHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class SqrtHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return (loss+1e-12).sqrt()\n</code></pre>"},{"location":"API/all/#torchzero.modules.SquareHomotopy","title":"SquareHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class SquareHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return loss.square().copysign(loss)\n</code></pre>"},{"location":"API/all/#torchzero.modules.StepSize","title":"StepSize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>this is exactly the same as LR, except the <code>lr</code> parameter can be renamed to any other name to avoid clashes</p> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class StepSize(TensorTransform):\n    \"\"\"this is exactly the same as LR, except the `lr` parameter can be renamed to any other name to avoid clashes\"\"\"\n    def __init__(self, step_size: float, key = 'step_size'):\n        defaults={\"key\": key, key: step_size}\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return lazy_lr(TensorList(tensors), lr=[s[s['key']] for s in settings], inplace=True)\n</code></pre>"},{"location":"API/all/#torchzero.modules.StrongWolfe","title":"StrongWolfe","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Interpolation line search satisfying Strong Wolfe condition.</p> <p>Parameters:</p> <ul> <li> <code>c1</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>sufficient descent condition. Defaults to 1e-4.</p> </li> <li> <code>c2</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>strong curvature condition. For CG set to 0.1. Defaults to 0.9.</p> </li> <li> <code>a_init</code>               (<code>str</code>, default:                   <code>'fixed'</code> )           \u2013            <p>strategy for initializing the initial step size guess. - \"fixed\" - uses a fixed value specified in <code>init_value</code> argument. - \"first-order\" - assumes first-order change in the function at iterate will be the same as that obtained at the previous step. - \"quadratic\" - interpolates quadratic to f(x_{-1}) and f_x. - \"quadratic-clip\" - same as quad, but uses min(1, 1.01*alpha) as described in Numerical Optimization. - \"previous\" - uses final step size found on previous iteration.</p> <p>For 2nd order methods it is usually best to leave at \"fixed\". For methods that do not produce well scaled search directions, e.g. conjugate gradient, \"first-order\" or \"quadratic-clip\" are recommended. Defaults to 'init'.</p> </li> <li> <code>a_max</code>               (<code>float</code>, default:                   <code>1000000000000.0</code> )           \u2013            <p>upper bound for the proposed step sizes. Defaults to 1e12.</p> </li> <li> <code>init_value</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>initial step size. Used when <code>a_init</code>=\"fixed\", and with other strategies as fallback value. Defaults to 1.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>25</code> )           \u2013            <p>maximum number of line search iterations. Defaults to 25.</p> </li> <li> <code>maxzoom</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of zoom iterations. Defaults to 10.</p> </li> <li> <code>maxeval</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of function evaluations. Defaults to None.</p> </li> <li> <code>tol_change</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>tolerance, terminates on small brackets. Defaults to 1e-9.</p> </li> <li> <code>interpolation</code>               (<code>str</code>, default:                   <code>'cubic'</code> )           \u2013            <p>What type of interpolation to use. - \"bisection\" - uses the middle point. This is robust, especially if the objective function is non-smooth, however it may need more function evaluations. - \"quadratic\" - minimizes a quadratic model, generally outperformed by \"cubic\". - \"cubic\" - minimizes a cubic model - this is the most widely used interpolation strategy. - \"polynomial\" - fits a a polynomial to all points obtained during line search. - \"polynomial2\" - alternative polynomial fit, where if a point is outside of bounds, a lower degree polynomial is tried. This may have faster convergence than \"cubic\" and \"polynomial\".</p> <p>Defaults to 'cubic'.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, the initial step size will be halved when line search failed to find a good direction. When a good direction is found, initial step size is reset to the original value. Defaults to True.</p> </li> <li> <code>fallback</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, when no point satisfied strong wolfe criteria, returns a point with value lower than initial value that doesn't satisfy the criteria. Defaults to False.</p> </li> <li> <code>plus_minus</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, enables the plus-minus variant, where if curvature is negative, line search is performed in the opposite direction. Defaults to False.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.StrongWolfe--examples","title":"Examples:","text":"<p>Conjugate gradient method with strong wolfe line search. Nocedal, Wright recommend setting c2 to 0.1 for CG. Since CG doesn't produce well scaled directions, initial alpha can be determined from function values by <code>a_init=\"first-order\"</code>.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.PolakRibiere(),\n    tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")\n)\n</code></pre> <p>LBFGS strong wolfe line search: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(),\n    tz.m.StrongWolfe()\n)\n</code></pre></p> Source code in <code>torchzero/modules/line_search/strong_wolfe.py</code> <pre><code>class StrongWolfe(LineSearchBase):\n    \"\"\"Interpolation line search satisfying Strong Wolfe condition.\n\n    Args:\n        c1 (float, optional): sufficient descent condition. Defaults to 1e-4.\n        c2 (float, optional): strong curvature condition. For CG set to 0.1. Defaults to 0.9.\n        a_init (str, optional):\n            strategy for initializing the initial step size guess.\n            - \"fixed\" - uses a fixed value specified in `init_value` argument.\n            - \"first-order\" - assumes first-order change in the function at iterate will be the same as that obtained at the previous step.\n            - \"quadratic\" - interpolates quadratic to f(x_{-1}) and f_x.\n            - \"quadratic-clip\" - same as quad, but uses min(1, 1.01*alpha) as described in Numerical Optimization.\n            - \"previous\" - uses final step size found on previous iteration.\n\n            For 2nd order methods it is usually best to leave at \"fixed\".\n            For methods that do not produce well scaled search directions, e.g. conjugate gradient,\n            \"first-order\" or \"quadratic-clip\" are recommended. Defaults to 'init'.\n        a_max (float, optional): upper bound for the proposed step sizes. Defaults to 1e12.\n        init_value (float, optional):\n            initial step size. Used when ``a_init``=\"fixed\", and with other strategies as fallback value. Defaults to 1.\n        maxiter (int, optional): maximum number of line search iterations. Defaults to 25.\n        maxzoom (int, optional): maximum number of zoom iterations. Defaults to 10.\n        maxeval (int | None, optional): maximum number of function evaluations. Defaults to None.\n        tol_change (float, optional): tolerance, terminates on small brackets. Defaults to 1e-9.\n        interpolation (str, optional):\n            What type of interpolation to use.\n            - \"bisection\" - uses the middle point. This is robust, especially if the objective function is non-smooth, however it may need more function evaluations.\n            - \"quadratic\" - minimizes a quadratic model, generally outperformed by \"cubic\".\n            - \"cubic\" - minimizes a cubic model - this is the most widely used interpolation strategy.\n            - \"polynomial\" - fits a a polynomial to all points obtained during line search.\n            - \"polynomial2\" - alternative polynomial fit, where if a point is outside of bounds, a lower degree polynomial is tried.\n            This may have faster convergence than \"cubic\" and \"polynomial\".\n\n            Defaults to 'cubic'.\n        adaptive (bool, optional):\n            if True, the initial step size will be halved when line search failed to find a good direction.\n            When a good direction is found, initial step size is reset to the original value. Defaults to True.\n        fallback (bool, optional):\n            if True, when no point satisfied strong wolfe criteria,\n            returns a point with value lower than initial value that doesn't satisfy the criteria. Defaults to False.\n        plus_minus (bool, optional):\n            if True, enables the plus-minus variant, where if curvature is negative, line search is performed\n            in the opposite direction. Defaults to False.\n\n\n    ## Examples:\n\n    Conjugate gradient method with strong wolfe line search. Nocedal, Wright recommend setting c2 to 0.1 for CG. Since CG doesn't produce well scaled directions, initial alpha can be determined from function values by ``a_init=\"first-order\"``.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.PolakRibiere(),\n        tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")\n    )\n    ```\n\n    LBFGS strong wolfe line search:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(),\n        tz.m.StrongWolfe()\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        c1: float = 1e-4,\n        c2: float = 0.9,\n        a_init: Literal['first-order', 'quadratic', 'quadratic-clip', 'previous', 'fixed'] = 'fixed',\n        a_max: float = 1e12,\n        init_value: float = 1,\n        maxiter: int = 25,\n        maxzoom: int = 10,\n        maxeval: int | None = None,\n        tol_change: float = 1e-9,\n        interpolation: Literal[\"quadratic\", \"cubic\", \"bisection\", \"polynomial\", 'polynomial2'] = 'cubic',\n        adaptive = True,\n        fallback:bool = False,\n        plus_minus = False,\n    ):\n        defaults=dict(init_value=init_value,init=a_init,a_max=a_max,c1=c1,c2=c2,maxiter=maxiter,maxzoom=maxzoom, fallback=fallback,\n                      maxeval=maxeval, adaptive=adaptive, interpolation=interpolation, plus_minus=plus_minus, tol_change=tol_change)\n        super().__init__(defaults=defaults)\n\n        self.global_state['initial_scale'] = 1.0\n\n    @torch.no_grad\n    def search(self, update, var):\n        self._g_prev = self._f_prev = None\n        objective = self.make_objective_with_derivative(var=var)\n\n        init_value, init, c1, c2, a_max, maxiter, maxzoom, maxeval, interpolation, adaptive, plus_minus, fallback, tol_change = itemgetter(\n            'init_value', 'init', 'c1', 'c2', 'a_max', 'maxiter', 'maxzoom',\n            'maxeval', 'interpolation', 'adaptive', 'plus_minus', 'fallback', 'tol_change')(self.defaults)\n\n        dir = as_tensorlist(var.get_updates())\n        grad_list = var.get_grads()\n\n        g_0 = -sum(t.sum() for t in torch._foreach_mul(grad_list, dir))\n        f_0 = var.get_loss(False)\n        dir_norm = dir.global_vector_norm()\n\n        inverted = False\n        if plus_minus and g_0 &gt; 0:\n            original_objective = objective\n            def inverted_objective(a):\n                l, g_a = original_objective(-a)\n                return l, -g_a\n            objective = inverted_objective\n            inverted = True\n\n        # --------------------- determine initial step size guess -------------------- #\n        init = init.lower().strip()\n\n        a_init = init_value\n        if init == 'fixed':\n            pass # use init_value\n\n        elif init == 'previous':\n            if 'a_prev' in self.global_state:\n                a_init = self.global_state['a_prev']\n\n        elif init == 'first-order':\n            if 'g_prev' in self.global_state and g_0 &lt; -torch.finfo(dir[0].dtype).tiny * 2:\n                a_prev = self.global_state['a_prev']\n                g_prev = self.global_state['g_prev']\n                if g_prev &lt; 0:\n                    a_init = a_prev * g_prev / g_0\n\n        elif init in ('quadratic', 'quadratic-clip'):\n            if 'f_prev' in self.global_state and g_0 &lt; -torch.finfo(dir[0].dtype).tiny * 2:\n                f_prev = self.global_state['f_prev']\n                if f_0 &lt; f_prev:\n                    a_init = 2 * (f_0 - f_prev) / g_0\n                    if init == 'quadratic-clip': a_init = min(1, 1.01*a_init)\n        else:\n            raise ValueError(init)\n\n        if adaptive:\n            a_init *= self.global_state.get('initial_scale', 1)\n\n        strong_wolfe = _StrongWolfe(\n            f=objective,\n            f_0=f_0,\n            g_0=g_0,\n            d_norm=dir_norm,\n            a_init=a_init,\n            a_max=a_max,\n            c1=c1,\n            c2=c2,\n            maxiter=maxiter,\n            maxzoom=maxzoom,\n            maxeval=maxeval,\n            tol_change=tol_change,\n            interpolation=interpolation,\n        )\n\n        a, f_a, g_a = strong_wolfe.search()\n        if inverted and a is not None: a = -a\n        if f_a is not None and (f_a &gt; f_0 or not math.isfinite(f_a)): a = None\n\n        if fallback:\n            if a is None or a==0 or not math.isfinite(a):\n                lowest = min(strong_wolfe.history.items(), key=lambda x: x[1][0])\n                if lowest[1][0] &lt; f_0:\n                    a = lowest[0]\n                    f_a, g_a = lowest[1]\n                    if inverted: a = -a\n\n        if a is not None and a != 0 and math.isfinite(a):\n            self.global_state['initial_scale'] = 1\n            self.global_state['a_prev'] = a\n            self.global_state['f_prev'] = f_0\n            self.global_state['g_prev'] = g_0\n            return a\n\n        # fail\n        if adaptive:\n            self.global_state['initial_scale'] = self.global_state.get('initial_scale', 1) * 0.5\n            finfo = torch.finfo(dir[0].dtype)\n            if self.global_state['initial_scale'] &lt; finfo.tiny * 2:\n                self.global_state['initial_scale'] = init_value * 2\n\n        return 0\n</code></pre>"},{"location":"API/all/#torchzero.modules.Sub","title":"Sub","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Subtract <code>other</code> from tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates :code:<code>tensors - other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Sub(BinaryOperationBase):\n    \"\"\"Subtract ``other`` from tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates :code:`tensors - other(tensors)`\n    \"\"\"\n    def __init__(self, other: Chainable | float, alpha: float = 1):\n        defaults = dict(alpha=alpha)\n        super().__init__(defaults, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        if isinstance(other, (int,float)): torch._foreach_sub_(update, other * self.defaults['alpha'])\n        else: torch._foreach_sub_(update, other, alpha=self.defaults['alpha'])\n        return update\n</code></pre>"},{"location":"API/all/#torchzero.modules.SubModules","title":"SubModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input - other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class SubModules(MultiOperationBase):\n    \"\"\"Calculates ``input - other``. ``input`` and ``other`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable | float, other: Chainable | float, alpha: float = 1):\n        defaults = dict(alpha=alpha)\n        super().__init__(defaults, input=input, other=other)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: float | list[torch.Tensor], other: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        alpha = self.defaults['alpha']\n\n        if isinstance(input, (int,float)):\n            assert isinstance(other, list)\n            return input - TensorList(other).mul_(alpha)\n\n        if isinstance(other, (int, float)): torch._foreach_sub_(input, other * alpha)\n        else: torch._foreach_sub_(input, other, alpha=alpha)\n        return input\n</code></pre>"},{"location":"API/all/#torchzero.modules.SubspaceNewton","title":"SubspaceNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Subspace Newton. Performs a Newton step in a subspace (random or spanned by past gradients).</p> <p>Parameters:</p> <ul> <li> <code>sketch_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>size of the random sketch. This many hessian-vector products will need to be evaluated each step.</p> </li> <li> <code>sketch_type</code>               (<code>str</code>, default:                   <code>'common_directions'</code> )           \u2013            <ul> <li>\"common_directions\" - uses history steepest descent directions as the basis[2]. It is orthonormalized on-line using Gram-Schmidt (default).</li> <li>\"orthonormal\" - random orthonormal basis. Orthonormality is necessary to use linear operator based modules such as trust region, but it can be slower to compute.</li> <li>\"rows\" - samples random rows.</li> <li>\"topk\" - samples top-rank rows with largest gradient magnitude.</li> <li>\"rademacher\" - approximately orthonormal (if dimension is large) scaled random rademacher basis.</li> <li>\"mixed\" - random orthonormal basis but with four directions set to gradient, slow and fast gradient EMAs, and previous update direction.</li> </ul> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>hessian damping (scale of identity matrix added to hessian). Defaults to 0.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>How to compute hessian-matrix product: - \"batched_autograd\" - uses batched autograd - \"autograd\" - uses unbatched autograd - \"forward\" - uses finite difference with forward formula, performing 1 backward pass per Hvp. - \"central\" - uses finite difference with a more accurate central formula, performing 2 backward passes per Hvp.</p> <p>. Defaults to \"batched_autograd\".</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>finite difference step size. Defaults to 1e-2.</p> </li> <li> <code>use_lstsq</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use least squares to solve <code>Hx=g</code>. Defaults to False.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>H_tfm</code>               (<code>Callable | None</code>)           \u2013            <p>optional hessian transforms, takes in two arguments - <code>(hessian, gradient)</code>.</p> <p>must return either a tuple: <code>(hessian, is_inverted)</code> with transformed hessian and a boolean value which must be True if transform inverted the hessian and False otherwise.</p> <p>Or it returns a single tensor which is used as the update.</p> <p>Defaults to None.</p> </li> <li> <code>eigval_fn</code>               (<code>Callable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional eigenvalues transform, for example <code>torch.abs</code> or <code>lambda L: torch.clip(L, min=1e-8)</code>. If this is specified, eigendecomposition will be used to invert the hessian.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random generator. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditions output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.SubspaceNewton--examples","title":"Examples","text":"<p>RSN with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.RSN(),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>RSN with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.RSN()),\n)\n</code></pre></p> References <ol> <li>Gower, Robert, et al. \"RSN: randomized subspace Newton.\" Advances in Neural Information Processing Systems 32 (2019).</li> <li>Wang, Po-Wei, Ching-pei Lee, and Chih-Jen Lin. \"The common-directions method for regularized empirical risk minimization.\" Journal of Machine Learning Research 20.58 (2019): 1-49.</li> </ol> Source code in <code>torchzero/modules/second_order/rsn.py</code> <pre><code>class SubspaceNewton(Transform):\n    \"\"\"Subspace Newton. Performs a Newton step in a subspace (random or spanned by past gradients).\n\n    Args:\n        sketch_size (int):\n            size of the random sketch. This many hessian-vector products will need to be evaluated each step.\n        sketch_type (str, optional):\n            - \"common_directions\" - uses history steepest descent directions as the basis[2]. It is orthonormalized on-line using Gram-Schmidt (default).\n            - \"orthonormal\" - random orthonormal basis. Orthonormality is necessary to use linear operator based modules such as trust region, but it can be slower to compute.\n            - \"rows\" - samples random rows.\n            - \"topk\" - samples top-rank rows with largest gradient magnitude.\n            - \"rademacher\" - approximately orthonormal (if dimension is large) scaled random rademacher basis.\n            - \"mixed\" - random orthonormal basis but with four directions set to gradient, slow and fast gradient EMAs, and previous update direction.\n        damping (float, optional): hessian damping (scale of identity matrix added to hessian). Defaults to 0.\n        hvp_method (str, optional):\n            How to compute hessian-matrix product:\n            - \"batched_autograd\" - uses batched autograd\n            - \"autograd\" - uses unbatched autograd\n            - \"forward\" - uses finite difference with forward formula, performing 1 backward pass per Hvp.\n            - \"central\" - uses finite difference with a more accurate central formula, performing 2 backward passes per Hvp.\n\n            . Defaults to \"batched_autograd\".\n        h (float, optional): finite difference step size. Defaults to 1e-2.\n        use_lstsq (bool, optional): whether to use least squares to solve ``Hx=g``. Defaults to False.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        H_tfm (Callable | None, optional):\n            optional hessian transforms, takes in two arguments - `(hessian, gradient)`.\n\n            must return either a tuple: `(hessian, is_inverted)` with transformed hessian and a boolean value\n            which must be True if transform inverted the hessian and False otherwise.\n\n            Or it returns a single tensor which is used as the update.\n\n            Defaults to None.\n        eigval_fn (Callable | None, optional):\n            optional eigenvalues transform, for example ``torch.abs`` or ``lambda L: torch.clip(L, min=1e-8)``.\n            If this is specified, eigendecomposition will be used to invert the hessian.\n        seed (int | None, optional): seed for random generator. Defaults to None.\n        inner (Chainable | None, optional): preconditions output of this module. Defaults to None.\n\n    ### Examples\n\n    RSN with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.RSN(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    RSN with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.RSN()),\n    )\n    ```\n\n\n    References:\n        1. [Gower, Robert, et al. \"RSN: randomized subspace Newton.\" Advances in Neural Information Processing Systems 32 (2019).](https://arxiv.org/abs/1905.10874)\n        2. Wang, Po-Wei, Ching-pei Lee, and Chih-Jen Lin. \"The common-directions method for regularized empirical risk minimization.\" Journal of Machine Learning Research 20.58 (2019): 1-49.\n    \"\"\"\n\n    def __init__(\n        self,\n        sketch_size: int = 100,\n        sketch_type: Literal[\"orthonormal\", \"common_directions\", \"mixed\", \"rademacher\", \"rows\", \"topk\"] = \"common_directions\",\n        damping:float=0,\n        eigval_fn: Callable[[torch.Tensor], torch.Tensor] | None = None,\n        eigv_tol: float | None = None,\n        truncate: int | None = None,\n        update_freq: int = 1,\n        precompute_inverse: bool = False,\n        use_lstsq: bool = False,\n        hvp_method: HVPMethod = \"batched_autograd\",\n        h: float = 1e-2,\n        seed: int | None = None,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"update_freq\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        params = objective.params\n        generator = self.get_generator(params[0].device, fs[\"seed\"])\n\n        ndim = sum(p.numel() for p in params)\n\n        device=params[0].device\n        dtype=params[0].dtype\n\n        # sample sketch matrix S: (ndim, sketch_size)\n        sketch_size = min(fs[\"sketch_size\"], ndim)\n        sketch_type = fs[\"sketch_type\"]\n        hvp_method = fs[\"hvp_method\"]\n\n        if sketch_type == \"rademacher\":\n            S = _rademacher_sketch(ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == 'orthonormal':\n            S = _orthonormal_sketch(ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == \"rows\":\n            S = _row_sketch(ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == \"topk\":\n            g_list = objective.get_grads(create_graph=hvp_method in (\"batched_autograd\", \"autograd\"))\n            g = torch.cat([t.ravel() for t in g_list])\n            S = _topk_rows(g, ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == 'common_directions':\n            # Wang, Po-Wei, Ching-pei Lee, and Chih-Jen Lin. \"The common-directions method for regularized empirical risk minimization.\" Journal of Machine Learning Research 20.58 (2019): 1-49.\n            g_list = objective.get_grads(create_graph=hvp_method in (\"batched_autograd\", \"autograd\"))\n            g = torch.cat([t.ravel() for t in g_list])\n\n            # initialize directions deque\n            if \"directions\" not in self.global_state:\n\n                g_norm = torch.linalg.vector_norm(g) # pylint:disable=not-callable\n                if g_norm &lt; torch.finfo(g.dtype).tiny * 2:\n                    g = torch.randn_like(g)\n                    g_norm = torch.linalg.vector_norm(g) # pylint:disable=not-callable\n\n                self.global_state[\"directions\"] = deque([g / g_norm], maxlen=sketch_size)\n                S = self.global_state[\"directions\"][0].unsqueeze(1)\n\n            # add new steepest descent direction orthonormal to existing columns\n            else:\n                S = torch.stack(tuple(self.global_state[\"directions\"]), dim=1)\n                p = g - S @ (S.T @ g)\n                p_norm = torch.linalg.vector_norm(p) # pylint:disable=not-callable\n                if p_norm &gt; torch.finfo(p.dtype).tiny * 2:\n                    p = p / p_norm\n                    self.global_state[\"directions\"].append(p)\n                    S = torch.cat([S, p.unsqueeze(1)], dim=1)\n\n        elif sketch_type == \"mixed\":\n            g_list = objective.get_grads(create_graph=hvp_method in (\"batched_autograd\", \"autograd\"))\n            g = torch.cat([t.ravel() for t in g_list])\n\n            # initialize state\n            if \"slow_ema\" not in self.global_state:\n                self.global_state[\"slow_ema\"] = torch.randn_like(g) * 1e-2\n                self.global_state[\"fast_ema\"] = torch.randn_like(g) * 1e-2\n                self.global_state[\"p_prev\"] = torch.randn_like(g)\n\n            # previous update direction\n            p_cur = torch.cat([t.ravel() for t in params])\n            prev_dir = p_cur - self.global_state[\"p_prev\"]\n            self.global_state[\"p_prev\"] = p_cur\n\n            # EMAs\n            slow_ema = self.global_state[\"slow_ema\"]\n            fast_ema = self.global_state[\"fast_ema\"]\n            slow_ema.lerp_(g, 0.001)\n            fast_ema.lerp_(g, 0.1)\n\n            # form and orthogonalize sketching matrix\n            S = torch.stack([g, slow_ema, fast_ema, prev_dir], dim=1)\n            if sketch_size &gt; 4:\n                S_random = torch.randn(ndim, sketch_size - 3, device=device, dtype=dtype, generator=generator) / math.sqrt(ndim)\n                S = torch.cat([S, S_random], dim=1)\n\n            S = _qr_orthonormalize(S)\n\n        else:\n            raise ValueError(f'Unknown sketch_type {sketch_type}')\n\n        # print(f'{S.shape = }')\n        # I = torch.eye(S.size(1), device=S.device, dtype=S.dtype)\n        # print(f'{torch.nn.functional.mse_loss(S.T @ S, I) = }')\n\n        # form sketched hessian\n        HS, _ = objective.hessian_matrix_product(S, rgrad=None, at_x0=True,\n                                                 hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n        H_sketched = S.T @ HS\n\n        # update state\n        _newton_update_state_(\n            state = self.global_state,\n            H = H_sketched,\n            damping = fs[\"damping\"],\n            eigval_fn = fs[\"eigval_fn\"],\n            eigv_tol = fs[\"eigv_tol\"],\n            truncate = fs[\"truncate\"],\n            precompute_inverse = fs[\"precompute_inverse\"],\n            use_lstsq = fs[\"use_lstsq\"]\n        )\n\n        self.global_state[\"S\"] = S\n\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n        fs = settings[0]\n\n        S = self.global_state[\"S\"]\n        b = torch.cat([t.ravel() for t in updates])\n        b_proj = S.T @ b\n\n        d_proj = _newton_solve(b=b_proj, state=self.global_state, use_lstsq=fs[\"use_lstsq\"])\n\n        d = S @ d_proj\n        vec_to_tensors_(d, updates)\n        return objective\n\n    def get_H(self, objective=...):\n        if \"H\" in self.global_state:\n            H_sketched = self.global_state[\"H\"]\n\n        else:\n            L = self.global_state[\"L\"]\n            Q = self.global_state[\"Q\"]\n            H_sketched = Q @ L.diag_embed() @ Q.mH\n\n        S: torch.Tensor = self.global_state[\"S\"]\n        return Sketched(S, H_sketched)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Sum","title":"Sum","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs sum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class Sum(ReduceOperationBase):\n    \"\"\"Outputs sum of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = False\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        sum = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_add_(sum, v)\n\n        if self.USE_MEAN and len(sorted_inputs) &gt; 1: torch._foreach_div_(sum, len(sorted_inputs))\n        return sum\n</code></pre>"},{"location":"API/all/#torchzero.modules.Sum.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.SumOfSquares","title":"SumOfSquares","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Sets loss to be the sum of squares of values returned by the closure.</p> <p>This is meant to be used to test least squares methods against ordinary minimization methods.</p> <p>To use this, the closure should return a vector of values to minimize sum of squares of. Please add the <code>backward</code> argument, it will always be False but it is required.</p> Source code in <code>torchzero/modules/least_squares/gn.py</code> <pre><code>class SumOfSquares(Transform):\n    \"\"\"Sets loss to be the sum of squares of values returned by the closure.\n\n    This is meant to be used to test least squares methods against ordinary minimization methods.\n\n    To use this, the closure should return a vector of values to minimize sum of squares of.\n    Please add the ``backward`` argument, it will always be False but it is required.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        closure = objective.closure\n\n        if closure is not None:\n\n            def sos_closure(backward=True):\n                if backward:\n                    objective.zero_grad()\n                    with torch.enable_grad():\n                        loss = closure(False)\n                        loss = loss.pow(2).sum()\n                        loss.backward()\n                    return loss\n\n                loss = closure(False)\n                return loss.pow(2).sum()\n\n            objective.closure = sos_closure\n\n        if objective.loss is not None:\n            objective.loss = objective.loss.pow(2).sum()\n\n        if objective.loss_approx is not None:\n            objective.loss_approx = objective.loss_approx.pow(2).sum()\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.Switch","title":"Switch","text":"<p>               Bases: <code>torchzero.modules.misc.switch.Alternate</code></p> <p>After <code>steps</code> steps switches to the next module.</p> <p>Parameters:</p> <ul> <li> <code>steps</code>               (<code>int | Iterable[int]</code>)           \u2013            <p>Number of steps to perform with each module.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Switch--examples","title":"Examples:","text":"<p>Start with Adam, switch to L-BFGS after 1000th step and Truncated Newton on 2000th step.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Switch(\n        [tz.m.Adam(), tz.m.LR(1e-3)],\n        [tz.m.LBFGS(), tz.m.Backtracking()],\n        [tz.m.NewtonCG(maxiter=20), tz.m.Backtracking()],\n        steps = (1000, 2000)\n    )\n)\n</code></pre> Source code in <code>torchzero/modules/misc/switch.py</code> <pre><code>class Switch(Alternate):\n    \"\"\"After ``steps`` steps switches to the next module.\n\n    Args:\n        steps (int | Iterable[int]): Number of steps to perform with each module.\n\n    ### Examples:\n\n    Start with Adam, switch to L-BFGS after 1000th step and Truncated Newton on 2000th step.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Switch(\n            [tz.m.Adam(), tz.m.LR(1e-3)],\n            [tz.m.LBFGS(), tz.m.Backtracking()],\n            [tz.m.NewtonCG(maxiter=20), tz.m.Backtracking()],\n            steps = (1000, 2000)\n        )\n    )\n    ```\n    \"\"\"\n\n    LOOP = False\n    def __init__(self, *modules: Chainable, steps: int | Iterable[int]):\n\n        if isinstance(steps, Iterable):\n            steps = list(steps)\n            if len(steps) != len(modules) - 1:\n                raise ValueError(f\"steps must be the same length as modules minus 1, got {len(modules) = }, {len(steps) = }\")\n\n            steps.append(1)\n\n        super().__init__(*modules, steps=steps)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Switch.LOOP","title":"LOOP  <code>class-attribute</code>","text":"<pre><code>LOOP = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.TerminateAfterNEvaluations","title":"TerminateAfterNEvaluations","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateAfterNEvaluations(TerminationCriteriaBase):\n    def __init__(self, maxevals:int):\n        defaults = dict(maxevals=maxevals)\n        super().__init__(defaults)\n\n    def termination_criteria(self, objective):\n        maxevals = self.defaults['maxevals']\n        assert objective.modular is not None\n        return objective.modular.num_evaluations &gt;= maxevals\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateAfterNSeconds","title":"TerminateAfterNSeconds","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateAfterNSeconds(TerminationCriteriaBase):\n    def __init__(self, seconds:float, sec_fn = time.time):\n        defaults = dict(seconds=seconds, sec_fn=sec_fn)\n        super().__init__(defaults)\n\n    def termination_criteria(self, objective):\n        max_seconds = self.defaults['seconds']\n        sec_fn = self.defaults['sec_fn']\n\n        if 'start' not in self.global_state:\n            self.global_state['start'] = sec_fn()\n            return False\n\n        seconds_passed = sec_fn() - self.global_state['start']\n        return seconds_passed &gt;= max_seconds\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateAfterNSteps","title":"TerminateAfterNSteps","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateAfterNSteps(TerminationCriteriaBase):\n    def __init__(self, steps:int):\n        defaults = dict(steps=steps)\n        super().__init__(defaults)\n\n    def termination_criteria(self, objective):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        max_steps = self.defaults['steps']\n        return step &gt;= max_steps\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateAll","title":"TerminateAll","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateAll(TerminationCriteriaBase):\n    def __init__(self, *criteria: TerminationCriteriaBase):\n        super().__init__()\n\n        self.set_children_sequence(criteria)\n\n    def termination_criteria(self, objective: Objective) -&gt; bool:\n        for c in self.get_children_sequence():\n            if not cast(TerminationCriteriaBase, c).termination_criteria(objective): return False\n\n        return True\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateAny","title":"TerminateAny","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateAny(TerminationCriteriaBase):\n    def __init__(self, *criteria: TerminationCriteriaBase):\n        super().__init__()\n\n        self.set_children_sequence(criteria)\n\n    def termination_criteria(self, objective: Objective) -&gt; bool:\n        for c in self.get_children_sequence():\n            if cast(TerminationCriteriaBase, c).termination_criteria(objective): return True\n\n        return False\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateByGradientNorm","title":"TerminateByGradientNorm","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateByGradientNorm(TerminationCriteriaBase):\n    def __init__(self, tol:float = 1e-8, n: int = 3, ord: Metrics = 2):\n        defaults = dict(tol=tol, ord=ord)\n        super().__init__(defaults, n=n)\n\n    def termination_criteria(self, objective):\n        tol = self.defaults['tol']\n        ord = self.defaults['ord']\n        return TensorList(objective.get_grads()).global_metric(ord) &lt;= tol\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateByUpdateNorm","title":"TerminateByUpdateNorm","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> <p>update is calculated as parameter difference</p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateByUpdateNorm(TerminationCriteriaBase):\n    \"\"\"update is calculated as parameter difference\"\"\"\n    def __init__(self, tol:float = 1e-8, n: int = 3, ord: Metrics = 2):\n        defaults = dict(tol=tol, ord=ord)\n        super().__init__(defaults, n=n)\n\n    def termination_criteria(self, objective):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        tol = self.defaults['tol']\n        ord = self.defaults['ord']\n\n        p_prev = self.get_state(objective.params, 'p_prev', cls=TensorList)\n        if step == 0:\n            p_prev.copy_(objective.params)\n            return False\n\n        should_terminate = (p_prev - objective.params).global_metric(ord) &lt;= tol\n        p_prev.copy_(objective.params)\n        return should_terminate\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateNever","title":"TerminateNever","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateNever(TerminationCriteriaBase):\n    def __init__(self):\n        super().__init__()\n\n    def termination_criteria(self, objective): return False\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateOnLossReached","title":"TerminateOnLossReached","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateOnLossReached(TerminationCriteriaBase):\n    def __init__(self, value: float):\n        defaults = dict(value=value)\n        super().__init__(defaults)\n\n    def termination_criteria(self, objective):\n        value = self.defaults['value']\n        return objective.get_loss(False) &lt;= value\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminateOnNoImprovement","title":"TerminateOnNoImprovement","text":"<p>               Bases: <code>torchzero.modules.termination.termination.TerminationCriteriaBase</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminateOnNoImprovement(TerminationCriteriaBase):\n    def __init__(self, tol:float = 1e-8, n: int = 10):\n        defaults = dict(tol=tol)\n        super().__init__(defaults, n=n)\n\n    def termination_criteria(self, objective):\n        tol = self.defaults['tol']\n\n        f = tofloat(objective.get_loss(False))\n        if 'f_min' not in self.global_state:\n            self.global_state['f_min'] = f\n            return False\n\n        f_min = self.global_state['f_min']\n        d = f_min - f\n        should_terminate = d &lt;= tol\n        self.global_state['f_min'] = min(f, f_min)\n        return should_terminate\n</code></pre>"},{"location":"API/all/#torchzero.modules.TerminationCriteriaBase","title":"TerminationCriteriaBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> Source code in <code>torchzero/modules/termination/termination.py</code> <pre><code>class TerminationCriteriaBase(Module):\n    def __init__(self, defaults:dict | None = None, n: int = 1):\n        if defaults is None: defaults = {}\n        safe_dict_update_(defaults, {\"_n\": n})\n        super().__init__(defaults)\n\n    @abstractmethod\n    def termination_criteria(self, objective: Objective) -&gt; bool:\n        ...\n\n    @final\n    def should_terminate(self, objective: Objective) -&gt; bool:\n        n_bad = self.global_state.get('_n_bad', 0)\n        n = self.defaults['_n']\n\n        if self.termination_criteria(objective):\n            n_bad += 1\n            if n_bad &gt;= n:\n                self.global_state['_n_bad'] = 0\n                return True\n\n        else:\n            n_bad = 0\n\n        self.global_state['_n_bad'] = n_bad\n        return False\n\n\n    def update(self, objective):\n        objective.should_terminate = self.should_terminate(objective)\n        if objective.should_terminate: self.global_state['_n_bad'] = 0\n\n    def apply(self, objective):\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.ThomasOptimalMethod","title":"ThomasOptimalMethod","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Thomas's \"optimal\" Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Thomas, Stephen Walter. Sequential estimation techniques for quasi-Newton algorithms. Cornell University, 1975.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ThomasOptimalMethod(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Thomas's \"optimal\" Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Thomas, Stephen Walter. Sequential estimation techniques for quasi-Newton algorithms. Cornell University, 1975.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        if 'R' not in state: state['R'] = torch.eye(H.size(-1), device=H.device, dtype=H.dtype)\n        H, state['R'] = thomas_H_(H=H, R=state['R'], s=s, y=y)\n        return H\n\n    def reset_P(self, P, s, y, inverse, init_scale, state):\n        super().reset_P(P, s, y, inverse, init_scale, state)\n        for st in self.state.values():\n            st.pop(\"R\", None)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Threshold","title":"Threshold","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs tensors thresholded such that values above <code>threshold</code> are set to <code>value</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Threshold(BinaryOperationBase):\n    \"\"\"Outputs tensors thresholded such that values above ``threshold`` are set to ``value``.\"\"\"\n    def __init__(self, threshold: Chainable | float, value: Chainable | float, update_above: bool):\n        defaults = dict(update_above=update_above)\n        super().__init__(defaults, threshold=threshold, value=value)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], threshold: list[torch.Tensor] | float, value: list[torch.Tensor] | float):\n        update_above = self.defaults['update_above']\n        update = TensorList(update)\n        if update_above:\n            if isinstance(value, list): return update.where(update&gt;threshold, value)\n            return update.masked_fill_(update&lt;=threshold, value)\n\n        if isinstance(value, list): return update.where(update&lt;threshold, value)\n        return update.masked_fill_(update&gt;=threshold, value)\n</code></pre>"},{"location":"API/all/#torchzero.modules.To","title":"To","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>Cast modules to specified device and dtype</p> Source code in <code>torchzero/modules/projections/cast.py</code> <pre><code>class To(ProjectionBase):\n    \"\"\"Cast modules to specified device and dtype\"\"\"\n    def __init__(self, modules: Chainable, dtype: torch.dtype | None, device:torch.types.Device | None = None):\n        defaults = dict(dtype=dtype, device=device)\n        super().__init__(modules, project_update=True, project_params=True, project_grad=True, defaults=defaults)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        casted = []\n        for tensor, state, setting in zip(tensors,states, settings):\n            state['dtype'] = tensor.dtype\n            state['device'] = tensor.device\n            tensor = tensor.to(dtype=setting['dtype'], device=setting['device'])\n            casted.append(tensor)\n        return casted\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        uncasted = []\n        for tensor, state in zip(projected_tensors, states):\n            tensor = tensor.to(dtype=state['dtype'], device=state['device'])\n            uncasted.append(tensor)\n        return uncasted\n</code></pre>"},{"location":"API/all/#torchzero.modules.TrustCG","title":"TrustCG","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Trust region via Steihaug-Toint Conjugate Gradient method.</p> <p>.. note::</p> <pre><code>If you wish to use exact hessian, use the matrix-free :code:`tz.m.NewtonCGSteihaug`\nwhich only uses hessian-vector products. While passing ``tz.m.Newton`` to this\nis possible, it is usually less efficient.\n</code></pre> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When :code:<code>hess_module</code> is GaussNewton, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>reg</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>regularization parameter for conjugate gradient. Defaults to 0.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>boundary_tol</code>               (<code>float | None</code>, default:                   <code>1e-06</code> )           \u2013            <p>The trust region only increases when suggested step's norm is at least <code>(1-boundary_tol)*trust_region</code>. This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.</p> </li> <li> <code>prefer_exact</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>when exact solution can be easily calculated without CG (e.g. hessian is stored as scaled identity), uses the exact solution. If False, always uses CG. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul> <p>Examples:</p> <p>Trust-SR1</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(hess_module=tz.m.SR1(inverse=False)),\n)\n</code></pre> Source code in <code>torchzero/modules/trust_region/trust_cg.py</code> <pre><code>class TrustCG(TrustRegionBase):\n    \"\"\"Trust region via Steihaug-Toint Conjugate Gradient method.\n\n    .. note::\n\n        If you wish to use exact hessian, use the matrix-free :code:`tz.m.NewtonCGSteihaug`\n        which only uses hessian-vector products. While passing ``tz.m.Newton`` to this\n        is possible, it is usually less efficient.\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set `inverse=False` when constructing them.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When :code:`hess_module` is GaussNewton, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        reg (int, optional): regularization parameter for conjugate gradient. Defaults to 0.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        boundary_tol (float | None, optional):\n            The trust region only increases when suggested step's norm is at least `(1-boundary_tol)*trust_region`.\n            This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.\n        prefer_exact (bool, optional):\n            when exact solution can be easily calculated without CG (e.g. hessian is stored as scaled identity),\n            uses the exact solution. If False, always uses CG. Defaults to True.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n    Examples:\n        Trust-SR1\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.TrustCG(hess_module=tz.m.SR1(inverse=False)),\n            )\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        boundary_tol: float | None = 1e-6, # tuned\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        reg: float = 0,\n        maxiter: int | None = None,\n        miniter: int = 1,\n        cg_tol: float = 1e-8,\n        prefer_exact: bool = True,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(reg=reg, prefer_exact=prefer_exact, cg_tol=cg_tol, maxiter=maxiter, miniter=miniter)\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            boundary_tol=boundary_tol,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            radius_fn=torch.linalg.vector_norm,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        if settings['prefer_exact'] and isinstance(H, linear_operator.ScaledIdentity):\n            return H.solve_bounded(g, radius)\n\n        x, _ = cg(H.matvec, g, trust_radius=radius, reg=settings['reg'], maxiter=settings[\"maxiter\"], miniter=settings[\"miniter\"], tol=settings[\"cg_tol\"])\n        return x\n</code></pre>"},{"location":"API/all/#torchzero.modules.TrustRegionBase","title":"TrustRegionBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Methods:</p> <ul> <li> <code>trust_region_apply</code>             \u2013              <p>Solves the trust region subproblem and outputs <code>Objective</code> with the solution direction.</p> </li> <li> <code>trust_region_update</code>             \u2013              <p>updates the state of this module after H or B have been updated, if necessary</p> </li> <li> <code>trust_solve</code>             \u2013              <p>Solve Hx=g with a trust region penalty/bound defined by <code>radius</code></p> </li> </ul> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>class TrustRegionBase(Module, ABC):\n    def __init__(\n        self,\n        defaults: dict | None,\n        hess_module: Chainable,\n        # suggested default values:\n        # Gould, Nicholas IM, et al. \"Sensitivity of trust-region algorithms to their parameters.\" 4OR 3.3 (2005): 227-241.\n        # which I found from https://github.com/patrick-kidger/optimistix/blob/c1dad7e75fc35bd5a4977ac3a872991e51e83d2c/optimistix/_solver/trust_region.py#L113-200\n        eta: float, # 0.0\n        nplus: float, # 3.5\n        nminus: float, # 0.25\n        rho_good: float, # 0.99\n        rho_bad: float, # 1e-4\n        boundary_tol: float | None, # None or 1e-1\n        init: float, # 1\n        max_attempts: int, # 10\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS, # \"default\"\n        radius_fn: Callable | None, # torch.linalg.vector_norm\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        if isinstance(radius_strategy, str): radius_strategy = _RADIUS_STRATEGIES[radius_strategy]\n        if defaults is None: defaults = {}\n\n        safe_dict_update_(\n            defaults,\n            dict(eta=eta, nplus=nplus, nminus=nminus, rho_good=rho_good, rho_bad=rho_bad, init=init,\n                 update_freq=update_freq, max_attempts=max_attempts, radius_strategy=radius_strategy,\n                 boundary_tol=boundary_tol)\n        )\n\n        super().__init__(defaults)\n\n        self._radius_fn = radius_fn\n        self.set_child('hess_module', hess_module)\n\n        if inner is not None:\n            self.set_child('inner', inner)\n\n    @abstractmethod\n    def trust_solve(\n        self,\n        f: float,\n        g: torch.Tensor,\n        H: LinearOperator,\n        radius: float,\n        params: list[torch.Tensor],\n        closure: Callable,\n        settings: Mapping[str, Any],\n    ) -&gt; torch.Tensor:\n        \"\"\"Solve Hx=g with a trust region penalty/bound defined by `radius`\"\"\"\n        ... # pylint:disable=unnecessary-ellipsis\n\n    def trust_region_update(self, objective: Objective, H: LinearOperator | None) -&gt; None:\n        \"\"\"updates the state of this module after H or B have been updated, if necessary\"\"\"\n\n    def trust_region_apply(self, objective: Objective, tensors:list[torch.Tensor], H: LinearOperator | None) -&gt; Objective:\n        \"\"\"Solves the trust region subproblem and outputs ``Objective`` with the solution direction.\"\"\"\n        assert H is not None\n\n        params = TensorList(objective.params)\n        settings = self.settings[params[0]]\n        g = _flatten_tensors(tensors)\n\n        max_attempts = settings['max_attempts']\n\n        # loss at x_0\n        loss = objective.loss\n        closure = objective.closure\n        if closure is None: raise RuntimeError(\"Trust region requires closure\")\n        if loss is None: loss = objective.get_loss(False)\n        loss = tofloat(loss)\n\n        # trust region step and update\n        success = False\n        d = None\n        while not success:\n            max_attempts -= 1\n            if max_attempts &lt; 0: break\n\n            trust_radius = self.global_state.get('trust_radius', settings['init'])\n\n            # solve Hx=g\n            d = self.trust_solve(f=loss, g=g, H=H, radius=trust_radius, params=params, closure=closure, settings=settings)\n\n            # update trust radius\n            radius_strategy: _RadiusStrategy = settings['radius_strategy']\n            self.global_state[\"trust_radius\"], success = radius_strategy(\n                params=params,\n                closure=closure,\n                d=d,\n                f=loss,\n                g=g,\n                H=H,\n                trust_radius=trust_radius,\n\n                eta=settings[\"eta\"],\n                nplus=settings[\"nplus\"],\n                nminus=settings[\"nminus\"],\n                rho_good=settings[\"rho_good\"],\n                rho_bad=settings[\"rho_bad\"],\n                boundary_tol=settings[\"boundary_tol\"],\n                init=settings[\"init\"],\n\n                state=self.global_state,\n                settings=settings,\n                radius_fn=self._radius_fn,\n            )\n\n        assert d is not None\n        if success: objective.updates = vec_to_tensors(d, params)\n        else: objective.updates = params.zeros_like()\n\n        return objective\n\n\n    @final\n    @torch.no_grad\n    def update(self, objective):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        if step % self.defaults[\"update_freq\"] == 0:\n\n            hessian_module = self.children['hess_module']\n            hessian_module.update(objective)\n            H = hessian_module.get_H(objective)\n            self.global_state[\"H\"] = H\n\n            self.trust_region_update(objective, H=H)\n\n\n    @final\n    @torch.no_grad\n    def apply(self, objective):\n        H = self.global_state.get('H', None)\n\n        # -------------------------------- inner step -------------------------------- #\n        objective = self.inner_step(\"inner\", objective, must_exist=False)\n\n        # ----------------------------------- apply ---------------------------------- #\n        return self.trust_region_apply(objective=objective, tensors=objective.get_updates(), H=H)\n</code></pre>"},{"location":"API/all/#torchzero.modules.TrustRegionBase.trust_region_apply","title":"trust_region_apply","text":"<pre><code>trust_region_apply(objective: Objective, tensors: list[Tensor], H: LinearOperator | None) -&gt; Objective\n</code></pre> <p>Solves the trust region subproblem and outputs <code>Objective</code> with the solution direction.</p> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>def trust_region_apply(self, objective: Objective, tensors:list[torch.Tensor], H: LinearOperator | None) -&gt; Objective:\n    \"\"\"Solves the trust region subproblem and outputs ``Objective`` with the solution direction.\"\"\"\n    assert H is not None\n\n    params = TensorList(objective.params)\n    settings = self.settings[params[0]]\n    g = _flatten_tensors(tensors)\n\n    max_attempts = settings['max_attempts']\n\n    # loss at x_0\n    loss = objective.loss\n    closure = objective.closure\n    if closure is None: raise RuntimeError(\"Trust region requires closure\")\n    if loss is None: loss = objective.get_loss(False)\n    loss = tofloat(loss)\n\n    # trust region step and update\n    success = False\n    d = None\n    while not success:\n        max_attempts -= 1\n        if max_attempts &lt; 0: break\n\n        trust_radius = self.global_state.get('trust_radius', settings['init'])\n\n        # solve Hx=g\n        d = self.trust_solve(f=loss, g=g, H=H, radius=trust_radius, params=params, closure=closure, settings=settings)\n\n        # update trust radius\n        radius_strategy: _RadiusStrategy = settings['radius_strategy']\n        self.global_state[\"trust_radius\"], success = radius_strategy(\n            params=params,\n            closure=closure,\n            d=d,\n            f=loss,\n            g=g,\n            H=H,\n            trust_radius=trust_radius,\n\n            eta=settings[\"eta\"],\n            nplus=settings[\"nplus\"],\n            nminus=settings[\"nminus\"],\n            rho_good=settings[\"rho_good\"],\n            rho_bad=settings[\"rho_bad\"],\n            boundary_tol=settings[\"boundary_tol\"],\n            init=settings[\"init\"],\n\n            state=self.global_state,\n            settings=settings,\n            radius_fn=self._radius_fn,\n        )\n\n    assert d is not None\n    if success: objective.updates = vec_to_tensors(d, params)\n    else: objective.updates = params.zeros_like()\n\n    return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.TrustRegionBase.trust_region_update","title":"trust_region_update","text":"<pre><code>trust_region_update(objective: Objective, H: LinearOperator | None) -&gt; None\n</code></pre> <p>updates the state of this module after H or B have been updated, if necessary</p> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>def trust_region_update(self, objective: Objective, H: LinearOperator | None) -&gt; None:\n    \"\"\"updates the state of this module after H or B have been updated, if necessary\"\"\"\n</code></pre>"},{"location":"API/all/#torchzero.modules.TrustRegionBase.trust_solve","title":"trust_solve","text":"<pre><code>trust_solve(f: float, g: Tensor, H: LinearOperator, radius: float, params: list[Tensor], closure: Callable, settings: Mapping[str, Any]) -&gt; Tensor\n</code></pre> <p>Solve Hx=g with a trust region penalty/bound defined by <code>radius</code></p> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>@abstractmethod\ndef trust_solve(\n    self,\n    f: float,\n    g: torch.Tensor,\n    H: LinearOperator,\n    radius: float,\n    params: list[torch.Tensor],\n    closure: Callable,\n    settings: Mapping[str, Any],\n) -&gt; torch.Tensor:\n    \"\"\"Solve Hx=g with a trust region penalty/bound defined by `radius`\"\"\"\n    ... # pylint:disable=unnecessary-ellipsis\n</code></pre>"},{"location":"API/all/#torchzero.modules.TwoPointNewton","title":"TwoPointNewton","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>two-point Newton method with frozen derivative with third order convergence.</p> <p>Sharma, Janak Raj, and Deepak Kumar. \"A fast and efficient composite Newton\u2013Chebyshev method for systems of nonlinear equations.\" Journal of Complexity 49 (2018): 56-73.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class TwoPointNewton(HigherOrderMethodBase):\n    \"\"\"two-point Newton method with frozen derivative with third order convergence.\n\n    Sharma, Janak Raj, and Deepak Kumar. \"A fast and efficient composite Newton\u2013Chebyshev method for systems of nonlinear equations.\" Journal of Complexity 49 (2018): 56-73.\"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f(x): return evaluate(x, 1)[1]\n        def f_j(x): return evaluate(x, 2)[1:]\n        x_star = two_point_newton(x, f, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/all/#torchzero.modules.UnaryLambda","title":"UnaryLambda","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies <code>fn</code> to input tensors.</p> <p><code>fn</code> must accept and return a list of tensors.</p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class UnaryLambda(TensorTransform):\n    \"\"\"Applies ``fn`` to input tensors.\n\n    ``fn`` must accept and return a list of tensors.\n    \"\"\"\n    def __init__(self, fn):\n        defaults = dict(fn=fn)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return settings[0]['fn'](tensors)\n</code></pre>"},{"location":"API/all/#torchzero.modules.UnaryParameterwiseLambda","title":"UnaryParameterwiseLambda","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies <code>fn</code> to each input tensor.</p> <p><code>fn</code> must accept and return a tensor.</p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class UnaryParameterwiseLambda(TensorTransform):\n    \"\"\"Applies ``fn`` to each input tensor.\n\n    ``fn`` must accept and return a tensor.\n    \"\"\"\n    def __init__(self, fn):\n        defaults = dict(fn=fn)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        return setting['fn'](tensor)\n</code></pre>"},{"location":"API/all/#torchzero.modules.Uniform","title":"Uniform","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with random numbers from uniform distribution between <code>low</code> and <code>high</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Uniform(Module):\n    \"\"\"Outputs tensors filled with random numbers from uniform distribution between ``low`` and ``high``.\"\"\"\n    def __init__(self, low: float, high: float):\n        defaults = dict(low=low, high=high)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        low,high = self.get_settings(objective.params, 'low','high')\n        objective.updates = [torch.empty_like(t).uniform_(l,h) for t,l,h in zip(objective.params, low, high)]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.UpdateGradientSignConsistency","title":"UpdateGradientSignConsistency","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Compares update and gradient signs. Output will have 1s where signs match, and 0s where they don't.</p> <p>Parameters:</p> <ul> <li> <code>normalize</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>renormalize update after masking. Defaults to False.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for normalization. Defaults to 1e-6.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class UpdateGradientSignConsistency(TensorTransform):\n    \"\"\"Compares update and gradient signs. Output will have 1s where signs match, and 0s where they don't.\n\n    Args:\n        normalize (bool, optional):\n            renormalize update after masking. Defaults to False.\n        eps (float, optional): epsilon for normalization. Defaults to 1e-6.\n    \"\"\"\n    def __init__(self, normalize = False, eps=1e-6):\n\n        defaults = dict(normalize=normalize, eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        normalize, eps = itemgetter('normalize', 'eps')(settings[0])\n\n        mask = (TensorList(tensors).mul_(grads)).gt_(0)\n        if normalize: mask = mask / mask.global_mean().clip(min = eps) # pyright: ignore[reportOperatorIssue]\n\n        return mask\n</code></pre>"},{"location":"API/all/#torchzero.modules.UpdateSign","title":"UpdateSign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs gradient with sign copied from the update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class UpdateSign(TensorTransform):\n    \"\"\"Outputs gradient with sign copied from the update.\"\"\"\n    def __init__(self):\n        super().__init__(uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        return [g.copysign(t) for t,g in zip(tensors, grads)] # no in-place\n</code></pre>"},{"location":"API/all/#torchzero.modules.UpdateToNone","title":"UpdateToNone","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Sets <code>update</code> attribute to None on <code>var</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class UpdateToNone(Module):\n    \"\"\"Sets ``update`` attribute to None on ``var``.\"\"\"\n    def __init__(self): super().__init__()\n    def apply(self, objective):\n        objective.updates = None\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.VectorProjection","title":"VectorProjection","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>projection that concatenates all parameters into a vector</p> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>class VectorProjection(ProjectionBase):\n    \"\"\"projection that concatenates all parameters into a vector\"\"\"\n    def __init__(\n        self,\n        modules: Chainable,\n        project_update=True,\n        project_params=True,\n        project_grad=True,\n    ):\n        super().__init__(modules, project_update=project_update, project_params=project_params, project_grad=project_grad)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        return [torch.cat([t.ravel() for t in tensors])]\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        return vec_to_tensors(vec=projected_tensors[0], reference=params)\n</code></pre>"},{"location":"API/all/#torchzero.modules.ViewAsReal","title":"ViewAsReal","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>View complex tensors as real tensors. Doesn't affect tensors that are already.</p> Source code in <code>torchzero/modules/projections/cast.py</code> <pre><code>class ViewAsReal(ProjectionBase):\n    \"\"\"View complex tensors as real tensors. Doesn't affect tensors that are already.\"\"\"\n    def __init__(self, modules: Chainable):\n        super().__init__(modules, project_update=True, project_params=True, project_grad=True, defaults=None)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        views = []\n        for tensor, state in zip(tensors,states):\n            is_complex = torch.is_complex(tensor)\n            state['is_complex'] = is_complex\n            if is_complex: tensor = torch.view_as_real(tensor)\n            views.append(tensor)\n        return views\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        un_views = []\n        for tensor, state in zip(projected_tensors, states):\n            if state['is_complex']: tensor = torch.view_as_complex(tensor)\n            un_views.append(tensor)\n        return un_views\n</code></pre>"},{"location":"API/all/#torchzero.modules.Warmup","title":"Warmup","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Learning rate warmup, linearly increases learning rate multiplier from <code>start_lr</code> to <code>end_lr</code> over <code>steps</code> steps.</p> <p>Parameters:</p> <ul> <li> <code>steps</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of steps to perform warmup for. Defaults to 100.</p> </li> <li> <code>start_lr</code>               (<code>_type_</code>, default:                   <code>1e-05</code> )           \u2013            <p>initial learning rate multiplier on first step. Defaults to 1e-5.</p> </li> <li> <code>end_lr</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>learning rate multiplier at the end and after warmup. Defaults to 1.</p> </li> </ul> Example <p>Adam with 1000 steps warmup</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n    tz.m.Warmup(steps=1000)\n)\n</code></pre> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class Warmup(TensorTransform):\n    \"\"\"Learning rate warmup, linearly increases learning rate multiplier from ``start_lr`` to ``end_lr`` over ``steps`` steps.\n\n    Args:\n        steps (int, optional): number of steps to perform warmup for. Defaults to 100.\n        start_lr (_type_, optional): initial learning rate multiplier on first step. Defaults to 1e-5.\n        end_lr (float, optional): learning rate multiplier at the end and after warmup. Defaults to 1.\n\n    Example:\n        Adam with 1000 steps warmup\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.Adam(),\n                tz.m.LR(1e-2),\n                tz.m.Warmup(steps=1000)\n            )\n\n    \"\"\"\n    def __init__(self, steps = 100, start_lr = 1e-5, end_lr:float = 1):\n        defaults = dict(start_lr=start_lr,end_lr=end_lr, steps=steps)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        start_lr, end_lr = unpack_dicts(settings, 'start_lr', 'end_lr', cls = NumberList)\n        num_steps = settings[0]['steps']\n        step = self.global_state.get('step', 0)\n\n        tensors = lazy_lr(\n            TensorList(tensors),\n            lr=_warmup_lr(step=step, start_lr=start_lr, end_lr=end_lr, steps=num_steps),\n            inplace=True\n        )\n        self.global_state['step'] = step + 1\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.WarmupNormClip","title":"WarmupNormClip","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Warmup via clipping of the update norm.</p> <p>Parameters:</p> <ul> <li> <code>start_norm</code>               (<code>_type_</code>, default:                   <code>1e-05</code> )           \u2013            <p>maximal norm on the first step. Defaults to 1e-5.</p> </li> <li> <code>end_norm</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>maximal norm on the last step. After that, norm clipping is disabled. Defaults to 1.</p> </li> <li> <code>steps</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of steps to perform warmup for. Defaults to 100.</p> </li> </ul> Example <p>Adam with 1000 steps norm clip warmup</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.WarmupNormClip(steps=1000)\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class WarmupNormClip(TensorTransform):\n    \"\"\"Warmup via clipping of the update norm.\n\n    Args:\n        start_norm (_type_, optional): maximal norm on the first step. Defaults to 1e-5.\n        end_norm (float, optional): maximal norm on the last step. After that, norm clipping is disabled. Defaults to 1.\n        steps (int, optional): number of steps to perform warmup for. Defaults to 100.\n\n    Example:\n        Adam with 1000 steps norm clip warmup\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.Adam(),\n                tz.m.WarmupNormClip(steps=1000)\n                tz.m.LR(1e-2),\n            )\n    \"\"\"\n    def __init__(self, steps = 100, start_norm = 1e-5, end_norm:float = 1):\n        defaults = dict(start_norm=start_norm,end_norm=end_norm, steps=steps)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        start_norm, end_norm = unpack_dicts(settings, 'start_norm', 'end_norm', cls = NumberList)\n        num_steps = settings[0]['steps']\n        step = self.global_state.get('step', 0)\n        if step &gt; num_steps: return tensors\n\n        tensors = TensorList(tensors)\n        norm = tensors.global_vector_norm()\n        current_max_norm = _warmup_lr(step, start_norm[0], end_norm[0], num_steps)\n        if norm &gt; current_max_norm:\n            tensors.mul_(current_max_norm / norm)\n\n        self.global_state['step'] = step + 1\n        return tensors\n</code></pre>"},{"location":"API/all/#torchzero.modules.WeightDecay","title":"WeightDecay","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Weight decay.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>)           \u2013            <p>weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.WeightDecay--examples","title":"Examples:","text":"<p>Adam with non-decoupled weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.WeightDecay(1e-3),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with decoupled weight decay that still scales with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.WeightDecay(1e-3),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with fully decoupled weight decay that doesn't scale with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.LR(1e-3),\n    tz.m.WeightDecay(1e-6)\n)\n</code></pre></p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class WeightDecay(TensorTransform):\n    \"\"\"Weight decay.\n\n    Args:\n        weight_decay (float): weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n        target (Target, optional): what to set on var. Defaults to 'update'.\n\n    ### Examples:\n\n    Adam with non-decoupled weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.WeightDecay(1e-3),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with decoupled weight decay that still scales with learning rate\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.WeightDecay(1e-3),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with fully decoupled weight decay that doesn't scale with learning rate\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.LR(1e-3),\n        tz.m.WeightDecay(1e-6)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, weight_decay: float, ord: int = 2):\n\n        defaults = dict(weight_decay=weight_decay, ord=ord)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        weight_decay = NumberList(s['weight_decay'] for s in settings)\n        ord = settings[0]['ord']\n\n        return weight_decay_(as_tensorlist(tensors), as_tensorlist(params), weight_decay, ord)\n</code></pre>"},{"location":"API/all/#torchzero.modules.WeightDropout","title":"WeightDropout","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Changes the closure so that it evaluates loss and gradients with random weights replaced with 0.</p> <p>Dropout can be disabled for a parameter by setting <code>use_dropout=False</code> in corresponding parameter group.</p> <p>Parameters:</p> <ul> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>probability that any weight is replaced with 0. Defaults to 0.5.</p> </li> </ul> Source code in <code>torchzero/modules/misc/regularization.py</code> <pre><code>class WeightDropout(Module):\n    \"\"\"\n    Changes the closure so that it evaluates loss and gradients with random weights replaced with 0.\n\n    Dropout can be disabled for a parameter by setting ``use_dropout=False`` in corresponding parameter group.\n\n    Args:\n        p (float, optional): probability that any weight is replaced with 0. Defaults to 0.5.\n    \"\"\"\n    def __init__(self, p: float = 0.5):\n        defaults = dict(p=p, use_dropout=True)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def update(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError('WeightDropout requires closure')\n        params = TensorList(objective.params)\n        p = NumberList(self.settings[p]['p'] for p in params)\n\n        # create masks\n        mask = []\n        for p in params:\n            prob = self.settings[p]['p']\n            use_dropout = self.settings[p]['use_dropout']\n            if use_dropout: mask.append(_bernoulli_like(p, prob))\n            else: mask.append(torch.ones_like(p))\n\n        # create a closure that evaluates masked parameters\n        @torch.no_grad\n        def dropout_closure(backward=True):\n            orig_params = params.clone()\n            params.mul_(mask)\n            if backward:\n                with torch.enable_grad(): loss = closure()\n            else:\n                loss = closure(False)\n            params.copy_(orig_params)\n            return loss\n\n        objective.closure = dropout_closure\n</code></pre>"},{"location":"API/all/#torchzero.modules.WeightedAveraging","title":"WeightedAveraging","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Weighted average of past <code>len(weights)</code> updates.</p> <p>Parameters:</p> <ul> <li> <code>weights</code>               (<code>Sequence[float]</code>)           \u2013            <p>a sequence of weights from oldest to newest.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/averaging.py</code> <pre><code>class WeightedAveraging(TensorTransform):\n    \"\"\"Weighted average of past ``len(weights)`` updates.\n\n    Args:\n        weights (Sequence[float]): a sequence of weights from oldest to newest.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, weights: Sequence[float] | torch.Tensor | Any):\n        defaults = dict(weights = tolist(weights))\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        weights = setting['weights']\n\n        if 'history' not in state:\n            state['history'] = deque(maxlen=len(weights))\n\n        history = state['history']\n        history.append(tensor)\n        if len(history) != len(weights):\n            weights = weights[-len(history):]\n\n        average = None\n        for i, (h, w) in enumerate(zip(history, weights)):\n            if average is None: average = h * (w / len(history))\n            else:\n                if w == 0: continue\n                average += h * (w / len(history))\n\n        assert average is not None\n        return average\n</code></pre>"},{"location":"API/all/#torchzero.modules.WeightedMean","title":"WeightedMean","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.WeightedSum</code></p> <p>Outputs weighted mean of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class WeightedMean(WeightedSum):\n    \"\"\"Outputs weighted mean of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = True\n</code></pre>"},{"location":"API/all/#torchzero.modules.WeightedMean.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.WeightedSum","title":"WeightedSum","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs a weighted sum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class WeightedSum(ReduceOperationBase):\n    \"\"\"Outputs a weighted sum of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = False\n    def __init__(self, *inputs: Chainable | float, weights: Iterable[float]):\n        weights = list(weights)\n        if len(inputs) != len(weights):\n            raise ValueError(f'Number of inputs {len(inputs)} must match number of weights {len(weights)}')\n        defaults = dict(weights=weights)\n        super().__init__(defaults=defaults, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        weights = self.defaults['weights']\n        sum = cast(list, sorted_inputs[0])\n        torch._foreach_mul_(sum, weights[0])\n        if len(sorted_inputs) &gt; 1:\n            for v, w in zip(sorted_inputs[1:], weights[1:]):\n                if isinstance(v, (int, float)): torch._foreach_add_(sum, v*w)\n                else: torch._foreach_add_(sum, v, alpha=w)\n\n        if self.USE_MEAN and len(sorted_inputs) &gt; 1: torch._foreach_div_(sum, len(sorted_inputs))\n        return sum\n</code></pre>"},{"location":"API/all/#torchzero.modules.WeightedSum.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/all/#torchzero.modules.Wrap","title":"Wrap","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Wraps a pytorch optimizer to use it as a module.</p> Note <p>Custom param groups are supported only by <code>set_param_groups</code>, settings passed to Optimizer will be applied to all parameters.</p> <p>Parameters:</p> <ul> <li> <code>opt_fn</code>               (<code>Callable[..., Optimizer] | Optimizer</code>)           \u2013            <p>function that takes in parameters and returns the optimizer, for example <code>torch.optim.Adam</code> or <code>lambda parameters: torch.optim.Adam(parameters, lr=1e-3)</code></p> </li> <li> <code>*args</code>           \u2013            </li> <li> <code>**kwargs</code>           \u2013            <p>Extra args to be passed to opt_fn. The function is called as <code>opt_fn(parameters, *args, **kwargs)</code>.</p> </li> <li> <code>use_param_groups</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to pass settings passed to Optimizer to the wrapped optimizer.</p> <p>Note that settings to the first parameter are used for all parameters, so if you specified per-parameter settings, they will be ignored.</p> </li> </ul>"},{"location":"API/all/#torchzero.modules.Wrap--example","title":"Example:","text":"<p>wrapping pytorch_optimizer.StableAdamW</p> <pre><code>from pytorch_optimizer import StableAdamW\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Wrap(StableAdamW, lr=1),\n    tz.m.Cautious(),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/wrappers/optim_wrapper.py</code> <pre><code>class Wrap(Module):\n    \"\"\"\n    Wraps a pytorch optimizer to use it as a module.\n\n    Note:\n        Custom param groups are supported only by ``set_param_groups``, settings passed to Optimizer will be applied to all parameters.\n\n    Args:\n        opt_fn (Callable[..., torch.optim.Optimizer] | torch.optim.Optimizer):\n            function that takes in parameters and returns the optimizer, for example ``torch.optim.Adam``\n            or ``lambda parameters: torch.optim.Adam(parameters, lr=1e-3)``\n        *args:\n        **kwargs:\n            Extra args to be passed to opt_fn. The function is called as ``opt_fn(parameters, *args, **kwargs)``.\n        use_param_groups:\n            Whether to pass settings passed to Optimizer to the wrapped optimizer.\n\n            Note that settings to the first parameter are used for all parameters,\n            so if you specified per-parameter settings, they will be ignored.\n\n    ### Example:\n    wrapping pytorch_optimizer.StableAdamW\n\n    ```python\n\n    from pytorch_optimizer import StableAdamW\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Wrap(StableAdamW, lr=1),\n        tz.m.Cautious(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    \"\"\"\n\n    def __init__(\n        self,\n        opt_fn: Callable[..., torch.optim.Optimizer] | torch.optim.Optimizer,\n        *args,\n        use_param_groups: bool = True,\n        **kwargs,\n    ):\n        defaults = dict(use_param_groups=use_param_groups)\n        super().__init__(defaults=defaults)\n\n        self._opt_fn = opt_fn\n        self._opt_args = args\n        self._opt_kwargs = kwargs\n        self._custom_param_groups = None\n\n        self.optimizer: torch.optim.Optimizer | None = None\n        if isinstance(self._opt_fn, torch.optim.Optimizer) or not callable(self._opt_fn):\n            self.optimizer = self._opt_fn\n\n    def set_param_groups(self, param_groups):\n        self._custom_param_groups = _make_param_groups(param_groups, differentiable=False)\n        return super().set_param_groups(param_groups)\n\n    @torch.no_grad\n    def apply(self, objective):\n        params = objective.params\n\n        # initialize opt on 1st step\n        if self.optimizer is None:\n            assert callable(self._opt_fn)\n            param_groups = params if self._custom_param_groups is None else self._custom_param_groups\n            self.optimizer = self._opt_fn(param_groups, *self._opt_args, **self._opt_kwargs)\n\n        # set optimizer per-parameter settings\n        if self.defaults[\"use_param_groups\"] and objective.modular is not None:\n            for group in self.optimizer.param_groups:\n                first_param = group['params'][0]\n                setting = self.settings[first_param]\n\n                # settings passed in `set_param_groups` are the highest priority\n                # schedulers will override defaults but not settings passed in `set_param_groups`\n                # this is consistent with how Optimizer does it.\n                if self._custom_param_groups is not None:\n                    setting = {k:v for k,v in setting if k not in self._custom_param_groups[0]}\n\n                group.update(setting)\n\n        # set grad to update\n        orig_grad = [p.grad for p in params]\n        for p, u in zip(params, objective.get_updates()):\n            p.grad = u\n\n        # if this is last module, simply use optimizer to update parameters\n        if objective.modular is not None and self is objective.modular.modules[-1]:\n            self.optimizer.step()\n\n            # restore grad\n            for p, g in zip(params, orig_grad):\n                p.grad = g\n\n            objective.stop = True; objective.skip_update = True\n            return objective\n\n        # this is not the last module, meaning update is difference in parameters\n        # and passed to next module\n        params_before_step = [p.clone() for p in params]\n        self.optimizer.step() # step and update params\n        for p, g in zip(params, orig_grad):\n            p.grad = g\n        objective.updates = list(torch._foreach_sub(params_before_step, params)) # set update to difference between params\n        for p, o in zip(params, params_before_step):\n            p.set_(o) # pyright: ignore[reportArgumentType]\n\n        return objective\n\n    def reset(self):\n        super().reset()\n        assert self.optimizer is not None\n        for g in self.optimizer.param_groups:\n            for p in g['params']:\n                state = self.optimizer.state[p]\n                state.clear()\n</code></pre>"},{"location":"API/all/#torchzero.modules.Zeros","title":"Zeros","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs zeros</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Zeros(Module):\n    \"\"\"Outputs zeros\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.zeros_like(p) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/all/#torchzero.modules.clip_grad_norm_","title":"clip_grad_norm_","text":"<pre><code>clip_grad_norm_(params: Iterable[Tensor], max_norm: float | None, ord: Union[Literal['mad', 'std', 'var', 'sum', 'l0', 'l1', 'l2', 'l3', 'l4', 'linf'], float, Tensor] = 2, dim: Union[int, Sequence[int], Literal['global'], NoneType] = None, inverse_dims: bool = False, min_size: int = 2, min_norm: float | None = None)\n</code></pre> <p>Clips gradient of an iterable of parameters to specified norm value. Gradients are modified in-place.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>Iterable[Tensor]</code>)           \u2013            <p>parameters with gradients to clip.</p> </li> <li> <code>max_norm</code>               (<code>float</code>)           \u2013            <p>value to clip norm to.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>def clip_grad_norm_(\n    params: Iterable[torch.Tensor],\n    max_norm: float | None,\n    ord: Metrics = 2,\n    dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n    inverse_dims: bool = False,\n    min_size: int = 2,\n    min_norm: float | None = None,\n):\n    \"\"\"Clips gradient of an iterable of parameters to specified norm value.\n    Gradients are modified in-place.\n\n    Args:\n        params (Iterable[torch.Tensor]): parameters with gradients to clip.\n        max_norm (float): value to clip norm to.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n    \"\"\"\n    grads = TensorList(p.grad for p in params if p.grad is not None)\n    _clip_norm_(grads, min=min_norm, max=max_norm, norm_value=None, ord=ord, dim=dim, inverse_dims=inverse_dims, min_size=min_size)\n</code></pre>"},{"location":"API/all/#torchzero.modules.clip_grad_value_","title":"clip_grad_value_","text":"<pre><code>clip_grad_value_(params: Iterable[Tensor], value: float)\n</code></pre> <p>Clips gradient of an iterable of parameters at specified value. Gradients are modified in-place. Args:     params (Iterable[Tensor]): iterable of tensors with gradients to clip.     value (float or int): maximum allowed value of gradient</p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>def clip_grad_value_(params: Iterable[torch.Tensor], value: float):\n    \"\"\"Clips gradient of an iterable of parameters at specified value.\n    Gradients are modified in-place.\n    Args:\n        params (Iterable[Tensor]): iterable of tensors with gradients to clip.\n        value (float or int): maximum allowed value of gradient\n    \"\"\"\n    grads = [p.grad for p in params if p.grad is not None]\n    torch._foreach_clamp_min_(grads, -value)\n    torch._foreach_clamp_max_(grads, value)\n</code></pre>"},{"location":"API/all/#torchzero.modules.decay_weights_","title":"decay_weights_","text":"<pre><code>decay_weights_(params: Iterable[Tensor], weight_decay: float | NumberList, ord: int = 2)\n</code></pre> <p>directly decays weights in-place</p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>@torch.no_grad\ndef decay_weights_(params: Iterable[torch.Tensor], weight_decay: float | NumberList, ord:int=2):\n    \"\"\"directly decays weights in-place\"\"\"\n    params = TensorList(params)\n    weight_decay_(params, params, -weight_decay, ord)\n</code></pre>"},{"location":"API/all/#torchzero.modules.normalize_grads_","title":"normalize_grads_","text":"<pre><code>normalize_grads_(params: Iterable[Tensor], norm_value: float, ord: Union[Literal['mad', 'std', 'var', 'sum', 'l0', 'l1', 'l2', 'l3', 'l4', 'linf'], float, Tensor] = 2, dim: Union[int, Sequence[int], Literal['global'], NoneType] = None, inverse_dims: bool = False, min_size: int = 1)\n</code></pre> <p>Normalizes gradient of an iterable of parameters to specified norm value. Gradients are modified in-place.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>Iterable[Tensor]</code>)           \u2013            <p>parameters with gradients to clip.</p> </li> <li> <code>norm_value</code>               (<code>float</code>)           \u2013            <p>value to clip norm to.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are normalized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>def normalize_grads_(\n    params: Iterable[torch.Tensor],\n    norm_value: float,\n    ord: Metrics = 2,\n    dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n    inverse_dims: bool = False,\n    min_size: int = 1,\n):\n    \"\"\"Normalizes gradient of an iterable of parameters to specified norm value.\n    Gradients are modified in-place.\n\n    Args:\n        params (Iterable[torch.Tensor]): parameters with gradients to clip.\n        norm_value (float): value to clip norm to.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are normalized.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n    \"\"\"\n    grads = TensorList(p.grad for p in params if p.grad is not None)\n    _clip_norm_(grads, min=None, max=None, norm_value=norm_value, ord=ord, dim=dim, inverse_dims=inverse_dims, min_size=min_size)\n</code></pre>"},{"location":"API/all/#torchzero.modules.orthogonalize_grads_","title":"orthogonalize_grads_","text":"<pre><code>orthogonalize_grads_(params: Iterable[Tensor], dual_norm_correction=False, method: Literal['newtonschulz', 'ns5', 'polar_express', 'svd', 'qr', 'eigh'] = 'newtonschulz', channel_first: bool = True)\n</code></pre> <p>Computes the zeroth power / orthogonalization of gradients of an iterable of parameters.</p> <p>This sets gradients in-place. Applies along first 2 dims (expected to be <code>out_channels, in_channels</code>).</p> <p>Note that the Muon page says that embeddings and classifier heads should not be orthogonalized. Args:     params (abc.Iterable[torch.Tensor]): parameters that hold gradients to orthogonalize.     dual_norm_correction (bool, optional):         enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.     method (str, optional):         Newton-Schulz is very fast, SVD is extremely slow but can be slighly more precise.     channel_first (bool, optional):         if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions         are considered batch dimensions.</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>def orthogonalize_grads_(\n    params: Iterable[torch.Tensor],\n    dual_norm_correction=False,\n    method: OrthogonalizeMethod = \"newtonschulz\",\n    channel_first:bool=True,\n):\n    \"\"\"Computes the zeroth power / orthogonalization of gradients of an iterable of parameters.\n\n    This sets gradients in-place. Applies along first 2 dims (expected to be `out_channels, in_channels`).\n\n    Note that the Muon page says that embeddings and classifier heads should not be orthogonalized.\n    Args:\n        params (abc.Iterable[torch.Tensor]): parameters that hold gradients to orthogonalize.\n        dual_norm_correction (bool, optional):\n            enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.\n        method (str, optional):\n            Newton-Schulz is very fast, SVD is extremely slow but can be slighly more precise.\n        channel_first (bool, optional):\n            if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions\n            are considered batch dimensions.\n    \"\"\"\n    for p in params:\n        if (p.grad is not None) and _is_at_least_2d(p.grad, channel_first=channel_first):\n            X = _orthogonalize_format(p.grad, method=method, channel_first=channel_first)\n            if dual_norm_correction: X = _dual_norm_correction(X, p.grad, channel_first=False)\n            p.grad.set_(X.view_as(p)) # pyright:ignore[reportArgumentType]\n</code></pre>"},{"location":"API/all/#torchzero.modules.orthograd_","title":"orthograd_","text":"<pre><code>orthograd_(params: Iterable[Tensor], eps: float = 1e-30)\n</code></pre> <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>Iterable[Tensor]</code>)           \u2013            <p>parameters that hold gradients to apply \u27c2Grad to.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-30</code> )           \u2013            <p>epsilon added to the denominator for numerical stability (default: 1e-30)</p> </li> </ul> <p>reference     https://arxiv.org/abs/2501.04697</p> Source code in <code>torchzero/modules/adaptive/orthograd.py</code> <pre><code>def orthograd_(params: Iterable[torch.Tensor], eps: float = 1e-30):\n    \"\"\"Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.\n\n    Args:\n        params (abc.Iterable[torch.Tensor]): parameters that hold gradients to apply \u27c2Grad to.\n        eps (float, optional): epsilon added to the denominator for numerical stability (default: 1e-30)\n\n    reference\n        https://arxiv.org/abs/2501.04697\n    \"\"\"\n    params = TensorList(params).with_grad()\n    grad = params.grad\n    grad -= (params.dot(grad)/(params.dot(params) + eps)) * params\n</code></pre>"},{"location":"API/core/","title":"API reference for core module","text":"<p>Modules:</p> <ul> <li> <code>chain</code>           \u2013            </li> <li> <code>functional</code>           \u2013            </li> <li> <code>modular</code>           \u2013            </li> <li> <code>module</code>           \u2013            </li> <li> <code>reformulation</code>           \u2013            </li> <li> <code>transform</code>           \u2013            </li> </ul> <p>Classes:</p> <ul> <li> <code>Chain</code>           \u2013            <p>Chain modules, mostly used internally</p> </li> <li> <code>Module</code>           \u2013            <p>Abstract base class for an optimizer modules.</p> </li> <li> <code>Optimizer</code>           \u2013            <p>Chains multiple modules into an optimizer.</p> </li> <li> <code>TensorTransform</code>           \u2013            <p><code>TensorTransform</code> is a <code>Transform</code> that doesn't use <code>Objective</code>, instead it operates</p> </li> <li> <code>Transform</code>           \u2013            <p><code>Transform</code> is a <code>Module</code> with only optional children.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>maybe_chain</code>             \u2013              <p>Returns a single module directly if only one is provided, otherwise wraps them in a <code>Chain</code>.</p> </li> <li> <code>step</code>             \u2013              <p>doesn't apply hooks!</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>Chainable</code>           \u2013            <p>Represent a PEP 604 union type</p> </li> </ul>"},{"location":"API/core/#torchzero.core.Chainable","title":"Chainable  <code>module-attribute</code>","text":"<pre><code>Chainable = torchzero.core.module.Module | collections.abc.Sequence[torchzero.core.module.Module]\n</code></pre> <p>Represent a PEP 604 union type</p> <p>E.g. for int | str</p>"},{"location":"API/core/#torchzero.core.Chain","title":"Chain","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Chain modules, mostly used internally</p> Source code in <code>torchzero/core/chain.py</code> <pre><code>class Chain(Module):\n    \"\"\"Chain modules, mostly used internally\"\"\"\n    def __init__(self, *modules: Module | Iterable[Module]):\n        super().__init__()\n        flat_modules: list[Module] = flatten(modules)\n        for i, module in enumerate(flat_modules):\n            self.set_child(f'module_{i}', module)\n\n    def update(self, objective):\n        if len(self.children) &gt; 1:\n            raise RuntimeError(\"can't call `update` on Chain with more than one child, as `update` and `apply` have to be called sequentially. Use the `step` method instead of update-apply.\")\n\n        if len(self.children) == 0: return\n        return self.children['module_0'].update(objective)\n\n    def apply(self, objective):\n        if len(self.children) &gt; 1:\n            raise RuntimeError(\"can't call `update` on Chain with more than one child, as `update` and `apply` have to be called sequentially. Use the `step` method instead of update-apply.\")\n\n        if len(self.children) == 0: return objective\n        return self.children['module_0'].apply(objective)\n\n    def step(self, objective):\n        children = [self.children[f'module_{i}'] for i in range(len(self.children))]\n        return _chain_step(objective, children)\n\n    def __repr__(self):\n        s = self.__class__.__name__\n        if self.children:\n            if s == 'Chain': s = 'C' # to shorten it\n            s = f'{s}({\", \".join(str(m) for m in self.children.values())})'\n        return s\n</code></pre>"},{"location":"API/core/#torchzero.core.Module","title":"Module","text":"<p>               Bases: <code>abc.ABC</code></p> <p>Abstract base class for an optimizer modules.</p> <p>Modules represent distinct steps or transformations within the optimization process (e.g., momentum, line search, gradient accumulation).</p> <p>A module does not store parameters, but it maintains per-parameter state and per-parameter settings where tensors are used as keys (same as torch.optim.Optimizer state.)</p> <p>Parameters:</p> <ul> <li> <code>defaults</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>a dict containing default values of optimization options (used when a parameter group doesn't specify them).</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>apply</code>             \u2013              <p>Updates <code>objective</code> using the internal state of this module.</p> </li> <li> <code>get_H</code>             \u2013              <p>returns a <code>LinearOperator</code> corresponding to hessian or hessian approximation.</p> </li> <li> <code>get_child_projected_buffers</code>             \u2013              <p>if params is None, assumes fake parameters</p> </li> <li> <code>get_generator</code>             \u2013              <p>If <code>seed=None</code>, returns <code>None</code>.</p> </li> <li> <code>get_state</code>             \u2013              <p>Returns values of per-parameter state for a given key.</p> </li> <li> <code>increment_counter</code>             \u2013              <p>first value is <code>start</code></p> </li> <li> <code>inner_step</code>             \u2013              <p>Passes <code>objective</code> to child and returns it.</p> </li> <li> <code>inner_step_tensors</code>             \u2013              <p>Steps with child module. Can be used to apply transforms to any internal buffers.</p> </li> <li> <code>on_get_projected_buffers</code>             \u2013              <p>runs before projected buffers are accessed</p> </li> <li> <code>reset</code>             \u2013              <p>Resets the internal state of the module (e.g. momentum) and all children. By default clears state and global state.</p> </li> <li> <code>reset_for_online</code>             \u2013              <p>Resets buffers that depend on previous evaluation, such as previous gradient and loss,</p> </li> <li> <code>set_param_groups</code>             \u2013              <p>Set custom parameter groups with per-parameter settings that this module will use.</p> </li> <li> <code>state_dict</code>             \u2013              <p>state dict</p> </li> <li> <code>step</code>             \u2013              <p>Perform a step with this module. Calls <code>update</code>, then <code>apply</code>.</p> </li> <li> <code>update</code>             \u2013              <p>Updates internal state of this module. This should not modify <code>objective.update</code>.</p> </li> </ul> Source code in <code>torchzero/core/module.py</code> <pre><code>class Module(ABC):\n    \"\"\"Abstract base class for an optimizer modules.\n\n    Modules represent distinct steps or transformations within the optimization\n    process (e.g., momentum, line search, gradient accumulation).\n\n    A module does not store parameters, but it maintains per-parameter state and per-parameter settings\n    where tensors are used as keys (same as torch.optim.Optimizer state.)\n\n    Args:\n        defaults (dict[str, Any] | None):\n            a dict containing default values of optimization options (used when a parameter group doesn't specify them).\n\"\"\"\n    def __init__(self, defaults: dict[str, Any] | None = None):\n        if defaults is None: defaults = {}\n        if any(isinstance(v, Module) for v in defaults.values()): raise RuntimeError(\"Passed a module to defaults\")\n        self.defaults: dict[str, Any] = defaults\n\n        # settings are stored like state in per-tensor defaultdict, with per-parameter overrides possible\n        # 0 - this module specific per-parameter setting overrides set via `set_param_groups` - highest priority\n        # 1 - global per-parameter setting overrides in param_groups passed to Optimizer - medium priority\n        # 2 - `defaults` - lowest priority\n        self.settings: defaultdict[torch.Tensor, ChainMap[str, Any]] = defaultdict(lambda: ChainMap({}, {}, self.defaults))\n        \"\"\"per-parameter settings.\"\"\"\n\n        self.state: defaultdict[torch.Tensor, dict[str, Any]] = defaultdict(dict)\n        \"\"\"Per-parameter state (e.g., momentum buffers).\"\"\"\n\n        self.global_state: dict[str, Any] = {}\n        \"\"\"Global state for things that are not per-parameter.\"\"\"\n\n        self.children: dict[str, Module] = {}\n        \"\"\"A dictionary of child modules.\"\"\"\n\n        self._overridden_keys = set()\n        \"\"\"tracks keys overridden with ``set_param_groups``, only used to not give a warning\"\"\"\n\n        self._projected_keys: defaultdict[ProjectedBuffer, set[str]] = defaultdict(set)\n        \"\"\"tracks keys with gradient-like buffers, covariance-like buffers, etc for reprojecting\"\"\"\n\n        self._fake_params: dict[str, list[torch.Tensor]] = {}\n        \"\"\"fake parameters for state keys and shape inference, key is name of child, value is list of fake parameters\"\"\"\n\n\n    def set_param_groups(self, param_groups: Params):\n        \"\"\"Set custom parameter groups with per-parameter settings that this module will use.\"\"\"\n        param_groups = _make_param_groups(param_groups, differentiable=False)\n        for group in param_groups:\n            settings = group.copy()\n            params = settings.pop('params')\n            if not settings: continue\n            self._overridden_keys.update(*settings.keys())\n\n            for param in params:\n                self.settings[param].maps[0].update(settings) # set module-specific per-parameter settings\n        return self\n\n    def set_child(self, key: str, module: \"Module | Sequence[Module] | None\"):\n        if key in self.children:\n            warnings.warn(f\"set_child overwriting child `{key}`\")\n\n        if module is None: return\n\n        from .chain import maybe_chain\n        self.children[key] = maybe_chain(module)\n\n    def set_children_sequence(self, modules: \"Iterable[Module | Sequence[Module]]\", prefix = 'module_'):\n        from .chain import maybe_chain\n\n        modules = list(modules)\n        for i, m in enumerate(modules):\n            self.set_child(f'{prefix}{i}', maybe_chain(m))\n\n    def get_children_sequence(self, prefix = 'module_'):\n        return [self.children[f'{prefix}{i}'] for i in range(len(self.children)) if f'{prefix}{i}' in self.children]\n\n    def inner_step(\n        self,\n        key: str,\n        objective: \"Objective\",\n        must_exist: bool = True,\n    ) -&gt; \"Objective\":\n        \"\"\"Passes ``objective`` to child and returns it.\"\"\"\n        child = self.children.get(key, None)\n\n        if child is None:\n            if must_exist: raise KeyError(f\"child `{key}` doesn't exist\")\n            return objective\n\n        return child.step(objective)\n\n\n    def inner_step_tensors(\n        self,\n        key: str,\n        tensors: list[torch.Tensor],\n        clone: bool,\n        params: Iterable[torch.Tensor] | None = None,\n        grads: Sequence[torch.Tensor] | None = None,\n        loss: torch.Tensor | None = None,\n        closure: Callable | None = None,\n        objective: \"Objective | None\" = None,\n        must_exist: bool = True\n    ) -&gt; list[torch.Tensor]:\n        \"\"\"Steps with child module. Can be used to apply transforms to any internal buffers.\n\n        If ``objective`` is specified, other attributes shouldn't to be specified.\n\n        Args:\n            key (str): Child module key.\n            tensors (Sequence[torch.Tensor]): tensors to pass to child module.\n            clone (bool):\n                If ``key`` exists, whether to clone ``tensors`` to avoid modifying buffers in-place.\n                If ``key`` doesn't exist, ``tensors`` are always returned without cloning\n            params (Iterable[torch.Tensor] | None, optional):\n                pass None if ``tensors`` have different shape, it will create fake params from tensors\n                for state keys and shape inference. Defaults to None.\n            grads (Sequence[torch.Tensor] | None, optional): grads. Defaults to None.\n            loss (torch.Tensor | None, optional): loss. Defaults to None.\n            closure (Callable | None, optional): closure. Defaults to None.\n            must_exist (bool, optional): if True, if ``key`` doesn't exist, raises ``KeyError``. Defaults to True.\n        \"\"\"\n\n        child = self.children.get(key, None)\n\n        if child is None:\n            if must_exist: raise KeyError(f\"child `{key}` doesn't exist\")\n            return tensors\n\n        if clone: tensors = [t.clone() for t in tensors]\n\n        # set fake params to same storage as tensors so as to not use any extra memory\n        # while they still refer to same python objects, so they can be used\n        # as state keys and for shape inference when params aren't given.\n        fake = params is None\n        if fake:\n            if key not in self._fake_params:\n                self._fake_params[key] = [torch.empty_like(t) for t in tensors]\n            params = self._fake_params[key]\n            _set_fake_params_(params, tensors)\n\n        update = step_tensors(modules=child, tensors=tensors, params=params, grads=grads,\n                            loss=loss, closure=closure, objective=objective)\n\n        # set fake params storage to empty\n        if fake:\n            _empty_fake_param_storage_(params)\n\n        return update\n\n\n    def __repr__(self):\n        s = self.__class__.__name__\n        if self.children:\n            s = f'{s}('\n            for k,v in self.children.items():\n                s = f'{s}{k}={v}, '\n            s = f'{s[:-2]})'\n        return s\n\n    @overload\n    def get_settings(self, params: Sequence[torch.Tensor], key: str, *,\n                     cls: type[ListLike] = list) -&gt; ListLike: ...\n    @overload\n    def get_settings(self, params: Sequence[torch.Tensor], key: list[str] | tuple[str,...], *,\n                     cls: type[ListLike] = list) -&gt; list[ListLike]: ...\n    @overload\n    def get_settings(self, params: Sequence[torch.Tensor], key: str, key2: str, *keys: str,\n                     cls: type[ListLike] = list) -&gt; list[ListLike]: ...\n\n    def get_settings(self, params: Sequence[torch.Tensor], key: str | list[str] | tuple[str,...], key2: str | None = None,\n                     *keys: str, cls: type[ListLike] = list) -&gt; ListLike | list[ListLike]:\n        return get_state_vals(self.settings, params, key, key2, *keys, must_exist=True, cls=cls) # pyright:ignore[reportArgumentType]\n\n\n    @overload\n    def get_state(self, params: Sequence[torch.Tensor], key: str, *,\n                   must_exist: bool = False, init: Init = torch.zeros_like,\n                   cls: type[ListLike] = list) -&gt; ListLike: ...\n    @overload\n    def get_state(self, params: Sequence[torch.Tensor], key: list[str] | tuple[str,...], *,\n                   must_exist: bool = False, init: Init | Sequence[Init] = torch.zeros_like,\n                   cls: type[ListLike] = list) -&gt; list[ListLike]: ...\n    @overload\n    def get_state(self, params: Sequence[torch.Tensor], key: str, key2: str, *keys: str,\n                   must_exist: bool = False, init: Init | Sequence[Init] = torch.zeros_like,\n                   cls: type[ListLike] = list) -&gt; list[ListLike]: ...\n\n    def get_state(self, params: Sequence[torch.Tensor], key: str | list[str] | tuple[str,...], key2: str | None = None, *keys: str,\n                   must_exist: bool = False, init: Init | Sequence[Init] = torch.zeros_like,\n                   cls: type[ListLike] = list) -&gt; ListLike | list[ListLike]:\n        \"\"\"Returns values of per-parameter state for a given key.\n        If key doesn't exist, create it with inits.\n\n        This functions like `operator.itemgetter`, returning a single value if called with a single key,\n        or tuple of called with multiple keys.\n\n        If you want to force it to return a tuple even with a single key, pass a list/tuple of 1 or more keys.\n\n        ```python\n        exp_avg = self.state_vals(\"exp_avg\")\n        # returns cls (by default TensorList)\n\n        exp_avg, exp_avg_sq = self.state_vals(\"exp_avg\", \"exp_avg_sq\")\n        # returns list of cls\n\n        exp_avg = self.state_vals([\"exp_avg\"])\n        # always returns a list of cls, even if got a single key\n        ```\n\n        Args:\n            *keys (str):\n                the keys to look for in each parameters state.\n                if a single key is specified, this returns a single value or cls,\n                otherwise this returns a list of values or cls per each key.\n            params (Iterable[torch.Tensor]): parameters to return the states for.\n            must_exist (bool, optional):\n                If a key doesn't exist in state, if True, raises a KeyError, if False, creates the value\n                using `init` argument (default = False).\n            init (Init | Sequence[Init], optional):\n                how to initialize a key if it doesn't exist.\n\n                can be\n                - Callable like torch.zeros_like\n                - string - \"param\" or \"grad\" to use cloned params or cloned grads.\n                - anything else other than list/tuples will be used as-is, tensors will be cloned.\n                - list/tuple of values per each parameter, only if got a single key.\n                - list/tuple of values per each key, only if got multiple keys.\n\n                if multiple `keys` are specified, inits is per-key!\n\n                Defaults to torch.zeros_like.\n            cls (type[ListLike], optional):\n                MutableSequence class to return, this only has effect when state_keys is a list/tuple. Defaults to list.\n\n        Returns:\n            - if state_keys has a single key and keys has a single key, return a single value.\n            - if state_keys has a single key and keys has multiple keys, return a list of values.\n            - if state_keys has multiple keys and keys has a single key, return cls.\n            - if state_keys has multiple keys and keys has multiple keys, return list of cls.\n        \"\"\"\n        return get_state_vals(self.state, params, key, key2, *keys, must_exist=must_exist, init=init, cls=cls) # pyright:ignore[reportArgumentType]\n\n    def clear_state_keys(self, *keys:str):\n        for s in self.state.values():\n            for k in keys:\n                if k in s: del s[k]\n\n    @overload\n    def store(self, params: Sequence[torch.Tensor], keys: str, values: Sequence): ...\n    @overload\n    def store(self, params: Sequence[torch.Tensor], keys: Sequence[str], values: Sequence[Sequence]): ...\n    def store(self, params: Sequence[torch.Tensor], keys: str | Sequence[str], values: Sequence):\n        if isinstance(keys, str):\n            for p,v in zip(params, values):\n                state = self.state[p]\n                state[keys] = v\n            return\n\n        for p, *p_v in zip(params, *values):\n            state = self.state[p]\n            for k,v in zip(keys, p_v): state[k] = v\n\n    def state_dict(self):\n        \"\"\"state dict\"\"\"\n        packed_state = {id(k):v for k,v in self.state.items()}\n        packed_settings = {id(k):v for k,v in self.settings.items()}\n\n        state_dict = {\n            \"state\": packed_state,\n            \"settings\":\n                {\n                    \"local\": {k:v.maps[0] for k,v in packed_settings.items()},\n                    \"global\": {k:v.maps[1] for k,v in packed_settings.items()},\n                    \"defaults\": {k:v.maps[2] for k,v in packed_settings.items()},\n                },\n            \"global_state\": self.global_state,\n            \"extra\": self._extra_pack(),\n            \"children\": {k: v.state_dict() for k, v in self.children.items()}\n        }\n        return state_dict\n\n    def _load_state_dict(self, state_dict: dict[str, Any], id_to_tensor: dict[int, torch.Tensor]):\n        \"\"\"loads state_dict, ``id_to_tensor`` is passed by ``Optimizer``\"\"\"\n        # load state\n        state = state_dict['state']\n        self.state.clear()\n        self.state.update({id_to_tensor[k]:v for k,v in state.items()})\n\n        # load settings\n        settings = state_dict['settings']\n        self.settings.clear()\n        for k, v in settings['local'].items(): self.settings[id_to_tensor[k]].maps[0].update(v)\n        for k, v in settings['global'].items(): self.settings[id_to_tensor[k]].maps[1].update(v)\n        for k, v in settings['defaults'].items(): self.settings[id_to_tensor[k]].maps[2].update(v)\n\n        # load global state\n        self.global_state.clear()\n        self.global_state.update(state_dict['global_state'])\n\n        # children\n        for k, v in state_dict['children']:\n            if k in self.children: self.children[k]._load_state_dict(v, id_to_tensor)\n            else: warnings.warn(f'State dict for {self} has child {k}, which is missing in {self}')\n\n        # extra info\n        self._extra_unpack(state_dict['extra'])\n\n    def get_generator(self, device: torch.types.Device, seed: int | None):\n        \"\"\"If ``seed=None``, returns ``None``.\n\n        Otherwise, if generator on this device and with this seed hasn't been created,\n        creates it and stores in global state.\n\n        Returns ``torch.Generator``.\"\"\"\n        if seed is None: return None\n\n        if device is None: device_obj = torch.get_default_device()\n        else: device_obj = torch.device(device)\n        key = f\"__generator-{seed}-{device_obj.type}:{device_obj.index}\"\n\n        if key not in self.global_state:\n            self.global_state[key] = torch.Generator(device).manual_seed(seed)\n\n        return self.global_state[key]\n\n    def increment_counter(self, key: str, start: int):\n        \"\"\"first value is ``start``\"\"\"\n        value = self.global_state.get(key, start - 1) + 1\n        self.global_state[key] = value\n        return value\n\n    def get_child_projected_buffers(self, key: str, buff: ProjectedBuffer | Sequence[ProjectedBuffer], params:Sequence[torch.Tensor] | None = None) -&gt; list[list[torch.Tensor]]:\n        \"\"\"if params is None, assumes fake parameters\"\"\"\n        if isinstance(buff, str): buff = (buff, )\n\n        child = self.children[key]\n        child.on_get_projected_buffers()\n        if params is None:\n            params = self._fake_params[key]\n\n        vals = []\n        for b in buff:\n            for buff_key in child._projected_keys[b]:\n                state = child.state[params[0]]\n                if buff_key in state:\n                    tensors = [child.state[p][buff_key] for p in params]\n                    if isinstance(tensors[0], torch.Tensor):\n                        vals.append(tensors)\n                    else: # its usually a deque\n                        assert isinstance(tensors[0], Sequence), type(tensors[0])\n                        vals.extend(zip(*tensors))\n\n                elif buff_key in child.global_state:\n                    val = child.global_state[buff_key]\n                    if len(val) == 0: continue\n                    if isinstance(val[0], torch.Tensor):\n                        vals.append(val)\n                    else:\n                        assert isinstance(val[0], Sequence)\n                        vals.extend(zip(*vals))\n\n        # recursively do this on children,\n        # note that if params are fake, children will have same fake params\n        # unless that child steps with something else. I don't think that is feasible to support it\n        for c in child.children:\n            vals.extend(child.get_child_projected_buffers(c, buff, params=params))\n\n        return vals\n\n    def add_projected_keys(self, buffer: ProjectedBuffer, *keys):\n        for k in keys: self._projected_keys[buffer].add(k)\n\n\n    # ---------------------------- OVERRIDABLE METHODS --------------------------- #\n    def update(self, objective:\"Objective\") -&gt; None:\n        \"\"\"Updates internal state of this module. This should not modify ``objective.update``.\n\n        Specifying ``update`` and ``apply`` methods is optional and allows certain meta-modules to be used,\n        such as ``tz.m.Online`` or trust regions. Alternatively, define all logic within the ``apply`` method.\n\n        ``update`` is guaranteed to be called at least once before ``apply``.\n\n        Args:\n            objective (Objective): ``Objective`` object\n        \"\"\"\n\n    @abstractmethod\n    def apply(self, objective: \"Objective\") -&gt; \"Objective\":\n        \"\"\"Updates ``objective`` using the internal state of this module.\n\n        If ``update`` method is defined, ``apply`` shouldn't modify the internal state of this module if possible.\n\n        Specifying ``update`` and ``apply`` methods is optional and allows certain meta-modules to be used,\n        such as ``tz.m.Online`` or trust regions. Alternatively, define all logic within the ``apply`` method.\n\n        ``update`` is guaranteed to be called at least once before ``apply``.\n\n        Args:\n            objective (Objective): ``Objective`` object\n        \"\"\"\n        # if apply is empty, it should be defined explicitly.\n        raise NotImplementedError(f\"{self.__class__.__name__} doesn't implement `apply`.\")\n\n    def step(self, objective: \"Objective\") -&gt; \"Objective\":\n        \"\"\"Perform a step with this module. Calls ``update``, then ``apply``.\"\"\"\n        self.update(objective)\n        return self.apply(objective)\n\n    def get_H(self, objective: \"Objective\") -&gt; LinearOperator | None:\n        \"\"\"returns a ``LinearOperator`` corresponding to hessian or hessian approximation.\n        The hessian approximation is assumed to be for all parameters concatenated to a vector.\"\"\"\n        # if this method is not defined it searches in children\n        # this should be overwritten to return None if child params are different from this modules params\n        H = None\n        for k,v in self.children.items():\n            H_v = v.get_H(objective)\n\n            if (H is not None) and (H_v is not None):\n                raise RuntimeError(f\"Two children of {self} have a hessian, second one is {k}={v}\")\n\n            if H_v is not None: H = H_v\n\n        return H\n\n    def reset(self):\n        \"\"\"Resets the internal state of the module (e.g. momentum) and all children. By default clears state and global state.\"\"\"\n        self.state.clear()\n\n        generator = self.global_state.get(\"generator\", None)\n        self.global_state.clear()\n        if generator is not None: self.global_state[\"generator\"] = generator\n\n        for c in self.children.values(): c.reset()\n\n    def reset_for_online(self):\n        \"\"\"Resets buffers that depend on previous evaluation, such as previous gradient and loss,\n        which may become inaccurate due to mini-batching.\n\n        ``Online`` module calls ``reset_for_online``,\n        then it calls ``update`` with previous parameters,\n        then it calls ``update`` with current parameters,\n        and then ``apply``.\n        \"\"\"\n        for c in self.children.values(): c.reset_for_online()\n\n    def on_get_projected_buffers(self):\n        \"\"\"runs before projected buffers are accessed\"\"\"\n\n    def _extra_pack(self) -&gt; dict:\n        \"\"\"extra information to store in ``state_dict`` of this optimizer.\n        Will be passed to ``_extra_unpack`` when loading the ``state_dict``.\"\"\"\n        return {}\n\n    def _extra_unpack(self, d: dict):\n        \"\"\"``_extra_pack`` return will be passed to this method when loading ``state_dict``.\n        This method is called after loading the rest of the state dict\"\"\"\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.apply","title":"apply","text":"<pre><code>apply(objective: Objective) -&gt; Objective\n</code></pre> <p>Updates <code>objective</code> using the internal state of this module.</p> <p>If <code>update</code> method is defined, <code>apply</code> shouldn't modify the internal state of this module if possible.</p> <p>Specifying <code>update</code> and <code>apply</code> methods is optional and allows certain meta-modules to be used, such as <code>tz.m.Online</code> or trust regions. Alternatively, define all logic within the <code>apply</code> method.</p> <p><code>update</code> is guaranteed to be called at least once before <code>apply</code>.</p> <p>Parameters:</p> <ul> <li> <code>objective</code>               (<code>Objective</code>)           \u2013            <p><code>Objective</code> object</p> </li> </ul> Source code in <code>torchzero/core/module.py</code> <pre><code>@abstractmethod\ndef apply(self, objective: \"Objective\") -&gt; \"Objective\":\n    \"\"\"Updates ``objective`` using the internal state of this module.\n\n    If ``update`` method is defined, ``apply`` shouldn't modify the internal state of this module if possible.\n\n    Specifying ``update`` and ``apply`` methods is optional and allows certain meta-modules to be used,\n    such as ``tz.m.Online`` or trust regions. Alternatively, define all logic within the ``apply`` method.\n\n    ``update`` is guaranteed to be called at least once before ``apply``.\n\n    Args:\n        objective (Objective): ``Objective`` object\n    \"\"\"\n    # if apply is empty, it should be defined explicitly.\n    raise NotImplementedError(f\"{self.__class__.__name__} doesn't implement `apply`.\")\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.get_H","title":"get_H","text":"<pre><code>get_H(objective: Objective) -&gt; LinearOperator | None\n</code></pre> <p>returns a <code>LinearOperator</code> corresponding to hessian or hessian approximation. The hessian approximation is assumed to be for all parameters concatenated to a vector.</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def get_H(self, objective: \"Objective\") -&gt; LinearOperator | None:\n    \"\"\"returns a ``LinearOperator`` corresponding to hessian or hessian approximation.\n    The hessian approximation is assumed to be for all parameters concatenated to a vector.\"\"\"\n    # if this method is not defined it searches in children\n    # this should be overwritten to return None if child params are different from this modules params\n    H = None\n    for k,v in self.children.items():\n        H_v = v.get_H(objective)\n\n        if (H is not None) and (H_v is not None):\n            raise RuntimeError(f\"Two children of {self} have a hessian, second one is {k}={v}\")\n\n        if H_v is not None: H = H_v\n\n    return H\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.get_child_projected_buffers","title":"get_child_projected_buffers","text":"<pre><code>get_child_projected_buffers(key: str, buff: Union[Literal['grad', 'grad_sq', 'grad_cu', 'covariance', 'inverse'], Sequence[Literal['grad', 'grad_sq', 'grad_cu', 'covariance', 'inverse']]], params: Sequence[Tensor] | None = None) -&gt; list[list[Tensor]]\n</code></pre> <p>if params is None, assumes fake parameters</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def get_child_projected_buffers(self, key: str, buff: ProjectedBuffer | Sequence[ProjectedBuffer], params:Sequence[torch.Tensor] | None = None) -&gt; list[list[torch.Tensor]]:\n    \"\"\"if params is None, assumes fake parameters\"\"\"\n    if isinstance(buff, str): buff = (buff, )\n\n    child = self.children[key]\n    child.on_get_projected_buffers()\n    if params is None:\n        params = self._fake_params[key]\n\n    vals = []\n    for b in buff:\n        for buff_key in child._projected_keys[b]:\n            state = child.state[params[0]]\n            if buff_key in state:\n                tensors = [child.state[p][buff_key] for p in params]\n                if isinstance(tensors[0], torch.Tensor):\n                    vals.append(tensors)\n                else: # its usually a deque\n                    assert isinstance(tensors[0], Sequence), type(tensors[0])\n                    vals.extend(zip(*tensors))\n\n            elif buff_key in child.global_state:\n                val = child.global_state[buff_key]\n                if len(val) == 0: continue\n                if isinstance(val[0], torch.Tensor):\n                    vals.append(val)\n                else:\n                    assert isinstance(val[0], Sequence)\n                    vals.extend(zip(*vals))\n\n    # recursively do this on children,\n    # note that if params are fake, children will have same fake params\n    # unless that child steps with something else. I don't think that is feasible to support it\n    for c in child.children:\n        vals.extend(child.get_child_projected_buffers(c, buff, params=params))\n\n    return vals\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.get_generator","title":"get_generator","text":"<pre><code>get_generator(device: Union[device, str, int, NoneType], seed: int | None)\n</code></pre> <p>If <code>seed=None</code>, returns <code>None</code>.</p> <p>Otherwise, if generator on this device and with this seed hasn't been created, creates it and stores in global state.</p> <p>Returns <code>torch.Generator</code>.</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def get_generator(self, device: torch.types.Device, seed: int | None):\n    \"\"\"If ``seed=None``, returns ``None``.\n\n    Otherwise, if generator on this device and with this seed hasn't been created,\n    creates it and stores in global state.\n\n    Returns ``torch.Generator``.\"\"\"\n    if seed is None: return None\n\n    if device is None: device_obj = torch.get_default_device()\n    else: device_obj = torch.device(device)\n    key = f\"__generator-{seed}-{device_obj.type}:{device_obj.index}\"\n\n    if key not in self.global_state:\n        self.global_state[key] = torch.Generator(device).manual_seed(seed)\n\n    return self.global_state[key]\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.get_state","title":"get_state","text":"<pre><code>get_state(params: Sequence[Tensor], key: str | list[str] | tuple[str, ...], key2: str | None = None, *keys: str, must_exist: bool = False, init: Any | Sequence[Any] = zeros_like, cls: type[~ListLike] = list) -&gt; Union[~ListLike, list[~ListLike]]\n</code></pre> <p>Returns values of per-parameter state for a given key. If key doesn't exist, create it with inits.</p> <p>This functions like <code>operator.itemgetter</code>, returning a single value if called with a single key, or tuple of called with multiple keys.</p> <p>If you want to force it to return a tuple even with a single key, pass a list/tuple of 1 or more keys.</p> <pre><code>exp_avg = self.state_vals(\"exp_avg\")\n# returns cls (by default TensorList)\n\nexp_avg, exp_avg_sq = self.state_vals(\"exp_avg\", \"exp_avg_sq\")\n# returns list of cls\n\nexp_avg = self.state_vals([\"exp_avg\"])\n# always returns a list of cls, even if got a single key\n</code></pre> <p>Parameters:</p> <ul> <li> <code>*keys</code>               (<code>str</code>)           \u2013            <p>the keys to look for in each parameters state. if a single key is specified, this returns a single value or cls, otherwise this returns a list of values or cls per each key.</p> </li> <li> <code>params</code>               (<code>Iterable[Tensor]</code>)           \u2013            <p>parameters to return the states for.</p> </li> <li> <code>must_exist</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If a key doesn't exist in state, if True, raises a KeyError, if False, creates the value using <code>init</code> argument (default = False).</p> </li> <li> <code>init</code>               (<code>Any | Sequence[Any]</code>, default:                   <code>zeros_like</code> )           \u2013            <p>how to initialize a key if it doesn't exist.</p> <p>can be - Callable like torch.zeros_like - string - \"param\" or \"grad\" to use cloned params or cloned grads. - anything else other than list/tuples will be used as-is, tensors will be cloned. - list/tuple of values per each parameter, only if got a single key. - list/tuple of values per each key, only if got multiple keys.</p> <p>if multiple <code>keys</code> are specified, inits is per-key!</p> <p>Defaults to torch.zeros_like.</p> </li> <li> <code>cls</code>               (<code>type[ListLike]</code>, default:                   <code>list</code> )           \u2013            <p>MutableSequence class to return, this only has effect when state_keys is a list/tuple. Defaults to list.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[~ListLike, list[~ListLike]]</code>           \u2013            <ul> <li>if state_keys has a single key and keys has a single key, return a single value.</li> </ul> </li> <li> <code>Union[~ListLike, list[~ListLike]]</code>           \u2013            <ul> <li>if state_keys has a single key and keys has multiple keys, return a list of values.</li> </ul> </li> <li> <code>Union[~ListLike, list[~ListLike]]</code>           \u2013            <ul> <li>if state_keys has multiple keys and keys has a single key, return cls.</li> </ul> </li> <li> <code>Union[~ListLike, list[~ListLike]]</code>           \u2013            <ul> <li>if state_keys has multiple keys and keys has multiple keys, return list of cls.</li> </ul> </li> </ul> Source code in <code>torchzero/core/module.py</code> <pre><code>def get_state(self, params: Sequence[torch.Tensor], key: str | list[str] | tuple[str,...], key2: str | None = None, *keys: str,\n               must_exist: bool = False, init: Init | Sequence[Init] = torch.zeros_like,\n               cls: type[ListLike] = list) -&gt; ListLike | list[ListLike]:\n    \"\"\"Returns values of per-parameter state for a given key.\n    If key doesn't exist, create it with inits.\n\n    This functions like `operator.itemgetter`, returning a single value if called with a single key,\n    or tuple of called with multiple keys.\n\n    If you want to force it to return a tuple even with a single key, pass a list/tuple of 1 or more keys.\n\n    ```python\n    exp_avg = self.state_vals(\"exp_avg\")\n    # returns cls (by default TensorList)\n\n    exp_avg, exp_avg_sq = self.state_vals(\"exp_avg\", \"exp_avg_sq\")\n    # returns list of cls\n\n    exp_avg = self.state_vals([\"exp_avg\"])\n    # always returns a list of cls, even if got a single key\n    ```\n\n    Args:\n        *keys (str):\n            the keys to look for in each parameters state.\n            if a single key is specified, this returns a single value or cls,\n            otherwise this returns a list of values or cls per each key.\n        params (Iterable[torch.Tensor]): parameters to return the states for.\n        must_exist (bool, optional):\n            If a key doesn't exist in state, if True, raises a KeyError, if False, creates the value\n            using `init` argument (default = False).\n        init (Init | Sequence[Init], optional):\n            how to initialize a key if it doesn't exist.\n\n            can be\n            - Callable like torch.zeros_like\n            - string - \"param\" or \"grad\" to use cloned params or cloned grads.\n            - anything else other than list/tuples will be used as-is, tensors will be cloned.\n            - list/tuple of values per each parameter, only if got a single key.\n            - list/tuple of values per each key, only if got multiple keys.\n\n            if multiple `keys` are specified, inits is per-key!\n\n            Defaults to torch.zeros_like.\n        cls (type[ListLike], optional):\n            MutableSequence class to return, this only has effect when state_keys is a list/tuple. Defaults to list.\n\n    Returns:\n        - if state_keys has a single key and keys has a single key, return a single value.\n        - if state_keys has a single key and keys has multiple keys, return a list of values.\n        - if state_keys has multiple keys and keys has a single key, return cls.\n        - if state_keys has multiple keys and keys has multiple keys, return list of cls.\n    \"\"\"\n    return get_state_vals(self.state, params, key, key2, *keys, must_exist=must_exist, init=init, cls=cls) # pyright:ignore[reportArgumentType]\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.increment_counter","title":"increment_counter","text":"<pre><code>increment_counter(key: str, start: int)\n</code></pre> <p>first value is <code>start</code></p> Source code in <code>torchzero/core/module.py</code> <pre><code>def increment_counter(self, key: str, start: int):\n    \"\"\"first value is ``start``\"\"\"\n    value = self.global_state.get(key, start - 1) + 1\n    self.global_state[key] = value\n    return value\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.inner_step","title":"inner_step","text":"<pre><code>inner_step(key: str, objective: Objective, must_exist: bool = True) -&gt; Objective\n</code></pre> <p>Passes <code>objective</code> to child and returns it.</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def inner_step(\n    self,\n    key: str,\n    objective: \"Objective\",\n    must_exist: bool = True,\n) -&gt; \"Objective\":\n    \"\"\"Passes ``objective`` to child and returns it.\"\"\"\n    child = self.children.get(key, None)\n\n    if child is None:\n        if must_exist: raise KeyError(f\"child `{key}` doesn't exist\")\n        return objective\n\n    return child.step(objective)\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.inner_step_tensors","title":"inner_step_tensors","text":"<pre><code>inner_step_tensors(key: str, tensors: list[Tensor], clone: bool, params: Iterable[Tensor] | None = None, grads: Sequence[Tensor] | None = None, loss: Tensor | None = None, closure: Callable | None = None, objective: Objective | None = None, must_exist: bool = True) -&gt; list[Tensor]\n</code></pre> <p>Steps with child module. Can be used to apply transforms to any internal buffers.</p> <p>If <code>objective</code> is specified, other attributes shouldn't to be specified.</p> <p>Parameters:</p> <ul> <li> <code>key</code>               (<code>str</code>)           \u2013            <p>Child module key.</p> </li> <li> <code>tensors</code>               (<code>Sequence[Tensor]</code>)           \u2013            <p>tensors to pass to child module.</p> </li> <li> <code>clone</code>               (<code>bool</code>)           \u2013            <p>If <code>key</code> exists, whether to clone <code>tensors</code> to avoid modifying buffers in-place. If <code>key</code> doesn't exist, <code>tensors</code> are always returned without cloning</p> </li> <li> <code>params</code>               (<code>Iterable[Tensor] | None</code>, default:                   <code>None</code> )           \u2013            <p>pass None if <code>tensors</code> have different shape, it will create fake params from tensors for state keys and shape inference. Defaults to None.</p> </li> <li> <code>grads</code>               (<code>Sequence[Tensor] | None</code>, default:                   <code>None</code> )           \u2013            <p>grads. Defaults to None.</p> </li> <li> <code>loss</code>               (<code>Tensor | None</code>, default:                   <code>None</code> )           \u2013            <p>loss. Defaults to None.</p> </li> <li> <code>closure</code>               (<code>Callable | None</code>, default:                   <code>None</code> )           \u2013            <p>closure. Defaults to None.</p> </li> <li> <code>must_exist</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, if <code>key</code> doesn't exist, raises <code>KeyError</code>. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/core/module.py</code> <pre><code>def inner_step_tensors(\n    self,\n    key: str,\n    tensors: list[torch.Tensor],\n    clone: bool,\n    params: Iterable[torch.Tensor] | None = None,\n    grads: Sequence[torch.Tensor] | None = None,\n    loss: torch.Tensor | None = None,\n    closure: Callable | None = None,\n    objective: \"Objective | None\" = None,\n    must_exist: bool = True\n) -&gt; list[torch.Tensor]:\n    \"\"\"Steps with child module. Can be used to apply transforms to any internal buffers.\n\n    If ``objective`` is specified, other attributes shouldn't to be specified.\n\n    Args:\n        key (str): Child module key.\n        tensors (Sequence[torch.Tensor]): tensors to pass to child module.\n        clone (bool):\n            If ``key`` exists, whether to clone ``tensors`` to avoid modifying buffers in-place.\n            If ``key`` doesn't exist, ``tensors`` are always returned without cloning\n        params (Iterable[torch.Tensor] | None, optional):\n            pass None if ``tensors`` have different shape, it will create fake params from tensors\n            for state keys and shape inference. Defaults to None.\n        grads (Sequence[torch.Tensor] | None, optional): grads. Defaults to None.\n        loss (torch.Tensor | None, optional): loss. Defaults to None.\n        closure (Callable | None, optional): closure. Defaults to None.\n        must_exist (bool, optional): if True, if ``key`` doesn't exist, raises ``KeyError``. Defaults to True.\n    \"\"\"\n\n    child = self.children.get(key, None)\n\n    if child is None:\n        if must_exist: raise KeyError(f\"child `{key}` doesn't exist\")\n        return tensors\n\n    if clone: tensors = [t.clone() for t in tensors]\n\n    # set fake params to same storage as tensors so as to not use any extra memory\n    # while they still refer to same python objects, so they can be used\n    # as state keys and for shape inference when params aren't given.\n    fake = params is None\n    if fake:\n        if key not in self._fake_params:\n            self._fake_params[key] = [torch.empty_like(t) for t in tensors]\n        params = self._fake_params[key]\n        _set_fake_params_(params, tensors)\n\n    update = step_tensors(modules=child, tensors=tensors, params=params, grads=grads,\n                        loss=loss, closure=closure, objective=objective)\n\n    # set fake params storage to empty\n    if fake:\n        _empty_fake_param_storage_(params)\n\n    return update\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.on_get_projected_buffers","title":"on_get_projected_buffers","text":"<pre><code>on_get_projected_buffers()\n</code></pre> <p>runs before projected buffers are accessed</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def on_get_projected_buffers(self):\n    \"\"\"runs before projected buffers are accessed\"\"\"\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> <p>Resets the internal state of the module (e.g. momentum) and all children. By default clears state and global state.</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def reset(self):\n    \"\"\"Resets the internal state of the module (e.g. momentum) and all children. By default clears state and global state.\"\"\"\n    self.state.clear()\n\n    generator = self.global_state.get(\"generator\", None)\n    self.global_state.clear()\n    if generator is not None: self.global_state[\"generator\"] = generator\n\n    for c in self.children.values(): c.reset()\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.reset_for_online","title":"reset_for_online","text":"<pre><code>reset_for_online()\n</code></pre> <p>Resets buffers that depend on previous evaluation, such as previous gradient and loss, which may become inaccurate due to mini-batching.</p> <p><code>Online</code> module calls <code>reset_for_online</code>, then it calls <code>update</code> with previous parameters, then it calls <code>update</code> with current parameters, and then <code>apply</code>.</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def reset_for_online(self):\n    \"\"\"Resets buffers that depend on previous evaluation, such as previous gradient and loss,\n    which may become inaccurate due to mini-batching.\n\n    ``Online`` module calls ``reset_for_online``,\n    then it calls ``update`` with previous parameters,\n    then it calls ``update`` with current parameters,\n    and then ``apply``.\n    \"\"\"\n    for c in self.children.values(): c.reset_for_online()\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.set_param_groups","title":"set_param_groups","text":"<pre><code>set_param_groups(param_groups: Iterable[Tensor | tuple[str, Tensor] | Mapping[str, Any]])\n</code></pre> <p>Set custom parameter groups with per-parameter settings that this module will use.</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def set_param_groups(self, param_groups: Params):\n    \"\"\"Set custom parameter groups with per-parameter settings that this module will use.\"\"\"\n    param_groups = _make_param_groups(param_groups, differentiable=False)\n    for group in param_groups:\n        settings = group.copy()\n        params = settings.pop('params')\n        if not settings: continue\n        self._overridden_keys.update(*settings.keys())\n\n        for param in params:\n            self.settings[param].maps[0].update(settings) # set module-specific per-parameter settings\n    return self\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.state_dict","title":"state_dict","text":"<pre><code>state_dict()\n</code></pre> <p>state dict</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def state_dict(self):\n    \"\"\"state dict\"\"\"\n    packed_state = {id(k):v for k,v in self.state.items()}\n    packed_settings = {id(k):v for k,v in self.settings.items()}\n\n    state_dict = {\n        \"state\": packed_state,\n        \"settings\":\n            {\n                \"local\": {k:v.maps[0] for k,v in packed_settings.items()},\n                \"global\": {k:v.maps[1] for k,v in packed_settings.items()},\n                \"defaults\": {k:v.maps[2] for k,v in packed_settings.items()},\n            },\n        \"global_state\": self.global_state,\n        \"extra\": self._extra_pack(),\n        \"children\": {k: v.state_dict() for k, v in self.children.items()}\n    }\n    return state_dict\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.step","title":"step","text":"<pre><code>step(objective: Objective) -&gt; Objective\n</code></pre> <p>Perform a step with this module. Calls <code>update</code>, then <code>apply</code>.</p> Source code in <code>torchzero/core/module.py</code> <pre><code>def step(self, objective: \"Objective\") -&gt; \"Objective\":\n    \"\"\"Perform a step with this module. Calls ``update``, then ``apply``.\"\"\"\n    self.update(objective)\n    return self.apply(objective)\n</code></pre>"},{"location":"API/core/#torchzero.core.Module.update","title":"update","text":"<pre><code>update(objective: Objective) -&gt; None\n</code></pre> <p>Updates internal state of this module. This should not modify <code>objective.update</code>.</p> <p>Specifying <code>update</code> and <code>apply</code> methods is optional and allows certain meta-modules to be used, such as <code>tz.m.Online</code> or trust regions. Alternatively, define all logic within the <code>apply</code> method.</p> <p><code>update</code> is guaranteed to be called at least once before <code>apply</code>.</p> <p>Parameters:</p> <ul> <li> <code>objective</code>               (<code>Objective</code>)           \u2013            <p><code>Objective</code> object</p> </li> </ul> Source code in <code>torchzero/core/module.py</code> <pre><code>def update(self, objective:\"Objective\") -&gt; None:\n    \"\"\"Updates internal state of this module. This should not modify ``objective.update``.\n\n    Specifying ``update`` and ``apply`` methods is optional and allows certain meta-modules to be used,\n    such as ``tz.m.Online`` or trust regions. Alternatively, define all logic within the ``apply`` method.\n\n    ``update`` is guaranteed to be called at least once before ``apply``.\n\n    Args:\n        objective (Objective): ``Objective`` object\n    \"\"\"\n</code></pre>"},{"location":"API/core/#torchzero.core.Optimizer","title":"Optimizer","text":"<p>               Bases: <code>torch.optim.optimizer.Optimizer</code></p> <p>Chains multiple modules into an optimizer.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>Iterable | Module</code>)           \u2013            <p>An iterable of parameters to optimize (typically <code>model.parameters()</code>), an iterable of parameter group dicts, or a <code>torch.nn.Module</code> instance.</p> </li> <li> <code>*modules</code>               (<code>Module</code>)           \u2013            <p>A sequence of <code>Module</code> instances that define the optimization algorithm steps.</p> </li> </ul> Source code in <code>torchzero/core/modular.py</code> <pre><code>class Optimizer(torch.optim.Optimizer):\n    \"\"\"Chains multiple modules into an optimizer.\n\n    Args:\n        params (Params | torch.nn.Module): An iterable of parameters to optimize\n            (typically `model.parameters()`), an iterable of parameter group dicts,\n            or a `torch.nn.Module` instance.\n        *modules (Module): A sequence of `Module` instances that define the\n            optimization algorithm steps.\n    \"\"\"\n    # this is specifically for lr schedulers\n    param_groups: list[ChainMap[str, Any]] # pyright:ignore[reportIncompatibleVariableOverride]\n\n    def __init__(self, params: Params | torch.nn.Module, *modules: Module):\n        if len(modules) == 0: raise RuntimeError(\"Empty list of modules passed to `Optimizer`\")\n        self.model: torch.nn.Module | None = None\n        \"\"\"The model whose parameters are being optimized, if a model instance was passed to `__init__`.\"\"\"\n        if isinstance(params, torch.nn.Module):\n            self.model = params\n            params = params.parameters()\n\n        self.modules = modules\n        \"\"\"Top-level modules providedduring initialization.\"\"\"\n\n        self.flat_modules = flatten_modules(self.modules)\n        \"\"\"A flattened list of all modules including all children.\"\"\"\n\n        param_groups = _make_param_groups(params, differentiable=False)\n        self._per_parameter_global_settings: dict[torch.Tensor, list[MutableMapping[str, Any]]] = {}\n        \"\"\"Maps each parameter tensor to a list of per-module global settings.\n        Each element in the list is ChainDict's 2nd map of a module.\"\"\"\n\n        # make sure there is no more than a single learning rate module\n        lr_modules = [m for m in self.flat_modules if 'lr' in m.defaults]\n        if len(lr_modules) &gt; 1:\n            warnings.warn(f'multiple learning rate modules detected: {lr_modules}. This may lead to componding of learning rate multiplication with per-parameter learning rates and schedulers.')\n\n        # iterate over all per-parameter settings overrides and check if they are applied at most once\n        for group in param_groups:\n            for k in group:\n                if k in ('params', 'lr'): continue\n                modules_with_k = [m for m in self.flat_modules if k in m.defaults and k not in m._overridden_keys]\n                if len(modules_with_k) &gt; 1:\n                    warnings.warn(f'`params` has a `{k}` key, and multiple modules have that key: {modules_with_k}. If you intended to only set `{k}` to one of them, use `module.set_param_groups(params)`')\n\n        # defaults for schedulers\n        defaults = {}\n        for m in self.flat_modules: defaults.update(m.defaults)\n        super().__init__(param_groups, defaults=defaults)\n\n        # note - this is what super().__init__(param_groups, defaults=defaults) does:\n\n        # self.defaults = defaults\n        # for param_group in param_groups:\n        #     self.add_param_group(param_group)\n\n        # add_param_group adds a ChainMap where defaults are lowest priority,\n        # and entries specifed in param_groups or scheduler are higher priority.\n        # pytorch schedulers do group[\"lr\"] = new_lr, which sets higher priority key.\n        # in each module, settings passed to that module by calling set_param_groups are highest priority\n\n        self.current_step = 0\n        \"\"\"global step counter for the optimizer.\"\"\"\n\n        self.num_evaluations = 0\n        \"\"\"number of times the objective has been evaluated (number of closure calls or number of steps if closure is None).\"\"\"\n\n        # reformulations will change the closure to return a different loss (e.g. a sqrt homotopy, gaussian homotopy)\n        # we want to return original loss so this attribute is used\n        self._closure_return = None\n        \"\"\"on each step, first time a closure is evaluated, this attribute is set to the returned value. `step` method returns this.\"\"\"\n\n        self.attrs = {}\n        \"\"\"custom attributes that can be set by modules, for example EMA of weights or best so far\"\"\"\n\n        self.should_terminate = False\n        \"\"\"is set to True by termination criteria modules.\"\"\"\n\n    def add_param_group(self, param_group: dict[str, Any]):\n        proc_param_group = _make_param_groups([param_group], differentiable=False)[0]\n        self.param_groups.append(ChainMap(proc_param_group, self.defaults))\n        # setting param_group[key] = value sets it to first map (the `proc_param_group`).\n        # therefore lr schedulers override defaults, but not settings passed to individual modules\n        # by `set_param_groups` .\n\n        for p in proc_param_group['params']:\n            # updates global per-parameter setting overrides (medium priority)\n            self._per_parameter_global_settings[p] = [m.settings[p].maps[1] for m in self.flat_modules]\n\n    def state_dict(self):\n        all_params = [p for g in self.param_groups for p in g['params']]\n        id_to_idx = {id(p): i for i,p in enumerate(all_params)}\n\n        groups = []\n        for g in self.param_groups:\n            g = g.copy()\n            g['params'] = [id_to_idx[id(p)] for p in g['params']]\n            groups.append(g)\n\n        state_dict = {\n            \"idx_to_id\": {v:k for k,v in id_to_idx.items()},\n            \"params\": all_params,\n            \"groups\": groups,\n            \"defaults\": self.defaults,\n            \"modules\": {i: m.state_dict() for i, m in enumerate(self.flat_modules)}\n        }\n        return state_dict\n\n    def load_state_dict(self, state_dict: dict):\n        self.defaults.clear()\n        self.defaults.update(state_dict['defaults'])\n\n        idx_to_param = dict(enumerate(state_dict['params']))\n        groups = []\n        for g in state_dict['groups']:\n            g = g.copy()\n            g['params'] = [idx_to_param[p] for p in g['params']]\n            groups.append(g)\n\n        self.param_groups.clear()\n        for group in groups:\n            self.add_param_group(group)\n\n        id_to_tensor = {state_dict['idx_to_id'][i]: p for i,p in enumerate(state_dict['params'])}\n        for m, sd in zip(self.flat_modules, state_dict['modules'].values()):\n            m._load_state_dict(sd, id_to_tensor)\n\n\n    def step(self, closure=None, loss=None, **kwargs): # pyright: ignore[reportIncompatibleMethodOverride]\n        # clear closure return from previous step\n        self._closure_return = None\n\n        # propagate global per-parameter setting overrides\n        for g in self.param_groups:\n            settings = dict(g.maps[0]) # ignore defaults\n            params = settings.pop('params')\n            if not settings: continue\n\n            for p in params:\n                if not p.requires_grad: continue\n                for map in self._per_parameter_global_settings[p]: map.update(settings)\n\n        # create Objective\n        params = [p for g in self.param_groups for p in g['params'] if p.requires_grad]\n\n        counter_closure = None\n        if closure is not None:\n            counter_closure = _EvalCounterClosure(self, closure)\n\n        objective = Objective(\n            params=params, closure=counter_closure, model=self.model,\n            current_step=self.current_step, modular=self, loss=loss, storage=kwargs\n        )\n\n        # step with all modules\n        objective = step(objective, self.modules)\n\n        # apply update to parameters unless `objective.skip_update = True`\n        # this does:\n        # if not objective.skip_update:\n        #   torch._foreach_sub_(objective.params, objective.get_updates())\n        objective.update_parameters()\n\n        # update attributes\n        self.attrs.update(objective.attrs)\n        if objective.should_terminate is not None:\n            self.should_terminate = objective.should_terminate\n\n        self.current_step += 1\n\n        # apply hooks\n        # this does:\n        # for hook in objective.post_step_hooks:\n        #     hook(objective, modules)\n        objective.apply_post_step_hooks(self.modules)\n\n        # return the first closure evaluation return\n        # could return loss if it was passed but that's pointless\n        return self._closure_return\n\n    def __repr__(self):\n        return f'Optimizer({\", \".join(str(m) for m in self.modules)})'\n</code></pre>"},{"location":"API/core/#torchzero.core.TensorTransform","title":"TensorTransform","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p><code>TensorTransform</code> is a <code>Transform</code> that doesn't use <code>Objective</code>, instead it operates on lists of tensors directly.</p> <p>This has a <code>concat_params</code> setting which is used in quite a few modules, for example it is optional in all full-matrix method like Quasi-Newton or full-matrix Adagrad.</p> <p>To use, subclass this and override one of <code>single_tensor_update</code> or <code>multi_tensor_update</code>, and one of <code>single_tensor_apply</code> or <code>multi_tensor_apply</code>.</p> <p>For copying:</p> <p>multi tensor: <pre><code>def multi_tensor_initialize(self, tensors, params, grads, loss, states, settings):\n    ...\ndef multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n    ...\ndef multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n    ...\n</code></pre></p> <p>single tensor:</p> <pre><code>def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n    ...\ndef single_tensor_update(self, tensor, param, grad, loss, state, setting):\n    ...\ndef single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n    ...\n</code></pre> <p>Methods:</p> <ul> <li> <code>multi_tensor_apply</code>             \u2013              <p>Updates <code>tensors</code> and returns it. This shouldn't modify <code>state</code> if possible.</p> </li> <li> <code>multi_tensor_initialize</code>             \u2013              <p>initialize <code>states</code> before first <code>update</code>.</p> </li> <li> <code>multi_tensor_update</code>             \u2013              <p>Updates <code>states</code>. This should not modify <code>tensor</code>.</p> </li> <li> <code>single_tensor_apply</code>             \u2013              <p>Updates <code>tensor</code> and returns it. This shouldn't modify <code>state</code> if possible.</p> </li> <li> <code>single_tensor_initialize</code>             \u2013              <p>initialize <code>state</code> before first <code>update</code>.</p> </li> <li> <code>single_tensor_update</code>             \u2013              <p>Updates <code>state</code>. This should not modify <code>tensor</code>.</p> </li> </ul> Source code in <code>torchzero/core/transform.py</code> <pre><code>class TensorTransform(Transform):\n    \"\"\"``TensorTransform`` is a ``Transform`` that doesn't use ``Objective``, instead it operates\n    on lists of tensors directly.\n\n    This has a ``concat_params`` setting which is used in quite a few modules, for example it is optional\n    in all full-matrix method like Quasi-Newton or full-matrix Adagrad.\n\n    To use, subclass this and override one of ``single_tensor_update`` or ``multi_tensor_update``,\n    and one of ``single_tensor_apply`` or ``multi_tensor_apply``.\n\n    For copying:\n\n    multi tensor:\n    ```\n    def multi_tensor_initialize(self, tensors, params, grads, loss, states, settings):\n        ...\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        ...\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        ...\n    ```\n\n    single tensor:\n\n    ```\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        ...\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n        ...\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        ...\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        defaults: dict[str, Any] | None = None,\n        update_freq: int = 1,\n        concat_params: bool = False,\n        uses_grad: bool = False,\n        uses_loss: bool = False,\n        inner: \"Chainable | None\" = None,\n    ):\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n        self._concat_params = concat_params\n        self._uses_grad = uses_grad\n        self._uses_loss = uses_loss\n\n\n    # ------------------------------- single tensor ------------------------------ #\n    def single_tensor_initialize(\n        self,\n        tensor: torch.Tensor,\n        param: torch.Tensor,\n        grad: torch.Tensor | None,\n        loss: torch.Tensor | None,\n        state: dict[str, Any],\n        setting: Mapping[str, Any],\n    ) -&gt; None:\n        \"\"\"initialize ``state`` before first ``update``.\n        \"\"\"\n\n    def single_tensor_update(\n        self,\n        tensor: torch.Tensor,\n        param: torch.Tensor,\n        grad: torch.Tensor | None,\n        loss: torch.Tensor | None,\n        state: dict[str, Any],\n        setting: Mapping[str, Any],\n    ) -&gt; None:\n        \"\"\"Updates ``state``. This should not modify ``tensor``.\n        \"\"\"\n\n    def single_tensor_apply(\n        self,\n        tensor: torch.Tensor,\n        param: torch.Tensor,\n        grad: torch.Tensor | None,\n        loss: torch.Tensor | None,\n        state: dict[str, Any],\n        setting: Mapping[str, Any],\n    ) -&gt; torch.Tensor:\n        \"\"\"Updates ``tensor`` and returns it. This shouldn't modify ``state`` if possible.\n        \"\"\"\n        raise NotImplementedError(f\"{self.__class__.__name__} doesn't implement `single_tensor_apply`.\")\n\n    # ------------------------------- multi tensor ------------------------------- #\n    def multi_tensor_initialize(\n        self,\n        tensors: list[torch.Tensor],\n        params: list[torch.Tensor],\n        grads: list[torch.Tensor] | None,\n        loss: torch.Tensor | None,\n        states: list[dict[str, Any]],\n        settings: Sequence[Mapping[str, Any]],\n    ) -&gt; None:\n        \"\"\"initialize ``states`` before first ``update``.\n        By default calls ``single_tensor_initialize`` on all tensors.\n        \"\"\"\n        if grads is None:\n            grads = cast(list, [None] * len(tensors))\n\n        for tensor, param, grad, state, setting in zip(tensors, params, grads, states, settings):\n            self.single_tensor_initialize(tensor=tensor, param=param, grad=grad, loss=loss, state=state, setting=setting)\n\n    def multi_tensor_update(\n        self,\n        tensors: list[torch.Tensor],\n        params: list[torch.Tensor],\n        grads: list[torch.Tensor] | None,\n        loss: torch.Tensor | None,\n        states: list[dict[str, Any]],\n        settings: Sequence[Mapping[str, Any]],\n    ) -&gt; None:\n        \"\"\"Updates ``states``. This should not modify ``tensor``.\n        By default calls ``single_tensor_update`` on all tensors.\n        \"\"\"\n\n        if grads is None:\n            grads = cast(list, [None] * len(tensors))\n\n        for tensor, param, grad, state, setting in zip(tensors, params, grads, states, settings):\n            self.single_tensor_update(tensor=tensor, param=param, grad=grad, loss=loss, state=state, setting=setting)\n\n    def multi_tensor_apply(\n        self,\n        tensors: list[torch.Tensor],\n        params: list[torch.Tensor],\n        grads: list[torch.Tensor] | None,\n        loss: torch.Tensor | None,\n        states: list[dict[str, Any]],\n        settings: Sequence[Mapping[str, Any]],\n    ) -&gt; Sequence[torch.Tensor]:\n        \"\"\"Updates ``tensors`` and returns it. This shouldn't modify ``state`` if possible.\n         By default calls ``single_tensor_apply`` on all tensors.\n         \"\"\"\n\n        if grads is None:\n            grads = cast(list, [None] * len(tensors))\n\n        ret = []\n        for tensor, param, grad, state, setting in zip(tensors, params, grads, states, settings):\n            u = self.single_tensor_apply(tensor=tensor, param=param, grad=grad, loss=loss, state=state, setting=setting)\n            ret.append(u)\n\n        return ret\n\n    def _get_grads_loss(self, objective: \"Objective\"):\n        \"\"\"evaluates grads and loss only if needed\"\"\"\n\n        if self._uses_grad: grads = objective.get_grads()\n        else: grads = None # better explicitly set to None rather than objective.grads because it shouldn't be used\n\n        if self._uses_loss: loss = objective.get_loss(backward=True)\n        else: loss = None\n\n        return grads, loss\n\n    @torch.no_grad\n    def _get_cat_updates_params_grads(self, objective: \"Objective\", grads: list[torch.Tensor] | None):\n        assert self._concat_params\n\n        cat_updates = [torch.cat([u.ravel() for u in objective.get_updates()])]\n        cat_params = [torch.cat([p.ravel() for p in objective.params])]\n\n        if grads is None: cat_grads = None\n        else: cat_grads = [torch.cat([g.ravel() for g in grads])]\n\n        return cat_updates, cat_params, cat_grads\n\n    def _gather_tensors(self, objective: \"Objective\", states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]):\n        \"\"\"returns everything for ``multi_tensor_*``. Concatenates if ```self._concat_params``.\n        evaluates grads and loss if ``self._uses_grad`` and ``self._uses_loss``\"\"\"\n\n        # evaluate grads and loss if `self._uses_grad` and `self._uses_loss`\n        grads, loss = self._get_grads_loss(objective)\n\n        # gather all things\n        # concatenate everything to a vec if `self._concat_params`\n        if self._concat_params:\n            tensors, params, grads = self._get_cat_updates_params_grads(objective, grads)\n            states = [states[0]]; settings = [settings[0]]\n\n        # or take original values\n        else:\n            tensors=objective.get_updates()\n            params = objective.params\n\n        return tensors, params, grads, loss, states, settings\n\n    @final\n    def update_states(self, objective: \"Objective\", states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; None:\n        tensors, params, grads, loss, states, settings = self._gather_tensors(objective, states, settings)\n\n        # initialize before the first update\n        num_updates = self.increment_counter(\"__num_updates\", 0)\n        if num_updates == 0:\n            self.multi_tensor_initialize(\n                tensors=tensors,\n                params=params,\n                grads=grads,\n                loss=loss,\n                states=states,\n                settings=settings\n            )\n\n        # update\n        self.multi_tensor_update(\n            tensors=tensors,\n            params=params,\n            grads=grads,\n            loss=loss,\n            states=states,\n            settings=settings\n        )\n\n    @final\n    def apply_states(self, objective: \"Objective\", states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; \"Objective\":\n        tensors, params, grads, loss, states, settings = self._gather_tensors(objective, states, settings)\n        # note: _gather tensors will re-cat again if `_concat_params`, this is necessary because objective\n        # may have been modified in functional logic, there is no way to know if that happened\n\n        # apply\n        ret = self.multi_tensor_apply(\n            tensors=tensors,\n            params=params,\n            grads=grads,\n            loss=loss,\n            states=states,\n            settings=settings\n        )\n\n        # uncat if needed and set objective.updates and return objective\n        if self._concat_params:\n            objective.updates = vec_to_tensors(ret[0], objective.params)\n\n        else:\n            objective.updates = list(ret)\n\n        return objective\n\n\n    # make sure _concat_params, _uses_grad and _uses_loss are saved in `state_dict`\n    def _extra_pack(self):\n        return {\n            \"__concat_params\": self._concat_params,\n            \"__uses_grad\": self._uses_grad,\n            \"__uses_loss\": self._uses_loss,\n        }\n\n    def _extra_unpack(self, d):\n        self._concat_params = d[\"__concat_params\"]\n        self._uses_grad = d[\"__uses_grad\"]\n        self._uses_loss = d[\"__uses_loss\"]\n</code></pre>"},{"location":"API/core/#torchzero.core.TensorTransform.multi_tensor_apply","title":"multi_tensor_apply","text":"<pre><code>multi_tensor_apply(tensors: list[Tensor], params: list[Tensor], grads: list[Tensor] | None, loss: Tensor | None, states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; Sequence[Tensor]\n</code></pre> <p>Updates <code>tensors</code> and returns it. This shouldn't modify <code>state</code> if possible. By default calls <code>single_tensor_apply</code> on all tensors.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>def multi_tensor_apply(\n    self,\n    tensors: list[torch.Tensor],\n    params: list[torch.Tensor],\n    grads: list[torch.Tensor] | None,\n    loss: torch.Tensor | None,\n    states: list[dict[str, Any]],\n    settings: Sequence[Mapping[str, Any]],\n) -&gt; Sequence[torch.Tensor]:\n    \"\"\"Updates ``tensors`` and returns it. This shouldn't modify ``state`` if possible.\n     By default calls ``single_tensor_apply`` on all tensors.\n     \"\"\"\n\n    if grads is None:\n        grads = cast(list, [None] * len(tensors))\n\n    ret = []\n    for tensor, param, grad, state, setting in zip(tensors, params, grads, states, settings):\n        u = self.single_tensor_apply(tensor=tensor, param=param, grad=grad, loss=loss, state=state, setting=setting)\n        ret.append(u)\n\n    return ret\n</code></pre>"},{"location":"API/core/#torchzero.core.TensorTransform.multi_tensor_initialize","title":"multi_tensor_initialize","text":"<pre><code>multi_tensor_initialize(tensors: list[Tensor], params: list[Tensor], grads: list[Tensor] | None, loss: Tensor | None, states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; None\n</code></pre> <p>initialize <code>states</code> before first <code>update</code>. By default calls <code>single_tensor_initialize</code> on all tensors.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>def multi_tensor_initialize(\n    self,\n    tensors: list[torch.Tensor],\n    params: list[torch.Tensor],\n    grads: list[torch.Tensor] | None,\n    loss: torch.Tensor | None,\n    states: list[dict[str, Any]],\n    settings: Sequence[Mapping[str, Any]],\n) -&gt; None:\n    \"\"\"initialize ``states`` before first ``update``.\n    By default calls ``single_tensor_initialize`` on all tensors.\n    \"\"\"\n    if grads is None:\n        grads = cast(list, [None] * len(tensors))\n\n    for tensor, param, grad, state, setting in zip(tensors, params, grads, states, settings):\n        self.single_tensor_initialize(tensor=tensor, param=param, grad=grad, loss=loss, state=state, setting=setting)\n</code></pre>"},{"location":"API/core/#torchzero.core.TensorTransform.multi_tensor_update","title":"multi_tensor_update","text":"<pre><code>multi_tensor_update(tensors: list[Tensor], params: list[Tensor], grads: list[Tensor] | None, loss: Tensor | None, states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; None\n</code></pre> <p>Updates <code>states</code>. This should not modify <code>tensor</code>. By default calls <code>single_tensor_update</code> on all tensors.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>def multi_tensor_update(\n    self,\n    tensors: list[torch.Tensor],\n    params: list[torch.Tensor],\n    grads: list[torch.Tensor] | None,\n    loss: torch.Tensor | None,\n    states: list[dict[str, Any]],\n    settings: Sequence[Mapping[str, Any]],\n) -&gt; None:\n    \"\"\"Updates ``states``. This should not modify ``tensor``.\n    By default calls ``single_tensor_update`` on all tensors.\n    \"\"\"\n\n    if grads is None:\n        grads = cast(list, [None] * len(tensors))\n\n    for tensor, param, grad, state, setting in zip(tensors, params, grads, states, settings):\n        self.single_tensor_update(tensor=tensor, param=param, grad=grad, loss=loss, state=state, setting=setting)\n</code></pre>"},{"location":"API/core/#torchzero.core.TensorTransform.single_tensor_apply","title":"single_tensor_apply","text":"<pre><code>single_tensor_apply(tensor: Tensor, param: Tensor, grad: Tensor | None, loss: Tensor | None, state: dict[str, Any], setting: Mapping[str, Any]) -&gt; Tensor\n</code></pre> <p>Updates <code>tensor</code> and returns it. This shouldn't modify <code>state</code> if possible.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>def single_tensor_apply(\n    self,\n    tensor: torch.Tensor,\n    param: torch.Tensor,\n    grad: torch.Tensor | None,\n    loss: torch.Tensor | None,\n    state: dict[str, Any],\n    setting: Mapping[str, Any],\n) -&gt; torch.Tensor:\n    \"\"\"Updates ``tensor`` and returns it. This shouldn't modify ``state`` if possible.\n    \"\"\"\n    raise NotImplementedError(f\"{self.__class__.__name__} doesn't implement `single_tensor_apply`.\")\n</code></pre>"},{"location":"API/core/#torchzero.core.TensorTransform.single_tensor_initialize","title":"single_tensor_initialize","text":"<pre><code>single_tensor_initialize(tensor: Tensor, param: Tensor, grad: Tensor | None, loss: Tensor | None, state: dict[str, Any], setting: Mapping[str, Any]) -&gt; None\n</code></pre> <p>initialize <code>state</code> before first <code>update</code>.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>def single_tensor_initialize(\n    self,\n    tensor: torch.Tensor,\n    param: torch.Tensor,\n    grad: torch.Tensor | None,\n    loss: torch.Tensor | None,\n    state: dict[str, Any],\n    setting: Mapping[str, Any],\n) -&gt; None:\n    \"\"\"initialize ``state`` before first ``update``.\n    \"\"\"\n</code></pre>"},{"location":"API/core/#torchzero.core.TensorTransform.single_tensor_update","title":"single_tensor_update","text":"<pre><code>single_tensor_update(tensor: Tensor, param: Tensor, grad: Tensor | None, loss: Tensor | None, state: dict[str, Any], setting: Mapping[str, Any]) -&gt; None\n</code></pre> <p>Updates <code>state</code>. This should not modify <code>tensor</code>.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>def single_tensor_update(\n    self,\n    tensor: torch.Tensor,\n    param: torch.Tensor,\n    grad: torch.Tensor | None,\n    loss: torch.Tensor | None,\n    state: dict[str, Any],\n    setting: Mapping[str, Any],\n) -&gt; None:\n    \"\"\"Updates ``state``. This should not modify ``tensor``.\n    \"\"\"\n</code></pre>"},{"location":"API/core/#torchzero.core.Transform","title":"Transform","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p><code>Transform</code> is a <code>Module</code> with only optional children.</p> <p><code>Transform</code> if more flexible in that as long as there are no children, it can use a custom list of states and settings instead of <code>self.state</code> and <code>self.setting</code>.</p> <p>To use, subclass this and override <code>update_states</code> and <code>apply_states</code>.</p> <p>Methods:</p> <ul> <li> <code>apply_states</code>             \u2013              <p>Updates <code>objective</code> using <code>states</code>.</p> </li> <li> <code>update_states</code>             \u2013              <p>Updates <code>states</code>. This should not modify <code>objective.update</code>.</p> </li> </ul> Source code in <code>torchzero/core/transform.py</code> <pre><code>class Transform(Module):\n    \"\"\"``Transform`` is a ``Module`` with only optional children.\n\n    ``Transform`` if more flexible in that as long as there are no children, it can use a custom list of states\n    and settings instead of ``self.state`` and ``self.setting``.\n\n    To use, subclass this and override ``update_states`` and ``apply_states``.\n    \"\"\"\n    def __init__(self, defaults: dict[str, Any] | None = None, update_freq: int = 1, inner: \"Chainable | None\" = None):\n\n        # store update_freq in defaults so that it is scheduleable\n        if defaults is None: defaults = {}\n        safe_dict_update_(defaults, {\"__update_freq\": update_freq})\n\n        super().__init__(defaults)\n\n        self._objective = None\n        if inner is not None:\n            self.set_child(\"__inner\", inner)\n\n    # settings shouldn't mutate, so they are typed as Sequence[Mapping]\n    def update_states(self, objective: \"Objective\", states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; None:\n        \"\"\"Updates ``states``. This should not modify ``objective.update``.\"\"\"\n\n    @abstractmethod\n    def apply_states(self, objective: \"Objective\", states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; \"Objective\":\n        \"\"\"Updates ``objective`` using ``states``.\"\"\"\n\n    def _get_states_settings(self, objective: \"Objective\") -&gt; tuple[list, tuple]:\n        # itemgetter is faster\n        # but need to make sure it returns a tuple, as if there is a single param, it returns the value\n        getter = itemgetter(*objective.params)\n        is_single = len(objective.params) == 1\n        states = getter(self.state)\n        settings = getter(self.settings)\n\n        if is_single:\n            states = [states, ]\n            settings = (settings, )\n\n        else:\n            states = list(states) # itemgetter returns tuple\n\n        return states, settings\n\n    @final\n    def update(self, objective:\"Objective\"):\n        step = self.increment_counter(\"__step\", 0)\n\n        if step % self.settings[objective.params[0]][\"__update_freq\"] == 0:\n            states, settings = self._get_states_settings(objective)\n            self.update_states(objective=objective, states=states, settings=settings)\n\n    @final\n    def apply(self, objective: \"Objective\"):\n\n        # inner step\n        if \"__inner\" in self.children:\n            inner = self.children[\"__inner\"]\n            objective = inner.step(objective)\n\n        # apply and return\n        states, settings = self._get_states_settings(objective)\n        return self.apply_states(objective=objective, states=states, settings=settings)\n</code></pre>"},{"location":"API/core/#torchzero.core.Transform.apply_states","title":"apply_states","text":"<pre><code>apply_states(objective: Objective, states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; Objective\n</code></pre> <p>Updates <code>objective</code> using <code>states</code>.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>@abstractmethod\ndef apply_states(self, objective: \"Objective\", states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; \"Objective\":\n    \"\"\"Updates ``objective`` using ``states``.\"\"\"\n</code></pre>"},{"location":"API/core/#torchzero.core.Transform.update_states","title":"update_states","text":"<pre><code>update_states(objective: Objective, states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; None\n</code></pre> <p>Updates <code>states</code>. This should not modify <code>objective.update</code>.</p> Source code in <code>torchzero/core/transform.py</code> <pre><code>def update_states(self, objective: \"Objective\", states: list[dict[str, Any]], settings: Sequence[Mapping[str, Any]]) -&gt; None:\n    \"\"\"Updates ``states``. This should not modify ``objective.update``.\"\"\"\n</code></pre>"},{"location":"API/core/#torchzero.core.maybe_chain","title":"maybe_chain","text":"<pre><code>maybe_chain(*modules: Module | Sequence[Module]) -&gt; Module\n</code></pre> <p>Returns a single module directly if only one is provided, otherwise wraps them in a <code>Chain</code>.</p> Source code in <code>torchzero/core/chain.py</code> <pre><code>def maybe_chain(*modules: Chainable) -&gt; Module:\n    \"\"\"Returns a single module directly if only one is provided, otherwise wraps them in a ``Chain``.\"\"\"\n    flat_modules: list[Module] = flatten(modules)\n    if len(flat_modules) == 1:\n        return flat_modules[0]\n    return Chain(*flat_modules)\n</code></pre>"},{"location":"API/core/#torchzero.core.step","title":"step","text":"<pre><code>step(objective: Objective, modules: Module | Sequence[Module])\n</code></pre> <p>doesn't apply hooks!</p> Source code in <code>torchzero/core/functional.py</code> <pre><code>def step(objective: \"Objective\", modules: \"Module | Sequence[Module]\"):\n    \"\"\"doesn't apply hooks!\"\"\"\n    if not isinstance(modules, Sequence):\n        modules = (modules, )\n\n    if len(modules) == 0:\n        raise RuntimeError(\"`modules` is an empty sequence\")\n\n    # if closure is None, assume backward has been called and gather grads\n    if objective.closure is None:\n        objective.grads = [p.grad if p.grad is not None else torch.zeros_like(p) for p in objective.params]\n\n    # step and return\n    return _chain_step(objective, modules)\n</code></pre>"},{"location":"API/modules/adaptive/","title":"Adaptive","text":"<p>This subpackage contains adaptive methods e.g. Adam, RMSprop, SOAP, etc.</p>"},{"location":"API/modules/adaptive/#see-also","title":"See also","text":"<ul> <li>Momentum - momentum methods (heavy ball, nesterov momentum)</li> <li>Quasi-newton - quasi-newton methods</li> </ul> <p>Classes:</p> <ul> <li> <code>AEGD</code>           \u2013            <p>AEGD (Adaptive gradient descent with energy) from https://arxiv.org/abs/2010.05109#page=10.26.</p> </li> <li> <code>ASAM</code>           \u2013            <p>Adaptive Sharpness-Aware Minimization from https://arxiv.org/pdf/2102.11600#page=6.52</p> </li> <li> <code>AdaHessian</code>           \u2013            <p>AdaHessian: An Adaptive Second Order Optimizer for Machine Learning (https://arxiv.org/abs/2006.00719)</p> </li> <li> <code>Adagrad</code>           \u2013            <p>Adagrad, divides by sum of past squares of gradients.</p> </li> <li> <code>AdagradNorm</code>           \u2013            <p>Adagrad-Norm, divides by sum of past means of squares of gradients.</p> </li> <li> <code>Adam</code>           \u2013            <p>Adam. Divides gradient EMA by EMA of gradient squares with debiased step size.</p> </li> <li> <code>Adan</code>           \u2013            <p>Adaptive Nesterov Momentum Algorithm from https://arxiv.org/abs/2208.06677</p> </li> <li> <code>AdaptiveHeavyBall</code>           \u2013            <p>Adaptive heavy ball from https://hal.science/hal-04832983v1/file/OJMO_2024__5__A7_0.pdf.</p> </li> <li> <code>BacktrackOnSignChange</code>           \u2013            <p>Negates or undoes update for parameters where where gradient or update sign changes.</p> </li> <li> <code>DualNormCorrection</code>           \u2013            <p>Dual norm correction for dualizer based optimizers (https://github.com/leloykun/adaptive-muon).</p> </li> <li> <code>ESGD</code>           \u2013            <p>Equilibrated Gradient Descent (https://arxiv.org/abs/1502.04390)</p> </li> <li> <code>FullMatrixAdagrad</code>           \u2013            <p>Full-matrix version of Adagrad, can be customized to make RMSprop or Adam (see examples).</p> </li> <li> <code>GGT</code>           \u2013            <p>GGT method from https://arxiv.org/pdf/1806.02958</p> </li> <li> <code>Lion</code>           \u2013            <p>Lion (EvoLved Sign Momentum) optimizer from https://arxiv.org/abs/2302.06675.</p> </li> <li> <code>MARSCorrection</code>           \u2013            <p>MARS variance reduction correction.</p> </li> <li> <code>MSAM</code>           \u2013            <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> </li> <li> <code>MSAMMomentum</code>           \u2013            <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> </li> <li> <code>MatrixMomentum</code>           \u2013            <p>Second order momentum method.</p> </li> <li> <code>MuonAdjustLR</code>           \u2013            <p>LR adjustment for Muon from \"Muon is Scalable for LLM Training\" (https://github.com/MoonshotAI/Moonlight/tree/master).</p> </li> <li> <code>NaturalGradient</code>           \u2013            <p>Natural gradient approximated via empirical fisher information matrix.</p> </li> <li> <code>OrthoGrad</code>           \u2013            <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> </li> <li> <code>Orthogonalize</code>           \u2013            <p>Uses Newton-Schulz iteration or SVD to compute the zeroth power / orthogonalization of update along first 2 dims.</p> </li> <li> <code>PSGDDenseNewton</code>           \u2013            <p>Dense hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDKronNewton</code>           \u2013            <p>Kron hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDKronWhiten</code>           \u2013            <p>Kron whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDLRANewton</code>           \u2013            <p>Low rank hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>PSGDLRAWhiten</code>           \u2013            <p>Low rank whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> </li> <li> <code>RMSprop</code>           \u2013            <p>Divides graient by EMA of gradient squares.</p> </li> <li> <code>Rprop</code>           \u2013            <p>Resilient propagation. The update magnitude gets multiplied by <code>nplus</code> if gradient didn't change the sign,</p> </li> <li> <code>SAM</code>           \u2013            <p>Sharpness-Aware Minimization from https://arxiv.org/pdf/2010.01412</p> </li> <li> <code>SOAP</code>           \u2013            <p>SOAP (ShampoO with Adam in the Preconditioner's eigenbasis from https://arxiv.org/abs/2409.11321).</p> </li> <li> <code>ScaleLRBySignChange</code>           \u2013            <p>learning rate gets multiplied by <code>nplus</code> if ascent/gradient didn't change the sign,</p> </li> <li> <code>Shampoo</code>           \u2013            <p>Shampoo from Preconditioned Stochastic Tensor Optimization (https://arxiv.org/abs/1802.09568).</p> </li> <li> <code>SignConsistencyLRs</code>           \u2013            <p>Outputs per-weight learning rates based on consecutive sign consistency.</p> </li> <li> <code>SignConsistencyMask</code>           \u2013            <p>Outputs a mask of sign consistency of current and previous inputs.</p> </li> <li> <code>SophiaH</code>           \u2013            <p>SophiaH optimizer from https://arxiv.org/abs/2305.14342</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>orthogonalize_grads_</code>             \u2013              <p>Computes the zeroth power / orthogonalization of gradients of an iterable of parameters.</p> </li> <li> <code>orthograd_</code>             \u2013              <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.AEGD","title":"AEGD","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>AEGD (Adaptive gradient descent with energy) from https://arxiv.org/abs/2010.05109#page=10.26.</p> Note <p>AEGD has a learning rate hyperparameter that can't really be removed from the update rule. To avoid compounding learning rate mofications, remove the <code>tz.m.LR</code> module if you had it.</p> <p>Parameters:</p> <ul> <li> <code>lr</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate (default: 0.1)</p> </li> <li> <code>c</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>term added to the original objective function (default: 1)</p> </li> </ul> Reference <p>Liu, Hailiang, and Xuping Tian. \"AEGD: Adaptive gradient descent with energy.\" arXiv preprint arXiv:2010.05109 (2020).</p> Source code in <code>torchzero/modules/adaptive/aegd.py</code> <pre><code>class AEGD(TensorTransform):\n    \"\"\"AEGD (Adaptive gradient descent with energy) from https://arxiv.org/abs/2010.05109#page=10.26.\n\n    Note:\n        AEGD has a learning rate hyperparameter that can't really be removed from the update rule.\n        To avoid compounding learning rate mofications, remove the ``tz.m.LR`` module if you had it.\n\n    Args:\n        lr (float, optional): learning rate (default: 0.1)\n        c (float, optional): term added to the original objective function (default: 1)\n\n    Reference:\n        [Liu, Hailiang, and Xuping Tian. \"AEGD: Adaptive gradient descent with energy.\" arXiv preprint arXiv:2010.05109 (2020).](https://arxiv.org/pdf/2010.05109)\n    \"\"\"\n    def __init__(\n        self,\n        lr: float = 0.1,\n        c: float = 1,\n    ):\n        defaults = dict(c=c, lr=lr)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        tensors = TensorList(tensors)\n\n        c, lr = unpack_dicts(settings, 'c', 'lr', cls=NumberList)\n        r = unpack_states(states, tensors, 'r', init=lambda t: torch.full_like(t, float(loss + c[0])**0.5), cls=TensorList)\n\n        update = aegd_(\n            f=loss,\n            g=tensors,\n            r_=r,\n            c=c,\n            eta=lr,\n        )\n\n        return update\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.ASAM","title":"ASAM","text":"<p>               Bases: <code>torchzero.modules.adaptive.sam.SAM</code></p> <p>Adaptive Sharpness-Aware Minimization from https://arxiv.org/pdf/2102.11600#page=6.52</p> <p>SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value. It performs two forward and backward passes per step.</p> <p>This implementation modifies the closure to return loss and calculate gradients of the SAM objective. All modules after this will use the modified objective.</p> Note <p>This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients at two points on each step.</p> <p>Parameters:</p> <ul> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Neighborhood size. Defaults to 0.05.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm of the SAM objective. Defaults to 2.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.ASAM--examples","title":"Examples:","text":"<p>ASAM-SGD:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ASAM(),\n    tz.m.LR(1e-2)\n)\n</code></pre> <p>ASAM-Adam:</p> <p><pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ASAM(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2)\n)\n</code></pre> References:     Kwon, J., Kim, J., Park, H., &amp; Choi, I. K. (2021, July). ASAM: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. In International Conference on Machine Learning (pp. 5905-5914). PMLR.</p> Source code in <code>torchzero/modules/adaptive/sam.py</code> <pre><code>class ASAM(SAM):\n    \"\"\"Adaptive Sharpness-Aware Minimization from https://arxiv.org/pdf/2102.11600#page=6.52\n\n    SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value.\n    It performs two forward and backward passes per step.\n\n    This implementation modifies the closure to return loss and calculate gradients\n    of the SAM objective. All modules after this will use the modified objective.\n\n    Note:\n        This module requires a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients at two points on each step.\n\n    Args:\n        rho (float, optional): Neighborhood size. Defaults to 0.05.\n        p (float, optional): norm of the SAM objective. Defaults to 2.\n\n    ### Examples:\n\n    ASAM-SGD:\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ASAM(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    ASAM-Adam:\n\n    ```\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ASAM(),\n        tz.m.Adam(),\n        tz.m.LR(1e-2)\n    )\n    ```\n    References:\n        [Kwon, J., Kim, J., Park, H., &amp; Choi, I. K. (2021, July). ASAM: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. In International Conference on Machine Learning (pp. 5905-5914). PMLR.](https://arxiv.org/abs/2102.11600)\n    \"\"\"\n    def __init__(self, rho: float = 0.5, p: float = 2, eps=1e-10):\n        super().__init__(rho=rho, p=p, eps=eps, asam=True)\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.AdaHessian","title":"AdaHessian","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>AdaHessian: An Adaptive Second Order Optimizer for Machine Learning (https://arxiv.org/abs/2006.00719)</p> <p>This is similar to Adam, but the second momentum is replaced by square root of an exponential moving average of random hessian-vector products.</p> Notes <ul> <li> <p>In most cases AdaHessian should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply AdaHessian preconditioning to another module's output.</p> </li> <li> <p>This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>first momentum. Defaults to 0.9.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>second momentum for squared hessian diagonal estimates. Defaults to 0.999.</p> </li> <li> <code>averaging</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to enable block diagonal averaging over 1st dimension on parameters that have 2+ dimensions. This can be set per-parameter in param groups.</p> </li> <li> <code>block_size</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>size of block in the block-diagonal averaging.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating hessian diagonal estimate via a hessian-vector product. This value can be increased to reduce computational cost. Defaults to 1.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>division stability epsilon. Defaults to 1e-8.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to <code>\"autograd\"</code>. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of hessian-vector products with random vectors to evaluate each time when updating the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random vectors. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>)           \u2013            <p>Inner module. If this is specified, operations are performed in the following order. 1. compute hessian diagonal estimate. 2. pass inputs to <code>inner</code>. 3. momentum and preconditioning are applied to the ouputs of <code>inner</code>.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.AdaHessian--examples","title":"Examples:","text":"<p>Using AdaHessian:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.AdaHessian(),\n    tz.m.LR(0.1)\n)\n</code></pre> <p>AdaHessian preconditioner can be applied to any other module by passing it to the <code>inner</code> argument. Turn off AdaHessian's first momentum to get just the preconditioning. Here is an example of applying AdaHessian preconditioning to nesterov momentum (<code>tz.m.NAG</code>): <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.AdaHessian(beta1=0, inner=tz.m.NAG(0.9)),\n    tz.m.LR(0.1)\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/adahessian.py</code> <pre><code>class AdaHessian(Transform):\n    \"\"\"AdaHessian: An Adaptive Second Order Optimizer for Machine Learning (https://arxiv.org/abs/2006.00719)\n\n    This is similar to Adam, but the second momentum is replaced by square root of an exponential moving average of random hessian-vector products.\n\n    Notes:\n        - In most cases AdaHessian should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply AdaHessian preconditioning to another module's output.\n\n        - This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        beta1 (float, optional): first momentum. Defaults to 0.9.\n        beta2 (float, optional): second momentum for squared hessian diagonal estimates. Defaults to 0.999.\n        averaging (bool, optional):\n            whether to enable block diagonal averaging over 1st dimension on parameters that have 2+ dimensions.\n            This can be set per-parameter in param groups.\n        block_size (int, optional):\n            size of block in the block-diagonal averaging.\n        update_freq (int, optional):\n            frequency of updating hessian diagonal estimate via a hessian-vector product.\n            This value can be increased to reduce computational cost. Defaults to 1.\n        eps (float, optional):\n            division stability epsilon. Defaults to 1e-8.\n        hvp_method (str, optional):\n            Determines how hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        n_samples (int, optional):\n            number of hessian-vector products with random vectors to evaluate each time when updating\n            the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n        seed (int | None, optional): seed for random vectors. Defaults to None.\n        inner (Chainable | None, optional):\n            Inner module. If this is specified, operations are performed in the following order.\n            1. compute hessian diagonal estimate.\n            2. pass inputs to ``inner``.\n            3. momentum and preconditioning are applied to the ouputs of ``inner``.\n\n    ## Examples:\n\n    Using AdaHessian:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.AdaHessian(),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    AdaHessian preconditioner can be applied to any other module by passing it to the ``inner`` argument.\n    Turn off AdaHessian's first momentum to get just the preconditioning. Here is an example of applying\n    AdaHessian preconditioning to nesterov momentum (``tz.m.NAG``):\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.AdaHessian(beta1=0, inner=tz.m.NAG(0.9)),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.9,\n        beta2: float = 0.999,\n        averaging: bool = True,\n        block_size: int | None = None,\n        update_freq: int = 1,\n        eps: float = 1e-8,\n        hessian_power: float = 1,\n        distribution: Distributions = 'rademacher',\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        n_samples = 1,\n        zHz: bool = True,\n        debias: bool = True,\n        seed: int | None = None,\n\n        exp_avg_tfm: Chainable | None = None,\n        D_exp_avg_sq_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"exp_avg_tfm\"], defaults[\"D_exp_avg_sq_tfm\"]\n        super().__init__(defaults)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.set_child('D_exp_avg_sq', D_exp_avg_sq_tfm)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2, averaging, block_size = unpack_dicts(settings, 'beta1', 'beta2', 'averaging', 'block_size', cls=NumberList)\n\n        exp_avg, D_exp_avg_sq = unpack_states(states, params, 'exp_avg', 'D_exp_avg_sq', cls=TensorList)\n\n        # ---------------------------- hutchinson hessian ---------------------------- #\n        fs = settings[0]\n        step = self.increment_counter(\"step\", start=0) # 0 on 1st update\n        update_freq = fs['update_freq']\n\n        if step % update_freq == 0:\n            self.increment_counter(\"num_Ds\", start=1)\n\n            D, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = fs['n_samples'],\n                distribution = fs['distribution'],\n                hvp_method = fs['hvp_method'],\n                h = fs['h'],\n                zHz = fs[\"zHz\"],\n                generator = self.get_generator(params[0].device, fs[\"seed\"]),\n            )\n\n            D = TensorList(D).zipmap_args(_block_average, block_size, averaging)\n            D_exp_avg_sq.mul_(beta2).addcmul_(D, D, value=1-beta2)\n\n        # --------------------------------- momentum --------------------------------- #\n        tensors = objective.get_updates() # do this after hutchinson to not disturb autograd\n        exp_avg.lerp_(tensors, 1-beta1)\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2, eps, hessian_power = unpack_dicts(settings, 'beta1', 'beta2', 'eps', 'hessian_power', cls=NumberList)\n        exp_avg, D_exp_avg_sq = unpack_states(states, params, 'exp_avg', 'D_exp_avg_sq', cls=TensorList)\n\n        # ---------------------------------- debias ---------------------------------- #\n        if settings[0][\"debias\"]:\n            bias_correction1 = 1.0 - (beta1 ** (self.global_state[\"step\"] + 1))\n            bias_correction2 = 1.0 - (beta2 ** self.global_state[\"num_Ds\"])\n            exp_avg = exp_avg / bias_correction1\n            D_exp_avg_sq = D_exp_avg_sq / bias_correction2\n\n\n        # -------------------------------- transforms -------------------------------- #\n        exp_avg = TensorList(self.inner_step_tensors(\n            \"exp_avg\", tensors=exp_avg, clone=True, objective=objective, must_exist=False))\n\n        D_exp_avg_sq = TensorList(self.inner_step_tensors(\n            \"D_exp_avg_sq\", tensors=D_exp_avg_sq, clone=True, objective=objective, must_exist=False))\n\n        # ------------------------------ compute update ------------------------------ #\n        denom = D_exp_avg_sq.lazy_pow(hessian_power / 2) + eps\n        objective.updates = exp_avg / denom\n        return objective\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Adagrad","title":"Adagrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adagrad, divides by sum of past squares of gradients.</p> <p>This implementation is identical to <code>torch.optim.Adagrad</code>.</p> <p>Parameters:</p> <ul> <li> <code>lr_decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>learning rate decay. Defaults to 0.</p> </li> <li> <code>initial_accumulator_value</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>initial value of the sum of squares of gradients. Defaults to 0.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-10</code> )           \u2013            <p>division epsilon. Defaults to 1e-10.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>step size. Defaults to 1.</p> </li> <li> <code>pow</code>               (<code>float</code>)           \u2013            <p>power for gradients and accumulator root. Defaults to 2.</p> </li> <li> <code>use_sqrt</code>               (<code>bool</code>)           \u2013            <p>whether to take the root of the accumulator. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adagrad.py</code> <pre><code>class Adagrad(TensorTransform):\n    \"\"\"Adagrad, divides by sum of past squares of gradients.\n\n    This implementation is identical to ``torch.optim.Adagrad``.\n\n    Args:\n        lr_decay (float, optional): learning rate decay. Defaults to 0.\n        initial_accumulator_value (float, optional): initial value of the sum of squares of gradients. Defaults to 0.\n        eps (float, optional): division epsilon. Defaults to 1e-10.\n        alpha (float, optional): step size. Defaults to 1.\n        pow (float, optional): power for gradients and accumulator root. Defaults to 2.\n        use_sqrt (bool, optional): whether to take the root of the accumulator. Defaults to True.\n        inner (Chainable | None, optional): Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n\n        # hyperparams\n        lr_decay: float = 0,\n        initial_accumulator_value: float = 0,\n        eps: float = 1e-10,\n        alpha: float = 1,\n\n        # tfms\n        inner: Chainable | None = None,\n        accumulator_tfm: Chainable | None = None\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"accumulator_tfm\"]\n        super().__init__(defaults=defaults, inner=inner)\n\n        self.set_child('accumulator', accumulator_tfm)\n        self.add_projected_keys(\"grad\", \"accumulator\")\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        state[\"accumulator\"] = torch.full_like(tensor, fill_value=setting[\"initial_accumulator_value\"])\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_addcmul_([state[\"accumulator\"] for state in states], tensors, tensors)\n        self.increment_counter(\"step\", start=0)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors_ = TensorList(tensors)\n        step = self.global_state[\"step\"] # 0 on first apply\n        eps, alpha, lr_decay = unpack_dicts(settings, \"eps\", \"alpha\", \"lr_decay\", cls=NumberList)\n\n        accumulator = [state[\"accumulator\"] for state in states]\n        accumulator = TensorList(self.inner_step_tensors(\n            \"accumulator\", tensors=accumulator, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        denom = accumulator.sqrt().add_(eps)\n        tensors_ /= denom\n\n        clr = alpha / (1 + step * lr_decay)\n        tensors_.lazy_mul_(clr)\n\n        return tensors_\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.AdagradNorm","title":"AdagradNorm","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adagrad-Norm, divides by sum of past means of squares of gradients.</p> <p>Parameters:</p> <ul> <li> <code>lr_decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>learning rate decay. Defaults to 0.</p> </li> <li> <code>initial_accumulator_value</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>initial value of the sum of squares of gradients. Defaults to 0.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-10</code> )           \u2013            <p>division epsilon. Defaults to 1e-10.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>step size. Defaults to 1.</p> </li> <li> <code>use_sqrt</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to take the root of the accumulator. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adagrad.py</code> <pre><code>class AdagradNorm(TensorTransform):\n    \"\"\"Adagrad-Norm, divides by sum of past means of squares of gradients.\n\n    Args:\n        lr_decay (float, optional): learning rate decay. Defaults to 0.\n        initial_accumulator_value (float, optional): initial value of the sum of squares of gradients. Defaults to 0.\n        eps (float, optional): division epsilon. Defaults to 1e-10.\n        alpha (float, optional): step size. Defaults to 1.\n        use_sqrt (bool, optional): whether to take the root of the accumulator. Defaults to True.\n        inner (Chainable | None, optional): Inner modules that are applied after updating accumulator and before preconditioning. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        lr_decay: float = 0,\n        initial_accumulator_value: float = 0,\n        eps: float = 1e-10,\n        beta:float | None = None,\n        beta_debias: bool = True,\n        layerwise: bool = True,\n        use_sqrt: bool = True,\n        alpha: float = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults=defaults, inner=inner)\n\n    @torch.no_grad\n    def multi_tensor_initialize(self, tensors, params, grads, loss, states, settings):\n\n        # layerwise initialize in each state\n        if settings[0][\"layerwise\"]:\n            for tensor, state, setting in zip(tensors, states, settings):\n\n                initial_accumulator_value = setting[\"initial_accumulator_value\"]\n                state[\"accumulator\"] = torch.tensor(initial_accumulator_value, device=tensor.device, dtype=tensor.dtype)\n\n        # global initialize in global state\n        else:\n            initial_accumulator_value = settings[0][\"initial_accumulator_value\"]\n            tensor = tensors[0]\n            self.global_state[\"accumulator\"] = torch.tensor(initial_accumulator_value, device=tensor.device, dtype=tensor.dtype)\n\n    def _get_accumulator(self, states, settings) -&gt; torch.Tensor | TensorList:\n        layerwise = settings[0][\"layerwise\"]\n        if layerwise:\n            return TensorList(s[\"accumulator\"] for s in states)\n\n        return self.global_state[\"accumulator\"]\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        accumulator = self._get_accumulator(states, settings)\n        self.increment_counter(\"step\", start=0)\n\n        # compute squared gradient norm (gg)\n        if isinstance(accumulator, TensorList): gg = tensors.tensorwise_dot(tensors)\n        else: gg = tensors.dot(tensors)\n\n        # update the accumulator\n        beta = settings[0][\"beta\"]\n        if beta is None: accumulator.add_(gg) # pyright:ignore[reportArgumentType]\n        else: accumulator.lerp_(gg, weight=1-beta) # pyright:ignore[reportArgumentType, reportCallIssue]\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        accumulator = self._get_accumulator(states, settings)\n        eps, alpha, lr_decay = unpack_dicts(settings, \"eps\", \"alpha\", \"lr_decay\", cls=NumberList)\n        step = self.global_state[\"step\"] # 0 on 1st step\n        fs = settings[0]\n        beta = fs[\"beta\"]\n\n        # ------------------------ debias if beta is not None ------------------------ #\n        if fs[\"beta_debias\"] and beta is not None:\n            accumulator = accumulator / (1 - beta ** (step + 1))\n\n\n        # ---------------------------- compute denominator --------------------------- #\n        if fs[\"use_sqrt\"]:\n            denom = accumulator.sqrt().add_(eps) # pyright:ignore[reportArgumentType]\n        else:\n            denom = accumulator + eps # pyright:ignore[reportOperatorIssue]\n\n\n        # ---------------------------- compute the update ---------------------------- #\n        tensors /= denom\n        clr = alpha / (1 + step * lr_decay) # lr decay\n        tensors.lazy_mul_(clr)\n\n        return tensors\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Adam","title":"Adam","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adam. Divides gradient EMA by EMA of gradient squares with debiased step size.</p> <p>This implementation is identical to :code:<code>torch.optim.Adam</code>.</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum. Defaults to 0.9.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>second momentum. Defaults to 0.999.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon. Defaults to 1e-8.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>learning rate. Defaults to 1.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>)           \u2013            <p>power used in second momentum power and root. Defaults to 2.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to apply debiasing to momentums based on current step. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adam.py</code> <pre><code>class Adam(TensorTransform):\n    \"\"\"Adam. Divides gradient EMA by EMA of gradient squares with debiased step size.\n\n    This implementation is identical to :code:`torch.optim.Adam`.\n\n    Args:\n        beta1 (float, optional): momentum. Defaults to 0.9.\n        beta2 (float, optional): second momentum. Defaults to 0.999.\n        eps (float, optional): epsilon. Defaults to 1e-8.\n        alpha (float, optional): learning rate. Defaults to 1.\n        amsgrad (bool, optional): Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.\n        pow (float, optional): power used in second momentum power and root. Defaults to 2.\n        debias (bool, optional): whether to apply debiasing to momentums based on current step. Defaults to True.\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.9,\n        beta2: float = 0.999,\n        eps: float = 1e-8,\n        amsgrad: bool = False,\n        alpha: float = 1.,\n        debias: bool = True,\n\n        exp_avg_tfm: Chainable | None = None,\n        exp_avg_sq_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"exp_avg_tfm\"], defaults[\"exp_avg_sq_tfm\"]\n        super().__init__(defaults)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.set_child('exp_avg_sq', exp_avg_sq_tfm)\n\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        self.increment_counter(\"step\", start=0)\n        beta1, beta2 = unpack_dicts(settings, 'beta1','beta2', cls=NumberList)\n\n        # ----------------------------- initialize states ---------------------------- #\n        if settings[0][\"amsgrad\"]:\n            exp_avg, exp_avg_sq, max_exp_avg_sq = unpack_states(\n                states, tensors, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        # ------------------------------ update moments ------------------------------ #\n        exp_avg.lerp_(tensors, weight=1-beta1)\n        exp_avg_sq.mul_(beta2).addcmul_(tensors, tensors, value=1-beta2)\n\n        if max_exp_avg_sq is not None:\n            max_exp_avg_sq.maximum_(exp_avg_sq)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state[\"step\"] # 0 on 1st step\n        fs = settings[0]\n\n        if fs[\"amsgrad\"]: key = \"max_exp_avg_sq\"\n        else: key = \"exp_avg_sq\"\n        exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', key, cls=TensorList)\n        beta1, beta2, alpha, eps = unpack_dicts(settings, 'beta1', 'beta2', 'alpha', 'eps', cls=NumberList)\n\n        # -------------------------------- transforms -------------------------------- #\n        exp_avg = TensorList(self.inner_step_tensors(\n            \"exp_avg\", tensors=exp_avg, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        exp_avg_sq = TensorList(self.inner_step_tensors(\n            \"exp_avg_sq\", tensors=exp_avg_sq, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        # ---------------------------------- debias ---------------------------------- #\n        if fs[\"debias\"]:\n            alpha = debiased_step_size((step + 1), beta1=beta1, beta2=beta2, alpha=alpha)\n            exp_avg = exp_avg * alpha\n\n        # ---------------------------------- update ---------------------------------- #\n        return exp_avg / exp_avg_sq.sqrt().add_(eps)\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Adan","title":"Adan","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adaptive Nesterov Momentum Algorithm from https://arxiv.org/abs/2208.06677</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.98</code> )           \u2013            <p>momentum. Defaults to 0.98.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.92</code> )           \u2013            <p>momentum for gradient differences. Defaults to 0.92.</p> </li> <li> <code>beta3</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>thrid (squared) momentum. Defaults to 0.99.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon. Defaults to 1e-8.</p> </li> </ul> <p>Example: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adan(),\n    tz.m.LR(1e-3),\n)\n</code></pre> Reference:     Xie, X., Zhou, P., Li, H., Lin, Z., &amp; Yan, S. (2024). Adan: Adaptive nesterov momentum algorithm for faster optimizing deep models. IEEE Transactions on Pattern Analysis and Machine Intelligence.</p> Source code in <code>torchzero/modules/adaptive/adan.py</code> <pre><code>class Adan(TensorTransform):\n    \"\"\"Adaptive Nesterov Momentum Algorithm from https://arxiv.org/abs/2208.06677\n\n    Args:\n        beta1 (float, optional): momentum. Defaults to 0.98.\n        beta2 (float, optional): momentum for gradient differences. Defaults to 0.92.\n        beta3 (float, optional): thrid (squared) momentum. Defaults to 0.99.\n        eps (float, optional): epsilon. Defaults to 1e-8.\n\n    Example:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adan(),\n        tz.m.LR(1e-3),\n    )\n    ```\n    Reference:\n        [Xie, X., Zhou, P., Li, H., Lin, Z., &amp; Yan, S. (2024). Adan: Adaptive nesterov momentum algorithm for faster optimizing deep models. IEEE Transactions on Pattern Analysis and Machine Intelligence](https://arxiv.org/abs/2208.06677).\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.98,\n        beta2: float = 0.92,\n        beta3: float = 0.99,\n        eps: float = 1e-8,\n\n        m_tfm: Chainable | None = None,\n        v_tfm: Chainable | None = None,\n        n_tfm: Chainable | None = None,\n    ):\n        defaults=dict(beta1=beta1, beta2=beta2, beta3=beta3, eps=eps)\n        super().__init__(defaults, uses_grad=False)\n\n        self.set_child(\"m\", m_tfm)\n        self.set_child(\"v\", v_tfm)\n        self.set_child(\"n\", n_tfm)\n\n        self.add_projected_keys(\"grad_sq\", \"m\", \"v\", \"g_prev\")\n        self.add_projected_keys(\"grad\", \"n\")\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        step = self.increment_counter(\"step\", start=0)\n\n        beta1, beta2, beta3 = unpack_dicts(settings, 'beta1','beta2','beta3', cls=NumberList)\n        g_prev, m, v, n = unpack_states(states, tensors, 'g_prev', 'm', 'v', 'n', cls=TensorList)\n\n        adan_update_(g=tensors, g_prev_=g_prev, m_=m, v_=v, n_=n, beta1=beta1, beta2=beta2, beta3=beta3, step=step+1)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        step = self.global_state[\"step\"] # 0 on 1st step\n\n        beta1, beta2, beta3, eps = unpack_dicts(settings, 'beta1','beta2','beta3', 'eps', cls=NumberList)\n        m, v, n = unpack_states(states, tensors, 'm', 'v', 'n')\n\n        # -------------------------------- transforms -------------------------------- #\n        m = TensorList(self.inner_step_tensors(\"m\", m, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n        v = TensorList(self.inner_step_tensors(\"v\", v, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n        n = TensorList(self.inner_step_tensors(\"n\", n, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        # ---------------------------------- update ---------------------------------- #\n        return adan_apply_(m_=m, v_=v, n_=n, beta1=beta1, beta2=beta2, beta3=beta3, eps=eps, step=step+1)\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.AdaptiveHeavyBall","title":"AdaptiveHeavyBall","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adaptive heavy ball from https://hal.science/hal-04832983v1/file/OJMO_2024__5__A7_0.pdf.</p> <p>Suitable for quadratic objectives with known f* (loss at minimum).</p> note <p>The step size is determined by the algorithm, so learning rate modules shouldn't be used.</p> <p>Parameters:</p> <ul> <li> <code>f_star</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>(estimated) minimal possible value of the objective function (lowest possible loss). Defaults to 0.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/adaptive_heavyball.py</code> <pre><code>class AdaptiveHeavyBall(TensorTransform):\n    \"\"\"Adaptive heavy ball from https://hal.science/hal-04832983v1/file/OJMO_2024__5__A7_0.pdf.\n\n    Suitable for quadratic objectives with known f* (loss at minimum).\n\n    note:\n        The step size is determined by the algorithm, so learning rate modules shouldn't be used.\n\n    Args:\n        f_star (int, optional):\n            (estimated) minimal possible value of the objective function (lowest possible loss). Defaults to 0.\n    \"\"\"\n    def __init__(self, f_star: float = 0):\n        defaults = dict(f_star=f_star)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        tensors = TensorList(tensors)\n        f_star = settings[0]['f_star']\n\n        f_prev = self.global_state.get('f_prev', None)\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', init=[params,tensors], cls=TensorList)\n\n        # -------------------------------- first step -------------------------------- #\n        if f_prev is None:\n            self.global_state['f_prev'] = loss\n            h = 2*(loss - f_star) / tensors.dot(tensors)\n            return h * tensors\n\n        # ------------------------------- further steps ------------------------------ #\n        update = adaptive_heavy_ball(\n            f=loss, f_star=f_star, f_prev=f_prev, g=tensors, g_prev=g_prev, p=TensorList(params), p_prev=p_prev)\n\n        # --------------------------- store previous values -------------------------- #\n        self.global_state['f_prev'] = loss\n        p_prev.copy_(params)\n        g_prev.copy_(tensors)\n\n        return update\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.BacktrackOnSignChange","title":"BacktrackOnSignChange","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Negates or undoes update for parameters where where gradient or update sign changes.</p> <p>This is part of RProp update rule.</p> <p>Parameters:</p> <ul> <li> <code>use_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, tracks sign change of the gradient, otherwise track sign change of the update. Defaults to True.</p> </li> <li> <code>backtrack</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, undoes the update when sign changes, otherwise negates it. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class BacktrackOnSignChange(TensorTransform):\n    \"\"\"Negates or undoes update for parameters where where gradient or update sign changes.\n\n    This is part of RProp update rule.\n\n    Args:\n        use_grad (bool, optional):\n            if True, tracks sign change of the gradient,\n            otherwise track sign change of the update. Defaults to True.\n        backtrack (bool, optional):\n            if True, undoes the update when sign changes, otherwise negates it.\n            Defaults to True.\n\n    \"\"\"\n    def __init__(self, use_grad = False, backtrack = True):\n        defaults = dict(use_grad=use_grad, backtrack=backtrack)\n        super().__init__(defaults, uses_grad=use_grad)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        tensors = TensorList(tensors)\n        backtrack = settings[0]['backtrack']\n\n        if self._uses_grad:\n            assert grads is not None\n            cur = TensorList(grads)\n        else: cur = tensors\n\n        tensors = backtrack_on_sign_change_(\n            tensors_ = tensors,\n            cur = cur,\n            prev_ = unpack_states(states, tensors, 'prev', cls=TensorList),\n            backtrack = backtrack,\n            step = step,\n        )\n\n        return tensors\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.DualNormCorrection","title":"DualNormCorrection","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Dual norm correction for dualizer based optimizers (https://github.com/leloykun/adaptive-muon). Orthogonalize already has this built in with the <code>dual_norm_correction</code> setting.</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>class DualNormCorrection(TensorTransform):\n    \"\"\"Dual norm correction for dualizer based optimizers (https://github.com/leloykun/adaptive-muon).\n    Orthogonalize already has this built in with the `dual_norm_correction` setting.\"\"\"\n    def __init__(self, channel_first: bool = True):\n        defaults = dict(channel_first=channel_first)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        assert grad is not None\n        if (tensor.ndim &gt;= 2) and (tensor.size(0) &gt; 1) and (tensor.size(1) &gt; 1):\n            return _dual_norm_correction(tensor, grad, channel_first=setting[\"channel_first\"])\n        return tensor\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.ESGD","title":"ESGD","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Equilibrated Gradient Descent (https://arxiv.org/abs/1502.04390)</p> <pre><code>This is similar to Adagrad, but the accumulates squared randomized hessian diagonal estimates instead of squared gradients.\n\nNotes:\n    - In most cases ESGD should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply ESGD preconditioning to another module's output.\n\n    - This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\nArgs:\n    damping (float, optional): added to denominator for stability. Defaults to 1e-4.\n    update_freq (int, optional):\n        frequency of updating hessian diagonal estimate via a hessian-vector product.\n        This value can be increased to reduce computational cost. Defaults to 20.\n    hvp_method (str, optional):\n        Determines how hessian-vector products are computed.\n\n        - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n        - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n        - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n        - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n        Defaults to ``\"autograd\"``.\n    h (float, optional):\n        The step size for finite difference if ``hvp_method`` is\n        ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n    n_samples (int, optional):\n        number of hessian-vector products with random vectors to evaluate each time when updating\n        the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n    seed (int | None, optional): seed for random vectors. Defaults to None.\n    inner (Chainable | None, optional):\n        Inner module. If this is specified, operations are performed in the following order.\n        1. compute hessian diagonal estimate.\n        2. pass inputs to :code:`inner`.\n        3. momentum and preconditioning are applied to the ouputs of :code:`inner`.\n\n### Examples:\n\nUsing ESGD:\n</code></pre> <p>```python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ESGD(),\n    tz.m.LR(0.1)\n)\n```\n\nESGD preconditioner can be applied to any other module by passing it to the :code:`inner` argument. Here is an example of applying\nESGD preconditioning to nesterov momentum (:code:`tz.m.NAG`):\n\n```python\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ESGD(beta1=0, inner=tz.m.NAG(0.9)),\n    tz.m.LR(0.1)\n)\n```\n</code></pre> Source code in <code>torchzero/modules/adaptive/esgd.py</code> <pre><code>class ESGD(Transform):\n    \"\"\"Equilibrated Gradient Descent (https://arxiv.org/abs/1502.04390)\n\n    This is similar to Adagrad, but the accumulates squared randomized hessian diagonal estimates instead of squared gradients.\n\n    Notes:\n        - In most cases ESGD should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply ESGD preconditioning to another module's output.\n\n        - This module requires a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        damping (float, optional): added to denominator for stability. Defaults to 1e-4.\n        update_freq (int, optional):\n            frequency of updating hessian diagonal estimate via a hessian-vector product.\n            This value can be increased to reduce computational cost. Defaults to 20.\n        hvp_method (str, optional):\n            Determines how hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        n_samples (int, optional):\n            number of hessian-vector products with random vectors to evaluate each time when updating\n            the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n        seed (int | None, optional): seed for random vectors. Defaults to None.\n        inner (Chainable | None, optional):\n            Inner module. If this is specified, operations are performed in the following order.\n            1. compute hessian diagonal estimate.\n            2. pass inputs to :code:`inner`.\n            3. momentum and preconditioning are applied to the ouputs of :code:`inner`.\n\n    ### Examples:\n\n    Using ESGD:\n```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ESGD(),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    ESGD preconditioner can be applied to any other module by passing it to the :code:`inner` argument. Here is an example of applying\n    ESGD preconditioning to nesterov momentum (:code:`tz.m.NAG`):\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ESGD(beta1=0, inner=tz.m.NAG(0.9)),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        damping: float = 1e-4,\n        update_freq: int = 20,\n        distribution: Distributions = 'gaussian',\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        n_samples = 1,\n        zHz: bool = False,\n        seed: int | None = None,\n        beta: float | None = None,\n        beta_debias: bool = True,\n\n        inner: Chainable | None = None,\n        Hz_sq_acc_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"Hz_sq_acc_tfm\"]\n        super().__init__(defaults, inner=inner)\n\n        self.set_child(\"Hz_sq_acc\", Hz_sq_acc_tfm)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n\n        fs = settings[0]\n        update_freq = fs['update_freq']\n\n        # ------------------------------- accumulate Hz ------------------------------ #\n        step = self.increment_counter(\"step\", start=0)\n\n        if step % update_freq == 0:\n            self.increment_counter(\"num_Hzs\", start=1)\n\n            Hz, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = fs['n_samples'],\n                distribution = fs['distribution'],\n                hvp_method = fs['hvp_method'],\n                h = fs['h'],\n                zHz = fs[\"zHz\"], # default is False, so it returns Hz, not z\u2299Hz\n                generator = self.get_generator(params[0].device, fs[\"seed\"]),\n            )\n\n            Hz = TensorList(Hz)\n            Hz_sq_acc = unpack_states(states, params, 'Hz_sq_acc', cls=TensorList)\n\n            beta = fs[\"beta\"]\n            if beta is None:\n                Hz_sq_acc.addcmul_(Hz, Hz)\n\n            else:\n                Hz_sq_acc.mul_(beta).addcmul_(Hz, Hz, value=1-beta)\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        tensors = TensorList(objective.get_updates())\n        Hz_sq_acc = unpack_states(states, tensors, 'Hz_sq_acc', cls=TensorList)\n        num_Hzs = self.global_state[\"num_Hzs\"]\n        fs = settings[0]\n\n        # ---------------------------------- debias ---------------------------------- #\n        beta = fs[\"beta\"]\n        beta_debias = fs[\"beta_debias\"]\n\n        if beta_debias and beta is not None:\n            bias_correction = 1.0 - beta ** num_Hzs\n            Hz_sq_acc = Hz_sq_acc / bias_correction\n\n        else:\n            Hz_sq_acc = Hz_sq_acc / num_Hzs\n\n        # ---------------------------------- update ---------------------------------- #\n        damping = [s[\"damping\"] for s in settings]\n\n        denom = (Hz_sq_acc / num_Hzs).sqrt_().add_(damping)\n\n        objective.updates = tensors.div_(denom)\n        return objective\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.FullMatrixAdagrad","title":"FullMatrixAdagrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Full-matrix version of Adagrad, can be customized to make RMSprop or Adam (see examples).</p> Note <p>A more memory-efficient version equivalent to full matrix Adagrad on last n gradients is implemented in <code>tz.m.GGT</code>.</p> <p>Parameters:</p> <ul> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-12</code> )           \u2013            <p>regularization, scale of identity matrix added to accumulator. Defaults to 1e-12.</p> </li> <li> <code>precond_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the inverse square root of the accumulator. Defaults to 1.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>momentum for gradient outer product accumulators. if None, uses sum. Defaults to None.</p> </li> <li> <code>beta_debias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use debiasing, only has effect when <code>beta</code> is not <code>None</code>. Defaults to True.</p> </li> <li> <code>init</code>               (<code>Literal[str]</code>, default:                   <code>'identity'</code> )           \u2013            <p>how to initialize the accumulator. - \"identity\" - with identity matrix (default). - \"zeros\" - with zero matrix. - \"ones\" - with matrix of ones.  -\"GGT\" - with the first outer product</p> </li> <li> <code>matrix_power</code>               (<code>float</code>, default:                   <code>-0.5</code> )           \u2013            <p>accumulator matrix power. Defaults to -1/2.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if False, each parameter will have it's own accumulator. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>inner modules to apply preconditioning to. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.FullMatrixAdagrad--examples","title":"Examples:","text":"<p>Plain full-matrix adagrad <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.FullMatrixAdagrd(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Full-matrix RMSprop <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.FullMatrixAdagrad(beta=0.99),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Full-matrix Adam <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.FullMatrixAdagrad(beta=0.999, inner=tz.m.EMA(0.9)),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/adagrad.py</code> <pre><code>class FullMatrixAdagrad(TensorTransform):\n    \"\"\"Full-matrix version of Adagrad, can be customized to make RMSprop or Adam (see examples).\n\n    Note:\n        A more memory-efficient version equivalent to full matrix Adagrad on last n gradients is implemented in ``tz.m.GGT``.\n\n    Args:\n        reg (float, optional): regularization, scale of identity matrix added to accumulator. Defaults to 1e-12.\n        precond_freq (int, optional): frequency of updating the inverse square root of the accumulator. Defaults to 1.\n        beta (float | None, optional): momentum for gradient outer product accumulators. if None, uses sum. Defaults to None.\n        beta_debias (bool, optional): whether to use debiasing, only has effect when ``beta`` is not ``None``. Defaults to True.\n        init (Literal[str], optional):\n            how to initialize the accumulator.\n            - \"identity\" - with identity matrix (default).\n            - \"zeros\" - with zero matrix.\n            - \"ones\" - with matrix of ones.\n             -\"GGT\" - with the first outer product\n        matrix_power (float, optional): accumulator matrix power. Defaults to -1/2.\n        concat_params (bool, optional): if False, each parameter will have it's own accumulator. Defaults to True.\n        inner (Chainable | None, optional): inner modules to apply preconditioning to. Defaults to None.\n\n    ## Examples:\n\n    Plain full-matrix adagrad\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.FullMatrixAdagrd(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Full-matrix RMSprop\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.FullMatrixAdagrad(beta=0.99),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Full-matrix Adam\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.FullMatrixAdagrad(beta=0.999, inner=tz.m.EMA(0.9)),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        reg: float = 1e-12,\n        precond_freq: int = 1,\n        beta: float | None = None,\n        beta_debias: bool=True,\n        init: Literal[\"identity\", \"zeros\", \"GGT\"] = \"identity\",\n        matrix_power: float = -1/2,\n        matrix_power_method: MatrixPowerMethod = \"eigh_abs\",\n        concat_params=True,\n\n        inner: Chainable | None = None,\n        accumulator_tfm: Chainable | None = None\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"concat_params\"], defaults[\"accumulator_tfm\"]\n        super().__init__(defaults=defaults, inner=inner, concat_params=concat_params)\n\n        self.set_child(\"accumulator\", accumulator_tfm)\n        self.add_projected_keys(\"covariance\", \"accumulator\")\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n\n        G = tensor.ravel()\n        GGT = torch.outer(G, G)\n\n        # initialize\n        if \"accumulator\" not in state:\n            init = setting['init']\n            if init == 'identity': state['accumulator'] = torch.eye(GGT.size(0), device=GGT.device, dtype=GGT.dtype)\n            elif init == 'zeros': state['accumulator'] =  torch.zeros_like(GGT)\n            elif init == 'GGT': state['accumulator'] = GGT.clone()\n            else: raise ValueError(init)\n\n        # update\n        beta = setting['beta']\n        accumulator: torch.Tensor = state[\"accumulator\"]\n\n        if beta is None: accumulator.add_(GGT)\n        else: accumulator.lerp_(GGT, 1-beta)\n\n        # update number of GG\u1d40 in accumulator for divide\n        state['num_GGTs'] = state.get('num_GGTs', 0) + 1\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        step = state.get('step', 0)\n        state['step'] = step + 1\n\n        accumulator: torch.Tensor = state['accumulator']\n        accumulator = self.inner_step_tensors(\"accumulator\", [accumulator], clone=True, must_exist=False)[0]\n\n        precond_freq = setting['precond_freq']\n        reg = setting['reg']\n        beta = setting[\"beta\"]\n\n        # add regularizer\n        if reg != 0:\n            device = accumulator.device; dtype = accumulator.dtype\n            accumulator = accumulator + torch.eye(accumulator.size(0), device=device, dtype=dtype).mul_(reg)\n\n        # for single value use sqrt\n        if tensor.numel() == 1:\n            dir = tensor.mul_(accumulator.squeeze() ** setting[\"matrix_power\"])\n\n        # otherwise use matrix inverse square root\n        else:\n\n            # compute inverse square root and store to state\n            try:\n                if \"B\" not in state or step % precond_freq == 0:\n                    B = state[\"B\"] = _matrix_power(accumulator, setting[\"matrix_power\"], method=setting[\"matrix_power_method\"])\n                else:\n                    B = state[\"B\"]\n\n                dir = (B @ tensor.ravel()).view_as(tensor)\n\n            # fallback to diagonal Adagrad on fail\n            except torch.linalg.LinAlgError:\n                dir = tensor.mul_(accumulator.diagonal() ** setting[\"matrix_power\"])\n\n        # debias\n        if setting[\"beta_debias\"] and beta is not None:\n            num_GGTs = state.get('num_GGTs', 1)\n            bias_correction = 1 - beta ** num_GGTs\n            dir *= bias_correction ** 0.5\n\n        return dir\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.GGT","title":"GGT","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>GGT method from https://arxiv.org/pdf/1806.02958</p> <p>The update rule is to stack recent gradients into M and compute eigendecomposition of M M^T via eigendecomposition of M^T M.</p> <p>This is equivalent to full-matrix Adagrad on recent gradients.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of past gradients to store. Defaults to 10.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the preconditioner (U and S). Defaults to 1.</p> </li> <li> <code>eig_tol</code>               (<code>float</code>, default:                   <code>1e-07</code> )           \u2013            <p>removes eigenvalues this much smaller than largest eigenvalue. Defaults to 1e-7.</p> </li> <li> <code>truncate</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>number of larges eigenvalues to keep. None to disable. Defaults to None.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>damping value. Defaults to 1e-4.</p> </li> <li> <code>rdamping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>value of damping relative to largest eigenvalue. Defaults to 0.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, treats all parameters as a single vector. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioner will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.GGT--examples","title":"Examples:","text":"<p>Limited-memory Adagrad</p> <p><pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGT(),\n    tz.m.LR(0.1)\n)\n</code></pre> Adam with L-Adagrad preconditioner (for debiasing second beta is 0.999 arbitrarily)</p> <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGT(inner=tz.m.EMA()),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.LR(0.01)\n)\n</code></pre> <p>Stable Adam with L-Adagrad preconditioner (this is what I would recommend)</p> <p><pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.GGT(inner=tz.m.EMA()),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.ClipNormByEMA(max_ema_growth=1.2),\n    tz.m.LR(0.01)\n)\n</code></pre> Reference:     Agarwal N. et al. Efficient full-matrix adaptive regularization //International Conference on Machine Learning. \u2013 PMLR, 2019. \u2013 \u0421. 102-110.</p> Source code in <code>torchzero/modules/adaptive/ggt.py</code> <pre><code>class GGT(TensorTransform):\n    \"\"\"\n    GGT method from https://arxiv.org/pdf/1806.02958\n\n    The update rule is to stack recent gradients into M and\n    compute eigendecomposition of M M^T via eigendecomposition of M^T M.\n\n    This is equivalent to full-matrix Adagrad on recent gradients.\n\n    Args:\n        history_size (int, optional): number of past gradients to store. Defaults to 10.\n        update_freq (int, optional): frequency of updating the preconditioner (U and S). Defaults to 1.\n        eig_tol (float, optional): removes eigenvalues this much smaller than largest eigenvalue. Defaults to 1e-7.\n        truncate (int, optional): number of larges eigenvalues to keep. None to disable. Defaults to None.\n        damping (float, optional): damping value. Defaults to 1e-4.\n        rdamping (float, optional): value of damping relative to largest eigenvalue. Defaults to 0.\n        concat_params (bool, optional): if True, treats all parameters as a single vector. Defaults to True.\n        inner (Chainable | None, optional): preconditioner will be applied to output of this module. Defaults to None.\n\n    ## Examples:\n\n    Limited-memory Adagrad\n\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGT(),\n        tz.m.LR(0.1)\n    )\n    ```\n    Adam with L-Adagrad preconditioner (for debiasing second beta is 0.999 arbitrarily)\n\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGT(inner=tz.m.EMA()),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.LR(0.01)\n    )\n    ```\n\n    Stable Adam with L-Adagrad preconditioner (this is what I would recommend)\n\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.GGT(inner=tz.m.EMA()),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.ClipNormByEMA(max_ema_growth=1.2),\n        tz.m.LR(0.01)\n    )\n    ```\n    Reference:\n        Agarwal N. et al. Efficient full-matrix adaptive regularization //International Conference on Machine Learning. \u2013 PMLR, 2019. \u2013 \u0421. 102-110.\n    \"\"\"\n\n    def __init__(\n        self,\n        history_size: int = 100,\n        update_freq: int = 1,\n        eig_tol: float = 1e-7,\n        truncate: int | None = None,\n        damping: float = 1e-4,\n        rdamping: float = 0,\n        matrix_power: float = -1/2,\n        basis_optimizer: LREOptimizerBase | None = None,\n        concat_params: bool = True,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults['concat_params']\n\n        super().__init__(defaults, concat_params=concat_params, inner=inner)\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n        history_size = setting['history_size']\n        update_freq = setting['update_freq']\n\n        if 'history' not in state: state['history'] = deque(maxlen=history_size)\n        history = state['history']\n\n        t = tensor.clone().view(-1)\n        history.append(t)\n\n        step = state.get('step', 0)\n        state['step'] = step + 1\n\n        if step % update_freq == 0 :\n\n            # compute new factors\n            L = state.get(\"L\", None)\n            U = state.get(\"U\", None)\n\n            L_new, U_new = ggt_update(\n                history,\n                damping=setting[\"damping\"],\n                rdamping=setting[\"rdamping\"],\n                truncate=setting[\"truncate\"],\n                eig_tol=setting[\"eig_tol\"],\n                matrix_power=setting[\"matrix_power\"],\n            )\n\n            # reproject basis optimizer\n            basis_optimizer: LREOptimizerBase | None = setting[\"basis_optimizer\"]\n            if basis_optimizer is not None:\n                if (L is not None) and (U is not None) and (L_new is not None) and (U_new is not None):\n                    basis_state = state[\"basis_state\"]\n                    basis_optimizer.reproject(L_old=L, Q_old=U, L_new=L_new, Q_new=U_new, state=basis_state)\n\n\n            # store new factors\n            if L_new is not None: state[\"L\"] = L_new\n            if U_new is not None: state[\"U\"] = U_new\n\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        g = tensor.view(-1)\n        U = state.get('U', None)\n\n        if U is None:\n            # fallback to element-wise preconditioning\n            history = torch.stack(tuple(state[\"history\"]), 0)\n            g /= history.square().mean(0).sqrt().add(1e-8)\n            return g.view_as(tensor)\n\n        L = state['L']\n\n        # step with basis optimizer\n        basis_optimizer: LREOptimizerBase | None = setting[\"basis_optimizer\"]\n        if basis_optimizer is not None:\n\n            if \"basis_state\" not in state: state[\"basis_state\"] = {}\n            basis_state = state[\"basis_state\"]\n\n            update = basis_optimizer.step(g, L=L, Q=U, state=basis_state)\n            return update.view_as(tensor)\n\n        # or just whiten\n        z = U.T @ g\n        update = (U * L.pow(setting[\"matrix_power\"])) @ z\n        return update.view_as(tensor)\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Lion","title":"Lion","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Lion (EvoLved Sign Momentum) optimizer from https://arxiv.org/abs/2302.06675.</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>dampening for momentum. Defaults to 0.9.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum factor. Defaults to 0.99.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/lion.py</code> <pre><code>class Lion(TensorTransform):\n    \"\"\"Lion (EvoLved Sign Momentum) optimizer from https://arxiv.org/abs/2302.06675.\n\n    Args:\n        beta1 (float, optional): dampening for momentum. Defaults to 0.9.\n        beta2 (float, optional): momentum factor. Defaults to 0.99.\n    \"\"\"\n\n    def __init__(self, beta1: float = 0.9, beta2: float = 0.99):\n        defaults = dict(beta1=beta1, beta2=beta2)\n        super().__init__(defaults)\n\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        beta1, beta2 = unpack_dicts(settings, 'beta1', 'beta2', cls=NumberList)\n        exp_avg = unpack_states(states, tensors, 'exp_avg', cls=TensorList)\n        return lion_(TensorList(tensors), exp_avg, beta1, beta2)\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.MARSCorrection","title":"MARSCorrection","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>MARS variance reduction correction.</p> <p>Place any other momentum-based optimizer after this, make sure <code>beta</code> parameter matches with momentum in the optimizer.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>use the same beta as you use in the momentum module. Defaults to 0.9.</p> </li> <li> <code>scaling</code>               (<code>float</code>, default:                   <code>0.025</code> )           \u2013            <p>controls the scale of gradient correction in variance reduction. Defaults to 0.025.</p> </li> <li> <code>max_norm</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>clips norm of corrected gradients, None to disable. Defaults to 1.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.MARSCorrection--examples","title":"Examples:","text":"<p>Mars-AdamW <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.MARSCorrection(beta=0.95),\n    tz.m.Adam(beta1=0.95, beta2=0.99),\n    tz.m.WeightDecay(1e-3),\n    tz.m.LR(0.1)\n)\n</code></pre></p> <p>Mars-Lion <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.MARSCorrection(beta=0.9),\n    tz.m.Lion(beta1=0.9),\n    tz.m.LR(0.1)\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/mars.py</code> <pre><code>class MARSCorrection(TensorTransform):\n    \"\"\"MARS variance reduction correction.\n\n    Place any other momentum-based optimizer after this,\n    make sure ``beta`` parameter matches with momentum in the optimizer.\n\n    Args:\n        beta (float, optional): use the same beta as you use in the momentum module. Defaults to 0.9.\n        scaling (float, optional): controls the scale of gradient correction in variance reduction. Defaults to 0.025.\n        max_norm (float, optional): clips norm of corrected gradients, None to disable. Defaults to 1.\n\n    ## Examples:\n\n    Mars-AdamW\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.MARSCorrection(beta=0.95),\n        tz.m.Adam(beta1=0.95, beta2=0.99),\n        tz.m.WeightDecay(1e-3),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    Mars-Lion\n    ```python\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.MARSCorrection(beta=0.9),\n        tz.m.Lion(beta1=0.9),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        beta: float = 0.9,\n        scaling: float = 0.025,\n        max_norm: float | None = 1,\n    ):\n        defaults = dict(beta=beta, scaling=scaling, max_norm=max_norm)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"g_prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        g_prev = unpack_states(states, tensors, 'g_prev', init=tensors, cls=TensorList)\n        beta, scaling = unpack_dicts(settings, 'beta', 'scaling', cls=NumberList)\n        max_norm = settings[0]['max_norm']\n\n        return mars_correction_(\n            tensors_=TensorList(tensors),\n            g_prev_=g_prev,\n            beta=beta,\n            scaling=scaling,\n            max_norm=max_norm,\n        )\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.MSAM","title":"MSAM","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> Note <p>Please make sure to place <code>tz.m.LR</code> inside the <code>modules</code> argument. For example, <code>tz.m.MSAMObjective([tz.m.Adam(), tz.m.LR(1e-3)])</code>. Putting LR after MSAM will lead to an incorrect update rule.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable</code>)           \u2013            <p>modules that will optimize the MSAM objective. Make sure <code>tz.m.LR</code> is one of them.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.3</code> )           \u2013            <p>perturbation strength. Defaults to 0.3.</p> </li> <li> <code>nesterov</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use nesterov momentum formula. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, MSAM momentum becomes similar to exponential moving average. Defaults to False.</p> </li> </ul> <p>Examples: AdamW-MSAM</p> <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.MSAMObjective(\n        [tz.m.Adam(), tz.m.WeightDecay(1e-3), tz.m.LR(1e-3)],\n        rho=1.\n    )\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/msam.py</code> <pre><code>class MSAM(Transform):\n    \"\"\"Momentum-SAM from https://arxiv.org/pdf/2401.12033.\n\n    Note:\n        Please make sure to place ``tz.m.LR`` inside the ``modules`` argument. For example,\n        ``tz.m.MSAMObjective([tz.m.Adam(), tz.m.LR(1e-3)])``. Putting LR after MSAM will lead\n        to an incorrect update rule.\n\n    Args:\n        modules (Chainable): modules that will optimize the MSAM objective. Make sure ``tz.m.LR`` is one of them.\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        rho (float, optional): perturbation strength. Defaults to 0.3.\n        nesterov (bool, optional): whether to use nesterov momentum formula. Defaults to False.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, MSAM momentum becomes similar to exponential moving average.\n            Defaults to False.\n\n    Examples:\n    AdamW-MSAM\n\n    ```py\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.MSAMObjective(\n            [tz.m.Adam(), tz.m.WeightDecay(1e-3), tz.m.LR(1e-3)],\n            rho=1.\n        )\n    )\n    ```\n    \"\"\"\n    def __init__(self, modules: Chainable, momentum:float=0.9, rho:float=0.3, weight_decay:float=0, nesterov=False, lerp=False):\n        defaults = dict(momentum=momentum, rho=rho, weight_decay=weight_decay, nesterov=nesterov, lerp=lerp)\n        super().__init__(defaults)\n\n        self.set_child('modules', modules)\n        self.add_projected_keys(\"grad\", \"velocity\")\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        velocity = unpack_states(states, objective.params, 'velocity', cls=TensorList)\n        fs = settings[0]\n\n        momentum, rho, weight_decay = unpack_dicts(settings, 'momentum', 'rho', 'weight_decay', cls=NumberList)\n\n        return msam_(\n            TensorList(objective.get_updates()),\n            params=TensorList(objective.params),\n            velocity_=velocity,\n            momentum=momentum,\n            lr=None,\n            rho=rho,\n            weight_decay=weight_decay,\n            nesterov=fs['nesterov'],\n            lerp=fs['lerp'],\n\n            # inner args\n            inner=self.children[\"modules\"],\n            objective=objective,\n        )\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.MSAMMomentum","title":"MSAMMomentum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Momentum-SAM from https://arxiv.org/pdf/2401.12033.</p> <p>This implementation expresses the update rule as function of gradient. This way it can be used as a drop-in replacement for momentum strategies in other optimizers.</p> <p>To combine MSAM with other optimizers in the way done in the official implementation, e.g. to make Adam_MSAM, use <code>tz.m.MSAMObjective</code> module.</p> <p>Note     MSAM has a learning rate hyperparameter that can't really be removed from the update rule.     To avoid compounding learning rate mofications, remove the <code>tz.m.LR</code> module if you had it.</p> <p>Parameters:</p> <ul> <li> <code>lr</code>               (<code>float</code>)           \u2013            <p>learning rate. Adding this module adds support for learning rate schedulers.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.3</code> )           \u2013            <p>perturbation strength. Defaults to 0.3.</p> </li> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>weight decay. It is applied to perturbed parameters, so it is differnet from applying :code:<code>tz.m.WeightDecay</code> after MSAM. Defaults to 0.</p> </li> <li> <code>nesterov</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use nesterov momentum formula. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.MSAMMomentum--examples","title":"Examples:","text":"<p>MSAM</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.MSAM(1e-3)\n)\n</code></pre> <p>Adam with MSAM instead of exponential average. Note that this is different from Adam_MSAM. To make Adam_MSAM and such, use the <code>tz.m.MSAMObjective</code> module.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.RMSprop(0.999, inner=tz.m.MSAM(1e-3)),\n    tz.m.Debias(0.9, 0.999),\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/msam.py</code> <pre><code>class MSAMMomentum(TensorTransform):\n    \"\"\"Momentum-SAM from https://arxiv.org/pdf/2401.12033.\n\n    This implementation expresses the update rule as function of gradient. This way it can be used as a drop-in\n    replacement for momentum strategies in other optimizers.\n\n    To combine MSAM with other optimizers in the way done in the official implementation,\n    e.g. to make Adam_MSAM, use ``tz.m.MSAMObjective`` module.\n\n    Note\n        MSAM has a learning rate hyperparameter that can't really be removed from the update rule.\n        To avoid compounding learning rate mofications, remove the ``tz.m.LR`` module if you had it.\n\n    Args:\n        lr (float): learning rate. Adding this module adds support for learning rate schedulers.\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        rho (float, optional): perturbation strength. Defaults to 0.3.\n        weight_decay (float, optional):\n            weight decay. It is applied to perturbed parameters, so it is differnet\n            from applying :code:`tz.m.WeightDecay` after MSAM. Defaults to 0.\n        nesterov (bool, optional): whether to use nesterov momentum formula. Defaults to False.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.\n\n    ### Examples:\n\n    MSAM\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.MSAM(1e-3)\n    )\n    ```\n\n    Adam with MSAM instead of exponential average. Note that this is different from Adam_MSAM.\n    To make Adam_MSAM and such, use the ``tz.m.MSAMObjective`` module.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.RMSprop(0.999, inner=tz.m.MSAM(1e-3)),\n        tz.m.Debias(0.9, 0.999),\n    )\n    ```\n    \"\"\"\n\n    def __init__(self, lr: float, momentum:float=0.9, rho:float=0.3,  weight_decay:float=0, nesterov=False, lerp=False,):\n        defaults = dict(lr = lr, momentum=momentum, rho=rho, nesterov=nesterov, lerp=lerp, weight_decay=weight_decay)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"velocity\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        velocity = unpack_states(states, tensors, 'velocity', cls=TensorList)\n        fs = settings[0]\n\n        lr, momentum, rho, weight_decay = unpack_dicts(settings, 'lr','momentum','rho','weight_decay', cls=NumberList)\n\n        return msam_(\n            TensorList(tensors),\n            params=TensorList(params),\n            velocity_=velocity,\n            momentum=momentum,\n            lr=lr,\n            rho=rho,\n            weight_decay=weight_decay,\n            nesterov=fs['nesterov'],\n            lerp=fs['lerp'],\n\n            # inner args\n            inner=None,\n            objective=None,\n        )\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.MatrixMomentum","title":"MatrixMomentum","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Second order momentum method.</p> <p>Matrix momentum is useful for convex objectives, also for some reason it has very really good generalization on elastic net logistic regression.</p> Notes <ul> <li> <p><code>mu</code> needs to be tuned very carefully. It is supposed to be smaller than (1/largest eigenvalue), otherwise this will be very unstable. I have devised an adaptive version of this - <code>tz.m.AdaptiveMatrixMomentum</code>, and it works well without having to tune <code>mu</code>, however the adaptive version doesn't work on stochastic objectives.</p> </li> <li> <p>In most cases <code>MatrixMomentum</code> should be the first module in the chain because it relies on autograd.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>mu</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>this has a similar role to (1 - beta) in normal momentum. Defaults to 0.1.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to <code>\"autograd\"</code>. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>hvp_tfm</code>               (<code>Chainable | None</code>)           \u2013            <p>optional module applied to hessian-vector products. Defaults to None.</p> </li> </ul> Reference <p>Orr, Genevieve, and Todd Leen. \"Using curvature information for fast stochastic search.\" Advances in neural information processing systems 9 (1996).</p> Source code in <code>torchzero/modules/adaptive/matrix_momentum.py</code> <pre><code>class MatrixMomentum(Transform):\n    \"\"\"Second order momentum method.\n\n    Matrix momentum is useful for convex objectives, also for some reason it has very really good generalization on elastic net logistic regression.\n\n    Notes:\n        - ``mu`` needs to be tuned very carefully. It is supposed to be smaller than (1/largest eigenvalue), otherwise this will be very unstable. I have devised an adaptive version of this - ``tz.m.AdaptiveMatrixMomentum``, and it works well without having to tune ``mu``, however the adaptive version doesn't work on stochastic objectives.\n\n        - In most cases ``MatrixMomentum`` should be the first module in the chain because it relies on autograd.\n\n        - This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument.\n\n    Args:\n        mu (float, optional): this has a similar role to (1 - beta) in normal momentum. Defaults to 0.1.\n        hvp_method (str, optional):\n            Determines how hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        hvp_tfm (Chainable | None, optional): optional module applied to hessian-vector products. Defaults to None.\n\n    Reference:\n        Orr, Genevieve, and Todd Leen. \"Using curvature information for fast stochastic search.\" Advances in neural information processing systems 9 (1996).\n    \"\"\"\n\n    def __init__(\n        self,\n        lr:float,\n        mu=0.1,\n        hvp_method: HVPMethod = \"autograd\",\n        h: float = 1e-3,\n        adaptive:bool = False,\n        adapt_freq: int | None = None,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(lr=lr, mu=mu, hvp_method=hvp_method, h=h, adaptive=adaptive, adapt_freq=adapt_freq)\n        super().__init__(defaults, inner=inner)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('p_prev')\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        step = self.increment_counter(\"step\", 0)\n        p = TensorList(objective.params)\n        p_prev = unpack_states(states, p, 'p_prev', init=p)\n\n        fs = settings[0]\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n\n        if step &gt; 0:\n            s = p - p_prev\n\n            Hs, _ = objective.hessian_vector_product(s, at_x0=True, rgrad=None, hvp_method=hvp_method, h=h, retain_graph=False)\n            Hs = [t.detach() for t in Hs]\n\n            self.store(p, (\"Hs\", \"s\"), (Hs, s))\n\n            # -------------------------------- adaptive mu ------------------------------- #\n            if fs[\"adaptive\"]:\n                g = TensorList(objective.get_grads())\n\n                if fs[\"adapt_freq\"] is None:\n                    # ---------------------------- deterministic case ---------------------------- #\n                    g_prev = unpack_states(states, p, \"g_prev\", cls=TensorList)\n                    y = g - g_prev\n                    g_prev.copy_(g)\n                    denom = y.global_vector_norm()\n                    denom = denom.clip(min=torch.finfo(denom.dtype).tiny * 2)\n                    self.global_state[\"mu_mul\"] = s.global_vector_norm() / denom\n\n                else:\n                    # -------------------------------- stochastic -------------------------------- #\n                    adapt_freq = self.defaults[\"adapt_freq\"]\n\n                    # we start on 1nd step, and want to adapt when we start, so use (step - 1)\n                    if (step - 1) % adapt_freq == 0:\n                        assert objective.closure is not None\n                        params = TensorList(objective.params)\n                        p_cur = params.clone()\n\n                        # move to previous params and evaluate p_prev with current mini-batch\n                        params.copy_(unpack_states(states, p, 'p_prev'))\n                        with torch.enable_grad():\n                            objective.closure()\n                        g_prev = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n                        y = g - g_prev\n\n                        # move back to current params\n                        params.copy_(p_cur)\n\n                        denom = y.global_vector_norm()\n                        denom = denom.clip(min=torch.finfo(denom.dtype).tiny * 2)\n                        self.global_state[\"mu_mul\"] = s.global_vector_norm() / denom\n\n        torch._foreach_copy_(p_prev, objective.params)\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        update = TensorList(objective.get_updates())\n        lr, mu = unpack_dicts(settings, \"lr\", 'mu', cls=NumberList)\n\n        if \"mu_mul\" in self.global_state:\n            mu = mu * self.global_state[\"mu_mul\"]\n\n        # --------------------------------- 1st step --------------------------------- #\n        # p_prev is not available so make a small step\n        step = self.global_state[\"step\"]\n        if step == 1:\n            if self.defaults[\"adaptive\"]:\n                # initialize\n                unpack_states(states, objective.params, \"g_prev\", init=objective.get_grads())\n\n            update.mul_(lr) # separate so that initial_step_size can clip correctly\n            update.mul_(initial_step_size(update, 1e-7))\n            return objective\n\n        # -------------------------- matrix momentum update -------------------------- #\n        s, Hs = unpack_states(states, objective.params, 's', 'Hs', cls=TensorList)\n\n        update.mul_(lr).sub_(s).add_(Hs*mu)\n        objective.updates = update\n        return objective\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.MuonAdjustLR","title":"MuonAdjustLR","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>LR adjustment for Muon from \"Muon is Scalable for LLM Training\" (https://github.com/MoonshotAI/Moonlight/tree/master). Orthogonalize already has this built in with the <code>adjust_lr</code> setting, however you might want to move this to be later in the chain.</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>class MuonAdjustLR(Transform):\n    \"\"\"LR adjustment for Muon from \"Muon is Scalable for LLM Training\" (https://github.com/MoonshotAI/Moonlight/tree/master).\n    Orthogonalize already has this built in with the ``adjust_lr`` setting, however you might want to move this to be later in the chain.\"\"\"\n    def __init__(self, channel_first: bool = True, alpha: float = 1):\n        defaults = dict(channel_first=channel_first, alpha=alpha)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alphas = [s['alpha'] for s in settings]\n        channel_first = [s[\"channel_first=channel_first\"] for s in settings]\n        tensors_alphas = [\n            (t, adjust_lr_for_muon(a, t.shape, cf)) for t, a, cf in zip(tensors, alphas, channel_first) if _is_at_least_2d(t, channel_first=cf)\n        ]\n        tensors = [i[0] for i in tensors_alphas]\n        a = [i[1] for i in alphas]\n        torch._foreach_mul_(tensors, a)\n        return tensors\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.NaturalGradient","title":"NaturalGradient","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Natural gradient approximated via empirical fisher information matrix.</p> <p>To use this, either pass vector of per-sample losses to the step method, or make sure the closure returns it. Gradients will be calculated via batched autograd within this module, you don't need to implement the backward pass. When using closure, please add the <code>backward</code> argument, it will always be False but it is required. See below for an example.</p> Note <p>Empirical fisher information matrix may give a really bad approximation in some cases. If that is the case, set <code>sqrt</code> to True to perform whitening instead, which is way more robust.</p> <p>Parameters:</p> <ul> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>regularization parameter. Defaults to 1e-8.</p> </li> <li> <code>sqrt</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, uses square root of empirical fisher information matrix. Both EFIM and it's square root can be calculated and stored efficiently without ndim^2 memory. Square root whitens the gradient and often performs much better, especially when you try to use NGD with a vector that isn't strictly per-sample gradients, but rather for example different losses.</p> </li> <li> <code>gn_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, uses Gauss-Newton G^T @ f as the gradient, which is effectively sum weighted by value and is equivalent to squaring the values. That makes the kernel trick solver incorrect, but for some reason it still works. If False, uses sum of per-sample gradients. This has an effect when <code>sqrt=False</code>, and affects the <code>grad</code> attribute. Defaults to False.</p> </li> <li> <code>batched</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use vmapping. Defaults to True.</p> </li> </ul> <p>Examples:</p> <p>training a neural network: <pre><code>X = torch.randn(64, 20)\ny = torch.randn(64, 10)\n\nmodel = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NaturalGradient(),\n    tz.m.LR(3e-2)\n)\n\nfor i in range(100):\n    y_hat = model(X) # (64, 10)\n    losses = (y_hat - y).pow(2).mean(0) # (10, )\n    opt.step(loss=losses)\n    if i % 10 == 0:\n        print(f'{losses.mean() = }')\n</code></pre></p> <p>training a neural network - closure version <pre><code>X = torch.randn(64, 20)\ny = torch.randn(64, 10)\n\nmodel = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NaturalGradient(),\n    tz.m.LR(3e-2)\n)\n\ndef closure(backward=True):\n    y_hat = model(X) # (64, 10)\n    return (y_hat - y).pow(2).mean(0) # (10, )\n\nfor i in range(100):\n    losses = opt.step(closure)\n    if i % 10 == 0:\n    print(f'{losses.mean() = }')\n</code></pre></p> <p>minimizing the rosenbrock function with a mix of natural gradient, whitening and gauss-newton: <pre><code>def rosenbrock(X):\n    x1, x2 = X\n    return torch.stack([(1 - x1).abs(), (10 * (x2 - x1**2).abs())])\n\nX = torch.tensor([-1.1, 2.5], requires_grad=True)\nopt = tz.Optimizer([X], tz.m.NaturalGradient(sqrt=True, gn_grad=True), tz.m.LR(0.05))\n\nfor iter in range(200):\n    losses = rosenbrock(X)\n    opt.step(loss=losses)\n    if iter % 20 == 0:\n        print(f'{losses.mean() = }')\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/natural_gradient.py</code> <pre><code>class NaturalGradient(Transform):\n    \"\"\"Natural gradient approximated via empirical fisher information matrix.\n\n    To use this, either pass vector of per-sample losses to the step method, or make sure\n    the closure returns it. Gradients will be calculated via batched autograd within this module,\n    you don't need to implement the backward pass. When using closure, please add the ``backward`` argument,\n    it will always be False but it is required. See below for an example.\n\n    Note:\n        Empirical fisher information matrix may give a really bad approximation in some cases.\n        If that is the case, set ``sqrt`` to True to perform whitening instead, which is way more robust.\n\n    Args:\n        reg (float, optional): regularization parameter. Defaults to 1e-8.\n        sqrt (bool, optional):\n            if True, uses square root of empirical fisher information matrix. Both EFIM and it's square\n            root can be calculated and stored efficiently without ndim^2 memory. Square root\n            whitens the gradient and often performs much better, especially when you try to use NGD\n            with a vector that isn't strictly per-sample gradients, but rather for example different losses.\n        gn_grad (bool, optional):\n            if True, uses Gauss-Newton G^T @ f as the gradient, which is effectively sum weighted by value\n            and is equivalent to squaring the values. That makes the kernel trick solver incorrect, but for\n            some reason it still works. If False, uses sum of per-sample gradients.\n            This has an effect when ``sqrt=False``, and affects the ``grad`` attribute.\n            Defaults to False.\n        batched (bool, optional): whether to use vmapping. Defaults to True.\n\n    Examples:\n\n    training a neural network:\n    ```python\n    X = torch.randn(64, 20)\n    y = torch.randn(64, 10)\n\n    model = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NaturalGradient(),\n        tz.m.LR(3e-2)\n    )\n\n    for i in range(100):\n        y_hat = model(X) # (64, 10)\n        losses = (y_hat - y).pow(2).mean(0) # (10, )\n        opt.step(loss=losses)\n        if i % 10 == 0:\n            print(f'{losses.mean() = }')\n    ```\n\n    training a neural network - closure version\n    ```python\n    X = torch.randn(64, 20)\n    y = torch.randn(64, 10)\n\n    model = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NaturalGradient(),\n        tz.m.LR(3e-2)\n    )\n\n    def closure(backward=True):\n        y_hat = model(X) # (64, 10)\n        return (y_hat - y).pow(2).mean(0) # (10, )\n\n    for i in range(100):\n        losses = opt.step(closure)\n        if i % 10 == 0:\n        print(f'{losses.mean() = }')\n    ```\n\n    minimizing the rosenbrock function with a mix of natural gradient, whitening and gauss-newton:\n    ```python\n    def rosenbrock(X):\n        x1, x2 = X\n        return torch.stack([(1 - x1).abs(), (10 * (x2 - x1**2).abs())])\n\n    X = torch.tensor([-1.1, 2.5], requires_grad=True)\n    opt = tz.Optimizer([X], tz.m.NaturalGradient(sqrt=True, gn_grad=True), tz.m.LR(0.05))\n\n    for iter in range(200):\n        losses = rosenbrock(X)\n        opt.step(loss=losses)\n        if iter % 20 == 0:\n            print(f'{losses.mean() = }')\n    ```\n    \"\"\"\n    def __init__(self, reg:float = 1e-8, sqrt:bool=False, gn_grad:bool=False, batched:bool=True, ):\n        super().__init__(defaults=dict(batched=batched, reg=reg, sqrt=sqrt, gn_grad=gn_grad))\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n        closure = objective.closure\n        fs = settings[0]\n        batched = fs['batched']\n        gn_grad = fs['gn_grad']\n\n        # compute per-sample losses\n        f = objective.loss\n        if f is None:\n            assert closure is not None\n            with torch.enable_grad():\n                f = objective.get_loss(backward=False) # n_out\n                assert isinstance(f, torch.Tensor)\n\n        # compute per-sample gradients\n        with torch.enable_grad():\n            G_list = jacobian_wrt([f.ravel()], params, batched=batched)\n\n        # set scalar loss and it's grad to objective\n        objective.loss = f.sum()\n        G = self.global_state[\"G\"] = flatten_jacobian(G_list) # (n_samples, ndim)\n\n        if gn_grad:\n            g = self.global_state[\"g\"] = G.H @ f.detach()\n\n        else:\n            g = self.global_state[\"g\"] = G.sum(0)\n\n        objective.grads = vec_to_tensors(g, params)\n\n        # set closure to calculate scalar value for line searches etc\n        if closure is not None:\n\n            def ngd_closure(backward=True):\n\n                if backward:\n                    objective.zero_grad()\n                    with torch.enable_grad():\n                        loss = closure(False)\n                        if gn_grad: loss = loss.pow(2)\n                        loss = loss.sum()\n                        loss.backward()\n                    return loss\n\n                loss = closure(False)\n                if gn_grad: loss = loss.pow(2)\n                return loss.sum()\n\n            objective.closure = ngd_closure\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        params = objective.params\n        fs = settings[0]\n        reg = fs['reg']\n        sqrt = fs['sqrt']\n\n        G: torch.Tensor = self.global_state['G'] # (n_samples, n_dim)\n\n        if sqrt:\n            # this computes U, S &lt;- SVD(M), then calculate update as U S^-1 U\u1d40g,\n            # but it computes it through eigendecompotision\n            L, U = ggt_update(G.H, damping=reg, rdamping=1e-16, truncate=0, eig_tol=1e-12)\n\n            if U is None or L is None:\n\n                # fallback to element-wise\n                g = self.global_state[\"g\"]\n                g /= G.square().mean(0).sqrt().add(reg)\n                objective.updates = vec_to_tensors(g, params)\n                return objective\n\n            # whiten\n            z = U.T @ self.global_state[\"g\"]\n            v = (U * L.rsqrt()) @ z\n            objective.updates = vec_to_tensors(v, params)\n            return objective\n\n        # we need (G^T G)v = g\n        # where g = G^T\n        # so we need to solve (G^T G)v = G^T\n        GGt = G @ G.H # (n_samples, n_samples)\n\n        if reg != 0:\n            GGt.add_(torch.eye(GGt.size(0), device=GGt.device, dtype=GGt.dtype).mul_(reg))\n\n        z, _ = torch.linalg.solve_ex(GGt, torch.ones_like(GGt[0])) # pylint:disable=not-callable\n        v = G.H @ z\n\n        objective.updates = vec_to_tensors(v, params)\n        return objective\n\n\n    def get_H(self, objective=...):\n        if \"G\" not in self.global_state: return linear_operator.ScaledIdentity()\n        G = self.global_state['G']\n        return linear_operator.AtA(G)\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.OrthoGrad","title":"OrthoGrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> <p>Parameters:</p> <ul> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon added to the denominator for numerical stability (default: 1e-30)</p> </li> <li> <code>renormalize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to graft projected gradient to original gradient norm. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/orthograd.py</code> <pre><code>class OrthoGrad(TensorTransform):\n    \"\"\"Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.\n\n    Args:\n        eps (float, optional): epsilon added to the denominator for numerical stability (default: 1e-30)\n        renormalize (bool, optional): whether to graft projected gradient to original gradient norm. Defaults to True.\n    \"\"\"\n    def __init__(self, eps: float = 1e-8, renormalize=True):\n        defaults = dict(eps=eps, renormalize=renormalize)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        eps = settings[0]['eps']\n        renormalize = settings[0]['renormalize']\n\n        params = TensorList(params)\n        target = TensorList(tensors)\n\n        scale = params.dot(target)/(params.dot(params) + eps)\n        if renormalize:\n            norm = target.global_vector_norm()\n            target -= params * scale\n            target *= (norm / target.global_vector_norm())\n            return target\n\n        target -= params * scale\n        return target\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Orthogonalize","title":"Orthogonalize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Uses Newton-Schulz iteration or SVD to compute the zeroth power / orthogonalization of update along first 2 dims.</p> <p>To disable orthogonalization for a parameter, put it into a parameter group with \"orthogonalize\" = False. The Muon page says that embeddings and classifier heads should not be orthogonalized. Usually only matrix parameters that are directly used in matmuls should be orthogonalized.</p> <p>To make Muon, use Split with Adam on 1d params</p> <p>Parameters:</p> <ul> <li> <code>adjust_lr</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Enables LR adjustment based on parameter size from \"Muon is Scalable for LLM Training\". Defaults to False.</p> </li> <li> <code>dual_norm_correction</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.</p> </li> <li> <code>method</code>               (<code>str</code>, default:                   <code>'newtonschulz'</code> )           \u2013            <p>Newton-Schulz is very fast, SVD is slow but can be more precise.</p> </li> <li> <code>channel_first</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions are considered batch dimensions.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Orthogonalize--examples","title":"Examples:","text":"<p>standard Muon with Adam fallback <pre><code>opt = tz.Optimizer(\n    model.head.parameters(),\n    tz.m.Split(\n        # apply muon only to 2D+ parameters\n        filter = lambda t: t.ndim &gt;= 2,\n        true = [\n            tz.m.HeavyBall(),\n            tz.m.Orthogonalize(),\n            tz.m.LR(1e-2),\n        ],\n        false = tz.m.Adam()\n    ),\n    tz.m.LR(1e-2)\n)\n</code></pre></p> Reference <p>Keller Jordan, Yuchen Jin, Vlado Boza, You Jiacheng, Franz Cesista, Laker Newhouse, Jeremy Bernstein - Muon: An optimizer for hidden layers in neural networks (2024) https://github.com/KellerJordan/Muon</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>class Orthogonalize(TensorTransform):\n    \"\"\"Uses Newton-Schulz iteration or SVD to compute the zeroth power / orthogonalization of update along first 2 dims.\n\n    To disable orthogonalization for a parameter, put it into a parameter group with \"orthogonalize\" = False.\n    The Muon page says that embeddings and classifier heads should not be orthogonalized.\n    Usually only matrix parameters that are directly used in matmuls should be orthogonalized.\n\n    To make Muon, use Split with Adam on 1d params\n\n    Args:\n        adjust_lr (bool, optional):\n            Enables LR adjustment based on parameter size from \"Muon is Scalable for LLM Training\". Defaults to False.\n        dual_norm_correction (bool, optional):\n            enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.\n        method (str, optional):\n            Newton-Schulz is very fast, SVD is slow but can be more precise.\n        channel_first (bool, optional):\n            if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions\n            are considered batch dimensions.\n\n    ## Examples:\n\n    standard Muon with Adam fallback\n    ```py\n    opt = tz.Optimizer(\n        model.head.parameters(),\n        tz.m.Split(\n            # apply muon only to 2D+ parameters\n            filter = lambda t: t.ndim &gt;= 2,\n            true = [\n                tz.m.HeavyBall(),\n                tz.m.Orthogonalize(),\n                tz.m.LR(1e-2),\n            ],\n            false = tz.m.Adam()\n        ),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    Reference:\n        Keller Jordan, Yuchen Jin, Vlado Boza, You Jiacheng, Franz Cesista, Laker Newhouse, Jeremy Bernstein - Muon: An optimizer for hidden layers in neural networks (2024) https://github.com/KellerJordan/Muon\n    \"\"\"\n    def __init__(self, adjust_lr=False, dual_norm_correction=False,\n                 method: OrthogonalizeMethod = 'newtonschulz', channel_first:bool=True):\n        defaults = dict(orthogonalize=True, dual_norm_correction=dual_norm_correction, adjust_lr=adjust_lr, method=method.lower(), channel_first=channel_first)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        orthogonalize, dual_norm_correction, adjust_lr, method, channel_first = itemgetter(\n            'orthogonalize', 'dual_norm_correction', 'adjust_lr', 'method', 'channel_first')(setting)\n\n        if not orthogonalize: return tensor\n\n        if _is_at_least_2d(tensor, channel_first=channel_first):\n\n            X = _orthogonalize_format(tensor, method, channel_first=channel_first)\n\n            if dual_norm_correction:\n                X = _dual_norm_correction(X, tensor, channel_first=channel_first)\n\n            if adjust_lr:\n                X.mul_(adjust_lr_for_muon(1, param.shape, channel_first=channel_first))\n\n            return X.view_as(param)\n\n        return tensor\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDDenseNewton","title":"PSGDDenseNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Dense hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_norm</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips norm of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>dQ</code>               (<code>str</code>, default:                   <code>'Q0.5EQ1.5'</code> )           \u2013            <p>geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".</p> </li> <li> <code>hvp_method</code>               (<code>Literal</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to compute hessian-vector products. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>if <code>hvp_method</code> is <code>\"fd_central\"</code> or <code>\"fd_forward\"</code>, controls finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution for random vectors for hessian-vector products. Defaults to 'normal'.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDDenseNewton--examples","title":"Examples:","text":"<p>Pure Dense Newton PSGD: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.DenseNewton(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Applying preconditioner to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.DenseNewton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_dense_newton.py</code> <pre><code>class PSGDDenseNewton(Transform):\n    \"\"\"Dense hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional):\n            adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_norm (float, optional): clips norm of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        dQ (str, optional): geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".\n        hvp_method (HVPMethod, optional): how to compute hessian-vector products. Defaults to 'autograd'.\n        h (float, optional):\n            if ``hvp_method`` is ``\"fd_central\"`` or ``\"fd_forward\"``, controls finite difference step size.\n            Defaults to 1e-3.\n        distribution (Distributions, optional):\n            distribution for random vectors for hessian-vector products. Defaults to 'normal'.\n\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure Dense Newton PSGD:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.DenseNewton(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Applying preconditioner to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.DenseNewton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        init_scale: float | None = None,\n        lr_preconditioner=0.1,\n        betaL=0.9,\n        damping=1e-9,\n        grad_clip_max_norm=float(\"inf\"),\n        update_probability=1.0,\n        dQ: Literal[\"QUAD4P\", \"QUAD\", \"QEP\", \"EQ\", \"QEQ\", \"Q0p5EQ1p5\", \"Q0.5EQ1.5\"] = \"Q0.5EQ1.5\",\n\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        distribution: Distributions = 'normal',\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        # -------------------------------- initialize -------------------------------- #\n        if \"Q\" not in self.global_state:\n\n            p = objective.params[0]\n            dQ = fs[\"dQ\"]\n            init_scale = fs[\"init_scale\"]\n\n            if init_scale is None:\n                self.global_state[\"Q\"] = None\n\n            else:\n                n = sum(p.numel() for p in objective.params)\n                if dQ == \"QUAD4P\":\n                    init_scale *= init_scale\n                self.global_state[\"Q\"] = torch.eye(n, dtype=p.dtype, device=p.device) * init_scale\n\n            self.global_state[\"L\"] = lift2single(torch.zeros([], dtype=p.dtype, device=p.device)) # Lipschitz smoothness constant estimation for the psgd criterion\n\n            if dQ == \"QUAD4P\":\n                self.global_state[\"update_precond\"] = update_precond_dense_quad4p\n                self.global_state[\"precond_grad\"] = lambda Q, g: Q @ g\n                assert torch.finfo(p.dtype).eps &lt; 1e-6, \"Directly fitting P needs at least single precision\"\n\n            elif dQ == \"QUAD\":\n                self.global_state[\"update_precond\"] = update_precond_dense_quad\n                self.global_state[\"precond_grad\"] = lambda Q, g: Q @ (Q @ g) # Q is symmetric; just save one transpose\n\n            else:\n                self.global_state[\"precond_grad\"] = lambda Q, g: Q.T @ (Q @ g)\n                if dQ == \"QEP\":\n                    self.global_state[\"update_precond\"] = update_precond_dense_qep\n                elif dQ == \"EQ\":\n                    self.global_state[\"update_precond\"] = update_precond_dense_eq\n                elif dQ == \"QEQ\":\n                    self.global_state[\"update_precond\"] = update_precond_dense_qeq\n                else:\n                    assert (dQ == \"Q0p5EQ1p5\") or (dQ == \"Q0.5EQ1.5\"), f\"Invalid choice for dQ: '{dQ}'\"\n                    self.global_state[\"update_precond\"] = update_precond_dense_q0p5eq1p5\n\n        # ---------------------------------- update ---------------------------------- #\n        Q = self.global_state[\"Q\"]\n        if (torch.rand([]) &lt; fs[\"update_probability\"]) or Q is None:\n\n            # hessian-vector product\n            vs = TensorList(objective.params).sample_like(distribution=fs[\"distribution\"])\n            Hvs, _ = objective.hessian_vector_product(z=vs, rgrad=None, at_x0=True, hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n\n            v = torch.cat([t.ravel() for t in vs]).unsqueeze(1)\n            h = torch.cat([t.ravel() for t in Hvs]).unsqueeze(1)\n\n            # initialize on the fly\n            if Q is None:\n                scale = (torch.mean(v*v))**(1/4) * (torch.mean(h**4) + fs[\"damping\"]**4)**(-1/8)\n                if fs[\"dQ\"] == \"QUAD4P\": # Q actually is P in this case\n                    scale *= scale\n                Q = self.global_state[\"Q\"] = torch.eye(len(v), dtype=v.dtype, device=v.device) * scale\n\n            # update preconditioner\n            self.global_state[\"update_precond\"](\n                Q=Q,\n                L=self.global_state[\"L\"],\n                v=v,\n                h=h,\n                lr=fs[\"lr_preconditioner\"],\n                betaL=fs[\"betaL\"],\n                damping=fs[\"damping\"],\n            )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n\n        # cat grads\n        g = torch.cat([t.ravel() for t in updates]).unsqueeze(1) # column vec\n        pre_grad = self.global_state[\"precond_grad\"](self.global_state[\"Q\"], g)\n\n        # norm clipping\n        grad_clip_max_norm = settings[0][\"grad_clip_max_norm\"]\n        if grad_clip_max_norm &lt; float(\"inf\"): # clip preconditioned gradient\n            grad_norm = torch.linalg.vector_norm(pre_grad)\n            if grad_norm &gt; grad_clip_max_norm:\n                pre_grad *= grad_clip_max_norm / grad_norm\n\n        vec_to_tensors_(pre_grad, updates)\n        return objective\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDKronNewton","title":"PSGDKronNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Kron hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.</p> </li> <li> <code>max_skew</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times <code>max_skew</code>, it uses a diagonal preconditioner. Defaults to 1.0.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_amp</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips amplitude of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>dQ</code>               (<code>str</code>, default:                   <code>'Q0.5EQ1.5'</code> )           \u2013            <p>geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".</p> </li> <li> <code>balance_probability</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.</p> </li> <li> <code>hvp_method</code>               (<code>Literal</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to compute hessian-vector products. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>if <code>hvp_method</code> is <code>\"fd_central\"</code> or <code>\"fd_forward\"</code>, controls finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution for random vectors for hessian-vector products. Defaults to 'normal'.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDKronNewton--examples","title":"Examples:","text":"<p>Pure PSGD Kron Newton: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronNewton(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Applying preconditioner to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronNewton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_kron_newton.py</code> <pre><code>class PSGDKronNewton(Transform):\n    \"\"\"Kron hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        max_dim (int, optional): dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.\n        max_skew (float, optional):\n            if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times ``max_skew``, it uses a diagonal preconditioner. Defaults to 1.0.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional): adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_amp (float, optional): clips amplitude of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        dQ (str, optional): geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".\n        balance_probability (float, optional):\n            probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.\n        hvp_method (HVPMethod, optional): how to compute hessian-vector products. Defaults to 'autograd'.\n        h (float, optional):\n            if ``hvp_method`` is ``\"fd_central\"`` or ``\"fd_forward\"``, controls finite difference step size.\n            Defaults to 1e-3.\n        distribution (Distributions, optional):\n            distribution for random vectors for hessian-vector products. Defaults to 'normal'.\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n\n    ###Examples:\n\n    Pure PSGD Kron Newton:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronNewton(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Applying preconditioner to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronNewton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        max_dim: int = 10_000,\n        max_skew: float = 1.0,\n        init_scale: float | None = None,\n        lr_preconditioner: float = 0.1,\n        betaL: float = 0.9,\n        damping: float = 1e-9,\n        grad_clip_max_amp: float = float(\"inf\"),\n        update_probability: float= 1.0,\n        dQ: Literal[\"QEP\", \"EQ\", \"QEQ\", \"QUAD\",  \"Q0.5EQ1.5\", \"Q0p5EQ1p5\", \"QUAD4P\"] = \"Q0.5EQ1.5\",\n        balance_probability: float = 0.01,\n\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        distribution: Distributions = 'normal',\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n\n    def _initialize_state(self, param, state, setting):\n        assert \"initialized\" not in state\n        state[\"initialized\"] = True\n\n        # initialize preconditioners\n        if setting[\"init_scale\"] is None:\n            warnings.warn(\"FYI: Will set the preconditioner initial scale on the fly. Recommend to set it manually.\")\n            state[\"QLs_exprs\"] = None\n        else:\n            state[\"QLs_exprs\"] = init_kron(\n                param.squeeze(),\n                Scale=setting[\"init_scale\"],\n                max_size=setting[\"max_dim\"],\n                max_skew=setting[\"max_skew\"],\n                dQ=setting[\"dQ\"],\n            )\n\n        dQ = setting[\"dQ\"]\n        if dQ == \"QUAD4P\":\n            assert torch.finfo(param.dtype).eps &lt; 1e-6, \"Directly fitting P needs at least single precision\"\n            state[\"update_precond\"] = update_precond_kron_newton_quad4p\n            state[\"precond_grad\"] = lambda QL, exprs, G: exprs[0](*QL[0], G) # it's exprA(*Q, G)\n\n        else:\n            state[\"precond_grad\"] = precond_grad_kron\n            if dQ == \"QEP\":\n                state[\"update_precond\"] = update_precond_kron_newton_quad\n            elif dQ == \"EQ\":\n                state[\"update_precond\"] = update_precond_kron_newton_qep\n            elif dQ == \"QEQ\":\n                state[\"update_precond\"] = update_precond_kron_newton_eq\n            elif dQ == \"QUAD\":\n                state[\"update_precond\"] = update_precond_kron_newton_qeq\n            else:\n                assert (dQ == \"Q0.5EQ1.5\") or (dQ == \"Q0p5EQ1p5\"), f\"Invalid choice for dQ: '{dQ}'\"\n                state[\"update_precond\"] = update_precond_kron_newton_q0p5eq1p5\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n\n        # initialize states\n        for param, state, setting in zip(objective.params, states, settings):\n            if \"initialized\" not in state:\n                self._initialize_state(param, state, setting)\n\n        fs = settings[0]\n\n        uninitialized = any(state[\"QLs_exprs\"] is None for state in states)\n        if (torch.rand([]) &lt; fs[\"update_probability\"]) or uninitialized:\n\n            # hessian-vector product\n            vs = TensorList(objective.params).sample_like(distribution=fs[\"distribution\"])\n            Hvs, _ = objective.hessian_vector_product(z=vs, rgrad=None, at_x0=True, hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n\n            # initialize on the fly (why does it use vs?)\n            if uninitialized:\n\n                scale = (sum([torch.sum(torch.abs(v)**2) for v in vs])/sum([v.numel() for v in vs])) ** (1/4) # (mean(|v|^2))^(1/4)\n\n                scale = scale * (max([torch.mean((torch.abs(h))**4) for h in Hvs]) + fs[\"damping\"]**4) ** (-1/8) # (mean(|v|^2))^(1/4) * (mean(|h|^4))^(-1/8)\n\n                for h, state, setting in zip(Hvs, states, settings):\n                    if state[\"QLs_exprs\"] is None:\n                        state[\"QLs_exprs\"] = init_kron(\n                            h.squeeze(),\n                            Scale=scale,\n                            max_size=setting[\"max_dim\"],\n                            max_skew=setting[\"max_skew\"],\n                            dQ=setting[\"dQ\"],\n                        )\n\n            # update preconditioner\n            for v, h, state, setting in zip(vs, Hvs, states, settings):\n                state[\"update_precond\"](\n                    *state[\"QLs_exprs\"],\n                    v.squeeze(),\n                    h.squeeze(),\n                    lr=setting[\"lr_preconditioner\"],\n                    betaL=setting[\"betaL\"],\n                    damping=setting[\"damping\"],\n                    balance_prob=setting[\"balance_probability\"]\n                )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n\n        params = objective.params\n        tensors = objective.get_updates()\n        pre_tensors = []\n\n        # precondition\n        for param, tensor, state in zip(params, tensors, states):\n            t = state[\"precond_grad\"](\n                *state[\"QLs_exprs\"],\n                tensor.squeeze(),\n            )\n            pre_tensors.append(t.view_as(param))\n\n        # norm clipping\n        grad_clip_max_amp = settings[0][\"grad_clip_max_amp\"]\n        if grad_clip_max_amp &lt; math.inf:\n            pre_tensors = TensorList(pre_tensors)\n            num_params = sum(t.numel() for t in pre_tensors)\n\n            avg_amp = pre_tensors.dot(pre_tensors.conj()).div(num_params).sqrt()\n\n            if avg_amp &gt; grad_clip_max_amp:\n                torch._foreach_mul_(pre_tensors, grad_clip_max_amp / avg_amp)\n\n        objective.updates = pre_tensors\n        return objective\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDKronWhiten","title":"PSGDKronWhiten","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Kron whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.</p> </li> <li> <code>max_skew</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times <code>max_skew</code>, it uses a diagonal preconditioner. Defaults to 1.0.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined from magnitude of the first gradient. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_amp</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips amplitude of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>dQ</code>               (<code>str</code>, default:                   <code>'Q0.5EQ1.5'</code> )           \u2013            <p>geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".</p> </li> <li> <code>balance_probability</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDKronWhiten--examples","title":"Examples:","text":"<p>Pure PSGD Kron: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Momentum into preconditioner (whitens momentum): <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.EMA(0.9),\n    tz.m.KronWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Updating the preconditioner from gradients and applying it to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.KronWhiten(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_kron_whiten.py</code> <pre><code>class PSGDKronWhiten(TensorTransform):\n    \"\"\"Kron whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        max_dim (int, optional): dimensions with size larger than this use diagonal preconditioner. Defaults to 10_000.\n        max_skew (float, optional):\n            if memory used by full preconditioner (dim^2) is larger than total number of elements in a parameter times ``max_skew``, it uses a diagonal preconditioner. Defaults to 1.0.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined from magnitude of the first gradient. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional): adds small noise to gradient when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_amp (float, optional): clips amplitude of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        dQ (str, optional): geometry for preconditioner update. Defaults to \"Q0.5EQ1.5\".\n        balance_probability (float, optional):\n            probablility of balancing the dynamic ranges of the factors of Q to avoid over/under-flow on each step. Defaults to 0.01.\n\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure PSGD Kron:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Momentum into preconditioner (whitens momentum):\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.EMA(0.9),\n        tz.m.KronWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Updating the preconditioner from gradients and applying it to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.KronWhiten(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        max_dim: int = 10_000,\n        max_skew: float = 1.0,\n        init_scale: float | None = None,\n        lr_preconditioner: float = 0.1,\n        betaL: float = 0.9,\n        damping: float = 1e-9,\n        grad_clip_max_amp: float = float(\"inf\"),\n        update_probability: float= 1.0,\n        dQ: Literal[\"QEP\", \"EQ\", \"QEQ\", \"QUAD\",  \"Q0.5EQ1.5\", \"Q0p5EQ1p5\", \"QUAD4P\"] = \"Q0.5EQ1.5\",\n        balance_probability: float = 0.01,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        # initialize preconditioners\n        if setting[\"init_scale\"] is None:\n            # warnings.warn(\"FYI: Will set the preconditioner initial scale on the fly. Recommend to set it manually.\")\n            state[\"QLs_exprs\"] = None\n        else:\n            state[\"QLs_exprs\"] = init_kron(\n                param.squeeze(),\n                Scale=setting[\"init_scale\"],\n                max_size=setting[\"max_dim\"],\n                max_skew=setting[\"max_skew\"],\n                dQ=setting[\"dQ\"],\n            )\n\n        dQ = setting[\"dQ\"]\n        if dQ == \"QUAD4P\":\n            assert torch.finfo(param.dtype).eps &lt; 1e-6, \"Directly fitting P needs at least single precision\"\n            state[\"update_precond\"] = update_precond_kron_whiten_quad4p\n            state[\"precond_grad\"] = lambda QL, exprs, G: exprs[0](*QL[0], G) # it's exprA(*Q, G)\n\n        else:\n            state[\"precond_grad\"] = precond_grad_kron\n            if dQ == \"QEP\":\n                state[\"update_precond\"] = update_precond_kron_whiten_qep\n            elif dQ == \"EQ\":\n                state[\"update_precond\"] = update_precond_kron_whiten_eq\n            elif dQ == \"QEQ\":\n                state[\"update_precond\"] = update_precond_kron_whiten_qeq\n            elif dQ == \"QUAD\":\n                state[\"update_precond\"] = update_precond_kron_whiten_quad\n            else:\n                assert (dQ == \"Q0.5EQ1.5\") or (dQ == \"Q0p5EQ1p5\"), f\"Invalid choice for dQ: '{dQ}'\"\n                state[\"update_precond\"] = update_precond_kron_whiten_q0p5eq1p5\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n\n        # initialize on the fly if not initialized\n        if any(state[\"QLs_exprs\"] is None for state in states):\n\n            scale = max([torch.mean((torch.abs(g))**4) for g in tensors])\n            scale = (scale + settings[0][\"damping\"]**4)**(-1/8)\n\n            for param, state, setting in zip(params, states, settings):\n                if state[\"QLs_exprs\"] is None:\n                    state[\"QLs_exprs\"] = init_kron(\n                        param.squeeze(),\n                        Scale=scale,\n                        max_size=setting[\"max_dim\"],\n                        max_skew=setting[\"max_skew\"],\n                        dQ=setting[\"dQ\"],\n                    )\n\n\n        # update preconditioners\n        # (could also try per-parameter probability)\n        if torch.rand([]) &lt; settings[0][\"update_probability\"]: # update Q\n            for tensor, state, setting in zip(tensors, states, settings):\n                state[\"update_precond\"](\n                    *state[\"QLs_exprs\"],\n                    tensor.squeeze(),\n                    lr=setting[\"lr_preconditioner\"],\n                    betaL=setting[\"betaL\"],\n                    damping=setting[\"damping\"],\n                    balance_prob=setting[\"balance_probability\"]\n                )\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n\n        pre_tensors = []\n\n        # precondition\n        for param, tensor, state in zip(params, tensors, states):\n            t = state[\"precond_grad\"](\n                *state[\"QLs_exprs\"],\n                tensor.squeeze(),\n            )\n            pre_tensors.append(t.view_as(param))\n\n        # norm clipping\n        grad_clip_max_amp = settings[0][\"grad_clip_max_amp\"]\n        if grad_clip_max_amp &lt; math.inf:\n            pre_tensors = TensorList(pre_tensors)\n            num_params = sum(t.numel() for t in pre_tensors)\n\n            avg_amp = pre_tensors.dot(pre_tensors.conj()).div(num_params).sqrt()\n\n            if avg_amp &gt; grad_clip_max_amp:\n                torch._foreach_mul_(pre_tensors, grad_clip_max_amp / avg_amp)\n\n        return pre_tensors\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDLRANewton","title":"PSGDLRANewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Low rank hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_norm</code>               (<code>float</code>, default:                   <code>inf</code> )           \u2013            <p>clips norm of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>hvp_method</code>               (<code>Literal</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to compute hessian-vector products. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>if <code>hvp_method</code> is <code>\"fd_central\"</code> or <code>\"fd_forward\"</code>, controls finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution for random vectors for hessian-vector products. Defaults to 'normal'.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDLRANewton--examples","title":"Examples:","text":"<p>Pure LRA Newton PSGD: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRANewton(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Applying preconditioner to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRANewton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_lra_newton.py</code> <pre><code>class PSGDLRANewton(Transform):\n    \"\"\"Low rank hessian preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        rank (int, optional):\n            Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional):\n            adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_norm (float, optional): clips norm of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        hvp_method (HVPMethod, optional): how to compute hessian-vector products. Defaults to 'autograd'.\n        h (float, optional):\n            if ``hvp_method`` is ``\"fd_central\"`` or ``\"fd_forward\"``, controls finite difference step size.\n            Defaults to 1e-3.\n        distribution (Distributions, optional):\n            distribution for random vectors for hessian-vector products. Defaults to 'normal'.\n\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure LRA Newton PSGD:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRANewton(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Applying preconditioner to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRANewton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 10,\n        init_scale: float | None = None,\n        lr_preconditioner=0.1,\n        betaL=0.9,\n        damping=1e-9,\n        grad_clip_max_norm=float(\"inf\"),\n        update_probability=1.0,\n\n        hvp_method: HVPMethod = 'autograd',\n        h: float = 1e-3,\n        distribution: Distributions = 'normal',\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        # initialize\n        if \"UVd\" not in self.global_state:\n            p = torch.cat([t.ravel() for t in objective.params])\n            _initialize_lra_state_(p, self.global_state, fs)\n\n        UVd = self.global_state[\"UVd\"]\n        if (torch.rand([]) &lt; fs[\"update_probability\"]) or (UVd[2] is None):\n\n            # hessian-vector product\n            vs = TensorList(objective.params).sample_like(distribution=fs[\"distribution\"])\n            Hvs, _ = objective.hessian_vector_product(z=vs, rgrad=None, at_x0=True, hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n\n            v = torch.cat([t.ravel() for t in vs]).unsqueeze(1)\n            h = torch.cat([t.ravel() for t in Hvs]).unsqueeze(1)\n\n            if UVd[2] is None:\n                UVd[2] = (torch.mean(v*v))**(1/4) * (torch.mean(h**4) + fs[\"damping\"]**4)**(-1/8) * torch.ones_like(v)\n\n            # update preconditioner\n            update_precond_lra_newton(UVd=UVd, Luvd=self.global_state[\"Luvd\"], v=v, h=h, lr=fs[\"lr_preconditioner\"], betaL=fs[\"betaL\"], damping=fs[\"damping\"])\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n\n        g = torch.cat([t.ravel() for t in updates]).unsqueeze(1) # column vec\n        pre_grad = precond_grad_lra(UVd=self.global_state[\"UVd\"], g=g)\n\n        # norm clipping\n        grad_clip_max_norm = settings[0][\"grad_clip_max_norm\"]\n        if grad_clip_max_norm &lt; float(\"inf\"): # clip preconditioned gradient\n            grad_norm = torch.linalg.vector_norm(pre_grad)\n            if grad_norm &gt; grad_clip_max_norm:\n                pre_grad *= grad_clip_max_norm / grad_norm\n\n        vec_to_tensors_(pre_grad, updates)\n        return objective\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDLRAWhiten","title":"PSGDLRAWhiten","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Low rank whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)</p> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.</p> </li> <li> <code>init_scale</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.</p> </li> <li> <code>lr_preconditioner</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>learning rate of the preconditioner. Defaults to 0.1.</p> </li> <li> <code>betaL</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.</p> </li> <li> <code>grad_clip_max_norm</code>               (<code>float</code>)           \u2013            <p>clips norm of the update. Defaults to float(\"inf\").</p> </li> <li> <code>update_probability</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>probability of updating preconditioner on each step. Defaults to 1.0.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, treats all parameters as concatenated to a single vector. If False, each parameter is preconditioned separately. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning will be applied to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.PSGDLRAWhiten--examples","title":"Examples:","text":"<p>Pure PSGD LRA: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRAWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Momentum into preconditioner (whitens momentum): <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.EMA(0.9),\n    tz.m.LRAWhiten(),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> <p>Updating the preconditioner from gradients and applying it to momentum: <pre><code>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.LRAWhiten(inner=tz.m.EMA(0.9)),\n    tz.m.LR(1e-3),\n)\n</code></pre></p> Source code in <code>torchzero/modules/adaptive/psgd/psgd_lra_whiten.py</code> <pre><code>class PSGDLRAWhiten(TensorTransform):\n    \"\"\"Low rank whitening preconditioner from Preconditioned Stochastic Gradient Descent (see https://github.com/lixilinx/psgd_torch)\n\n    Args:\n        rank (int, optional):\n            Preconditioner has a diagonal part and a low rank part, whose rank is decided by this setting. Defaults to 10.\n        init_scale (float | None, optional):\n            initial scale of the preconditioner. If None, determined based on a heuristic. Defaults to None.\n        lr_preconditioner (float, optional): learning rate of the preconditioner. Defaults to 0.1.\n        betaL (float, optional): EMA factor for the L-smoothness constant wrt Q. Defaults to 0.9.\n        damping (float, optional):\n            adds small noise to hessian-vector product when updating the preconditioner. Defaults to 1e-9.\n        grad_clip_max_norm (float, optional): clips norm of the update. Defaults to float(\"inf\").\n        update_probability (float, optional): probability of updating preconditioner on each step. Defaults to 1.0.\n        concat_params (bool, optional):\n            if True, treats all parameters as concatenated to a single vector.\n            If False, each parameter is preconditioned separately. Defaults to True.\n        inner (Chainable | None, optional): preconditioning will be applied to output of this module. Defaults to None.\n\n    ###Examples:\n\n    Pure PSGD LRA:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRAWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Momentum into preconditioner (whitens momentum):\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.EMA(0.9),\n        tz.m.LRAWhiten(),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    Updating the preconditioner from gradients and applying it to momentum:\n    ```py\n    optimizer = tz.Optimizer(\n        model.parameters(),\n        tz.m.LRAWhiten(inner=tz.m.EMA(0.9)),\n        tz.m.LR(1e-3),\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 10,\n        init_scale: float | None = None,\n        lr_preconditioner=0.1,\n        betaL=0.9,\n        damping=1e-9,\n        grad_clip_max_amp=float(\"inf\"),\n        update_probability=1.0,\n\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults[\"inner\"], defaults[\"self\"]\n        super().__init__(defaults, concat_params=concat_params, inner=inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        _initialize_lra_state_(tensor, state, setting)\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n\n        g = tensor.ravel().unsqueeze(1) # column vector\n\n        UVd = state[\"UVd\"]\n        if UVd[2] is None: # initialize d on the fly\n            UVd[2] = (torch.mean(g**4) + setting[\"damping\"]**4)**(-1/8) * torch.ones_like(g)\n\n        if torch.rand([]) &lt; setting[\"update_probability\"]:  # update preconditioner\n            update_precond_lra_whiten(\n                UVd=UVd,\n                Luvd=state[\"Luvd\"],\n                g=g,\n                lr=setting[\"lr_preconditioner\"],\n                betaL=setting[\"betaL\"],\n                damping=setting[\"damping\"],\n            )\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n\n        g = tensor.ravel().unsqueeze(1)\n        pre_grad = precond_grad_lra(UVd=state[\"UVd\"], g=g)\n\n        # norm clipping\n        grad_clip_max_amp = setting[\"grad_clip_max_amp\"]\n        if grad_clip_max_amp &lt; float(\"inf\"): # clip preconditioned gradient\n            amp = torch.sqrt(torch.mean(pre_grad * pre_grad))\n            if amp &gt; grad_clip_max_amp:\n                pre_grad *= grad_clip_max_amp/amp\n\n        return pre_grad.view_as(tensor)\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.RMSprop","title":"RMSprop","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Divides graient by EMA of gradient squares.</p> <p>This implementation is identical to :code:<code>torch.optim.RMSprop</code>.</p> <p>Parameters:</p> <ul> <li> <code>smoothing</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for exponential moving average of gradient squares. Defaults to 0.99.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for division. Defaults to 1e-8.</p> </li> <li> <code>centered</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to center EMA of gradient squares using an additional EMA. Defaults to False.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>applies Adam debiasing. Defaults to False.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>)           \u2013            <p>power used in second momentum power and root. Defaults to 2.</p> </li> <li> <code>init</code>               (<code>str</code>, default:                   <code>'zeros'</code> )           \u2013            <p>how to initialize EMA, either \"update\" to use first update or \"zeros\". Defaults to \"update\".</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>Inner modules that are applied after updating EMA and before preconditioning. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/rmsprop.py</code> <pre><code>class RMSprop(TensorTransform):\n    \"\"\"Divides graient by EMA of gradient squares.\n\n    This implementation is identical to :code:`torch.optim.RMSprop`.\n\n    Args:\n        smoothing (float, optional): beta for exponential moving average of gradient squares. Defaults to 0.99.\n        eps (float, optional): epsilon for division. Defaults to 1e-8.\n        centered (bool, optional): whether to center EMA of gradient squares using an additional EMA. Defaults to False.\n        debias (bool, optional): applies Adam debiasing. Defaults to False.\n        amsgrad (bool, optional): Whether to divide by maximum of EMA of gradient squares instead. Defaults to False.\n        pow (float, optional): power used in second momentum power and root. Defaults to 2.\n        init (str, optional): how to initialize EMA, either \"update\" to use first update or \"zeros\". Defaults to \"update\".\n        inner (Chainable | None, optional):\n            Inner modules that are applied after updating EMA and before preconditioning. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        smoothing: float = 0.99,\n        eps: float = 1e-8,\n        centered: bool = False,\n        debias: bool = False,\n        amsgrad: bool = False,\n        init: Literal[\"zeros\", \"update\"] = \"zeros\",\n\n        inner: Chainable | None = None,\n        exp_avg_sq_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"inner\"], defaults[\"exp_avg_sq_tfm\"]\n        super().__init__(defaults, inner=inner)\n\n        self.set_child('exp_avg_sq', exp_avg_sq_tfm)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"exp_avg_sq_max\")\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        if setting[\"init\"] == \"zeros\":\n            state[\"exp_avg_sq\"] = torch.zeros_like(tensor)\n            if setting[\"centered\"]: state[\"exp_avg\"] = torch.zeros_like(tensor)\n            if setting[\"amsgrad\"]: state[\"amsgrad\"] = torch.zeros_like(tensor)\n\n        else:\n            state[\"exp_avg_sq\"] = tensor ** 2\n            if setting[\"centered\"]: state[\"exp_avg\"] = tensor.clone()\n            if setting[\"amsgrad\"]: state[\"amsgrad\"] = tensor ** 2\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        self.increment_counter(\"step\", start = 0)\n        fs = settings[0]\n\n        exp_avg_sq = unpack_states(states, tensors, \"exp_avg_sq\", cls=TensorList)\n\n        # update exponential average\n        smoothing = NumberList(s[\"smoothing\"] for s in settings)\n        exp_avg_sq.mul_(smoothing).addcmul_(tensors, tensors, value=1-smoothing)\n\n        # update mean estimate if centered\n        if fs[\"centered\"]:\n            exp_avg = unpack_states(states, tensors, \"exp_avg\", cls=TensorList)\n            exp_avg.lerp_(tensors, 1-smoothing)\n\n        # amsgrad\n        if fs[\"amsgrad\"]:\n            exp_avg_sq_max = unpack_states(states, tensors, \"exp_avg_sq_max\", cls=TensorList)\n            exp_avg_sq_max.maximum_(exp_avg_sq)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        step = self.global_state[\"step\"] # 0 on 1st step\n        eps = NumberList(s[\"eps\"] for s in settings)\n        fs = settings[0]\n\n        if fs[\"amsgrad\"]: key = \"max_exp_avg_sq\"\n        else: key = \"exp_avg_sq\"\n        exp_avg_sq = TensorList(s[key] for s in states)\n\n        # load mean estimate if centered\n        exp_avg = None\n        if fs['centered']:\n            exp_avg = TensorList(s[\"exp_avg\"] for s in states)\n\n        # debias exp_avg_sq and exp_avg\n        if fs[\"debias\"]:\n            smoothing = NumberList(s[\"smoothing\"] for s in settings)\n            bias_correction = 1 - (smoothing ** (step + 1))\n            exp_avg_sq = exp_avg_sq / bias_correction\n\n            if fs['centered']:\n                assert exp_avg is not None\n                exp_avg = exp_avg / bias_correction\n\n        # apply transform to potentially debiased exp_avg_sq\n        exp_avg_sq = TensorList(self.inner_step_tensors(\n            \"exp_avg_sq\", exp_avg_sq, params=params, grads=grads, loss=loss, clone=True, must_exist=False\n        ))\n\n        # center\n        if fs[\"centered\"]:\n            assert exp_avg is not None\n            exp_avg_sq = exp_avg_sq.addcmul(exp_avg, exp_avg, value=-1)\n\n        return tensors.div_(exp_avg_sq.sqrt().add_(eps))\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Rprop","title":"Rprop","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Resilient propagation. The update magnitude gets multiplied by <code>nplus</code> if gradient didn't change the sign, or <code>nminus</code> if it did. Then the update is applied with the sign of the current gradient.</p> <p>Additionally, if gradient changes sign, the update for that weight is reverted. Next step, magnitude for that weight won't change.</p> <p>Compared to pytorch this also implements backtracking update when sign changes.</p> <p>This implementation is identical to <code>torch.optim.Rprop</code> if <code>backtrack</code> is set to False.</p> <p>Parameters:</p> <ul> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>1.2</code> )           \u2013            <p>multiplicative increase factor for when ascent didn't change sign (default: 1.2).</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplicative decrease factor for when ascent changed sign (default: 0.5).</p> </li> <li> <code>lb</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>minimum step size, can be None (default: 1e-6)</p> </li> <li> <code>ub</code>               (<code>float</code>, default:                   <code>50</code> )           \u2013            <p>maximum step size, can be None (default: 50)</p> </li> <li> <code>backtrack</code>               (<code>float</code>, default:                   <code>True</code> )           \u2013            <p>if True, when ascent sign changes, undoes last weight update, otherwise sets update to 0. When this is False, this exactly matches pytorch Rprop. (default: True)</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>initial per-parameter learning rate (default: 1).</p> </li> </ul> <p>reference     Riedmiller, M., &amp; Braun, H. (1993, March). A direct adaptive method for faster backpropagation learning:     The RPROP algorithm. In IEEE international conference on neural networks (pp. 586-591). IEEE.</p> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class Rprop(TensorTransform):\n    \"\"\"\n    Resilient propagation. The update magnitude gets multiplied by ``nplus`` if gradient didn't change the sign,\n    or ``nminus`` if it did. Then the update is applied with the sign of the current gradient.\n\n    Additionally, if gradient changes sign, the update for that weight is reverted.\n    Next step, magnitude for that weight won't change.\n\n    Compared to pytorch this also implements backtracking update when sign changes.\n\n    This implementation is identical to ``torch.optim.Rprop`` if ``backtrack`` is set to False.\n\n    Args:\n        nplus (float): multiplicative increase factor for when ascent didn't change sign (default: 1.2).\n        nminus (float): multiplicative decrease factor for when ascent changed sign (default: 0.5).\n        lb (float): minimum step size, can be None (default: 1e-6)\n        ub (float): maximum step size, can be None (default: 50)\n        backtrack (float):\n            if True, when ascent sign changes, undoes last weight update, otherwise sets update to 0.\n            When this is False, this exactly matches pytorch Rprop. (default: True)\n        alpha (float): initial per-parameter learning rate (default: 1).\n\n    reference\n        *Riedmiller, M., &amp; Braun, H. (1993, March). A direct adaptive method for faster backpropagation learning:\n        The RPROP algorithm. In IEEE international conference on neural networks (pp. 586-591). IEEE.*\n    \"\"\"\n    def __init__(\n        self,\n        nplus: float = 1.2,\n        nminus: float = 0.5,\n        lb: float = 1e-6,\n        ub: float = 50,\n        backtrack=True,\n        alpha: float = 1,\n    ):\n        defaults = dict(nplus = nplus, nminus = nminus, alpha = alpha, lb = lb, ub = ub, backtrack=backtrack)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        nplus, nminus, lb, ub, alpha = unpack_dicts(settings, 'nplus', 'nminus', 'lb', 'ub', 'alpha', cls=NumberList)\n        prev, allowed, magnitudes = unpack_states(\n            states, tensors,\n            'prev','allowed','magnitudes',\n            init=[torch.zeros_like, _bool_ones_like, torch.zeros_like],\n            cls = TensorList,\n        )\n\n        tensors = rprop_(\n            tensors_ = TensorList(tensors),\n            prev_ = prev,\n            allowed_ = allowed,\n            magnitudes_ = magnitudes,\n            nplus = nplus,\n            nminus = nminus,\n            lb = lb,\n            ub = ub,\n            alpha = alpha,\n            backtrack=settings[0]['backtrack'],\n            step=step,\n        )\n\n        return tensors\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SAM","title":"SAM","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Sharpness-Aware Minimization from https://arxiv.org/pdf/2010.01412</p> <p>SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value. It performs two forward and backward passes per step.</p> <p>This implementation modifies the closure to return loss and calculate gradients of the SAM objective. All modules after this will use the modified objective.</p> <p>.. note::     This module requires a closure passed to the optimizer step,     as it needs to re-evaluate the loss and gradients at two points on each step.</p> <p>Parameters:</p> <ul> <li> <code>rho</code>               (<code>float</code>, default:                   <code>0.05</code> )           \u2013            <p>Neighborhood size. Defaults to 0.05.</p> </li> <li> <code>p</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm of the SAM objective. Defaults to 2.</p> </li> <li> <code>asam</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>enables ASAM variant which makes perturbation relative to weight magnitudes. ASAM requires a much larger <code>rho</code>, like 0.5 or 1. The <code>tz.m.ASAM</code> class is idential to setting this argument to True, but it has larger <code>rho</code> by default.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SAM--examples","title":"Examples:","text":"<p>SAM-SGD:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SAM(),\n    tz.m.LR(1e-2)\n)\n</code></pre> <p>SAM-Adam:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SAM(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2)\n)\n</code></pre> References <p>Foret, P., Kleiner, A., Mobahi, H., &amp; Neyshabur, B. (2020). Sharpness-aware minimization for efficiently improving generalization. arXiv preprint arXiv:2010.01412.</p> Source code in <code>torchzero/modules/adaptive/sam.py</code> <pre><code>class SAM(Transform):\n    \"\"\"Sharpness-Aware Minimization from https://arxiv.org/pdf/2010.01412\n\n    SAM functions by seeking parameters that lie in neighborhoods having uniformly low loss value.\n    It performs two forward and backward passes per step.\n\n    This implementation modifies the closure to return loss and calculate gradients\n    of the SAM objective. All modules after this will use the modified objective.\n\n    .. note::\n        This module requires a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients at two points on each step.\n\n    Args:\n        rho (float, optional): Neighborhood size. Defaults to 0.05.\n        p (float, optional): norm of the SAM objective. Defaults to 2.\n        asam (bool, optional):\n            enables ASAM variant which makes perturbation relative to weight magnitudes.\n            ASAM requires a much larger ``rho``, like 0.5 or 1.\n            The ``tz.m.ASAM`` class is idential to setting this argument to True, but\n            it has larger ``rho`` by default.\n\n    ### Examples:\n\n    SAM-SGD:\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SAM(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    SAM-Adam:\n\n    ```\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SAM(),\n        tz.m.Adam(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    References:\n        [Foret, P., Kleiner, A., Mobahi, H., &amp; Neyshabur, B. (2020). Sharpness-aware minimization for efficiently improving generalization. arXiv preprint arXiv:2010.01412.](https://arxiv.org/abs/2010.01412#page=3.16)\n    \"\"\"\n    def __init__(self, rho: float = 0.05, p: float = 2, eps=1e-10, asam=False):\n        defaults = dict(rho=rho, p=p, eps=eps, asam=asam)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n\n        params = objective.params\n        closure = objective.closure\n        zero_grad = objective.zero_grad\n        if closure is None: raise RuntimeError(\"SAM requires a closure passed to the optimizer step\")\n        p, rho = unpack_dicts(settings, 'p', 'rho', cls=NumberList)\n        fs = settings[0]\n        eps = fs['eps']\n        asam = fs['asam']\n\n        # 1/p + 1/q = 1\n        # okay, authors of SAM paper, I will manually solve your equation\n        # so q = -p/(1-p)\n        q = -p / (1-p)\n        # as a validation for 2 it is -2 / -1 = 2\n\n        @torch.no_grad\n        def sam_closure(backward=True):\n            orig_grads = None\n            if not backward:\n                # if backward is False, make sure this doesn't modify gradients\n                # to avoid issues\n                orig_grads = [p.grad for p in params]\n\n            # gradient at initial parameters\n            zero_grad()\n            with torch.enable_grad():\n                closure()\n\n            grad = TensorList(p.grad if p.grad is not None else torch.zeros_like(p) for p in params)\n            grad_abs = grad.abs()\n\n            # compute e\n            term1 = grad.sign().mul_(rho)\n            term2 = grad_abs.pow(q-1)\n\n            if asam:\n                grad_abs.mul_(torch._foreach_abs(params))\n\n            denom = grad_abs.pow_(q).sum().pow(1/p)\n\n            e = term1.mul_(term2).div_(denom.clip(min=eps))\n\n            if asam:\n                e.mul_(torch._foreach_pow(params, 2))\n\n            # calculate loss and gradient approximation of inner problem\n            torch._foreach_add_(params, e)\n            if backward:\n                zero_grad()\n                with torch.enable_grad():\n                    # this sets .grad attributes\n                    sam_loss = closure()\n\n            else:\n                sam_loss = closure(False)\n\n            # and restore initial parameters\n            torch._foreach_sub_(params, e)\n\n            if orig_grads is not None:\n                for param,orig_grad in zip(params, orig_grads):\n                    param.grad = orig_grad\n\n            return sam_loss\n\n        objective.closure = sam_closure\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SOAP","title":"SOAP","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>SOAP (ShampoO with Adam in the Preconditioner's eigenbasis from https://arxiv.org/abs/2409.11321).</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.95</code> )           \u2013            <p>beta for first momentum. Defaults to 0.95.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.95</code> )           \u2013            <p>beta for second momentum. Defaults to 0.95.</p> </li> <li> <code>shampoo_beta</code>               (<code>float | None</code>, default:                   <code>0.95</code> )           \u2013            <p>beta for covariance matrices accumulators. Can be None, then it just sums them like Adagrad (which works worse). Defaults to 0.95.</p> </li> <li> <code>precond_freq</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>How often to update the preconditioner. Defaults to 10.</p> </li> <li> <code>merge_small</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to merge small dims. Defaults to True.</p> </li> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>4096</code> )           \u2013            <p>Won't precondition dims larger than this. Defaults to 10_000.</p> </li> <li> <code>precondition_1d</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to precondition 1d params (SOAP paper sets this to False). Defaults to True.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for dividing first momentum by second. Defaults to 1e-8.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>enables adam bias correction. Defaults to True.</p> </li> <li> <code>proj_exp_avg</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, maintains exponential average of gradients (momentum) in projected space. If False - in original space Defaults to True.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>learning rate. Defaults to 1.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>output of this module is projected and Adam will run on it, but preconditioners are updated from original gradients.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SOAP--examples","title":"Examples:","text":"<p>SOAP:</p> <p><pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAP(),\n    tz.m.LR(1e-3)\n)\n</code></pre> Stabilized SOAP:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAP(),\n    tz.m.NormalizeByEMA(max_ema_growth=1.2),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/soap.py</code> <pre><code>class SOAP(TensorTransform):\n    \"\"\"SOAP (ShampoO with Adam in the Preconditioner's eigenbasis from https://arxiv.org/abs/2409.11321).\n\n    Args:\n        beta1 (float, optional): beta for first momentum. Defaults to 0.95.\n        beta2 (float, optional): beta for second momentum. Defaults to 0.95.\n        shampoo_beta (float | None, optional):\n            beta for covariance matrices accumulators. Can be None, then it just sums them like Adagrad (which works worse). Defaults to 0.95.\n        precond_freq (int, optional): How often to update the preconditioner. Defaults to 10.\n        merge_small (bool, optional): Whether to merge small dims. Defaults to True.\n        max_dim (int, optional): Won't precondition dims larger than this. Defaults to 10_000.\n        precondition_1d (bool, optional):\n            Whether to precondition 1d params (SOAP paper sets this to False). Defaults to True.\n        eps (float, optional):\n            epsilon for dividing first momentum by second. Defaults to 1e-8.\n        debias (bool, optional):\n            enables adam bias correction. Defaults to True.\n        proj_exp_avg (bool, optional):\n            if True, maintains exponential average of gradients (momentum) in projected space.\n            If False - in original space Defaults to True.\n        alpha (float, optional):\n            learning rate. Defaults to 1.\n        inner (Chainable | None, optional):\n            output of this module is projected and Adam will run on it, but preconditioners are updated\n            from original gradients.\n\n    ### Examples:\n    SOAP:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SOAP(),\n        tz.m.LR(1e-3)\n    )\n    ```\n    Stabilized SOAP:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SOAP(),\n        tz.m.NormalizeByEMA(max_ema_growth=1.2),\n        tz.m.LR(1e-2)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.95,\n        beta2: float = 0.95,\n        shampoo_beta: float | None = 0.95,\n        precond_freq: int = 10,\n        merge_small: bool = True,\n        max_dim: int = 4096,\n        precondition_1d: bool = True,\n        eps: float = 1e-8,\n        debias: bool = True,\n        proj_exp_avg: bool = True,\n        alpha: float = 1,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"inner\"]\n\n        super().__init__(defaults)\n        self.set_child(\"inner\", inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        if setting[\"merge_small\"]:\n            tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n        state[\"exp_avg_proj\"] = torch.zeros_like(tensor)\n        state[\"exp_avg_sq_proj\"] = torch.zeros_like(tensor)\n\n        if tensor.ndim &lt;= 1 and not setting[\"precondition_1d\"]:\n            state['GG'] = []\n\n        else:\n            max_dim = setting[\"max_dim\"]\n            state['GG'] = [\n                torch.zeros(s, s, dtype=tensor.dtype, device=tensor.device) if 1&lt;s&lt;max_dim else None for s in tensor.shape\n            ]\n\n        # either scalar parameter, 1d with precondition_1d=False, or all dims are too big.\n        if len([i is not None for i in state['GG']]) == 0:\n            state['GG'] = None\n\n        # first covariance accumulation\n        if state['GG'] is not None:\n            update_soap_covariances_(tensor, GGs_=state['GG'], beta=setting[\"shampoo_beta\"])\n\n            # get projection matrix with first gradients with eigh\n            try: state['Q'] = get_orthogonal_matrix(state['GG'])\n            except torch.linalg.LinAlgError as e:\n                warnings.warn(f\"torch.linalg.eigh raised an error when initializing SOAP Q matrices on 1st step, diagonal preconditioning will be used for this parameter. The error was:\\n{e}\")\n                state[\"GG\"] = None\n\n        state['step'] = 0\n\n\n    # no update to avoid running merge_dims twice\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        # note\n        # do not modify tensors in-place\n        # because they are used to update preconditioner at the end\n\n        steps = [s[\"step\"] for s in states]\n        if any(s == 0 for s in steps):\n            # skip 1st update so to avoid using current gradient in the projection\n            # I scale it instead to avoid issues with further modules\n            for s in states: s[\"step\"] += 1\n            return TensorList(tensors).clamp(-0.1, 0.1)\n            # return TensorList(tensors).zero_()\n\n        fs = settings[0]\n        merged_updates = [] # for when exp_avg is maintained unprojected\n        merged_grads = [] # this doesn't go into preconditioner\n        projected = []\n\n        # -------------------------------- inner step -------------------------------- #\n        updates = tensors\n        has_inner = \"inner\" in self.children\n        if has_inner:\n            updates = self.inner_step_tensors(\"inner\", updates, clone=True,\n                                              params=params, grads=grads, loss=loss)\n\n        # ---------------------------------- project --------------------------------- #\n        for grad, update, state, setting in zip(tensors, updates, states, settings):\n            if setting[\"merge_small\"]:\n                update, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(update, setting[\"max_dim\"])\n                if has_inner: # grad is a different tensor, merge it too\n                    grad, _, _ = _merge_small_dims(grad, setting[\"max_dim\"])\n                else: # in this case update is still just grad\n                    grad = update\n\n            merged_updates.append(update)\n            merged_grads.append(grad)\n\n            if state['GG'] is not None:\n                update = project(update, state['Q'])\n\n            projected.append(update)\n\n\n        # ------------------------ run adam in projected space ----------------------- #\n        exp_avg_proj, exp_avg_sq_proj = unpack_states(states, projected, \"exp_avg_proj\", \"exp_avg_sq_proj\", must_exist=True, cls=TensorList)\n        alpha, beta1, beta2, eps = unpack_dicts(settings, \"alpha\", \"beta1\", \"beta2\", \"eps\", cls=NumberList)\n\n        # lerp exp_avg in projected space\n        if fs[\"proj_exp_avg\"]:\n            exp_avg_proj.lerp_(projected, weight=1-beta1)\n\n        # or lerp in original space and project\n        else:\n            exp_avg = exp_avg_proj\n            exp_avg.lerp_(merged_updates, weight=1-beta1)\n            exp_avg_proj = []\n            for t, state, setting in zip(exp_avg, states, settings):\n                if state['GG'] is not None:\n                    t = project(t, state[\"Q\"])\n                exp_avg_proj.append(t)\n\n        # lerp exp_avg_sq\n        exp_avg_sq_proj.mul_(beta2).addcmul_(projected, projected, value=1-beta2)\n\n        # adam direction\n        denom = exp_avg_sq_proj.sqrt().add_(eps)\n        dirs_proj = exp_avg_proj / denom\n\n        # ------------------------------- project back ------------------------------- #\n        dirs: list[torch.Tensor] = []\n        for dir, state, setting in zip(dirs_proj, states, settings):\n            if state['GG'] is not None:\n                dir = project_back(dir, state['Q'])\n\n            if setting[\"merge_small\"]:\n                dir = _unmerge_small_dims(dir, state['flat_sizes'], state['sort_idxs'])\n\n            dirs.append(dir)\n\n        # -------------------------- update preconditioners -------------------------- #\n        # Update is done after the gradient step to avoid using current gradients in the projection.\n\n        for grad, state, setting in zip(merged_grads, states, settings):\n            if state['GG'] is not None:\n\n                # lerp covariances\n                update_soap_covariances_(grad, state['GG'], beta=setting[\"shampoo_beta\"])\n\n                # (state['step'] - 1) since we start updating on 2nd step\n                if (state['step'] - 1) % setting['precond_freq'] == 0:\n\n                    # unproject exp_avg before updating if it is maintained projected\n                    exp_avg = None\n                    if fs[\"proj_exp_avg\"]:\n                        exp_avg = project_back(state[\"exp_avg_proj\"], state[\"Q\"])\n\n                    # update projection matrix and exp_avg_sq_proj\n                    try:\n                        state['Q'], state['exp_avg_sq_proj'] = get_orthogonal_matrix_QR(\n                            state[\"exp_avg_sq_proj\"], state['GG'], state['Q'])\n\n                        # re-project exp_avg if it is maintained projected\n                        if fs[\"proj_exp_avg\"]:\n                            assert exp_avg is not None\n                            state[\"exp_avg_proj\"] = project(exp_avg, state[\"Q\"])\n\n                    except torch.linalg.LinAlgError:\n                        pass\n\n            state[\"step\"] += 1\n\n\n        # ------------------------- bias-corrected step size ------------------------- #\n        if fs[\"debias\"]:\n            steps1 = [s+1 for s in steps]\n            bias_correction1 = 1.0 - beta1 ** steps1\n            bias_correction2 = 1.0 - beta2 ** steps1\n            alpha = alpha * (bias_correction2 ** .5) / bias_correction1\n\n        torch._foreach_mul_(dirs, alpha)\n        return dirs\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.ScaleLRBySignChange","title":"ScaleLRBySignChange","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>learning rate gets multiplied by <code>nplus</code> if ascent/gradient didn't change the sign, or <code>nminus</code> if it did.</p> <p>This is part of RProp update rule.</p> <p>Parameters:</p> <ul> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>1.2</code> )           \u2013            <p>learning rate gets multiplied by <code>nplus</code> if ascent/gradient didn't change the sign</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>learning rate gets multiplied by <code>nminus</code> if ascent/gradient changed the sign</p> </li> <li> <code>lb</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>lower bound for lr.</p> </li> <li> <code>ub</code>               (<code>float</code>, default:                   <code>50.0</code> )           \u2013            <p>upper bound for lr.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial learning rate.</p> </li> </ul> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class ScaleLRBySignChange(TensorTransform):\n    \"\"\"\n    learning rate gets multiplied by ``nplus`` if ascent/gradient didn't change the sign,\n    or ``nminus`` if it did.\n\n    This is part of RProp update rule.\n\n    Args:\n        nplus (float): learning rate gets multiplied by ``nplus`` if ascent/gradient didn't change the sign\n        nminus (float): learning rate gets multiplied by ``nminus`` if ascent/gradient changed the sign\n        lb (float): lower bound for lr.\n        ub (float): upper bound for lr.\n        alpha (float): initial learning rate.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        nplus: float = 1.2,\n        nminus: float = 0.5,\n        lb=1e-6,\n        ub=50.0,\n        alpha=1.0,\n        use_grad=False,\n    ):\n        defaults = dict(nplus=nplus, nminus=nminus, alpha=alpha, lb=lb, ub=ub, use_grad=use_grad)\n        super().__init__(defaults, uses_grad=use_grad)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        tensors = TensorList(tensors)\n        if self._uses_grad:\n            assert grads is not None\n            cur = TensorList(grads)\n        else: cur = tensors\n\n        nplus, nminus, lb, ub = unpack_dicts(settings, 'nplus', 'nminus', 'lb', 'ub', cls=NumberList)\n        prev, lrs = unpack_states(states, tensors, 'prev', 'lrs', cls=TensorList)\n\n        if step == 0:\n            lrs.set_(tensors.full_like([s['alpha'] for s in settings]))\n\n        tensors = scale_by_sign_change_(\n            tensors_ = tensors,\n            cur = cur,\n            prev_ = prev,\n            lrs_ = lrs,\n            nplus = nplus,\n            nminus = nminus,\n            lb = lb,\n            ub = ub,\n            step = step,\n        )\n        return tensors\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.Shampoo","title":"Shampoo","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Shampoo from Preconditioned Stochastic Tensor Optimization (https://arxiv.org/abs/1802.09568).</p> Notes <p>Shampoo is usually grafted to another optimizer like Adam, otherwise it can be unstable. An example of how to do grafting is given below in the Examples section.</p> <p>Shampoo is a very computationally expensive optimizer, increase <code>update_freq</code> if it is too slow.</p> <p>SOAP optimizer usually outperforms Shampoo and is also not as computationally expensive. SOAP implementation is available as <code>tz.m.SOAP</code>.</p> <p>Parameters:</p> <ul> <li> <code>update_freq</code>               (<code>int</code>)           \u2013            <p>preconditioner update frequency. Defaults to 10.</p> </li> <li> <code>matrix_power</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>overrides matrix exponent. By default uses <code>-1/grad.ndim</code>. Defaults to None.</p> </li> <li> <code>merge_small</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to merge small dims on tensors. Defaults to True.</p> </li> <li> <code>max_dim</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>maximum dimension size for preconditioning. Defaults to 10_000.</p> </li> <li> <code>precondition_1d</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to precondition 1d tensors. Defaults to True.</p> </li> <li> <code>adagrad_eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for adagrad division for tensors where shampoo can't be applied. Defaults to 1e-8.</p> </li> <li> <code>matrix_power_method</code>               (<code>Literal</code>, default:                   <code>'eigh_abs'</code> )           \u2013            <p>how to compute matrix power.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>if None calculates sum as in standard Shampoo, otherwise uses EMA of preconditioners. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>module applied after updating preconditioners and before applying preconditioning. For example if beta\u22480.999 and <code>inner=tz.m.EMA(0.9)</code>, this becomes Adam with shampoo preconditioner (ignoring debiasing). Defaults to None.</p> </li> </ul> <p>Examples: Shampoo grafted to Adam</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GraftModules(\n        direction = tz.m.Shampoo(),\n        magnitude = tz.m.Adam(),\n    ),\n    tz.m.LR(1e-3)\n)\n</code></pre> <p>Adam with Shampoo preconditioner</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Shampoo(beta=0.999, inner=tz.m.EMA(0.9)),\n    tz.m.Debias(0.9, 0.999),\n    tz.m.LR(1e-3)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/shampoo.py</code> <pre><code>class Shampoo(TensorTransform):\n    \"\"\"Shampoo from Preconditioned Stochastic Tensor Optimization (https://arxiv.org/abs/1802.09568).\n\n    Notes:\n        Shampoo is usually grafted to another optimizer like Adam, otherwise it can be unstable. An example of how to do grafting is given below in the Examples section.\n\n        Shampoo is a very computationally expensive optimizer, increase ``update_freq`` if it is too slow.\n\n        SOAP optimizer usually outperforms Shampoo and is also not as computationally expensive. SOAP implementation is available as ``tz.m.SOAP``.\n\n    Args:\n        update_freq (int, optional): preconditioner update frequency. Defaults to 10.\n        matrix_power (float | None, optional): overrides matrix exponent. By default uses ``-1/grad.ndim``. Defaults to None.\n        merge_small (bool, optional): whether to merge small dims on tensors. Defaults to True.\n        max_dim (int, optional): maximum dimension size for preconditioning. Defaults to 10_000.\n        precondition_1d (bool, optional): whether to precondition 1d tensors. Defaults to True.\n        adagrad_eps (float, optional): epsilon for adagrad division for tensors where shampoo can't be applied. Defaults to 1e-8.\n        matrix_power_method (MatrixPowerMethod, optional): how to compute matrix power.\n        beta (float | None, optional):\n            if None calculates sum as in standard Shampoo, otherwise uses EMA of preconditioners. Defaults to None.\n        inner (Chainable | None, optional):\n            module applied after updating preconditioners and before applying preconditioning.\n            For example if beta\u22480.999 and `inner=tz.m.EMA(0.9)`, this becomes Adam with shampoo preconditioner (ignoring debiasing).\n            Defaults to None.\n\n    Examples:\n    Shampoo grafted to Adam\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GraftModules(\n            direction = tz.m.Shampoo(),\n            magnitude = tz.m.Adam(),\n        ),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with Shampoo preconditioner\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Shampoo(beta=0.999, inner=tz.m.EMA(0.9)),\n        tz.m.Debias(0.9, 0.999),\n        tz.m.LR(1e-3)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        reg: float = 1e-12,\n        precond_freq: int = 10,\n        matrix_power: float | None = None,\n        merge_small: bool = True,\n        max_dim: int = 10_000,\n        precondition_1d: bool = True,\n        adagrad_eps: float = 1e-8,\n        matrix_power_method: MatrixPowerMethod = \"eigh_abs\",\n        beta: float | None = None,\n        beta_debias: bool = True,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults[\"inner\"]\n\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        if setting[\"merge_small\"]:\n            tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n        if tensor.ndim &lt;= 1 and not setting[\"precondition_1d\"]:\n            state[\"accumulators\"] = []\n\n        else:\n            max_dim = setting[\"max_dim\"]\n            state['accumulators'] = [\n                torch.eye(s, dtype=tensor.dtype, device=tensor.device) if 1&lt;s&lt;max_dim else None for s in tensor.shape\n            ]\n            state['preconditioners'] = [\n                torch.eye(s, dtype=tensor.dtype, device=tensor.device) if 1&lt;s&lt;max_dim else None for s in tensor.shape\n            ]\n\n        # either scalar parameter, 1d with precondition_1d=False, or too big, then diagonal preconditioner is used.\n        if len([i is not None for i in state['accumulators']]) == 0:\n            state['diagonal_accumulator'] = torch.zeros_like(tensor)\n\n        state['step'] = 0\n        state[\"num_GTG\"] = 0\n\n    @torch.no_grad\n    def single_tensor_update(self, tensor, param, grad, loss, state, setting):\n        if setting[\"merge_small\"]:\n            tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n            if \"inner\" not in self.children:\n                state[\"merged\"] = tensor\n\n        if 'diagonal_accumulator' in state:\n            update_diagonal_(tensor, state['diagonal_accumulator'], beta=setting[\"beta\"])\n        else:\n            update_shampoo_preconditioner_(\n                tensor,\n                accumulators_=state['accumulators'],\n                preconditioners_=state['preconditioners'],\n                step=state['step'],\n                precond_freq=setting[\"precond_freq\"],\n                matrix_power=setting[\"matrix_power\"],\n                beta=setting[\"beta\"],\n                reg=setting[\"reg\"],\n                matrix_power_method=setting[\"matrix_power_method\"],\n            )\n\n        if state[\"step\"] % setting[\"precond_freq\"] == 0:\n            state[\"num_GTG\"] += 1\n\n        state[\"step\"] += 1\n\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n\n        if setting[\"merge_small\"]:\n            if \"inner\" not in self.children:\n                tensor = state.pop(\"merged\")\n            else:\n                tensor, state['flat_sizes'], state['sort_idxs'] = _merge_small_dims(tensor, setting[\"max_dim\"])\n\n        if 'diagonal_accumulator' in state:\n            dir = apply_diagonal_(tensor, state['diagonal_accumulator'], eps=setting[\"adagrad_eps\"])\n        else:\n            dir = apply_shampoo_preconditioner(tensor, preconditioners_=state['preconditioners'])\n\n        if setting[\"merge_small\"]:\n            dir = _unmerge_small_dims(dir, state['flat_sizes'], state['sort_idxs'])\n\n        if setting['beta_debias'] and setting[\"beta\"] is not None:\n            bias_correction = 1 - (setting[\"beta\"] ** state[\"num_GTG\"])\n            dir *= bias_correction ** 0.5\n\n        return dir\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SignConsistencyLRs","title":"SignConsistencyLRs","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs per-weight learning rates based on consecutive sign consistency.</p> <p>The learning rate for a weight is multiplied by <code>nplus</code> when two consecutive update signs are the same, otherwise it is multiplied by <code>nplus</code>. The learning rates are bounded to be in <code>(lb, ub)</code> range.</p>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SignConsistencyLRs--examples","title":"Examples:","text":"<p>GD scaled by consecutive gradient sign consistency</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Mul(tz.m.SignConsistencyLRs()),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class SignConsistencyLRs(TensorTransform):\n    \"\"\"Outputs per-weight learning rates based on consecutive sign consistency.\n\n    The learning rate for a weight is multiplied by ``nplus`` when two consecutive update signs are the same, otherwise it is multiplied by ``nplus``. The learning rates are bounded to be in ``(lb, ub)`` range.\n\n    ### Examples:\n\n    GD scaled by consecutive gradient sign consistency\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Mul(tz.m.SignConsistencyLRs()),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n\"\"\"\n    def __init__(\n        self,\n        nplus: float = 1.2,\n        nminus: float = 0.5,\n        lb: float | None = 1e-6,\n        ub: float | None = 50,\n        alpha: float = 1,\n    ):\n        defaults = dict(nplus = nplus, nminus = nminus, alpha = alpha, lb = lb, ub = ub)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        target = TensorList(tensors)\n        nplus, nminus, lb, ub = unpack_dicts(settings, 'nplus', 'nminus', 'lb', 'ub', cls=NumberList)\n        prev, lrs = unpack_states(states, tensors, 'prev', 'lrs', cls=TensorList)\n\n        if step == 0:\n            lrs.set_(target.full_like([s['alpha'] for s in settings]))\n\n        target = sign_consistency_lrs_(\n            tensors = target,\n            prev_ = prev,\n            lrs_ = lrs,\n            nplus = nplus,\n            nminus = nminus,\n            lb = lb,\n            ub = ub,\n            step = step,\n        )\n        return target.clone()\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SignConsistencyMask","title":"SignConsistencyMask","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs a mask of sign consistency of current and previous inputs.</p> <p>The output is 0 for weights where input sign changed compared to previous input, 1 otherwise.</p>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SignConsistencyMask--examples","title":"Examples:","text":"<p>GD that skips update for weights where gradient sign changed compared to previous gradient.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Mul(tz.m.SignConsistencyMask()),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/rprop.py</code> <pre><code>class SignConsistencyMask(TensorTransform):\n    \"\"\"\n    Outputs a mask of sign consistency of current and previous inputs.\n\n    The output is 0 for weights where input sign changed compared to previous input, 1 otherwise.\n\n    ### Examples:\n\n    GD that skips update for weights where gradient sign changed compared to previous gradient.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Mul(tz.m.SignConsistencyMask()),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', cls=TensorList)\n        mask = prev.mul_(tensors).gt_(0)\n        prev.copy_(tensors)\n        return mask\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SophiaH","title":"SophiaH","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>SophiaH optimizer from https://arxiv.org/abs/2305.14342</p> <p>This is similar to Adam, but the second momentum is replaced by an exponential moving average of randomized hessian diagonal estimates, and the update is agressively clipped.</p> Notes <ul> <li> <p>In most cases SophiaH should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply SophiaH preconditioning to another module's output.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float</code>, default:                   <code>0.96</code> )           \u2013            <p>first momentum. Defaults to 0.96.</p> </li> <li> <code>beta2</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum for hessian diagonal estimate. Defaults to 0.99.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>frequency of updating hessian diagonal estimate via a hessian-vector product. Defaults to 10.</p> </li> <li> <code>precond_scale</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>scale of the preconditioner. Defaults to 1.</p> </li> <li> <code>clip</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>clips update to (-clip, clip). Defaults to 1.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-12</code> )           \u2013            <p>clips hessian diagonal esimate to be no less than this value. Defaults to 1e-12.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to <code>\"autograd\"</code>. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of hessian-vector products with random vectors to evaluate each time when updating the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random vectors. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>)           \u2013            <p>preconditioning is applied to the output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.SophiaH--examples","title":"Examples:","text":"<p>Using SophiaH:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SophiaH(),\n    tz.m.LR(0.1)\n)\n</code></pre> <p>SophiaH preconditioner can be applied to any other module by passing it to the <code>inner</code> argument. Turn off SophiaH's first momentum to get just the preconditioning. Here is an example of applying SophiaH preconditioning to nesterov momentum (<code>tz.m.NAG</code>):</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SophiaH(beta1=0, inner=tz.m.NAG(0.96)),\n    tz.m.LR(0.1)\n)\n</code></pre> Source code in <code>torchzero/modules/adaptive/sophia_h.py</code> <pre><code>class SophiaH(Transform):\n    \"\"\"SophiaH optimizer from https://arxiv.org/abs/2305.14342\n\n    This is similar to Adam, but the second momentum is replaced by an exponential moving average of randomized hessian diagonal estimates, and the update is agressively clipped.\n\n    Notes:\n        - In most cases SophiaH should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply SophiaH preconditioning to another module's output.\n\n        - This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        beta1 (float, optional): first momentum. Defaults to 0.96.\n        beta2 (float, optional): momentum for hessian diagonal estimate. Defaults to 0.99.\n        update_freq (int, optional):\n            frequency of updating hessian diagonal estimate via a hessian-vector product. Defaults to 10.\n        precond_scale (float, optional):\n            scale of the preconditioner. Defaults to 1.\n        clip (float, optional):\n            clips update to (-clip, clip). Defaults to 1.\n        eps (float, optional):\n            clips hessian diagonal esimate to be no less than this value. Defaults to 1e-12.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products. If a single hessian-vector is evaluated, equivalent to ``\"autograd\"``. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        n_samples (int, optional):\n            number of hessian-vector products with random vectors to evaluate each time when updating\n            the preconditioner. Larger values may lead to better hessian diagonal estimate. Defaults to 1.\n        seed (int | None, optional): seed for random vectors. Defaults to None.\n        inner (Chainable | None, optional): preconditioning is applied to the output of this module. Defaults to None.\n\n    ### Examples:\n\n    Using SophiaH:\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SophiaH(),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    SophiaH preconditioner can be applied to any other module by passing it to the ``inner`` argument.\n    Turn off SophiaH's first momentum to get just the preconditioning. Here is an example of applying\n    SophiaH preconditioning to nesterov momentum (``tz.m.NAG``):\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SophiaH(beta1=0, inner=tz.m.NAG(0.96)),\n        tz.m.LR(0.1)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.96,\n        beta2: float = 0.99,\n        update_freq: int = 10,\n        precond_scale: float = 1,\n        clip: float = 1,\n        eps: float = 1e-12,\n        hvp_method: HVPMethod = 'autograd',\n        distribution: Distributions = 'gaussian',\n        h: float = 1e-3,\n        n_samples = 1,\n        zHz: bool = True,\n        debias: bool = False,\n        seed: int | None = None,\n\n        exp_avg_tfm: Chainable | None = None,\n        D_exp_avg_tfm: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['exp_avg_tfm'], defaults[\"D_exp_avg_tfm\"]\n        super().__init__(defaults)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.set_child('D_exp_avg', D_exp_avg_tfm)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2 = unpack_dicts(settings, 'beta1', 'beta2', cls=NumberList)\n\n        exp_avg, D_exp_avg = unpack_states(states, params, 'exp_avg', 'D_exp_avg', cls=TensorList)\n\n        step = self.increment_counter(\"step\", start=0) # 0 on 1st update\n\n        # ---------------------------- hutchinson hessian ---------------------------- #\n        fs = settings[0]\n        update_freq = fs['update_freq']\n\n        if step % update_freq == 0:\n            self.increment_counter(\"num_Ds\", start=1)\n\n            D, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = fs['n_samples'],\n                distribution = fs['distribution'],\n                hvp_method = fs['hvp_method'],\n                h = fs['h'],\n                zHz = fs[\"zHz\"],\n                generator = self.get_generator(params[0].device, fs[\"seed\"]),\n            )\n\n            D_exp_avg.lerp_(D, weight=1-beta2)\n\n        # --------------------------------- momentum --------------------------------- #\n        tensors = objective.get_updates() # do this after hutchinson to not disturb autograd\n        exp_avg.lerp_(tensors, 1-beta1)\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        params = objective.params\n\n        beta1, beta2, eps, precond_scale, clip = unpack_dicts(\n            settings, 'beta1', 'beta2', 'eps', 'precond_scale', 'clip', cls=NumberList)\n\n        exp_avg, D_exp_avg = unpack_states(states, params, 'exp_avg', 'D_exp_avg')\n\n        # ---------------------------------- debias ---------------------------------- #\n        if settings[0][\"debias\"]:\n            bias_correction1 = 1.0 - (beta1 ** (self.global_state[\"step\"] + 1))\n            bias_correction2 = 1.0 - (beta2 ** self.global_state[\"num_Ds\"])\n\n            exp_avg = exp_avg / bias_correction1\n            D_exp_avg = D_exp_avg / bias_correction2\n\n        # -------------------------------- transforms -------------------------------- #\n        exp_avg = TensorList(self.inner_step_tensors(\n            \"exp_avg\", tensors=exp_avg, clone=True, objective=objective, must_exist=False))\n\n        D_exp_avg = TensorList(self.inner_step_tensors(\n            \"D_exp_avg\", tensors=D_exp_avg, clone=True, objective=objective, must_exist=False))\n\n        # ------------------------------ compute update ------------------------------ #\n        denom = D_exp_avg.lazy_mul(precond_scale).clip(min=eps)\n        objective.updates = (exp_avg / denom).clip_(-clip, clip)\n        return objective\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.orthogonalize_grads_","title":"orthogonalize_grads_","text":"<pre><code>orthogonalize_grads_(params: Iterable[Tensor], dual_norm_correction=False, method: Literal['newtonschulz', 'ns5', 'polar_express', 'svd', 'qr', 'eigh'] = 'newtonschulz', channel_first: bool = True)\n</code></pre> <p>Computes the zeroth power / orthogonalization of gradients of an iterable of parameters.</p> <p>This sets gradients in-place. Applies along first 2 dims (expected to be <code>out_channels, in_channels</code>).</p> <p>Note that the Muon page says that embeddings and classifier heads should not be orthogonalized. Args:     params (abc.Iterable[torch.Tensor]): parameters that hold gradients to orthogonalize.     dual_norm_correction (bool, optional):         enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.     method (str, optional):         Newton-Schulz is very fast, SVD is extremely slow but can be slighly more precise.     channel_first (bool, optional):         if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions         are considered batch dimensions.</p> Source code in <code>torchzero/modules/adaptive/muon.py</code> <pre><code>def orthogonalize_grads_(\n    params: Iterable[torch.Tensor],\n    dual_norm_correction=False,\n    method: OrthogonalizeMethod = \"newtonschulz\",\n    channel_first:bool=True,\n):\n    \"\"\"Computes the zeroth power / orthogonalization of gradients of an iterable of parameters.\n\n    This sets gradients in-place. Applies along first 2 dims (expected to be `out_channels, in_channels`).\n\n    Note that the Muon page says that embeddings and classifier heads should not be orthogonalized.\n    Args:\n        params (abc.Iterable[torch.Tensor]): parameters that hold gradients to orthogonalize.\n        dual_norm_correction (bool, optional):\n            enables dual norm correction from https://github.com/leloykun/adaptive-muon. Defaults to False.\n        method (str, optional):\n            Newton-Schulz is very fast, SVD is extremely slow but can be slighly more precise.\n        channel_first (bool, optional):\n            if True, orthogonalizes along 1st two dimensions, otherwise along last 2. Other dimensions\n            are considered batch dimensions.\n    \"\"\"\n    for p in params:\n        if (p.grad is not None) and _is_at_least_2d(p.grad, channel_first=channel_first):\n            X = _orthogonalize_format(p.grad, method=method, channel_first=channel_first)\n            if dual_norm_correction: X = _dual_norm_correction(X, p.grad, channel_first=False)\n            p.grad.set_(X.view_as(p)) # pyright:ignore[reportArgumentType]\n</code></pre>"},{"location":"API/modules/adaptive/#torchzero.modules.adaptive.orthograd_","title":"orthograd_","text":"<pre><code>orthograd_(params: Iterable[Tensor], eps: float = 1e-30)\n</code></pre> <p>Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>Iterable[Tensor]</code>)           \u2013            <p>parameters that hold gradients to apply \u27c2Grad to.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-30</code> )           \u2013            <p>epsilon added to the denominator for numerical stability (default: 1e-30)</p> </li> </ul> <p>reference     https://arxiv.org/abs/2501.04697</p> Source code in <code>torchzero/modules/adaptive/orthograd.py</code> <pre><code>def orthograd_(params: Iterable[torch.Tensor], eps: float = 1e-30):\n    \"\"\"Applies \u27c2Grad - projects gradient of an iterable of parameters to be orthogonal to the weights.\n\n    Args:\n        params (abc.Iterable[torch.Tensor]): parameters that hold gradients to apply \u27c2Grad to.\n        eps (float, optional): epsilon added to the denominator for numerical stability (default: 1e-30)\n\n    reference\n        https://arxiv.org/abs/2501.04697\n    \"\"\"\n    params = TensorList(params).with_grad()\n    grad = params.grad\n    grad -= (params.dot(grad)/(params.dot(params) + eps)) * params\n</code></pre>"},{"location":"API/modules/clipping/","title":"Clippping","text":"<p>This subpackage contains modules like gradient clipping, normalization, centralization, etc.</p> <p>Classes:</p> <ul> <li> <code>Centralize</code>           \u2013            <p>Centralizes the update.</p> </li> <li> <code>ClipNorm</code>           \u2013            <p>Clips update norm to be no larger than <code>value</code>.</p> </li> <li> <code>ClipNormByEMA</code>           \u2013            <p>Clips norm to be no larger than the norm of an exponential moving average of past updates.</p> </li> <li> <code>ClipNormGrowth</code>           \u2013            <p>Clips update norm growth.</p> </li> <li> <code>ClipValue</code>           \u2013            <p>Clips update magnitude to be within <code>(-value, value)</code> range.</p> </li> <li> <code>ClipValueByEMA</code>           \u2013            <p>Clips magnitude of update to be no larger than magnitude of exponential moving average of past (unclipped) updates.</p> </li> <li> <code>ClipValueGrowth</code>           \u2013            <p>Clips update value magnitude growth.</p> </li> <li> <code>Normalize</code>           \u2013            <p>Normalizes the update.</p> </li> <li> <code>NormalizeByEMA</code>           \u2013            <p>Sets norm of the update to be the same as the norm of an exponential moving average of past updates.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>clip_grad_norm_</code>             \u2013              <p>Clips gradient of an iterable of parameters to specified norm value.</p> </li> <li> <code>clip_grad_value_</code>             \u2013              <p>Clips gradient of an iterable of parameters at specified value.</p> </li> <li> <code>normalize_grads_</code>             \u2013              <p>Normalizes gradient of an iterable of parameters to specified norm value.</p> </li> </ul>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.Centralize","title":"Centralize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Centralizes the update.</p> <p>Parameters:</p> <ul> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are centralized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to centralize by global mean of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are centralized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> </ul> <p>Examples:</p> <p>Standard gradient centralization: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Centralize(dim=0),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>References: - Yong, H., Huang, J., Hua, X., &amp; Zhang, L. (2020). Gradient centralization: A new optimization technique for deep neural networks. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part I 16 (pp. 635-652). Springer International Publishing. https://arxiv.org/abs/2004.01461</p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class Centralize(TensorTransform):\n    \"\"\"Centralizes the update.\n\n    Args:\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are centralized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to centralize by global mean of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are centralized.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n\n    Examples:\n\n    Standard gradient centralization:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Centralize(dim=0),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    References:\n    - Yong, H., Huang, J., Hua, X., &amp; Zhang, L. (2020). Gradient centralization: A new optimization technique for deep neural networks. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part I 16 (pp. 635-652). Springer International Publishing. https://arxiv.org/abs/2004.01461\n    \"\"\"\n    def __init__(\n        self,\n        dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n        inverse_dims: bool = False,\n        min_size: int = 2,\n    ):\n        defaults = dict(dim=dim,min_size=min_size,inverse_dims=inverse_dims)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        dim, min_size, inverse_dims = itemgetter('dim', 'min_size', 'inverse_dims')(settings[0])\n\n        _centralize_(tensors_ = TensorList(tensors), dim=dim, inverse_dims=inverse_dims, min_size=min_size)\n\n        return tensors\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.ClipNorm","title":"ClipNorm","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update norm to be no larger than <code>value</code>.</p> <p>Parameters:</p> <ul> <li> <code>max_norm</code>               (<code>float</code>)           \u2013            <p>value to clip norm to.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are normalized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal numer of elements in a parameter or slice to clip norm. Defaults to 1.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>what this affects.</p> </li> </ul> <p>Examples:</p> <p>Gradient norm clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ClipNorm(1),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Update norm clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.ClipNorm(1),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class ClipNorm(TensorTransform):\n    \"\"\"Clips update norm to be no larger than ``value``.\n\n    Args:\n        max_norm (float): value to clip norm to.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are normalized.\n        min_size (int, optional):\n            minimal numer of elements in a parameter or slice to clip norm. Defaults to 1.\n        target (str, optional):\n            what this affects.\n\n    Examples:\n\n    Gradient norm clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ClipNorm(1),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Update norm clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.ClipNorm(1),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        max_norm: float,\n        ord: Metrics = 2,\n        dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n        inverse_dims: bool = False,\n        min_size: int = 1,\n    ):\n        defaults = dict(max_norm=max_norm,ord=ord,dim=dim,min_size=min_size,inverse_dims=inverse_dims)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        max_norm = NumberList(s['max_norm'] for s in settings)\n        ord, dim, min_size, inverse_dims = itemgetter('ord', 'dim', 'min_size', 'inverse_dims')(settings[0])\n        _clip_norm_(\n            tensors_ = TensorList(tensors),\n            min = 0,\n            max = max_norm,\n            norm_value = None,\n            ord = ord,\n            dim = dim,\n            inverse_dims=inverse_dims,\n            min_size = min_size,\n        )\n        return tensors\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.ClipNormByEMA","title":"ClipNormByEMA","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips norm to be no larger than the norm of an exponential moving average of past updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for the exponential moving average. Defaults to 0.99.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>order of the norm. Defaults to 2.</p> </li> <li> <code>eps</code>               (<code>float</code>)           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.</p> </li> <li> <code>max_ema_growth</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.</p> </li> <li> <code>ema_init</code>               (<code>str</code>)           \u2013            <p>How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/ema_clipping.py</code> <pre><code>class ClipNormByEMA(TensorTransform):\n    \"\"\"Clips norm to be no larger than the norm of an exponential moving average of past updates.\n\n    Args:\n        beta (float, optional): beta for the exponential moving average. Defaults to 0.99.\n        ord (float, optional): order of the norm. Defaults to 2.\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n        tensorwise (bool, optional):\n            if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.\n        max_ema_growth (float | None, optional):\n            if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.\n        ema_init (str, optional):\n            How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.\n    \"\"\"\n    NORMALIZE = False\n    def __init__(\n        self,\n        beta=0.99,\n        ord: Metrics = 2,\n        tensorwise:bool=True,\n        max_ema_growth: float | None = 1.5,\n        init: float = 0.0,\n        min_norm: float = 1e-6,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(beta=beta, ord=ord, tensorwise=tensorwise, init=init, min_norm=min_norm, max_ema_growth=max_ema_growth)\n        super().__init__(defaults, inner=inner)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        eps = torch.finfo(tensors[0].dtype).tiny * 2\n        ord, tensorwise, init, max_ema_growth = itemgetter('ord', 'tensorwise', 'init', 'max_ema_growth')(settings[0])\n\n        beta, min_norm = unpack_dicts(settings, 'beta', 'min_norm', cls=NumberList)\n\n        exp_avg = unpack_states(states, tensors, 'exp_avg', init = lambda x: torch.full_like(x, init), cls=TensorList)\n\n        exp_avg.lerp_(tensors, 1-beta)\n\n        # ----------------------------- tensorwise update ---------------------------- #\n        if tensorwise:\n            tensors_norm = tensors.norm(ord)\n            ema_norm = exp_avg.metric(ord)\n\n            # clip ema norm growth\n            if max_ema_growth is not None:\n                prev_ema_norm = unpack_states(states, tensors, 'prev_ema_norm', init=ema_norm, cls=TensorList)\n                allowed_norm = (prev_ema_norm * max_ema_growth).clip(min=min_norm)\n\n                ema_denom = (ema_norm / allowed_norm).clip(min=1)\n                exp_avg.div_(ema_denom)\n                ema_norm.div_(ema_denom)\n\n                prev_ema_norm.set_(ema_norm)\n\n\n        # ------------------------------- global update ------------------------------ #\n        else:\n            tensors_norm = tensors.global_metric(ord)\n            ema_norm = exp_avg.global_metric(ord)\n\n            # clip ema norm growth\n            if max_ema_growth is not None:\n                prev_ema_norm = self.global_state.setdefault('prev_ema_norm', ema_norm)\n                allowed_norm = (prev_ema_norm * max_ema_growth).clip(min=min_norm[0])\n\n                if ema_norm &gt; allowed_norm:\n                    exp_avg.div_(ema_norm / allowed_norm)\n                    ema_norm = allowed_norm\n\n                prev_ema_norm.set_(ema_norm)\n\n\n        # ------------------- compute denominator to clip/normalize ------------------ #\n        denom = tensors_norm / ema_norm.clip(min=eps)\n        if self.NORMALIZE: denom.clip_(min=eps)\n        else: denom.clip_(min=1)\n        self.global_state['denom'] = denom\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        denom = self.global_state.pop('denom')\n        torch._foreach_div_(tensors, denom)\n        return tensors\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.ClipNormByEMA.NORMALIZE","title":"NORMALIZE  <code>class-attribute</code>","text":"<pre><code>NORMALIZE = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.ClipNormGrowth","title":"ClipNormGrowth","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update norm growth.</p> <p>Parameters:</p> <ul> <li> <code>add</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>additive clipping, next update norm is at most <code>previous norm + add</code>. Defaults to None.</p> </li> <li> <code>mul</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>multiplicative clipping, next update norm is at most <code>previous norm * mul</code>. Defaults to 1.5.</p> </li> <li> <code>min_value</code>               (<code>float | None</code>, default:                   <code>0.0001</code> )           \u2013            <p>minimum value for multiplicative clipping to prevent collapse to 0. Next norm is at most :code:<code>max(prev_norm, min_value) * mul</code>. Defaults to 1e-4.</p> </li> <li> <code>max_decay</code>               (<code>float | None</code>, default:                   <code>2</code> )           \u2013            <p>bounds the tracked multiplicative clipping decay to prevent collapse to 0. Next norm is at most :code:<code>max(previous norm * mul, max_decay)</code>. Defaults to 2.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to \"update\".</p> </li> </ul> Source code in <code>torchzero/modules/clipping/growth_clipping.py</code> <pre><code>class ClipNormGrowth(TensorTransform):\n    \"\"\"Clips update norm growth.\n\n    Args:\n        add (float | None, optional): additive clipping, next update norm is at most `previous norm + add`. Defaults to None.\n        mul (float | None, optional):\n            multiplicative clipping, next update norm is at most `previous norm * mul`. Defaults to 1.5.\n        min_value (float | None, optional):\n            minimum value for multiplicative clipping to prevent collapse to 0.\n            Next norm is at most :code:`max(prev_norm, min_value) * mul`. Defaults to 1e-4.\n        max_decay (float | None, optional):\n            bounds the tracked multiplicative clipping decay to prevent collapse to 0.\n            Next norm is at most :code:`max(previous norm * mul, max_decay)`.\n            Defaults to 2.\n        ord (float, optional): norm order. Defaults to 2.\n        tensorwise (bool, optional):\n            if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.\n        target (Target, optional): what to set on var. Defaults to \"update\".\n    \"\"\"\n    def __init__(\n        self,\n        add: float | None = None,\n        mul: float | None = 1.5,\n        min_value: float | None = 1e-4,\n        max_decay: float | None = 2,\n        ord: float = 2,\n        tensorwise=True,\n    ):\n        defaults = dict(add=add, mul=mul, min_value=min_value, max_decay=max_decay, ord=ord, tensorwise=tensorwise)\n        super().__init__(defaults)\n\n\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensorwise = settings[0]['tensorwise']\n        tensors = TensorList(tensors)\n\n        if tensorwise:\n            ts = tensors\n            stts = states\n            stns = settings\n\n        else:\n            ts = [tensors.to_vec()]\n            stts = [self.global_state]\n            stns = [settings[0]]\n\n\n        for t, state, setting in zip(ts, stts, stns):\n            if 'prev_norm' not in state:\n                state['prev_norm'] = torch.linalg.vector_norm(t, ord=setting['ord']) # pylint:disable=not-callable\n                state['prev_denom'] = 1\n                continue\n\n            _,  state['prev_norm'], state['prev_denom'] = norm_growth_clip_(\n                tensor_ = t,\n                prev_norm = state['prev_norm'],\n                add = setting['add'],\n                mul = setting['mul'],\n                min_value = setting['min_value'],\n                max_decay = setting['max_decay'],\n                ord = setting['ord'],\n            )\n\n        if not tensorwise:\n            tensors.from_vec_(ts[0])\n\n        return tensors\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.ClipValue","title":"ClipValue","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update magnitude to be within <code>(-value, value)</code> range.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>float</code>)           \u2013            <p>value to clip to.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>refer to <code>target argument</code> in documentation.</p> </li> </ul> <p>Examples:</p> <p>Gradient clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.ClipValue(1),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Update clipping: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.ClipValue(1),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class ClipValue(TensorTransform):\n    \"\"\"Clips update magnitude to be within ``(-value, value)`` range.\n\n    Args:\n        value (float): value to clip to.\n        target (str): refer to ``target argument`` in documentation.\n\n    Examples:\n\n    Gradient clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.ClipValue(1),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Update clipping:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.ClipValue(1),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, value: float):\n        defaults = dict(value=value)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        value = [s['value'] for s in settings]\n        return TensorList(tensors).clip_([-v for v in value], value)\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.ClipValueByEMA","title":"ClipValueByEMA","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips magnitude of update to be no larger than magnitude of exponential moving average of past (unclipped) updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for the exponential moving average. Defaults to 0.99.</p> </li> <li> <code>ema_init</code>               (<code>str</code>)           \u2013            <p>How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.</p> </li> <li> <code>exp_avg_tfm</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional modules applied to exponential moving average before clipping by it. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/ema_clipping.py</code> <pre><code>class ClipValueByEMA(TensorTransform):\n    \"\"\"Clips magnitude of update to be no larger than magnitude of exponential moving average of past (unclipped) updates.\n\n    Args:\n        beta (float, optional): beta for the exponential moving average. Defaults to 0.99.\n        ema_init (str, optional):\n            How to initialize exponential moving average on first step,\n            \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.\n        exp_avg_tfm (Chainable | None, optional):\n            optional modules applied to exponential moving average before clipping by it. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        beta=0.99,\n        init: float = 0,\n\n        inner: Chainable | None = None,\n        exp_avg_tfm:Chainable | None=None,\n    ):\n        defaults = dict(beta=beta, init=init)\n        super().__init__(defaults, inner=inner)\n\n        self.set_child('exp_avg', exp_avg_tfm)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    def single_tensor_initialize(self, tensor, param, grad, loss, state, setting):\n        state[\"exp_avg\"] = tensor.abs() * setting[\"init\"]\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        beta = unpack_dicts(settings, 'beta', cls=NumberList)\n\n        exp_avg = unpack_states(states, tensors, 'exp_avg', must_exist=True, cls=TensorList)\n        exp_avg.lerp_(tensors.abs(), 1-beta)\n\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        exp_avg = unpack_states(states, tensors, 'exp_avg')\n\n        exp_avg = TensorList(\n            self.inner_step_tensors(\"exp_avg\", exp_avg, clone=True, params=params, grads=grads, loss=loss, must_exist=False))\n\n        tensors.clip_(-exp_avg, exp_avg)\n        return tensors\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.ClipValueGrowth","title":"ClipValueGrowth","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Clips update value magnitude growth.</p> <p>Parameters:</p> <ul> <li> <code>add</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>additive clipping, next update is at most <code>previous update + add</code>. Defaults to None.</p> </li> <li> <code>mul</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>multiplicative clipping, next update is at most <code>previous update * mul</code>. Defaults to 1.5.</p> </li> <li> <code>min_value</code>               (<code>float | None</code>, default:                   <code>0.0001</code> )           \u2013            <p>minimum value for multiplicative clipping to prevent collapse to 0. Next update is at most :code:<code>max(prev_update, min_value) * mul</code>. Defaults to 1e-4.</p> </li> <li> <code>max_decay</code>               (<code>float | None</code>, default:                   <code>2</code> )           \u2013            <p>bounds the tracked multiplicative clipping decay to prevent collapse to 0. Next update is at most :code:<code>max(previous update * mul, max_decay)</code>. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to \"update\".</p> </li> </ul> Source code in <code>torchzero/modules/clipping/growth_clipping.py</code> <pre><code>class ClipValueGrowth(TensorTransform):\n    \"\"\"Clips update value magnitude growth.\n\n    Args:\n        add (float | None, optional): additive clipping, next update is at most `previous update + add`. Defaults to None.\n        mul (float | None, optional): multiplicative clipping, next update is at most `previous update * mul`. Defaults to 1.5.\n        min_value (float | None, optional):\n            minimum value for multiplicative clipping to prevent collapse to 0.\n            Next update is at most :code:`max(prev_update, min_value) * mul`. Defaults to 1e-4.\n        max_decay (float | None, optional):\n            bounds the tracked multiplicative clipping decay to prevent collapse to 0.\n            Next update is at most :code:`max(previous update * mul, max_decay)`.\n            Defaults to 2.\n        target (Target, optional): what to set on var. Defaults to \"update\".\n    \"\"\"\n    def __init__(\n        self,\n        add: float | None = None,\n        mul: float | None = 1.5,\n        min_value: float | None = 1e-4,\n        max_decay: float | None = 2,\n    ):\n        defaults = dict(add=add, mul=mul, min_value=min_value, max_decay=max_decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"prev\")\n\n\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        add, mul, min_value, max_decay = itemgetter('add','mul','min_value','max_decay')(setting)\n        add: float | None\n\n        if add is None and mul is None:\n            return tensor\n\n        if 'prev' not in state:\n            state['prev'] = tensor.clone()\n            return tensor\n\n        prev: torch.Tensor = state['prev']\n\n        # additive bound\n        if add is not None:\n            growth = (tensor.abs() - prev.abs()).clip(min=0)\n            tensor.sub_(torch.where(growth &gt; add, (growth-add).copysign_(tensor), 0))\n\n        # multiplicative bound\n        growth = None\n        if mul is not None:\n            prev_magn = prev.abs()\n            if min_value is not None: prev_magn.clip_(min=min_value)\n            growth = (tensor.abs() / prev_magn).clamp_(min=1e-8)\n\n            denom = torch.where(growth &gt; mul, growth/mul, 1)\n\n            tensor.div_(denom)\n\n        # limit max growth decay\n        if max_decay is not None:\n            if growth is None:\n                prev_magn = prev.abs()\n                if min_value is not None: prev_magn.clip_(min=min_value)\n                growth = (tensor.abs() / prev_magn).clamp_(min=1e-8)\n\n            new_prev = torch.where(growth &lt; (1/max_decay), prev/max_decay, tensor)\n        else:\n            new_prev = tensor.clone()\n\n        state['prev'] = new_prev\n        return tensor\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.Normalize","title":"Normalize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Normalizes the update.</p> <p>Parameters:</p> <ul> <li> <code>norm_value</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>desired norm value.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are normalized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>what this affects.</p> </li> </ul> <p>Examples: Gradient normalization: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Normalize(1),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>Update normalization:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.Normalize(1),\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>class Normalize(TensorTransform):\n    \"\"\"Normalizes the update.\n\n    Args:\n        norm_value (float): desired norm value.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are normalized.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n        target (str, optional):\n            what this affects.\n\n    Examples:\n    Gradient normalization:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Normalize(1),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Update normalization:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.Normalize(1),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        norm_value: float = 1,\n        ord: Metrics = 2,\n        dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n        inverse_dims: bool = False,\n        min_size: int = 1,\n    ):\n        defaults = dict(norm_value=norm_value,ord=ord,dim=dim,min_size=min_size, inverse_dims=inverse_dims)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        norm_value = NumberList(s['norm_value'] for s in settings)\n        ord, dim, min_size, inverse_dims = itemgetter('ord', 'dim', 'min_size', 'inverse_dims')(settings[0])\n\n        _clip_norm_(\n            tensors_ = TensorList(tensors),\n            min = None,\n            max = None,\n            norm_value = norm_value,\n            ord = ord,\n            dim = dim,\n            inverse_dims=inverse_dims,\n            min_size = min_size,\n        )\n\n        return tensors\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.NormalizeByEMA","title":"NormalizeByEMA","text":"<p>               Bases: <code>torchzero.modules.clipping.ema_clipping.ClipNormByEMA</code></p> <p>Sets norm of the update to be the same as the norm of an exponential moving average of past updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>beta for the exponential moving average. Defaults to 0.99.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>order of the norm. Defaults to 2.</p> </li> <li> <code>eps</code>               (<code>float</code>)           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.</p> </li> <li> <code>max_ema_growth</code>               (<code>float | None</code>, default:                   <code>1.5</code> )           \u2013            <p>if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.</p> </li> <li> <code>ema_init</code>               (<code>str</code>)           \u2013            <p>How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/ema_clipping.py</code> <pre><code>class NormalizeByEMA(ClipNormByEMA):\n    \"\"\"Sets norm of the update to be the same as the norm of an exponential moving average of past updates.\n\n    Args:\n        beta (float, optional): beta for the exponential moving average. Defaults to 0.99.\n        ord (float, optional): order of the norm. Defaults to 2.\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n        tensorwise (bool, optional):\n            if True, norms are calculated parameter-wise, otherwise treats all parameters as single vector. Defaults to True.\n        max_ema_growth (float | None, optional):\n            if specified, restricts how quickly exponential moving average norm can grow. The norm is allowed to grow by at most this value per step. Defaults to 1.5.\n        ema_init (str, optional):\n            How to initialize exponential moving average on first step, \"update\" to use the first update or \"zeros\". Defaults to 'zeros'.\n    \"\"\"\n    NORMALIZE = True\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.NormalizeByEMA.NORMALIZE","title":"NORMALIZE  <code>class-attribute</code>","text":"<pre><code>NORMALIZE = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.clip_grad_norm_","title":"clip_grad_norm_","text":"<pre><code>clip_grad_norm_(params: Iterable[Tensor], max_norm: float | None, ord: Union[Literal['mad', 'std', 'var', 'sum', 'l0', 'l1', 'l2', 'l3', 'l4', 'linf'], float, Tensor] = 2, dim: Union[int, Sequence[int], Literal['global'], NoneType] = None, inverse_dims: bool = False, min_size: int = 2, min_norm: float | None = None)\n</code></pre> <p>Clips gradient of an iterable of parameters to specified norm value. Gradients are modified in-place.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>Iterable[Tensor]</code>)           \u2013            <p>parameters with gradients to clip.</p> </li> <li> <code>max_norm</code>               (<code>float</code>)           \u2013            <p>value to clip norm to.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>def clip_grad_norm_(\n    params: Iterable[torch.Tensor],\n    max_norm: float | None,\n    ord: Metrics = 2,\n    dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n    inverse_dims: bool = False,\n    min_size: int = 2,\n    min_norm: float | None = None,\n):\n    \"\"\"Clips gradient of an iterable of parameters to specified norm value.\n    Gradients are modified in-place.\n\n    Args:\n        params (Iterable[torch.Tensor]): parameters with gradients to clip.\n        max_norm (float): value to clip norm to.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n    \"\"\"\n    grads = TensorList(p.grad for p in params if p.grad is not None)\n    _clip_norm_(grads, min=min_norm, max=max_norm, norm_value=None, ord=ord, dim=dim, inverse_dims=inverse_dims, min_size=min_size)\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.clip_grad_value_","title":"clip_grad_value_","text":"<pre><code>clip_grad_value_(params: Iterable[Tensor], value: float)\n</code></pre> <p>Clips gradient of an iterable of parameters at specified value. Gradients are modified in-place. Args:     params (Iterable[Tensor]): iterable of tensors with gradients to clip.     value (float or int): maximum allowed value of gradient</p> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>def clip_grad_value_(params: Iterable[torch.Tensor], value: float):\n    \"\"\"Clips gradient of an iterable of parameters at specified value.\n    Gradients are modified in-place.\n    Args:\n        params (Iterable[Tensor]): iterable of tensors with gradients to clip.\n        value (float or int): maximum allowed value of gradient\n    \"\"\"\n    grads = [p.grad for p in params if p.grad is not None]\n    torch._foreach_clamp_min_(grads, -value)\n    torch._foreach_clamp_max_(grads, value)\n</code></pre>"},{"location":"API/modules/clipping/#torchzero.modules.clipping.normalize_grads_","title":"normalize_grads_","text":"<pre><code>normalize_grads_(params: Iterable[Tensor], norm_value: float, ord: Union[Literal['mad', 'std', 'var', 'sum', 'l0', 'l1', 'l2', 'l3', 'l4', 'linf'], float, Tensor] = 2, dim: Union[int, Sequence[int], Literal['global'], NoneType] = None, inverse_dims: bool = False, min_size: int = 1)\n</code></pre> <p>Normalizes gradient of an iterable of parameters to specified norm value. Gradients are modified in-place.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>Iterable[Tensor]</code>)           \u2013            <p>parameters with gradients to clip.</p> </li> <li> <code>norm_value</code>               (<code>float</code>)           \u2013            <p>value to clip norm to.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>dim</code>               (<code>int | Sequence[int] | str | None</code>, default:                   <code>None</code> )           \u2013            <p>calculates norm along those dimensions. If list/tuple, tensors are normalized along all dimensios in <code>dim</code> that they have. Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector. Defaults to None.</p> </li> <li> <code>inverse_dims</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, the <code>dims</code> argument is inverted, and all other dimensions are normalized.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal size of a dimension to normalize along it. Defaults to 1.</p> </li> </ul> Source code in <code>torchzero/modules/clipping/clipping.py</code> <pre><code>def normalize_grads_(\n    params: Iterable[torch.Tensor],\n    norm_value: float,\n    ord: Metrics = 2,\n    dim: int | Sequence[int] | Literal[\"global\"] | None = None,\n    inverse_dims: bool = False,\n    min_size: int = 1,\n):\n    \"\"\"Normalizes gradient of an iterable of parameters to specified norm value.\n    Gradients are modified in-place.\n\n    Args:\n        params (Iterable[torch.Tensor]): parameters with gradients to clip.\n        norm_value (float): value to clip norm to.\n        ord (float, optional): norm order. Defaults to 2.\n        dim (int | Sequence[int] | str | None, optional):\n            calculates norm along those dimensions.\n            If list/tuple, tensors are normalized along all dimensios in `dim` that they have.\n            Can be set to \"global\" to normalize by global norm of all gradients concatenated to a vector.\n            Defaults to None.\n        inverse_dims (bool, optional):\n            if True, the `dims` argument is inverted, and all other dimensions are normalized.\n        min_size (int, optional):\n            minimal size of a dimension to normalize along it. Defaults to 1.\n    \"\"\"\n    grads = TensorList(p.grad for p in params if p.grad is not None)\n    _clip_norm_(grads, min=None, max=None, norm_value=norm_value, ord=ord, dim=dim, inverse_dims=inverse_dims, min_size=min_size)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/","title":"Quasi-newton methods","text":"<p>This subpackage contains conjugate gradient methods.</p>"},{"location":"API/modules/conjugate_gradient/#see-also","title":"See also","text":"<ul> <li>Line search - conjugate gradient methods usually require a line search.</li> </ul> <p>Classes:</p> <ul> <li> <code>ConjugateDescent</code>           \u2013            <p>Conjugate Descent (CD).</p> </li> <li> <code>DYHS</code>           \u2013            <p>Dai-Yuan - Hestenes\u2013Stiefel hybrid conjugate gradient method.</p> </li> <li> <code>DaiYuan</code>           \u2013            <p>Dai\u2013Yuan nonlinear conjugate gradient method.</p> </li> <li> <code>FletcherReeves</code>           \u2013            <p>Fletcher\u2013Reeves nonlinear conjugate gradient method.</p> </li> <li> <code>HagerZhang</code>           \u2013            <p>Hager-Zhang nonlinear conjugate gradient method,</p> </li> <li> <code>HestenesStiefel</code>           \u2013            <p>Hestenes\u2013Stiefel nonlinear conjugate gradient method.</p> </li> <li> <code>LiuStorey</code>           \u2013            <p>Liu-Storey nonlinear conjugate gradient method.</p> </li> <li> <code>PolakRibiere</code>           \u2013            <p>Polak-Ribi\u00e8re-Polyak nonlinear conjugate gradient method.</p> </li> <li> <code>ProjectedGradientMethod</code>           \u2013            <p>Projected gradient method. Directly projects the gradient onto subspace conjugate to past directions.</p> </li> </ul>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.ConjugateDescent","title":"ConjugateDescent","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Conjugate Descent (CD).</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class ConjugateDescent(ConguateGradientBase):\n    \"\"\"Conjugate Descent (CD).\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return conjugate_descent_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.DYHS","title":"DYHS","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Dai-Yuan - Hestenes\u2013Stiefel hybrid conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class DYHS(ConguateGradientBase):\n    \"\"\"Dai-Yuan - Hestenes\u2013Stiefel hybrid conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return dyhs_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.DaiYuan","title":"DaiYuan","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Dai\u2013Yuan nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1)</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class DaiYuan(ConguateGradientBase):\n    \"\"\"Dai\u2013Yuan nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1)`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return dai_yuan_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.FletcherReeves","title":"FletcherReeves","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Fletcher\u2013Reeves nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class FletcherReeves(ConguateGradientBase):\n    \"\"\"Fletcher\u2013Reeves nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def initialize(self, p, g):\n        self.global_state['prev_gg'] = g.dot(g)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        gg = g.dot(g)\n        beta = fletcher_reeves_beta(gg, self.global_state['prev_gg'])\n        self.global_state['prev_gg'] = gg\n        return beta\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.HagerZhang","title":"HagerZhang","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Hager-Zhang nonlinear conjugate gradient method,</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class HagerZhang(ConguateGradientBase):\n    \"\"\"Hager-Zhang nonlinear conjugate gradient method,\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return hager_zhang_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.HestenesStiefel","title":"HestenesStiefel","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Hestenes\u2013Stiefel nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class HestenesStiefel(ConguateGradientBase):\n    \"\"\"Hestenes\u2013Stiefel nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return hestenes_stiefel_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.LiuStorey","title":"LiuStorey","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Liu-Storey nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class LiuStorey(ConguateGradientBase):\n    \"\"\"Liu-Storey nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, restart_interval: int | None | Literal['auto'] = 'auto', clip_beta=False, inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return liu_storey_beta(g, prev_d, prev_g)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.PolakRibiere","title":"PolakRibiere","text":"<p>               Bases: <code>torchzero.modules.conjugate_gradient.cg.ConguateGradientBase</code></p> <p>Polak-Ribi\u00e8re-Polyak nonlinear conjugate gradient method.</p> Note <p>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class PolakRibiere(ConguateGradientBase):\n    \"\"\"Polak-Ribi\u00e8re-Polyak nonlinear conjugate gradient method.\n\n    Note:\n        This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n    \"\"\"\n    def __init__(self, clip_beta=True, restart_interval: int | None | Literal['auto'] = 'auto', inner: Chainable | None = None):\n        super().__init__({}, clip_beta=clip_beta, restart_interval=restart_interval, inner=inner)\n\n    def get_beta(self, p, g, prev_g, prev_d):\n        return polak_ribiere_beta(g, prev_g)\n</code></pre>"},{"location":"API/modules/conjugate_gradient/#torchzero.modules.conjugate_gradient.ProjectedGradientMethod","title":"ProjectedGradientMethod","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Projected gradient method. Directly projects the gradient onto subspace conjugate to past directions.</p> Notes <ul> <li>This method uses N^2 memory.</li> <li>This requires step size to be determined via a line search, so put a line search like <code>tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")</code> after this.</li> <li>This is not the same as projected gradient descent.</li> </ul> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.  (algorithm 5 in section 6)</p> Source code in <code>torchzero/modules/conjugate_gradient/cg.py</code> <pre><code>class ProjectedGradientMethod(HessianUpdateStrategy): # this doesn't maintain hessian\n    \"\"\"Projected gradient method. Directly projects the gradient onto subspace conjugate to past directions.\n\n    Notes:\n        - This method uses N^2 memory.\n        - This requires step size to be determined via a line search, so put a line search like ``tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")`` after this.\n        - This is not the same as projected gradient descent.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.  (algorithm 5 in section 6)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        init_scale: float | Literal[\"auto\"] = 1,\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = 'auto',\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        # inverse: bool = True,\n        inner: Chainable | None = None,\n    ):\n        super().__init__(\n            defaults=None,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return projected_gradient_(H=H, y=y)\n</code></pre>"},{"location":"API/modules/experimental/","title":"Experimental","text":"<p>This subpackage contains various horrible atrocities that are generally less tested.</p> <p>Those are various ideas of mine plus some other modules that I decided not to move to other sub-packages for whatever reason. This is generally less tested.</p> <p>Classes:</p> <ul> <li> <code>BlockPartition</code>           \u2013            <p>splits parameters into blocks (for now flatttens them and chunks)</p> </li> <li> <code>CoordinateMomentum</code>           \u2013            <p>Maintains a momentum buffer, on each step each value in the buffer has <code>p</code> chance to be updated with the new value.</p> </li> <li> <code>CubicAdam</code>           \u2013            <p>Adam which has 3rd momentum and minimizes a cubic polynomial.</p> </li> <li> <code>CurveBall</code>           \u2013            <p>CurveBall method from https://arxiv.org/pdf/1805.08095#page=4.09.</p> </li> <li> <code>FFTProjection</code>           \u2013            <p>Project update into Fourier space of real-valued inputs.</p> </li> <li> <code>GradMin</code>           \u2013            <p>Reformulates the objective to minimize sum of gradient magnitudes via autograd. This is not expected to be practical.</p> </li> <li> <code>HigherOrderNewton</code>           \u2013            <p>A basic arbitrary order newton's method with optional trust region and proximal penalty.</p> </li> <li> <code>InfinityNormTrustRegion</code>           \u2013            <p>Trust region with L-infinity norm via <code>scipy.optimize.lsq_linear</code>.</p> </li> <li> <code>NewtonNewton</code>           \u2013            <p>Applies Newton-like preconditioning to Newton step.</p> </li> <li> <code>NewtonSolver</code>           \u2013            <p>Matrix free newton via with any custom solver (this is for testing, use NewtonCG or NystromPCG).</p> </li> <li> <code>ReduceOutwardLR</code>           \u2013            <p>When update sign matches weight sign, the learning rate for that weight is multiplied by <code>mul</code>.</p> </li> <li> <code>ScipyNewtonCG</code>           \u2013            <p>NewtonCG with scipy solvers (any from scipy.sparse.linalg)</p> </li> <li> <code>SubspaceCubicAdam</code>           \u2013            <p>Runs cubic Adam in low rank eigenbasis.</p> </li> <li> <code>TensorizeProjection</code>           \u2013            <p>flattens and concatenates all parameters into a vector and then reshapes it into a tensor</p> </li> </ul>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.BlockPartition","title":"BlockPartition","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>splits parameters into blocks (for now flatttens them and chunks)</p> Source code in <code>torchzero/modules/experimental/structural_projections.py</code> <pre><code>class BlockPartition(ProjectionBase):\n    \"\"\"splits parameters into blocks (for now flatttens them and chunks)\"\"\"\n    def __init__(self, modules: Chainable, max_size: int, batched: bool = False, project_update=True, project_params=False, project_grad=False):\n        defaults = dict(max_size=max_size, batched=batched)\n        super().__init__(modules, project_update=project_update, project_params=project_params, project_grad=project_grad, defaults=defaults)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        partitioned = []\n        for p,t in zip(params, tensors):\n            settings = self.settings[p]\n            max_size = settings['max_size']\n            n = t.numel()\n            if n &lt;= max_size:\n                partitioned.append(t)\n                continue\n\n            t_flat = t.view(-1)\n\n            batched = settings['batched']\n            num_chunks = math.ceil(n / max_size)\n\n            if batched:\n                chunks_size = num_chunks * max_size\n                if num_chunks * max_size &gt; n:\n                    t_flat = torch.cat([t_flat, torch.zeros(n-chunks_size, dtype=t_flat.dtype, device=t_flat.device)])\n                partitioned.append(t_flat.view(num_chunks, -1))\n\n            else:\n                partitioned.extend(t_flat.chunk(num_chunks))\n\n        return partitioned\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        ti = iter(projected_tensors)\n        unprojected = []\n        for p in params:\n            settings = self.settings[p]\n            n = p.numel()\n\n            if settings['batched']:\n                unprojected.append(next(ti).view(-1)[:n].view_as(p))\n\n            else:\n                chunks = []\n                t_n = 0\n                while t_n &lt; n:\n                    t = next(ti)\n                    chunks.append(t)\n                    t_n += t.numel()\n\n                assert t_n == n\n                unprojected.append(torch.cat(chunks).view_as(p))\n\n        return unprojected\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.CoordinateMomentum","title":"CoordinateMomentum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains a momentum buffer, on each step each value in the buffer has <code>p</code> chance to be updated with the new value.</p> <p>Parameters:</p> <ul> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>description. Defaults to 0.1.</p> </li> </ul> Source code in <code>torchzero/modules/experimental/coordinate_momentum.py</code> <pre><code>class CoordinateMomentum(TensorTransform):\n    \"\"\"Maintains a momentum buffer, on each step each value in the buffer has ``p`` chance to be updated with the new value.\n\n    Args:\n        p (float, optional): _description_. Defaults to 0.1.\n    \"\"\"\n    def __init__(self, p: float = 0.1):\n        defaults = dict(p=p)\n        super().__init__(defaults)\n\n        self.add_projected_keys(\"grad\", \"velocity\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        p = NumberList(s['p'] for s in settings)\n        velocity = unpack_states(states, tensors, 'velocity', cls=TensorList)\n        return coordinate_momentum_(TensorList(tensors), velocity_=velocity, p=p).clone()\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.CubicAdam","title":"CubicAdam","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Adam which has 3rd momentum and minimizes a cubic polynomial.</p> Source code in <code>torchzero/modules/experimental/cubic_adam.py</code> <pre><code>class CubicAdam(TensorTransform):\n    \"\"\"Adam which has 3rd momentum and minimizes a cubic polynomial.\"\"\"\n    def __init__(\n        self,\n        beta1: float = 0.9,\n        beta2: float = 0.99,\n        beta3: float = 0.99,\n        eps: float = 1e-8,\n        debiased:bool=True,\n        alpha: float = 1.,\n\n        mode: _cubic_adam_mode = 'signed_cbrt'\n    ):\n        defaults=dict(beta1=beta1,beta2=beta2,beta3=beta3,eps=eps,debiased=debiased,alpha=alpha,mode=mode)\n        super().__init__(defaults)\n\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\")\n        self.add_projected_keys(\"grad_cu\", \"exp_avg_cu\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        beta1,beta2,beta3,eps,alpha=unpack_dicts(settings, 'beta1','beta2','beta3','eps','alpha', cls=NumberList)\n        exp_avg, exp_avg_sq, exp_avg_cu = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', 'exp_avg_cu', cls=TensorList)\n\n        return cubic_adam_(\n            tensors=TensorList(tensors),\n            exp_avg_=exp_avg,\n            exp_avg_sq_=exp_avg_sq,\n            exp_avg_cu_=exp_avg_cu,\n            alpha=alpha,\n            beta1=beta1,\n            beta2=beta2,\n            beta3=beta3,\n            eps=eps,\n            debiased=settings[0]['debiased'],\n            step=step,\n\n            mode=settings[0][\"mode\"]\n        )\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.CurveBall","title":"CurveBall","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>CurveBall method from https://arxiv.org/pdf/1805.08095#page=4.09.</p> <p>For now this implementation does not include automatic \u03c1, \u03b1 and \u03b2 hyper-parameters in closed form, therefore it is expected to underperform compared to official implementation (https://github.com/jotaf98/pytorch-curveball/tree/master) so I moved this to experimental.</p> <p>Parameters:</p> <ul> <li> <code>precond_lr</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>learning rate for updating preconditioned gradients. Defaults to 1e-3.</p> </li> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>decay rate for preconditioned gradients. Defaults to 0.9.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to calculate hessian vector products. Defaults to \"autograd\".</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size for when hvp_method is set to finite difference. Defaults to 1e-3.</p> </li> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>hessian regularization. Defaults to 1.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>Inner modules. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/experimental/curveball.py</code> <pre><code>class CurveBall(Transform):\n    \"\"\"CurveBall method from https://arxiv.org/pdf/1805.08095#page=4.09.\n\n    For now this implementation does not include automatic \u03c1, \u03b1 and \u03b2 hyper-parameters in closed form, therefore it is expected to underperform compared to official implementation (https://github.com/jotaf98/pytorch-curveball/tree/master) so I moved this to experimental.\n\n    Args:\n        precond_lr (float, optional): learning rate for updating preconditioned gradients. Defaults to 1e-3.\n        momentum (float, optional): decay rate for preconditioned gradients. Defaults to 0.9.\n        hvp_method (str, optional): how to calculate hessian vector products. Defaults to \"autograd\".\n        h (float, optional): finite difference step size for when hvp_method is set to finite difference. Defaults to 1e-3.\n        reg (float, optional): hessian regularization. Defaults to 1.\n        inner (Chainable | None, optional): Inner modules. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        precond_lr: float=1e-3,\n        momentum: float=0.9,\n        hvp_method: HVPMethod = \"autograd\",\n        h: float = 1e-3,\n        reg: float = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(precond_lr=precond_lr, momentum=momentum, hvp_method=hvp_method, h=h, reg=reg)\n        super().__init__(defaults)\n\n        self.set_child('inner', inner)\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        params = objective.params\n        fs = settings[0]\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n\n        precond_lr, momentum, reg = unpack_dicts(settings, 'precond_lr', 'momentum', 'reg', cls=NumberList)\n\n        closure = objective.closure\n        assert closure is not None\n\n        z, Hz = unpack_states(states, params, 'z', 'Hz', cls=TensorList)\n        Hz, _ = objective.hessian_vector_product(z, rgrad=None, at_x0=True, hvp_method=hvp_method, h=h)\n\n        Hz = TensorList(Hz)\n        Hzz = Hz.add_(z * reg)\n\n        objective = self.inner_step(\"inner\", objective, must_exist=False)\n        updates = objective.get_updates()\n\n        z = curveball(TensorList(updates), z, Hzz, momentum=momentum, precond_lr=precond_lr)\n        objective.updates = z.neg()\n\n        return objective\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.FFTProjection","title":"FFTProjection","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>Project update into Fourier space of real-valued inputs.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable</code>)           \u2013            <p>modules that will optimize the projected update.</p> </li> <li> <code>one_d</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <ul> <li>If True, uses 1d fft on parameters concatenated into a vector.</li> <li>If False, uses n-dimensional fft on each parameter (default).</li> </ul> </li> <li> <code>norm</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Normalization mode.</p> <ul> <li>\"forward\" - normalize by 1/n</li> <li>\"backward\" - no normalization</li> <li>\"ortho\" - normalize by 1/sqrt(n) (making the FFT orthonormal)</li> </ul> <p>Calling the backward transform (:func:<code>~torch.fft.irfft</code>) with the same normalization mode will apply an overall normalization of <code>1/n</code> between the two transforms. This is required to make :func:<code>~torch.fft.irfft</code> the exact inverse.</p> <p>Default is \"backward\" (no normalization).</p> <p>The actual torch.fft.rfft default is None, so I set it to None too. I guess None and \"backward\" are the same.</p> </li> </ul> Source code in <code>torchzero/modules/experimental/fft.py</code> <pre><code>class FFTProjection(ProjectionBase):\n    # norm description copied from pytorch docstring\n    \"\"\"Project update into Fourier space of real-valued inputs.\n\n    Args:\n        modules (Chainable): modules that will optimize the projected update.\n        one_d (bool, optional):\n            * If True, uses 1d fft on parameters concatenated into a vector.\n            * If False, uses n-dimensional fft on each parameter (default).\n        norm (str, optional):\n            Normalization mode.\n\n            * \"forward\" - normalize by 1/n\n            * \"backward\" - no normalization\n            * \"ortho\" - normalize by 1/sqrt(n) (making the FFT orthonormal)\n\n            Calling the backward transform (:func:`~torch.fft.irfft`) with the same\n            normalization mode will apply an overall normalization of ``1/n`` between\n            the two transforms. This is required to make :func:`~torch.fft.irfft`\n            the exact inverse.\n\n            Default is \"backward\" (no normalization).\n\n            The actual torch.fft.rfft default is None, so I set it to None too. I guess None and \"backward\"\n            are the same.\n    \"\"\"\n\n    def __init__(\n        self,\n        modules: Chainable,\n        one_d: bool = False,\n        norm=None,\n        project_update=True,\n        project_params=False,\n        project_grad=False,\n    ):\n        defaults = dict(one_d=one_d, norm=norm)\n        super().__init__(modules, project_update=project_update, project_params=project_params, project_grad=project_grad, defaults=defaults)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        settings = settings[0]\n        one_d = settings['one_d']\n        norm = settings['norm']\n\n        # 1d fft, concatenate all parameters into a vector and calculate fft\n        if one_d:\n            vec = torch.cat([t.view(-1) for t in tensors])\n            self.global_state['length'] = len(vec)\n            return [torch.view_as_real(torch.fft.rfft(vec, norm=norm))] # pylint:disable=not-callable\n\n        # multidimensional fft for each parameter\n        return [torch.view_as_real(torch.fft.rfftn(t, norm=norm)) if t.numel() &gt; 1 else t for t in tensors] # pylint:disable=not-callable\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        settings = settings[0]\n        one_d = settings['one_d']\n        norm = settings['norm']\n\n        if one_d:\n            vec = torch.view_as_complex(projected_tensors[0])\n            unprojected_vec = torch.fft.irfft(vec, n=self.global_state['length'], norm=norm) # pylint:disable=not-callable\n            return vec_to_tensors(unprojected_vec, reference=params)\n\n        return [torch.fft.irfftn(torch.view_as_complex(t.contiguous()), s=p.shape, norm=norm) if t.numel() &gt; 1 else t for t, p in zip(projected_tensors, params)] # pylint:disable=not-callable\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.GradMin","title":"GradMin","text":"<p>               Bases: <code>torchzero.core.reformulation.Reformulation</code></p> <p>Reformulates the objective to minimize sum of gradient magnitudes via autograd. This is not expected to be practical.</p> <p>Parameters:</p> <ul> <li> <code>loss_term</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>adds loss value times this to sum of gradient magnitudes. Defaults to 1.</p> </li> <li> <code>relative</code>               (<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>whether to make loss_term relative to gradient magnitude. Defaults to False.</p> </li> <li> <code>graft</code>               (<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>whether to make loss term same as gradient magnitude. Defaults to False.</p> </li> <li> <code>square</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use sum of squared gradient magnitudes, if False uses absolute values. Defaults to False.</p> </li> <li> <code>mean</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use mean, if False uses sum. Defaults to True.</p> </li> <li> <code>maximize_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maximize gradient magnitudes instead of minimizing. Defaults to False.</p> </li> <li> <code>create_graph</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to create graph. Defaults to False.</p> </li> <li> <code>modify_loss</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to modify the loss value to make line searches minimize new objective. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/experimental/gradmin.py</code> <pre><code>class GradMin(Reformulation):\n    \"\"\"Reformulates the objective to minimize sum of gradient magnitudes via autograd. This is not expected to be practical.\n\n    Args:\n        loss_term (float, optional): adds loss value times this to sum of gradient magnitudes. Defaults to 1.\n        relative (bool, optional): whether to make loss_term relative to gradient magnitude. Defaults to False.\n        graft (bool, optional): whether to make loss term same as gradient magnitude. Defaults to False.\n        square (bool, optional): whether to use sum of squared gradient magnitudes, if False uses absolute values. Defaults to False.\n        mean (bool, optional): whether to use mean, if False uses sum. Defaults to True.\n        maximize_grad (bool, optional): whether to maximize gradient magnitudes instead of minimizing. Defaults to False.\n        create_graph (bool, optional): whether to create graph. Defaults to False.\n        modify_loss (bool, optional): whether to modify the loss value to make line searches minimize new objective. Defaults to True.\n    \"\"\"\n    def __init__(\n        self,\n        modules: Chainable,\n        loss_term: float | None = 0,\n        relative: Literal['loss_to_grad', 'grad_to_loss'] | None = None,\n        graft: Literal['loss_to_grad', 'grad_to_loss'] | None = None,\n        square=False,\n        mean=True,\n        maximize_grad=False,\n        create_graph=False,\n        modify_loss: bool = True,\n    ):\n        if (relative is not None) and (graft is not None): warnings.warn('both relative and graft loss are True, they will clash with each other')\n        defaults = dict(loss_term=loss_term, relative=relative, graft=graft, square=square, mean=mean, maximize_grad=maximize_grad, create_graph=create_graph, modify_loss=modify_loss)\n        super().__init__(defaults, modules=modules)\n\n    @torch.no_grad\n    def closure(self, backward, closure, params, objective):\n        settings = self.settings[params[0]]\n        loss_term = settings['loss_term']\n        relative = settings['relative']\n        graft = settings['graft']\n        square = settings['square']\n        maximize_grad = settings['maximize_grad']\n        create_graph = settings['create_graph']\n        modify_loss = settings['modify_loss']\n        mean = settings['mean']\n\n        with torch.enable_grad():\n            for p in params: p.grad = None\n            loss = closure(False)\n            grads = TensorList(torch.autograd.grad(loss, params, create_graph=True))\n\n            if square: grads = grads ** 2\n            else: grads = grads.abs()\n\n            if mean: f = grads.global_mean()\n            else: f = grads.global_sum()\n\n\n            if graft == 'grad_to_loss': f = f * (loss.detach()/f.detach()).detach()\n            if relative == 'grad_to_loss': f = f * loss\n\n            if loss_term is not None and loss_term != 0:\n                if relative == 'loss_to_grad': loss_term = loss_term * f\n                l = loss\n                if graft == 'loss_to_grad': l = loss * (f.detach()/loss.detach()).detach()\n                f = f + l*loss_term\n\n            if maximize_grad: f = -f\n            if modify_loss: loss = f\n\n            grad = None\n            if backward:\n                for p in params: p.grad = None\n                grad = TensorList(torch.autograd.grad(f, params, create_graph=create_graph))\n\n        return loss, grad\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.HigherOrderNewton","title":"HigherOrderNewton","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>A basic arbitrary order newton's method with optional trust region and proximal penalty.</p> <p>This constructs an nth order taylor approximation via autograd and minimizes it with <code>scipy.optimize.minimize</code> trust region newton solvers with optional proximal penalty.</p> <p>The hessian of taylor approximation is easier to evaluate, plus it can be evaluated in a batched mode, so it can be more efficient in very specific instances.</p> Notes <ul> <li>In most cases HigherOrderNewton should be the first module in the chain because it relies on extra autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</li> <li>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating higher order derivatives. The closure must accept a <code>backward</code> argument (refer to documentation).</li> <li>this uses roughly O(N^order) memory and solving the subproblem is very expensive.</li> <li>\"none\" and \"proximal\" trust methods may generate subproblems that have no minima, causing divergence.</li> </ul> <p>Args:</p> <pre><code>order (int, optional):\n    Order of the method, number of taylor series terms (orders of derivatives) used to approximate the function. Defaults to 4.\ntrust_method (str | None, optional):\n    Method used for trust region.\n    - \"bounds\" - the model is minimized within bounds defined by trust region.\n    - \"proximal\" - the model is minimized with penalty for going too far from current point.\n    - \"none\" - disables trust region.\n\n    Defaults to 'bounds'.\nincrease (float, optional): trust region multiplier on good steps. Defaults to 1.5.\ndecrease (float, optional): trust region multiplier on bad steps. Defaults to 0.75.\ntrust_init (float | None, optional):\n    initial trust region size. If none, defaults to 1 on :code:`trust_method=\"bounds\"` and 0.1 on ``\"proximal\"``. Defaults to None.\ntrust_tol (float, optional):\n    Maximum ratio of expected loss reduction to actual reduction for trust region increase.\n    Should 1 or higer. Defaults to 2.\nde_iters (int | None, optional):\n    If this is specified, the model is minimized via differential evolution first to possibly escape local minima,\n    then it is passed to scipy.optimize.minimize. Defaults to None.\nvectorize (bool, optional): whether to enable vectorized jacobians (usually faster). Defaults to True.\n</code></pre> Source code in <code>torchzero/modules/experimental/higher_order_newton.py</code> <pre><code>class HigherOrderNewton(Module):\n    \"\"\"A basic arbitrary order newton's method with optional trust region and proximal penalty.\n\n    This constructs an nth order taylor approximation via autograd and minimizes it with\n    ``scipy.optimize.minimize`` trust region newton solvers with optional proximal penalty.\n\n    The hessian of taylor approximation is easier to evaluate, plus it can be evaluated in a batched mode,\n    so it can be more efficient in very specific instances.\n\n    Notes:\n        - In most cases HigherOrderNewton should be the first module in the chain because it relies on extra autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n        - This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating higher order derivatives. The closure must accept a ``backward`` argument (refer to documentation).\n        - this uses roughly O(N^order) memory and solving the subproblem is very expensive.\n        - \"none\" and \"proximal\" trust methods may generate subproblems that have no minima, causing divergence.\n\n    Args:\n\n        order (int, optional):\n            Order of the method, number of taylor series terms (orders of derivatives) used to approximate the function. Defaults to 4.\n        trust_method (str | None, optional):\n            Method used for trust region.\n            - \"bounds\" - the model is minimized within bounds defined by trust region.\n            - \"proximal\" - the model is minimized with penalty for going too far from current point.\n            - \"none\" - disables trust region.\n\n            Defaults to 'bounds'.\n        increase (float, optional): trust region multiplier on good steps. Defaults to 1.5.\n        decrease (float, optional): trust region multiplier on bad steps. Defaults to 0.75.\n        trust_init (float | None, optional):\n            initial trust region size. If none, defaults to 1 on :code:`trust_method=\"bounds\"` and 0.1 on ``\"proximal\"``. Defaults to None.\n        trust_tol (float, optional):\n            Maximum ratio of expected loss reduction to actual reduction for trust region increase.\n            Should 1 or higer. Defaults to 2.\n        de_iters (int | None, optional):\n            If this is specified, the model is minimized via differential evolution first to possibly escape local minima,\n            then it is passed to scipy.optimize.minimize. Defaults to None.\n        vectorize (bool, optional): whether to enable vectorized jacobians (usually faster). Defaults to True.\n    \"\"\"\n    def __init__(\n        self,\n        order: int = 4,\n        trust_method: Literal['bounds', 'proximal', 'none'] | None = 'bounds',\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        init: float | None = None,\n        eta: float = 1e-6,\n        max_attempts = 10,\n        boundary_tol: float = 1e-2,\n        de_iters: int | None = None,\n        derivatives_method: DerivativesMethod = \"batched_autograd\",\n    ):\n        if init is None:\n            if trust_method == 'bounds': init = 1\n            else: init = 0.1\n\n        defaults = dict(order=order, trust_method=trust_method, nplus=nplus, nminus=nminus, eta=eta, init=init, de_iters=de_iters, max_attempts=max_attempts, boundary_tol=boundary_tol, rho_good=rho_good, rho_bad=rho_bad, derivatives_method=derivatives_method)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        params = TensorList(objective.params)\n        closure = objective.closure\n        if closure is None: raise RuntimeError('HigherOrderNewton requires closure')\n\n        settings = self.defaults\n        order = settings['order']\n        nplus = settings['nplus']\n        nminus = settings['nminus']\n        eta = settings['eta']\n        init = settings['init']\n        trust_method = settings['trust_method']\n        de_iters = settings['de_iters']\n        max_attempts = settings['max_attempts']\n        boundary_tol = settings['boundary_tol']\n        rho_good = settings['rho_good']\n        rho_bad = settings['rho_bad']\n\n        # ------------------------ calculate grad and hessian ------------------------ #\n        loss, *derivatives = objective.derivatives(order=order, at_x0=True, method=self.defaults[\"derivatives_method\"])\n\n        x0 = torch.cat([p.ravel() for p in params])\n\n        success = False\n        x_star = None\n        while not success:\n            max_attempts -= 1\n            if max_attempts &lt; 0: break\n\n            # load trust region value\n            trust_value = self.global_state.get('trust_region', init)\n\n            # make sure its not too small or too large\n            finfo = torch.finfo(x0.dtype)\n            if trust_value &lt; finfo.tiny*2 or trust_value &gt; finfo.max / (2*nplus):\n                trust_value = self.global_state['trust_region'] = settings['init']\n\n            # determine tr and prox values\n            if trust_method is None: trust_method = 'none'\n            else: trust_method = trust_method.lower()\n\n            if trust_method == 'none':\n                trust_region = None\n                prox = 0\n\n            elif trust_method == 'bounds':\n                trust_region = trust_value\n                prox = 0\n\n            elif trust_method == 'proximal':\n                trust_region = None\n                prox = 1 / trust_value\n\n            else:\n                raise ValueError(trust_method)\n\n            # minimize the model\n            x_star, expected_loss = _poly_minimize(\n                trust_region=trust_region,\n                prox=prox,\n                de_iters=de_iters,\n                c=loss.item(),\n                x=x0,\n                derivatives=derivatives,\n            )\n\n            # update trust region\n            if trust_method == 'none':\n                success = True\n            else:\n                pred_reduction = loss - expected_loss\n\n                vec_to_tensors_(x_star, params)\n                loss_star = closure(False)\n                vec_to_tensors_(x0, params)\n                reduction = loss - loss_star\n\n                rho = reduction / (max(pred_reduction, finfo.tiny * 2)) # pyright:ignore[reportArgumentType]\n\n                # failed step\n                if rho &lt; rho_bad:\n                    self.global_state['trust_region'] = trust_value * nminus\n\n                # very good step\n                elif rho &gt; rho_good:\n                    step = (x_star - x0)\n                    magn = torch.linalg.vector_norm(step) # pylint:disable=not-callable\n                    if trust_method == 'proximal' or (trust_value - magn) / trust_value &lt;= boundary_tol:\n                        # close to boundary\n                        self.global_state['trust_region'] = trust_value * nplus\n\n                # if the ratio is high enough then accept the proposed step\n                success = rho &gt; eta\n\n        assert x_star is not None\n        if success:\n            difference = vec_to_tensors(x0 - x_star, params)\n            objective.updates = list(difference)\n        else:\n            objective.updates = params.zeros_like()\n\n        return objective\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.InfinityNormTrustRegion","title":"InfinityNormTrustRegion","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Trust region with L-infinity norm via <code>scipy.optimize.lsq_linear</code>.</p> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When :code:<code>hess_module</code> is GaussNewton, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>boundary_tol</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The trust region only increases when suggested step's norm is at least <code>(1-boundary_tol)*trust_region</code>. This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.</p> </li> <li> <code>tol</code>               (<code>float | None</code>, default:                   <code>1e-10</code> )           \u2013            <p>tolerance for least squares solver.</p> </li> <li> <code>fallback</code>               (<code>bool</code>)           \u2013            <p>if <code>True</code>, when <code>hess_module</code> maintains hessian inverse which can't be inverted efficiently, it will be inverted anyway. When <code>False</code> (default), a <code>RuntimeError</code> will be raised instead.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul> <p>Examples:</p> <p>BFGS with infinity-norm trust region</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.InfinityNormTrustRegion(hess_module=tz.m.BFGS(inverse=False)),\n)\n</code></pre> Source code in <code>torchzero/modules/experimental/l_infinity.py</code> <pre><code>class InfinityNormTrustRegion(TrustRegionBase):\n    \"\"\"Trust region with L-infinity norm via ``scipy.optimize.lsq_linear``.\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set `inverse=False` when constructing them.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When :code:`hess_module` is GaussNewton, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        boundary_tol (float | None, optional):\n            The trust region only increases when suggested step's norm is at least `(1-boundary_tol)*trust_region`.\n            This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.\n        tol (float | None, optional): tolerance for least squares solver.\n        fallback (bool, optional):\n            if ``True``, when ``hess_module`` maintains hessian inverse which can't be inverted efficiently, it will\n            be inverted anyway. When ``False`` (default), a ``RuntimeError`` will be raised instead.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n    Examples:\n        BFGS with infinity-norm trust region\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.InfinityNormTrustRegion(hess_module=tz.m.BFGS(inverse=False)),\n            )\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Module,\n        prefer_dense:bool=True,\n        tol: float = 1e-10,\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        boundary_tol: float | None = None,\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(tol=tol, prefer_dense=prefer_dense)\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            boundary_tol=boundary_tol,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            radius_fn=torch.amax,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        if settings['prefer_dense'] and H.is_dense():\n            # convert to array if possible to avoid many conversions\n            # between torch and numpy, plus it seems that it uses\n            # a better solver\n            A = H.to_tensor().numpy(force=True).astype(np.float64)\n        else:\n            # memory efficient linear operator (is this still faster on CUDA?)\n            A = H.scipy_linop()\n\n        try:\n            d_np = lsq_linear(\n                A,\n                g.numpy(force=True).astype(np.float64),\n                tol=settings['bounds'],\n                bounds=(-radius, radius),\n            ).x\n            return torch.as_tensor(d_np, device=g.device, dtype=g.dtype)\n\n        except np.linalg.LinAlgError:\n            self.children['hess_module'].reset()\n            g_max = g.amax()\n            if g_max &gt; radius:\n                g = g * (radius / g_max)\n            return g\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.NewtonNewton","title":"NewtonNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Applies Newton-like preconditioning to Newton step.</p> <p>This is a method that I thought of and then it worked. Here is how it works:</p> <ol> <li> <p>Calculate newton step by solving Hx=g</p> </li> <li> <p>Calculate jacobian of x wrt parameters and call it H2</p> </li> <li> <p>Solve H2 x2 = x for x2.</p> </li> <li> <p>Optionally, repeat (if order is higher than 3.)</p> </li> </ol> Source code in <code>torchzero/modules/experimental/newtonnewton.py</code> <pre><code>class NewtonNewton(Transform):\n    \"\"\"Applies Newton-like preconditioning to Newton step.\n\n    This is a method that I thought of and then it worked. Here is how it works:\n\n    1. Calculate newton step by solving Hx=g\n\n    2. Calculate jacobian of x wrt parameters and call it H2\n\n    3. Solve H2 x2 = x for x2.\n\n    4. Optionally, repeat (if order is higher than 3.)\n    \"\"\"\n    def __init__(\n        self,\n        reg: float = 1e-6,\n        order: int = 3,\n        vectorize: bool = True,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(order=order, reg=reg, vectorize=vectorize)\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        params = TensorList(objective.params)\n        closure = objective.closure\n        if closure is None: raise RuntimeError('NewtonNewton requires closure')\n\n        reg = fs['reg']\n        vectorize = fs['vectorize']\n        order = fs['order']\n\n        # ------------------------ calculate grad and hessian ------------------------ #\n        P = None\n        with torch.enable_grad():\n            loss = objective.loss = objective.loss_approx = closure(False)\n            g_list = torch.autograd.grad(loss, params, create_graph=True)\n            objective.grads = list(g_list)\n\n            xp = torch.cat([t.ravel() for t in g_list])\n            I = torch.eye(xp.numel(), dtype=xp.dtype, device=xp.device)\n\n            for o in range(2, order + 1):\n                is_last = o == order\n                H_list = jacobian_wrt([xp], params, create_graph=not is_last, batched=vectorize)\n                with torch.no_grad() if is_last else nullcontext():\n                    H = flatten_jacobian(H_list)\n                    if reg != 0: H = H + I * reg\n                    if P is None: P = H\n                    else: P = P @ H\n\n                    if not is_last:\n                        x = _try_cholesky_solve(H, xp)\n                        if x is None: x = _try_lu_solve(H, xp)\n                        if x is None: x = _least_squares_solve(H, xp)\n                        xp = x.squeeze()\n\n        self.global_state[\"P\"] = P\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n        P = self.global_state['P']\n        b = torch.cat([t.ravel() for t in updates])\n\n        sol = _try_cholesky_solve(P, b)\n        if sol is None: sol = _try_lu_solve(P, b)\n        if sol is None: sol = _least_squares_solve(P, b)\n\n        vec_to_tensors_(sol, updates)\n        return objective\n\n    @torch.no_grad\n    def get_H(self, objective=...):\n        return Dense(self.global_state[\"P\"])\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.NewtonSolver","title":"NewtonSolver","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Matrix free newton via with any custom solver (this is for testing, use NewtonCG or NystromPCG).</p> Source code in <code>torchzero/modules/experimental/newton_solver.py</code> <pre><code>class NewtonSolver(Module):\n    \"\"\"Matrix free newton via with any custom solver (this is for testing, use NewtonCG or NystromPCG).\"\"\"\n    def __init__(\n        self,\n        solver: Callable[[list[torch.Tensor]], Any] = lambda p: Optimizer(p, LBFGS()),\n        maxiter=None,\n        maxiter1=None,\n        tol:float | None=1e-3,\n        reg: float = 0,\n        warm_start=True,\n        hvp_method: HVPMethod = \"autograd\",\n        reset_solver: bool = False,\n        h: float= 1e-3,\n\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults)\n\n        self.set_child(\"inner\", inner)\n\n        self._num_hvps = 0\n        self._num_hvps_last_step = 0\n\n    @torch.no_grad\n    def apply(self, objective):\n\n        params = TensorList(objective.params)\n        closure = objective.closure\n        if closure is None: raise RuntimeError('NewtonCG requires closure')\n\n        settings = self.settings[params[0]]\n        solver_cls = settings['solver']\n        maxiter = settings['maxiter']\n        maxiter1 = settings['maxiter1']\n        tol = settings['tol']\n        hvp_method = settings['hvp_method']\n        warm_start = settings['warm_start']\n        h = settings['h']\n        reset_solver = settings['reset_solver']\n\n        self._num_hvps_last_step = 0\n\n        # ---------------------- Hessian vector product function --------------------- #\n        _, H_mv = objective.list_Hvp_function(hvp_method=hvp_method, h=h, at_x0=True)\n\n        # -------------------------------- inner step -------------------------------- #\n        objective = self.inner_step(\"inner\", objective, must_exist=False)\n        b = TensorList(objective.get_updates())\n\n        # ---------------------------------- run cg ---------------------------------- #\n        x0 = None\n        if warm_start: x0 = self.get_state(params, 'prev_x', cls=TensorList) # initialized to 0 which is default anyway\n        if x0 is None: x = b.zeros_like().requires_grad_(True)\n        else: x = x0.clone().requires_grad_(True)\n\n\n        if 'solver' not in self.global_state:\n            if maxiter1 is not None: maxiter = maxiter1\n            solver = self.global_state['solver'] = solver_cls(x)\n            self.global_state['x'] = x\n\n        else:\n            if reset_solver:\n                solver = self.global_state['solver'] = solver_cls(x)\n            else:\n                solver_params = self.global_state['x']\n                solver_params.set_(x)\n                x = solver_params\n                solver = self.global_state['solver']\n\n        def lstsq_closure(backward=True):\n            Hx = H_mv(x).detach()\n            # loss = (Hx-b).pow(2).global_mean()\n            # if backward:\n            #     solver.zero_grad()\n            #     loss.backward(inputs=x)\n\n            residual = Hx - b\n            loss = residual.pow(2).global_mean()\n            if backward:\n                with torch.no_grad():\n                    H_residual = H_mv(residual)\n                    n = residual.global_numel()\n                    x.set_grad_((2.0 / n) * H_residual)\n\n            return loss\n\n        if maxiter is None: maxiter = b.global_numel()\n        loss = None\n        initial_loss = lstsq_closure(False) if tol is not None else None # skip unnecessary closure if tol is None\n        if initial_loss is None or initial_loss &gt; torch.finfo(b[0].dtype).eps:\n            for i in range(maxiter):\n                loss = solver.step(lstsq_closure)\n                assert loss is not None\n                if initial_loss is not None and loss/initial_loss &lt; tol: break\n\n        # print(f'{loss = }')\n\n        if warm_start:\n            assert x0 is not None\n            x0.copy_(x)\n\n        objective.updates = x.detach()\n        self._num_hvps += self._num_hvps_last_step\n        return objective\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.ReduceOutwardLR","title":"ReduceOutwardLR","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>When update sign matches weight sign, the learning rate for that weight is multiplied by <code>mul</code>.</p> <p>This means updates that move weights towards zero have higher learning rates.</p> Warning <p>This sounded good but after testing turns out it sucks.</p> Source code in <code>torchzero/modules/experimental/reduce_outward_lr.py</code> <pre><code>class ReduceOutwardLR(TensorTransform):\n    \"\"\"When update sign matches weight sign, the learning rate for that weight is multiplied by `mul`.\n\n    This means updates that move weights towards zero have higher learning rates.\n\n    Warning:\n        This sounded good but after testing turns out it sucks.\n    \"\"\"\n    def __init__(self, mul = 0.5, use_grad=False, invert=False):\n        defaults = dict(mul=mul, use_grad=use_grad, invert=invert)\n        super().__init__(defaults, uses_grad=use_grad)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        params = TensorList(params)\n        tensors = TensorList(tensors)\n\n        mul = [s['mul'] for s in settings]\n        s = settings[0]\n        use_grad = self._uses_grad\n        invert = s['invert']\n\n        if use_grad: cur = grads\n        else: cur = tensors\n        assert cur is not None\n\n        # mask of weights where sign matches with update sign (minus ascent sign), multiplied by `mul`.\n        if invert: mask = (params * cur) &gt; 0\n        else: mask = (params * cur) &lt; 0\n\n        tensors.masked_set_(mask, tensors*mul)\n\n        return tensors\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.ScipyNewtonCG","title":"ScipyNewtonCG","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>NewtonCG with scipy solvers (any from scipy.sparse.linalg)</p> Source code in <code>torchzero/modules/experimental/scipy_newton_cg.py</code> <pre><code>class ScipyNewtonCG(Module):\n    \"\"\"NewtonCG with scipy solvers (any from scipy.sparse.linalg)\"\"\"\n    def __init__(\n        self,\n        solver = gcrotmk,\n        hvp_method: Literal[\"fd_forward\", \"fd_central\", \"autograd\"] = \"autograd\",\n        h: float = 1e-3,\n        warm_start=False,\n        inner: Chainable | None = None,\n        kwargs: dict | None = None,\n    ):\n        defaults = dict(hvp_method=hvp_method, solver=solver, h=h, warm_start=warm_start)\n        super().__init__(defaults,)\n\n        if inner is not None:\n            self.set_child('inner', inner)\n\n        self._num_hvps = 0\n        self._num_hvps_last_step = 0\n\n        if kwargs is None: kwargs = {}\n        self._kwargs = kwargs\n\n    @torch.no_grad\n    def apply(self, objective):\n        params = TensorList(objective.params)\n        closure = objective.closure\n        if closure is None: raise RuntimeError('NewtonCG requires closure')\n\n        fs = self.settings[params[0]]\n        hvp_method = fs['hvp_method']\n        solver = fs['solver']\n        h = fs['h']\n        warm_start = fs['warm_start']\n\n        self._num_hvps_last_step = 0\n        # ---------------------- Hessian vector product function --------------------- #\n        device = params[0].device; dtype=params[0].dtype\n        if hvp_method == 'autograd':\n            grad = objective.get_grads(create_graph=True)\n\n            def H_mm(x_np):\n                self._num_hvps_last_step += 1\n                x = vec_to_tensors(torch.as_tensor(x_np, device=device, dtype=dtype), grad)\n                with torch.enable_grad():\n                    Hvp = TensorList(torch.autograd.grad(grad, params, x, retain_graph=True))\n                return torch.cat([t.ravel() for t in Hvp]).numpy(force=True)\n\n        else:\n\n            with torch.enable_grad():\n                grad = objective.get_grads()\n\n            if hvp_method == 'forward':\n                def H_mm(x_np):\n                    self._num_hvps_last_step += 1\n                    x = vec_to_tensors(torch.as_tensor(x_np, device=device, dtype=dtype), grad)\n                    Hvp = TensorList(hvp_fd_forward(closure, params, x, h=h, g_0=grad)[1])\n                    return torch.cat([t.ravel() for t in Hvp]).numpy(force=True)\n\n            elif hvp_method == 'central':\n                def H_mm(x_np):\n                    self._num_hvps_last_step += 1\n                    x = vec_to_tensors(torch.as_tensor(x_np, device=device, dtype=dtype), grad)\n                    Hvp = TensorList(hvp_fd_central(closure, params, x, h=h)[1])\n                    return torch.cat([t.ravel() for t in Hvp]).numpy(force=True)\n\n            else:\n                raise ValueError(hvp_method)\n\n        ndim = sum(p.numel() for p in params)\n        H = LinearOperator(shape=(ndim,ndim), matvec=H_mm, rmatvec=H_mm) # type:ignore\n\n        # -------------------------------- inner step -------------------------------- #\n        objective = self.inner_step(\"inner\", objective, must_exist=False)\n        b = TensorList(objective.get_updates())\n\n        # ---------------------------------- run cg ---------------------------------- #\n        x0 = None\n        if warm_start: x0 = self.global_state.get('x_prev', None) # initialized to 0 which is default anyway\n\n        x_np = solver(H, b.to_vec().nan_to_num().numpy(force=True), x0=x0, **self._kwargs)\n        if isinstance(x_np, tuple): x_np = x_np[0]\n\n        if warm_start:\n            self.global_state['x_prev'] = x_np\n\n        objective.updates = vec_to_tensors(torch.as_tensor(x_np, device=device, dtype=dtype), params)\n\n        self._num_hvps += self._num_hvps_last_step\n        return objective\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.SubspaceCubicAdam","title":"SubspaceCubicAdam","text":"<p>               Bases: <code>torchzero.modules.adaptive.lre_optimizers.LREOptimizerBase</code></p> <p>Runs cubic Adam in low rank eigenbasis.</p> Source code in <code>torchzero/modules/experimental/cubic_adam.py</code> <pre><code>class SubspaceCubicAdam(LREOptimizerBase):\n    \"\"\"Runs cubic Adam in low rank eigenbasis.\"\"\"\n    def __init__(self, beta1=0.9, beta2=0.95, beta3=0.95, eps=1e-8, mode: _cubic_adam_mode = 'signed_cbrt', cautious:bool=False, exact_reproject:bool=True):\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.beta3 = beta3\n        self.eps = eps\n        self.cautious = cautious\n        self.mode: _cubic_adam_mode = mode\n        self.exact_reproject = exact_reproject\n\n    def step(self, g, L, Q, state):\n        g = Q.T @ g\n\n        if \"exp_avg\" not in state:\n            state[\"exp_avg\"] = torch.zeros_like(g)\n            state[\"exp_avg_sq\"] = torch.zeros_like(g)\n            state[\"exp_avg_cu\"] = torch.zeros_like(g)\n            state[\"current_step\"] = 1\n\n        dir = cubic_adam_(\n            tensors = TensorList([g]),\n            exp_avg_ = TensorList([state[\"exp_avg\"]]),\n            exp_avg_sq_ = TensorList([state[\"exp_avg_sq\"]]),\n            exp_avg_cu_ = TensorList([state[\"exp_avg_cu\"]]),\n            alpha = 1,\n            beta1 = self.beta1,\n            beta2 = self.beta2,\n            beta3 = self.beta3,\n            eps = self.eps,\n            debiased = True,\n            step = state[\"current_step\"],\n\n            mode=self.mode,\n        )[0]\n\n        state[\"current_step\"] += 1\n        return Q @ dir\n\n    def reproject(self, L_old, Q_old, L_new, Q_new, state):\n        if  \"exp_avg\" not in state: return\n\n        C = Q_new.T @ Q_old\n\n        state[\"exp_avg\"] = C @ state[\"exp_avg\"]\n        state[\"exp_avg_sq\"] = _squared_reproject(C, state[\"exp_avg_sq\"], exact=self.exact_reproject)\n        state[\"exp_avg_cu\"] = C.pow(3) @ state[\"exp_avg_cu\"] # exact reproject with 1_000_000 is feasible\n</code></pre>"},{"location":"API/modules/experimental/#torchzero.modules.experimental.TensorizeProjection","title":"TensorizeProjection","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>flattens and concatenates all parameters into a vector and then reshapes it into a tensor</p> Source code in <code>torchzero/modules/experimental/structural_projections.py</code> <pre><code>class TensorizeProjection(ProjectionBase):\n    \"\"\"flattens and concatenates all parameters into a vector and then reshapes it into a tensor\"\"\"\n    def __init__(self, modules: Chainable, max_side: int, project_update=True, project_params=False, project_grad=False):\n        defaults = dict(max_side=max_side)\n        super().__init__(modules, defaults=defaults, project_update=project_update, project_params=project_params, project_grad=project_grad)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        max_side = self.settings[params[0]]['max_side']\n        num_elems = sum(t.numel() for t in tensors)\n\n        if num_elems &lt; max_side:\n            self.global_state['remainder'] = 0\n            # return 1d\n            return [torch.cat([t.view(-1) for t in tensors])]\n\n\n        # determine appropriate shape to reshape into\n        ndims = math.ceil(math.log(num_elems, max_side)) # determine number of dims\n        dim_size = math.ceil(num_elems ** (1/ndims)) # average size of a dim with ndims\n        dims = [dim_size for _ in range(ndims)]\n        required_elems = math.prod(dims)\n\n        # add few extra zeros to vec to match a reshapable size\n        remainder = required_elems-num_elems\n        if remainder &gt; 0: tensors = tensors + [torch.zeros(remainder, dtype=tensors[0].dtype, device=tensors[0].device)]\n        self.global_state['remainder'] = remainder\n\n        # flatten and reshape\n        vec = torch.cat([t.view(-1) for t in tensors])\n        return [vec.view(dims)]\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        remainder = self.global_state['remainder']\n        # warnings.warn(f'{tensors[0].shape = }')\n        vec = projected_tensors[0].view(-1)\n        if remainder &gt; 0: vec = vec[:-remainder]\n        return vec_to_tensors(vec, params)\n</code></pre>"},{"location":"API/modules/grad_approximation/","title":"Gradient approximations","text":"<p>This subpackage contains modules that estimate the gradient using function values.</p> <p>Classes:</p> <ul> <li> <code>FDM</code>           \u2013            <p>Approximate gradients via finite difference method.</p> </li> <li> <code>ForwardGradient</code>           \u2013            <p>Forward gradient method.</p> </li> <li> <code>GaussianSmoothing</code>           \u2013            <p>Gradient approximation via Gaussian smoothing method.</p> </li> <li> <code>GradApproximator</code>           \u2013            <p>Base class for gradient approximations.</p> </li> <li> <code>MeZO</code>           \u2013            <p>Gradient approximation via memory-efficient zeroth order optimizer (MeZO) - https://arxiv.org/abs/2305.17333.</p> </li> <li> <code>RDSA</code>           \u2013            <p>Gradient approximation via Random-direction stochastic approximation (RDSA) method.</p> </li> <li> <code>RandomizedFDM</code>           \u2013            <p>Gradient approximation via a randomized finite-difference method.</p> </li> <li> <code>SPSA</code>           \u2013            <p>Gradient approximation via Simultaneous perturbation stochastic approximation (SPSA) method.</p> </li> <li> <code>SPSA1</code>           \u2013            <p>One-measurement variant of SPSA. Unlike standard two-measurement SPSA, the estimated</p> </li> </ul>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.FDM","title":"FDM","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>Approximate gradients via finite difference method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>magnitude of parameter perturbation. Defaults to 1e-3.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to 'closure'.</p> </li> </ul> <p>Examples: plain FDM:</p> <pre><code>fdm = tz.Optimizer(model.parameters(), tz.m.FDM(), tz.m.LR(1e-2))\n</code></pre> <p>Any gradient-based method can use FDM-estimated gradients. <pre><code>fdm_ncg = tz.Optimizer(\n    model.parameters(),\n    tz.m.FDM(),\n    # set hvp_method to \"forward\" so that it\n    # uses gradient difference instead of autograd\n    tz.m.NewtonCG(hvp_method=\"forward\"),\n    tz.m.Backtracking()\n)\n</code></pre></p> Source code in <code>torchzero/modules/grad_approximation/fdm.py</code> <pre><code>class FDM(GradApproximator):\n    \"\"\"Approximate gradients via finite difference method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): magnitude of parameter perturbation. Defaults to 1e-3.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        target (GradTarget, optional): what to set on var. Defaults to 'closure'.\n\n    Examples:\n    plain FDM:\n\n    ```python\n    fdm = tz.Optimizer(model.parameters(), tz.m.FDM(), tz.m.LR(1e-2))\n    ```\n\n    Any gradient-based method can use FDM-estimated gradients.\n    ```python\n    fdm_ncg = tz.Optimizer(\n        model.parameters(),\n        tz.m.FDM(),\n        # set hvp_method to \"forward\" so that it\n        # uses gradient difference instead of autograd\n        tz.m.NewtonCG(hvp_method=\"forward\"),\n        tz.m.Backtracking()\n    )\n    ```\n    \"\"\"\n    def __init__(self, h: float=1e-3, formula: _FD_Formula = 'central', target: GradTarget = 'closure'):\n        defaults = dict(h=h, formula=formula)\n        super().__init__(defaults, target=target)\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        grads = []\n        loss_approx = None\n\n        for p in params:\n            g = torch.zeros_like(p)\n            grads.append(g)\n\n            settings = self.settings[p]\n            h = settings['h']\n            fd_fn = _FD_FUNCS[settings['formula']]\n\n            p_flat = p.ravel(); g_flat = g.ravel()\n            for i in range(len(p_flat)):\n                loss, loss_approx, d = fd_fn(closure=closure, param=p_flat, idx=i, h=h, v_0=loss)\n                g_flat[i] = d\n\n        return grads, loss, loss_approx\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.ForwardGradient","title":"ForwardGradient","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Forward gradient method.</p> <p>This method samples one or more directional derivatives evaluated via autograd jacobian-vector products. This is very similar to randomized finite difference.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution for random gradient samples. Defaults to \"gaussian\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>jvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>how to calculate jacobian vector product, note that with <code>forward</code> and 'central' this is equivalent to randomized finite difference. Defaults to 'autograd'.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Baydin, A. G., Pearlmutter, B. A., Syme, D., Wood, F., &amp; Torr, P. (2022). Gradients without backpropagation. arXiv preprint arXiv:2202.08587.</p> Source code in <code>torchzero/modules/grad_approximation/forward_gradient.py</code> <pre><code>class ForwardGradient(RandomizedFDM):\n    \"\"\"Forward gradient method.\n\n    This method samples one or more directional derivatives evaluated via autograd jacobian-vector products. This is very similar to randomized finite difference.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n\n    Args:\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        distribution (Distributions, optional): distribution for random gradient samples. Defaults to \"gaussian\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        jvp_method (str, optional):\n            how to calculate jacobian vector product, note that with `forward` and 'central' this is equivalent to randomized finite difference. Defaults to 'autograd'.\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Baydin, A. G., Pearlmutter, B. A., Syme, D., Wood, F., &amp; Torr, P. (2022). Gradients without backpropagation. arXiv preprint arXiv:2202.08587.\n    \"\"\"\n    PRE_MULTIPLY_BY_H = False\n    def __init__(\n        self,\n        n_samples: int = 1,\n        distribution: Distributions = \"gaussian\",\n        pre_generate = True,\n        jvp_method: Literal['autograd', 'forward', 'central'] = 'autograd',\n        h: float = 1e-3,\n        target: GradTarget = \"closure\",\n        seed: int | None | torch.Generator = None,\n    ):\n        super().__init__(h=h, n_samples=n_samples, distribution=distribution, target=target, pre_generate=pre_generate, seed=seed)\n        self.defaults['jvp_method'] = jvp_method\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        params = TensorList(params)\n        loss_approx = None\n\n        fs = self.settings[params[0]]\n        n_samples = fs['n_samples']\n        jvp_method = fs['jvp_method']\n        h = fs['h']\n        distribution = fs['distribution']\n        default = [None]*n_samples\n        perturbations = list(zip(*(self.state[p].get('perturbations', default) for p in params)))\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n        grad = None\n        for i in range(n_samples):\n            prt = perturbations[i]\n            if prt[0] is None:\n                prt = params.sample_like(distribution=distribution, variance=1, generator=generator)\n\n            else: prt = TensorList(prt)\n\n            if jvp_method == 'autograd':\n                with torch.enable_grad():\n                    loss, d = jvp(partial(closure, False), params=params, tangent=prt)\n\n            elif jvp_method == 'forward':\n                loss, d = jvp_fd_forward(partial(closure, False), params=params, tangent=prt, v_0=loss, h=h)\n\n            elif jvp_method == 'central':\n                loss_approx, d = jvp_fd_central(partial(closure, False), params=params, tangent=prt, h=h)\n\n            else: raise ValueError(jvp_method)\n\n            if grad is None: grad = prt * d\n            else: grad += prt * d\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.ForwardGradient.PRE_MULTIPLY_BY_H","title":"PRE_MULTIPLY_BY_H  <code>class-attribute</code>","text":"<pre><code>PRE_MULTIPLY_BY_H = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.GaussianSmoothing","title":"GaussianSmoothing","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Gradient approximation via Gaussian smoothing method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-2.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of random gradient samples. Defaults to 100.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'forward2'</code> )           \u2013            <p>finite difference formula. Defaults to 'forward2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution. Defaults to \"gaussian\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Yurii Nesterov, Vladimir Spokoiny. (2015). Random Gradient-Free Minimization of Convex Functions. https://gwern.net/doc/math/2015-nesterov.pdf</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class GaussianSmoothing(RandomizedFDM):\n    \"\"\"\n    Gradient approximation via Gaussian smoothing method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-2.\n        n_samples (int, optional): number of random gradient samples. Defaults to 100.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'forward2'.\n        distribution (Distributions, optional): distribution. Defaults to \"gaussian\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n\n    References:\n        Yurii Nesterov, Vladimir Spokoiny. (2015). Random Gradient-Free Minimization of Convex Functions. https://gwern.net/doc/math/2015-nesterov.pdf\n    \"\"\"\n    def __init__(\n        self,\n        h: float = 1e-2,\n        n_samples: int = 100,\n        formula: _FD_Formula = \"forward2\",\n        distribution: Distributions = \"gaussian\",\n        pre_generate: bool = True,\n        return_approx_loss: bool = False,\n        target: GradTarget = \"closure\",\n        seed: int | None | torch.Generator = None,\n    ):\n        super().__init__(h=h, n_samples=n_samples,formula=formula,distribution=distribution,pre_generate=pre_generate,target=target,seed=seed, return_approx_loss=return_approx_loss)\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.GradApproximator","title":"GradApproximator","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for gradient approximations. This is an abstract class, to use it, subclass it and override <code>approximate</code>.</p> <p>GradientApproximator modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure.</p> <p>Parameters:</p> <ul> <li> <code>defaults</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>dict with defaults. Defaults to None.</p> </li> <li> <code>target</code>               (<code>str</code>, default:                   <code>'closure'</code> )           \u2013            <p>whether to set <code>var.grad</code>, <code>var.update</code> or 'var.closure`. Defaults to 'closure'.</p> </li> </ul> <p>Example:</p> <p>Basic SPSA method implementation. <pre><code>class SPSA(GradApproximator):\n    def __init__(self, h=1e-3):\n        defaults = dict(h=h)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        perturbation = [rademacher_like(p) * self.settings[p]['h'] for p in params]\n\n        # evaluate params + perturbation\n        torch._foreach_add_(params, perturbation)\n        loss_plus = closure(False)\n\n        # evaluate params - perturbation\n        torch._foreach_sub_(params, perturbation)\n        torch._foreach_sub_(params, perturbation)\n        loss_minus = closure(False)\n\n        # restore original params\n        torch._foreach_add_(params, perturbation)\n\n        # calculate SPSA gradients\n        spsa_grads = []\n        for p, pert in zip(params, perturbation):\n            settings = self.settings[p]\n            h = settings['h']\n            d = (loss_plus - loss_minus) / (2*(h**2))\n            spsa_grads.append(pert * d)\n\n        # returns tuple: (grads, loss, loss_approx)\n        # loss must be with initial parameters\n        # since we only evaluated loss with perturbed parameters\n        # we only have loss_approx\n        return spsa_grads, None, loss_plus\n</code></pre></p> <p>Methods:</p> <ul> <li> <code>approximate</code>             \u2013              <p>Returns a tuple: <code>(grad, loss, loss_approx)</code>, make sure this resets parameters to their original values!</p> </li> <li> <code>pre_step</code>             \u2013              <p>This runs once before each step, whereas <code>approximate</code> may run multiple times per step if further modules</p> </li> </ul> Source code in <code>torchzero/modules/grad_approximation/grad_approximator.py</code> <pre><code>class GradApproximator(Module, ABC):\n    \"\"\"Base class for gradient approximations.\n    This is an abstract class, to use it, subclass it and override `approximate`.\n\n    GradientApproximator modifies the closure to evaluate the estimated gradients,\n    and further closure-based modules will use the modified closure.\n\n    Args:\n        defaults (dict[str, Any] | None, optional): dict with defaults. Defaults to None.\n        target (str, optional):\n            whether to set `var.grad`, `var.update` or 'var.closure`. Defaults to 'closure'.\n\n    Example:\n\n    Basic SPSA method implementation.\n    ```python\n    class SPSA(GradApproximator):\n        def __init__(self, h=1e-3):\n            defaults = dict(h=h)\n            super().__init__(defaults)\n\n        @torch.no_grad\n        def approximate(self, closure, params, loss):\n            perturbation = [rademacher_like(p) * self.settings[p]['h'] for p in params]\n\n            # evaluate params + perturbation\n            torch._foreach_add_(params, perturbation)\n            loss_plus = closure(False)\n\n            # evaluate params - perturbation\n            torch._foreach_sub_(params, perturbation)\n            torch._foreach_sub_(params, perturbation)\n            loss_minus = closure(False)\n\n            # restore original params\n            torch._foreach_add_(params, perturbation)\n\n            # calculate SPSA gradients\n            spsa_grads = []\n            for p, pert in zip(params, perturbation):\n                settings = self.settings[p]\n                h = settings['h']\n                d = (loss_plus - loss_minus) / (2*(h**2))\n                spsa_grads.append(pert * d)\n\n            # returns tuple: (grads, loss, loss_approx)\n            # loss must be with initial parameters\n            # since we only evaluated loss with perturbed parameters\n            # we only have loss_approx\n            return spsa_grads, None, loss_plus\n    ```\n    \"\"\"\n    def __init__(self, defaults: dict[str, Any] | None = None, return_approx_loss:bool=False, target: GradTarget = 'closure'):\n        super().__init__(defaults)\n        self._target: GradTarget = target\n        self._return_approx_loss = return_approx_loss\n\n    @abstractmethod\n    def approximate(self, closure: Callable, params: list[torch.Tensor], loss: torch.Tensor | None) -&gt; tuple[Iterable[torch.Tensor], torch.Tensor | None, torch.Tensor | None]:\n        \"\"\"Returns a tuple: ``(grad, loss, loss_approx)``, make sure this resets parameters to their original values!\"\"\"\n\n    def pre_step(self, objective: Objective) -&gt; None:\n        \"\"\"This runs once before each step, whereas `approximate` may run multiple times per step if further modules\n        evaluate gradients at multiple points. This is useful for example to pre-generate new random perturbations.\"\"\"\n\n    @torch.no_grad\n    def update(self, objective):\n        self.pre_step(objective)\n\n        if objective.closure is None: raise RuntimeError(\"Gradient approximation requires closure\")\n        params, closure, loss = objective.params, objective.closure, objective.loss\n\n        if self._target == 'closure':\n\n            def approx_closure(backward=True):\n                if backward:\n                    # set loss to None because closure might be evaluated at different points\n                    grad, l, l_approx = self.approximate(closure=closure, params=params, loss=None)\n                    for p, g in zip(params, grad): p.grad = g\n                    if l is not None: return l\n                    if self._return_approx_loss and l_approx is not None: return l_approx\n                    return closure(False)\n\n                return closure(False)\n\n            objective.closure = approx_closure\n            return\n\n        # if var.grad is not None:\n        #     warnings.warn('Using grad approximator when `var.grad` is already set.')\n        grad, loss, loss_approx = self.approximate(closure=closure, params=params, loss=loss)\n        if loss_approx is not None: objective.loss_approx = loss_approx\n        if loss is not None: objective.loss = objective.loss_approx = loss\n        if self._target == 'grad': objective.grads = list(grad)\n        elif self._target == 'update': objective.updates = list(grad)\n        else: raise ValueError(self._target)\n        return\n\n    def apply(self, objective):\n        return objective\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.GradApproximator.approximate","title":"approximate","text":"<pre><code>approximate(closure: Callable, params: list[Tensor], loss: Tensor | None) -&gt; tuple[Iterable[Tensor], Tensor | None, Tensor | None]\n</code></pre> <p>Returns a tuple: <code>(grad, loss, loss_approx)</code>, make sure this resets parameters to their original values!</p> Source code in <code>torchzero/modules/grad_approximation/grad_approximator.py</code> <pre><code>@abstractmethod\ndef approximate(self, closure: Callable, params: list[torch.Tensor], loss: torch.Tensor | None) -&gt; tuple[Iterable[torch.Tensor], torch.Tensor | None, torch.Tensor | None]:\n    \"\"\"Returns a tuple: ``(grad, loss, loss_approx)``, make sure this resets parameters to their original values!\"\"\"\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.GradApproximator.pre_step","title":"pre_step","text":"<pre><code>pre_step(objective: Objective) -&gt; None\n</code></pre> <p>This runs once before each step, whereas <code>approximate</code> may run multiple times per step if further modules evaluate gradients at multiple points. This is useful for example to pre-generate new random perturbations.</p> Source code in <code>torchzero/modules/grad_approximation/grad_approximator.py</code> <pre><code>def pre_step(self, objective: Objective) -&gt; None:\n    \"\"\"This runs once before each step, whereas `approximate` may run multiple times per step if further modules\n    evaluate gradients at multiple points. This is useful for example to pre-generate new random perturbations.\"\"\"\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.MeZO","title":"MeZO","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>Gradient approximation via memory-efficient zeroth order optimizer (MeZO) - https://arxiv.org/abs/2305.17333.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central2'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'rademacher'</code> )           \u2013            <p>distribution. Defaults to \"rademacher\". If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Malladi, S., Gao, T., Nichani, E., Damian, A., Lee, J. D., Chen, D., &amp; Arora, S. (2023). Fine-tuning language models with just forward passes. Advances in Neural Information Processing Systems, 36, 53038-53075. https://arxiv.org/abs/2305.17333</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class MeZO(GradApproximator):\n    \"\"\"Gradient approximation via memory-efficient zeroth order optimizer (MeZO) - https://arxiv.org/abs/2305.17333.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"rademacher\".\n            If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Malladi, S., Gao, T., Nichani, E., Damian, A., Lee, J. D., Chen, D., &amp; Arora, S. (2023). Fine-tuning language models with just forward passes. Advances in Neural Information Processing Systems, 36, 53038-53075. https://arxiv.org/abs/2305.17333\n    \"\"\"\n\n    def __init__(self, h: float=1e-3, n_samples: int = 1, formula: _FD_Formula = 'central2',\n                 distribution: Distributions = 'rademacher', return_approx_loss: bool = False, target: GradTarget = 'closure'):\n\n        defaults = dict(h=h, formula=formula, n_samples=n_samples, distribution=distribution)\n        super().__init__(defaults, return_approx_loss=return_approx_loss, target=target)\n\n    def _seeded_perturbation(self, params: list[torch.Tensor], distribution, seed, h):\n        prt = TensorList(params).sample_like(\n            distribution=distribution,\n            variance=h,\n            generator=torch.Generator(params[0].device).manual_seed(seed)\n        )\n        return prt\n\n    def pre_step(self, objective):\n        h = NumberList(self.settings[p]['h'] for p in objective.params)\n\n        n_samples = self.defaults['n_samples']\n        distribution = self.defaults['distribution']\n\n        step = objective.current_step\n\n        # create functions that generate a deterministic perturbation from seed based on current step\n        prt_fns = []\n        for i in range(n_samples):\n\n            prt_fn = partial(self._seeded_perturbation, params=objective.params, distribution=distribution, seed=1_000_000*step + i, h=h)\n            prt_fns.append(prt_fn)\n\n        self.global_state['prt_fns'] = prt_fns\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        params = TensorList(params)\n        loss_approx = None\n\n        h = NumberList(self.settings[p]['h'] for p in params)\n        n_samples = self.defaults['n_samples']\n        fd_fn = _RFD_FUNCS[self.defaults['formula']]\n\n        prt_fns = self.global_state['prt_fns']\n\n        grad = None\n        for i in range(n_samples):\n            loss, loss_approx, d = fd_fn(closure=closure, params=params, p_fn=prt_fns[i], h=h, f_0=loss)\n            if grad is None: grad = prt_fns[i]().mul_(d)\n            else: grad += prt_fns[i]().mul_(d)\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.RDSA","title":"RDSA","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Gradient approximation via Random-direction stochastic approximation (RDSA) method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central2'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution. Defaults to \"gaussian\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class RDSA(RandomizedFDM):\n    \"\"\"\n    Gradient approximation via Random-direction stochastic approximation (RDSA) method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"gaussian\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771\n\n    \"\"\"\n    def __init__(\n        self,\n        h: float = 1e-3,\n        n_samples: int = 1,\n        formula: _FD_Formula = \"central2\",\n        distribution: Distributions = \"gaussian\",\n        pre_generate: bool = True,\n        return_approx_loss: bool = False,\n        target: GradTarget = \"closure\",\n        seed: int | None | torch.Generator = None,\n    ):\n        super().__init__(h=h, n_samples=n_samples,formula=formula,distribution=distribution,pre_generate=pre_generate,target=target,seed=seed, return_approx_loss=return_approx_loss)\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.RandomizedFDM","title":"RandomizedFDM","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>Gradient approximation via a randomized finite-difference method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'rademacher'</code> )           \u2013            <p>distribution. Defaults to \"rademacher\". If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> <p>Examples:</p>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.RandomizedFDM--simultaneous-perturbation-stochastic-approximation-spsa-method","title":"Simultaneous perturbation stochastic approximation (SPSA) method","text":"<p>SPSA is randomized FDM with rademacher distribution and central formula. <pre><code>spsa = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"rademacher\"),\n    tz.m.LR(1e-2)\n)\n</code></pre></p>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.RandomizedFDM--random-direction-stochastic-approximation-rdsa-method","title":"Random-direction stochastic approximation (RDSA) method","text":"<p>RDSA is randomized FDM with usually gaussian distribution and central formula. <pre><code>rdsa = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"gaussian\"),\n    tz.m.LR(1e-2)\n)\n</code></pre></p>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.RandomizedFDM--gaussian-smoothing-method","title":"Gaussian smoothing method","text":"<p>GS uses many gaussian samples with possibly a larger finite difference step size. <pre><code>gs = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(n_samples=100, distribution=\"gaussian\", formula=\"forward2\", h=1e-1),\n    tz.m.NewtonCG(hvp_method=\"forward\"),\n    tz.m.Backtracking()\n)\n</code></pre></p>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.RandomizedFDM--randomizedfdm-with-momentum","title":"RandomizedFDM with momentum","text":"<p>Momentum might help by reducing the variance of the estimated gradients. <pre><code>momentum_spsa = tz.Optimizer(\n    model.parameters(),\n    tz.m.RandomizedFDM(),\n    tz.m.HeavyBall(0.9),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class RandomizedFDM(GradApproximator):\n    \"\"\"Gradient approximation via a randomized finite-difference method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"rademacher\".\n            If this is set to a value higher than zero, instead of using directional derivatives in a new random direction on each step, the direction changes gradually with momentum based on this value. This may make it possible to use methods with memory. Defaults to 0.\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    Examples:\n    #### Simultaneous perturbation stochastic approximation (SPSA) method\n\n    SPSA is randomized FDM with rademacher distribution and central formula.\n    ```py\n    spsa = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"rademacher\"),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    #### Random-direction stochastic approximation (RDSA) method\n\n    RDSA is randomized FDM with usually gaussian distribution and central formula.\n    ```\n    rdsa = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(formula=\"fd_central\", distribution=\"gaussian\"),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    #### Gaussian smoothing method\n\n    GS uses many gaussian samples with possibly a larger finite difference step size.\n    ```\n    gs = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(n_samples=100, distribution=\"gaussian\", formula=\"forward2\", h=1e-1),\n        tz.m.NewtonCG(hvp_method=\"forward\"),\n        tz.m.Backtracking()\n    )\n    ```\n\n    #### RandomizedFDM with momentum\n\n    Momentum might help by reducing the variance of the estimated gradients.\n    ```\n    momentum_spsa = tz.Optimizer(\n        model.parameters(),\n        tz.m.RandomizedFDM(),\n        tz.m.HeavyBall(0.9),\n        tz.m.LR(1e-3)\n    )\n    ```\n    \"\"\"\n    PRE_MULTIPLY_BY_H = True\n    def __init__(\n        self,\n        h: float = 1e-3,\n        n_samples: int = 1,\n        formula: _FD_Formula = \"central\",\n        distribution: Distributions = \"rademacher\",\n        pre_generate: bool = True,\n        return_approx_loss: bool = False,\n        seed: int | None | torch.Generator = None,\n        target: GradTarget = \"closure\",\n    ):\n        defaults = dict(h=h, formula=formula, n_samples=n_samples, distribution=distribution, pre_generate=pre_generate, seed=seed)\n        super().__init__(defaults, return_approx_loss=return_approx_loss, target=target)\n\n\n    def pre_step(self, objective):\n        h = self.get_settings(objective.params, 'h')\n        pre_generate = self.defaults['pre_generate']\n\n        if pre_generate:\n            n_samples = self.defaults['n_samples']\n            distribution = self.defaults['distribution']\n\n            params = TensorList(objective.params)\n            generator = self.get_generator(params[0].device, self.defaults['seed'])\n            perturbations = [params.sample_like(distribution=distribution, variance=1, generator=generator) for _ in range(n_samples)]\n\n            # this is false for ForwardGradient where h isn't used and it subclasses this\n            if self.PRE_MULTIPLY_BY_H:\n                torch._foreach_mul_([p for l in perturbations for p in l], [v for vv in h for v in [vv]*n_samples])\n\n            for param, prt in zip(params, zip(*perturbations)):\n                self.state[param]['perturbations'] = prt\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        params = TensorList(params)\n        loss_approx = None\n\n        h = NumberList(self.settings[p]['h'] for p in params)\n        n_samples = self.defaults['n_samples']\n        distribution = self.defaults['distribution']\n        fd_fn = _RFD_FUNCS[self.defaults['formula']]\n\n        default = [None]*n_samples\n        perturbations = list(zip(*(self.state[p].get('perturbations', default) for p in params)))\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n        grad = None\n        for i in range(n_samples):\n            prt = perturbations[i]\n\n            if prt[0] is None:\n                prt = params.sample_like(distribution=distribution, generator=generator, variance=1).mul_(h)\n\n            else: prt = TensorList(prt)\n\n            loss, loss_approx, d = fd_fn(closure=closure, params=params, p_fn=lambda: prt, h=h, f_0=loss)\n            # here `d` is a numberlist of directional derivatives, due to per parameter `h` values.\n\n            # support for per-sample values which gives better estimate\n            if d[0].numel() &gt; 1: d = d.map(torch.mean)\n\n            if grad is None: grad = prt * d\n            else: grad += prt * d\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n\n        # mean if got per-sample values\n        if loss is not None:\n            if loss.numel() &gt; 1:\n                loss = loss.mean()\n\n        if loss_approx is not None:\n            if loss_approx.numel() &gt; 1:\n                loss_approx = loss_approx.mean()\n\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.RandomizedFDM.PRE_MULTIPLY_BY_H","title":"PRE_MULTIPLY_BY_H  <code>class-attribute</code>","text":"<pre><code>PRE_MULTIPLY_BY_H = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.SPSA","title":"SPSA","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.rfdm.RandomizedFDM</code></p> <p>Gradient approximation via Simultaneous perturbation stochastic approximation (SPSA) method.</p> Note <p>This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients, and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size of jvp_method is set to <code>forward</code> or <code>central</code>. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random gradient samples. Defaults to 1.</p> </li> <li> <code>formula</code>               (<code>Literal</code>, default:                   <code>'central'</code> )           \u2013            <p>finite difference formula. Defaults to 'central2'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'rademacher'</code> )           \u2013            <p>distribution. Defaults to \"rademacher\".</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random generator. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on var. Defaults to \"closure\".</p> </li> </ul> References <p>Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771</p> Source code in <code>torchzero/modules/grad_approximation/rfdm.py</code> <pre><code>class SPSA(RandomizedFDM):\n    \"\"\"\n    Gradient approximation via Simultaneous perturbation stochastic approximation (SPSA) method.\n\n    Note:\n        This module is a gradient approximator. It modifies the closure to evaluate the estimated gradients,\n        and further closure-based modules will use the modified closure. All modules after this will use estimated gradients.\n\n    Args:\n        h (float, optional): finite difference step size of jvp_method is set to `forward` or `central`. Defaults to 1e-3.\n        n_samples (int, optional): number of random gradient samples. Defaults to 1.\n        formula (_FD_Formula, optional): finite difference formula. Defaults to 'central2'.\n        distribution (Distributions, optional): distribution. Defaults to \"rademacher\".\n        pre_generate (bool, optional):\n            whether to pre-generate gradient samples before each step. If samples are not pre-generated, whenever a method performs multiple closure evaluations, the gradient will be evaluated in different directions each time. Defaults to True.\n        seed (int | None | torch.Generator, optional): Seed for random generator. Defaults to None.\n        target (GradTarget, optional): what to set on var. Defaults to \"closure\".\n\n    References:\n        Chen, Y. (2021). Theoretical study and comparison of SPSA and RDSA algorithms. arXiv preprint arXiv:2107.12771. https://arxiv.org/abs/2107.12771\n    \"\"\"\n</code></pre>"},{"location":"API/modules/grad_approximation/#torchzero.modules.grad_approximation.SPSA1","title":"SPSA1","text":"<p>               Bases: <code>torchzero.modules.grad_approximation.grad_approximator.GradApproximator</code></p> <p>One-measurement variant of SPSA. Unlike standard two-measurement SPSA, the estimated gradient often won't be a descent direction, however the expectation is biased towards the descent direction. Therefore this variant of SPSA is only recommended for a specific class of problems where the objective function changes on each evaluation, for example feedback control problems.</p> <p>Parameters:</p> <ul> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size, recommended to set to same value as learning rate. Defaults to 1e-3.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>number of random samples. Defaults to 1.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>measurement noise estimate. Defaults to 1e-8.</p> </li> <li> <code>seed</code>               (<code>int | None | Generator</code>, default:                   <code>None</code> )           \u2013            <p>random seed. Defaults to None.</p> </li> <li> <code>target</code>               (<code>Literal</code>, default:                   <code>'closure'</code> )           \u2013            <p>what to set on closure. Defaults to \"closure\".</p> </li> </ul> Reference <p>SPALL, JAMES C. \"A One-measurement Form of Simultaneous Stochastic Approximation.\"</p> Source code in <code>torchzero/modules/grad_approximation/spsa1.py</code> <pre><code>class SPSA1(GradApproximator):\n    \"\"\"One-measurement variant of SPSA. Unlike standard two-measurement SPSA, the estimated\n    gradient often won't be a descent direction, however the expectation is biased towards\n    the descent direction. Therefore this variant of SPSA is only recommended for a specific\n    class of problems where the objective function changes on each evaluation,\n    for example feedback control problems.\n\n    Args:\n        h (float, optional):\n            finite difference step size, recommended to set to same value as learning rate. Defaults to 1e-3.\n        n_samples (int, optional): number of random samples. Defaults to 1.\n        eps (float, optional): measurement noise estimate. Defaults to 1e-8.\n        seed (int | None | torch.Generator, optional): random seed. Defaults to None.\n        target (GradTarget, optional): what to set on closure. Defaults to \"closure\".\n\n    Reference:\n        [SPALL, JAMES C. \"A One-measurement Form of Simultaneous Stochastic Approximation](https://www.jhuapl.edu/spsa/PDF-SPSA/automatica97_one_measSPSA.pdf).\"\n    \"\"\"\n\n    def __init__(\n        self,\n        h: float = 1e-3,\n        n_samples: int = 1,\n        eps: float = 1e-8, # measurement noise\n        pre_generate = False,\n        seed: int | None | torch.Generator = None,\n        target: GradTarget = \"closure\",\n    ):\n        defaults = dict(h=h, eps=eps, n_samples=n_samples, pre_generate=pre_generate, seed=seed)\n        super().__init__(defaults, target=target)\n\n\n    def pre_step(self, objective):\n\n        if self.defaults['pre_generate']:\n\n            params = TensorList(objective.params)\n            generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n            n_samples = self.defaults['n_samples']\n            h = self.get_settings(objective.params, 'h')\n\n            perturbations = [params.rademacher_like(generator=generator) for _ in range(n_samples)]\n            torch._foreach_mul_([p for l in perturbations for p in l], [v for vv in h for v in [vv]*n_samples])\n\n            for param, prt in zip(params, zip(*perturbations)):\n                self.state[param]['perturbations'] = prt\n\n    @torch.no_grad\n    def approximate(self, closure, params, loss):\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n        params = TensorList(params)\n        orig_params = params.clone() # store to avoid small changes due to float imprecision\n        loss_approx = None\n\n        h, eps = self.get_settings(params, \"h\", \"eps\", cls=NumberList)\n        n_samples = self.defaults['n_samples']\n\n        default = [None]*n_samples\n        # perturbations are pre-multiplied by h\n        perturbations = list(zip(*(self.state[p].get('perturbations', default) for p in params)))\n\n        grad = None\n        for i in range(n_samples):\n            prt = perturbations[i]\n\n            if prt[0] is None:\n                prt = params.rademacher_like(generator=generator).mul_(h)\n\n            else: prt = TensorList(prt)\n\n            params += prt\n            L = closure(False)\n            params.copy_(orig_params)\n\n            sample = prt * ((L + eps) / h)\n            if grad is None: grad = sample\n            else: grad += sample\n\n        assert grad is not None\n        if n_samples &gt; 1: grad.div_(n_samples)\n\n        # mean if got per-sample values\n        return grad, loss, loss_approx\n</code></pre>"},{"location":"API/modules/least_squares/","title":"Least-squares","text":"<p>This subpackage contains modules for least-squares problems.</p> <p>Classes:</p> <ul> <li> <code>GaussNewton</code>           \u2013            <p>Gauss-newton method.</p> </li> <li> <code>SumOfSquares</code>           \u2013            <p>Sets loss to be the sum of squares of values returned by the closure.</p> </li> </ul>"},{"location":"API/modules/least_squares/#torchzero.modules.least_squares.GaussNewton","title":"GaussNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Gauss-newton method.</p> <p>To use this, the closure should return a vector of values to minimize sum of squares of. Please add the <code>backward</code> argument, it will always be False but it is required. Gradients will be calculated via batched autograd within this module, you don't need to implement the backward pass. Please see below for an example.</p> Note <p>This method requires <code>ndim^2</code> memory, however, if it is used within <code>tz.m.TrustCG</code> trust region, the memory requirement is <code>ndim*m</code>, where <code>m</code> is number of values in the output.</p> <p>Parameters:</p> <ul> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>regularization parameter. Defaults to 1e-8.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of computing the jacobian. When jacobian is not computed, only residuals are computed and updated. Defaults to 1.</p> </li> <li> <code>batched</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use vmapping. Defaults to True.</p> </li> </ul> <p>Examples:</p> <p>minimizing the rosenbrock function: <pre><code>def rosenbrock(X):\n    x1, x2 = X\n    return torch.stack([(1 - x1), 100 * (x2 - x1**2)])\n\nX = torch.tensor([-1.1, 2.5], requires_grad=True)\nopt = tz.Optimizer([X], tz.m.GaussNewton(), tz.m.Backtracking())\n\n# define the closure for line search\ndef closure(backward=True):\n    return rosenbrock(X)\n\n# minimize\nfor iter in range(10):\n    loss = opt.step(closure)\n    print(f'{loss = }')\n</code></pre></p> <p>training a neural network with a matrix-free GN trust region: <pre><code>X = torch.randn(64, 20)\ny = torch.randn(64, 10)\n\nmodel = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.GaussNewton()),\n)\n\ndef closure(backward=True):\n    y_hat = model(X) # (64, 10)\n    return (y_hat - y).pow(2).mean(0) # (10, )\n\nfor i in range(100):\n    losses = opt.step(closure)\n    if i % 10 == 0:\n        print(f'{losses.mean() = }')\n</code></pre></p> Source code in <code>torchzero/modules/least_squares/gn.py</code> <pre><code>class GaussNewton(Transform):\n    \"\"\"Gauss-newton method.\n\n    To use this, the closure should return a vector of values to minimize sum of squares of.\n    Please add the ``backward`` argument, it will always be False but it is required.\n    Gradients will be calculated via batched autograd within this module, you don't need to\n    implement the backward pass. Please see below for an example.\n\n    Note:\n        This method requires ``ndim^2`` memory, however, if it is used within ``tz.m.TrustCG`` trust region,\n        the memory requirement is ``ndim*m``, where ``m`` is number of values in the output.\n\n    Args:\n        reg (float, optional): regularization parameter. Defaults to 1e-8.\n        update_freq (int, optional):\n            frequency of computing the jacobian. When jacobian is not computed, only residuals are computed and updated.\n            Defaults to 1.\n        batched (bool, optional): whether to use vmapping. Defaults to True.\n\n    Examples:\n\n    minimizing the rosenbrock function:\n    ```python\n    def rosenbrock(X):\n        x1, x2 = X\n        return torch.stack([(1 - x1), 100 * (x2 - x1**2)])\n\n    X = torch.tensor([-1.1, 2.5], requires_grad=True)\n    opt = tz.Optimizer([X], tz.m.GaussNewton(), tz.m.Backtracking())\n\n    # define the closure for line search\n    def closure(backward=True):\n        return rosenbrock(X)\n\n    # minimize\n    for iter in range(10):\n        loss = opt.step(closure)\n        print(f'{loss = }')\n    ```\n\n    training a neural network with a matrix-free GN trust region:\n    ```python\n    X = torch.randn(64, 20)\n    y = torch.randn(64, 10)\n\n    model = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.GaussNewton()),\n    )\n\n    def closure(backward=True):\n        y_hat = model(X) # (64, 10)\n        return (y_hat - y).pow(2).mean(0) # (10, )\n\n    for i in range(100):\n        losses = opt.step(closure)\n        if i % 10 == 0:\n            print(f'{losses.mean() = }')\n    ```\n    \"\"\"\n    def __init__(self, reg:float = 1e-8, update_freq: int= 1, batched:bool=True, inner: Chainable | None = None):\n        defaults=dict(update_freq=update_freq,batched=batched, reg=reg)\n        super().__init__(defaults=defaults)\n        if inner is not None: self.set_child('inner', inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        params = objective.params\n        closure = objective.closure\n        batched = fs['batched']\n        update_freq = fs['update_freq']\n\n        # compute residuals\n        r = objective.loss\n        if r is None:\n            assert closure is not None\n            with torch.enable_grad():\n                r = objective.get_loss(backward=False) # n_residuals\n                assert isinstance(r, torch.Tensor)\n\n        if r.numel() == 1:\n            r = r.view(1,1)\n            warnings.warn(\"Gauss-newton got a single residual. Make sure objective function returns a vector of residuals.\")\n\n        # set sum of squares scalar loss and it's gradient to objective\n        objective.loss = r.pow(2).sum()\n\n        step = self.increment_counter(\"step\", start=0)\n\n        if step % update_freq == 0:\n\n            # compute jacobian\n            with torch.enable_grad():\n                J_list = jacobian_wrt([r.ravel()], params, batched=batched)\n\n            J = self.global_state[\"J\"] = flatten_jacobian(J_list) # (n_residuals, ndim)\n\n        else:\n            J = self.global_state[\"J\"]\n\n        Jr = J.T @ r.detach() # (ndim)\n\n        # if there are more residuals, solve (J^T J)x = J^T r, so we need Jr\n        # otherwise solve (J J^T)z = r and set x = J^T z, so we need r\n        n_residuals, ndim = J.shape\n        if n_residuals &gt;= ndim or \"inner\" in self.children:\n            self.global_state[\"Jr\"] = Jr\n\n        else:\n            self.global_state[\"r\"] = r\n\n        objective.grads = vec_to_tensors(Jr, objective.params)\n\n        # set closure to calculate sum of squares for line searches etc\n        if closure is not None:\n            def sos_closure(backward=True):\n\n                if backward:\n                    objective.zero_grad()\n                    with torch.enable_grad():\n                        loss = closure(False).pow(2).sum()\n                        loss.backward()\n                    return loss\n\n                loss = closure(False).pow(2).sum()\n                return loss\n\n            objective.closure = sos_closure\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        fs = settings[0]\n        reg = fs['reg']\n\n        J: torch.Tensor = self.global_state['J']\n        nresiduals, ndim = J.shape\n        if nresiduals &gt;= ndim or \"inner\" in self.children:\n\n            # (J^T J)v = J^T r\n            Jr: torch.Tensor = self.global_state['Jr']\n\n            # inner step\n            if \"inner\" in self.children:\n\n                # var.grad is set to unflattened Jr\n                assert objective.grads is not None\n                objective = self.inner_step(\"inner\", objective, must_exist=True)\n                Jr_list = objective.get_updates()\n                Jr = torch.cat([t.ravel() for t in Jr_list])\n\n            JtJ = J.T @ J # (ndim, ndim)\n            if reg != 0:\n                JtJ.add_(torch.eye(JtJ.size(0), device=JtJ.device, dtype=JtJ.dtype).mul_(reg))\n\n            if nresiduals &gt;= ndim:\n                v, info = torch.linalg.solve_ex(JtJ, Jr) # pylint:disable=not-callable\n            else:\n                v = torch.linalg.lstsq(JtJ, Jr).solution # pylint:disable=not-callable\n\n            objective.updates = vec_to_tensors(v, objective.params)\n            return objective\n\n        # else:\n        # solve (J J^T)z = r and set v = J^T z\n        # we need (J^T J)v = J^T r\n        # if z is solution to (G G^T)z = r, and v = J^T z\n        # then (J^T J)v = (J^T J) (J^T z) = J^T (J J^T) z = J^T r\n        # therefore (J^T J)v = J^T r\n        # also this gives a minimum norm solution\n\n        r = self.global_state['r']\n\n        JJT = J @ J.T # (nresiduals, nresiduals)\n        if reg != 0:\n            JJT.add_(torch.eye(JJT.size(0), device=JJT.device, dtype=JJT.dtype).mul_(reg))\n\n        z, info = torch.linalg.solve_ex(JJT, r) # pylint:disable=not-callable\n        v = J.T @ z\n\n        objective.updates = vec_to_tensors(v, objective.params)\n        return objective\n\n    def get_H(self, objective=...):\n        J = self.global_state['J']\n        return linear_operator.AtA(J)\n</code></pre>"},{"location":"API/modules/least_squares/#torchzero.modules.least_squares.SumOfSquares","title":"SumOfSquares","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Sets loss to be the sum of squares of values returned by the closure.</p> <p>This is meant to be used to test least squares methods against ordinary minimization methods.</p> <p>To use this, the closure should return a vector of values to minimize sum of squares of. Please add the <code>backward</code> argument, it will always be False but it is required.</p> Source code in <code>torchzero/modules/least_squares/gn.py</code> <pre><code>class SumOfSquares(Transform):\n    \"\"\"Sets loss to be the sum of squares of values returned by the closure.\n\n    This is meant to be used to test least squares methods against ordinary minimization methods.\n\n    To use this, the closure should return a vector of values to minimize sum of squares of.\n    Please add the ``backward`` argument, it will always be False but it is required.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        closure = objective.closure\n\n        if closure is not None:\n\n            def sos_closure(backward=True):\n                if backward:\n                    objective.zero_grad()\n                    with torch.enable_grad():\n                        loss = closure(False)\n                        loss = loss.pow(2).sum()\n                        loss.backward()\n                    return loss\n\n                loss = closure(False)\n                return loss.pow(2).sum()\n\n            objective.closure = sos_closure\n\n        if objective.loss is not None:\n            objective.loss = objective.loss.pow(2).sum()\n\n        if objective.loss_approx is not None:\n            objective.loss_approx = objective.loss_approx.pow(2).sum()\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        return objective\n</code></pre>"},{"location":"API/modules/line_search/","title":"Line search","text":"<p>This subpackage contains line search methods.</p>"},{"location":"API/modules/line_search/#see-also","title":"See also","text":"<ul> <li>Step size - step size selection methods like Barzilai-Borwein and Polyak's step size.</li> <li>Trust region - trust region methods.</li> </ul> <p>Classes:</p> <ul> <li> <code>AdaptiveBacktracking</code>           \u2013            <p>Adaptive backtracking line search. After each line search procedure, a new initial step size is set</p> </li> <li> <code>AdaptiveBisection</code>           \u2013            <p>A line search that evaluates previous step size, if value increased, backtracks until the value stops decreasing,</p> </li> <li> <code>Backtracking</code>           \u2013            <p>Backtracking line search.</p> </li> <li> <code>LineSearchBase</code>           \u2013            <p>Base class for line searches.</p> </li> <li> <code>ScipyMinimizeScalar</code>           \u2013            <p>Line search via :code:<code>scipy.optimize.minimize_scalar</code> which implements brent, golden search and bounded brent methods.</p> </li> <li> <code>StrongWolfe</code>           \u2013            <p>Interpolation line search satisfying Strong Wolfe condition.</p> </li> </ul>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.AdaptiveBacktracking","title":"AdaptiveBacktracking","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Adaptive backtracking line search. After each line search procedure, a new initial step size is set such that optimal step size in the procedure would be found on the second line search iteration.</p> <p>Parameters:</p> <ul> <li> <code>init</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial step size. Defaults to 1.0.</p> </li> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplies each consecutive step size by this value. Defaults to 0.5.</p> </li> <li> <code>c</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>sufficient decrease condition. Defaults to 1e-4.</p> </li> <li> <code>condition</code>               (<code>Literal</code>, default:                   <code>'armijo'</code> )           \u2013            <p>termination condition, only ones that do not use gradient at f(x+a*d) can be specified. - \"armijo\" - sufficient decrease condition. - \"decrease\" - any decrease in objective function value satisfies the condition.</p> <p>\"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage. Defaults to 'armijo'.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>maximum number of function evaluations per step. Defaults to 10.</p> </li> <li> <code>target_iters</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>sets next step size such that this number of iterations are expected to be performed until optimal step size is found. Defaults to 1.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>if initial step size is optimal, it is multiplied by this value. Defaults to 2.0.</p> </li> <li> <code>scale_beta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>momentum for initial step size, at 0 disables momentum. Defaults to 0.0.</p> </li> </ul> Source code in <code>torchzero/modules/line_search/backtracking.py</code> <pre><code>class AdaptiveBacktracking(LineSearchBase):\n    \"\"\"Adaptive backtracking line search. After each line search procedure, a new initial step size is set\n    such that optimal step size in the procedure would be found on the second line search iteration.\n\n    Args:\n        init (float, optional): initial step size. Defaults to 1.0.\n        beta (float, optional): multiplies each consecutive step size by this value. Defaults to 0.5.\n        c (float, optional): sufficient decrease condition. Defaults to 1e-4.\n        condition (TerminationCondition, optional):\n            termination condition, only ones that do not use gradient at f(x+a*d) can be specified.\n            - \"armijo\" - sufficient decrease condition.\n            - \"decrease\" - any decrease in objective function value satisfies the condition.\n\n            \"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage.\n            Defaults to 'armijo'.\n        maxiter (int, optional): maximum number of function evaluations per step. Defaults to 10.\n        target_iters (int, optional):\n            sets next step size such that this number of iterations are expected\n            to be performed until optimal step size is found. Defaults to 1.\n        nplus (float, optional):\n            if initial step size is optimal, it is multiplied by this value. Defaults to 2.0.\n        scale_beta (float, optional):\n            momentum for initial step size, at 0 disables momentum. Defaults to 0.0.\n    \"\"\"\n    def __init__(\n        self,\n        init: float = 1.0,\n        beta: float = 0.5,\n        c: float = 1e-4,\n        condition: TerminationCondition = 'armijo',\n        maxiter: int = 20,\n        target_iters = 1,\n        nplus = 2.0,\n        scale_beta = 0.0,\n    ):\n        defaults=dict(init=init,beta=beta,c=c,condition=condition,maxiter=maxiter,target_iters=target_iters,nplus=nplus,scale_beta=scale_beta)\n        super().__init__(defaults=defaults)\n\n        self.global_state['beta_scale'] = 1.0\n        self.global_state['initial_scale'] = 1.0\n\n    def reset(self):\n        super().reset()\n        self.global_state['beta_scale'] = 1.0\n        self.global_state['initial_scale'] = 1.0\n\n    @torch.no_grad\n    def search(self, update, var):\n        init, beta, c,condition, maxiter, target_iters, nplus, scale_beta=itemgetter(\n            'init','beta','c','condition', 'maxiter','target_iters','nplus','scale_beta')(self.defaults)\n\n        objective = self.make_objective(var=var)\n\n        # directional derivative (0 if c = 0 because it is not needed)\n        if c == 0: d = 0\n        else: d = -sum(t.sum() for t in torch._foreach_mul(var.get_grads(), update))\n\n        # scale beta\n        beta = beta * self.global_state['beta_scale']\n\n        # scale step size so that decrease is expected at target_iters\n        init = init * self.global_state['initial_scale']\n\n        step_size = backtracking_line_search(objective, d, init=init, beta=beta, c=c, condition=condition, maxiter=maxiter)\n\n        # found an alpha that reduces loss\n        if step_size is not None:\n\n            # update initial_scale\n            # initial step size satisfied conditions, increase initial_scale by nplus\n            if step_size == init and target_iters &gt; 0:\n                self.global_state['initial_scale'] *= nplus ** target_iters\n\n                # clip by maximum possibel value to avoid overflow exception\n                self.global_state['initial_scale'] = min(\n                    self.global_state['initial_scale'],\n                    torch.finfo(var.params[0].dtype).max / 2,\n                )\n\n            else:\n                # otherwise make initial_scale such that target_iters iterations will satisfy armijo\n                init_target = step_size\n                for _ in range(target_iters):\n                    init_target = step_size / beta\n\n                self.global_state['initial_scale'] = _lerp(\n                    self.global_state['initial_scale'], init_target / init, 1-scale_beta\n                )\n\n            # revert beta_scale\n            self.global_state['beta_scale'] = min(1.0, self.global_state['beta_scale'] * math.sqrt(1.5))\n\n            return step_size\n\n        # on fail reduce beta scale value\n        self.global_state['beta_scale'] /= 1.5\n        return 0\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.AdaptiveBisection","title":"AdaptiveBisection","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>A line search that evaluates previous step size, if value increased, backtracks until the value stops decreasing, otherwise forward-tracks until value stops decreasing.</p> <p>Parameters:</p> <ul> <li> <code>init</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial step size. Defaults to 1.0.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>multiplier to step size if initial step size is optimal. Defaults to 2.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplier to step size if initial step size is too big. Defaults to 0.5.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of function evaluations per step. Defaults to 10.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>when enabled, if line search failed, step size will continue decreasing on the next step. Otherwise it will restart the line search from <code>init</code> step size. Defaults to True.</p> </li> </ul> Source code in <code>torchzero/modules/line_search/adaptive.py</code> <pre><code>class AdaptiveBisection(LineSearchBase):\n    \"\"\"A line search that evaluates previous step size, if value increased, backtracks until the value stops decreasing,\n    otherwise forward-tracks until value stops decreasing.\n\n    Args:\n        init (float, optional): initial step size. Defaults to 1.0.\n        nplus (float, optional): multiplier to step size if initial step size is optimal. Defaults to 2.\n        nminus (float, optional): multiplier to step size if initial step size is too big. Defaults to 0.5.\n        maxiter (int, optional): maximum number of function evaluations per step. Defaults to 10.\n        adaptive (bool, optional):\n            when enabled, if line search failed, step size will continue decreasing on the next step.\n            Otherwise it will restart the line search from ``init`` step size. Defaults to True.\n    \"\"\"\n    def __init__(\n        self,\n        init: float = 1.0,\n        nplus: float = 2,\n        nminus: float = 0.5,\n        maxiter: int = 10,\n        adaptive=True,\n    ):\n        defaults=dict(init=init,nplus=nplus,nminus=nminus,maxiter=maxiter,adaptive=adaptive)\n        super().__init__(defaults=defaults)\n\n    def reset(self):\n        super().reset()\n\n    @torch.no_grad\n    def search(self, update, var):\n        init, nplus, nminus, maxiter, adaptive = itemgetter(\n            'init', 'nplus', 'nminus', 'maxiter', 'adaptive')(self.defaults)\n\n        objective = self.make_objective(var=var)\n\n        # scale a_prev\n        a_prev = self.global_state.get('a_prev', init)\n        if adaptive: a_prev = a_prev * self.global_state.get('init_scale', 1)\n\n        a_init = a_prev\n        if a_init &lt; torch.finfo(var.params[0].dtype).tiny * 2:\n            a_init = torch.finfo(var.params[0].dtype).max / 2\n\n        step_size, f, niter = adaptive_bisection(\n            objective,\n            a_init=a_init,\n            maxiter=maxiter,\n            nplus=nplus,\n            nminus=nminus,\n        )\n\n        # found an alpha that reduces loss\n        if step_size != 0:\n            assert (var.loss is None) or (math.isfinite(f) and f &lt; var.loss)\n            self.global_state['init_scale'] = 1\n\n            # if niter == 1, forward tracking failed to decrease function value compared to f_a_prev\n            if niter == 1 and step_size &gt;= a_init: step_size *= nminus\n\n            self.global_state['a_prev'] = step_size\n            return step_size\n\n        # on fail reduce beta scale value\n        self.global_state['init_scale'] = self.global_state.get('init_scale', 1) * nminus**maxiter\n        self.global_state['a_prev'] = init\n        return 0\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.Backtracking","title":"Backtracking","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Backtracking line search.</p> <p>Parameters:</p> <ul> <li> <code>init</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial step size. Defaults to 1.0.</p> </li> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>multiplies each consecutive step size by this value. Defaults to 0.5.</p> </li> <li> <code>c</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>sufficient decrease condition. Defaults to 1e-4.</p> </li> <li> <code>condition</code>               (<code>Literal</code>, default:                   <code>'armijo'</code> )           \u2013            <p>termination condition, only ones that do not use gradient at f(x+a*d) can be specified. - \"armijo\" - sufficient decrease condition. - \"decrease\" - any decrease in objective function value satisfies the condition.</p> <p>\"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage. Defaults to 'armijo'.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of function evaluations per step. Defaults to 10.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>when enabled, if line search failed, step size will continue decreasing on the next step. Otherwise it will restart the line search from <code>init</code> step size. Defaults to True.</p> </li> </ul> <p>Examples: Gradient descent with backtracking line search:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>L-BFGS with backtracking line search: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(),\n    tz.m.Backtracking()\n)\n</code></pre></p> Source code in <code>torchzero/modules/line_search/backtracking.py</code> <pre><code>class Backtracking(LineSearchBase):\n    \"\"\"Backtracking line search.\n\n    Args:\n        init (float, optional): initial step size. Defaults to 1.0.\n        beta (float, optional): multiplies each consecutive step size by this value. Defaults to 0.5.\n        c (float, optional): sufficient decrease condition. Defaults to 1e-4.\n        condition (TerminationCondition, optional):\n            termination condition, only ones that do not use gradient at f(x+a*d) can be specified.\n            - \"armijo\" - sufficient decrease condition.\n            - \"decrease\" - any decrease in objective function value satisfies the condition.\n\n            \"goldstein\" can techincally be specified but it doesn't make sense because there is not zoom stage.\n            Defaults to 'armijo'.\n        maxiter (int, optional): maximum number of function evaluations per step. Defaults to 10.\n        adaptive (bool, optional):\n            when enabled, if line search failed, step size will continue decreasing on the next step.\n            Otherwise it will restart the line search from ``init`` step size. Defaults to True.\n\n    Examples:\n    Gradient descent with backtracking line search:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    L-BFGS with backtracking line search:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        init: float = 1.0,\n        beta: float = 0.5,\n        c: float = 1e-4,\n        condition: TerminationCondition = 'armijo',\n        maxiter: int = 10,\n        adaptive=True,\n    ):\n        defaults=dict(init=init,beta=beta,c=c,condition=condition,maxiter=maxiter,adaptive=adaptive)\n        super().__init__(defaults=defaults)\n\n    def reset(self):\n        super().reset()\n\n    @torch.no_grad\n    def search(self, update, var):\n        init, beta, c, condition, maxiter, adaptive = itemgetter(\n            'init', 'beta', 'c', 'condition', 'maxiter', 'adaptive')(self.defaults)\n\n        objective = self.make_objective(var=var)\n\n        # # directional derivative\n        if c == 0: d = 0\n        else: d = -sum(t.sum() for t in torch._foreach_mul(var.get_grads(), var.get_updates()))\n\n        # scale init\n        init_scale = self.global_state.get('init_scale', 1)\n        if adaptive: init = init * init_scale\n\n        step_size = backtracking_line_search(objective, d, init=init, beta=beta,c=c, condition=condition, maxiter=maxiter)\n\n        # found an alpha that reduces loss\n        if step_size is not None:\n            #self.global_state['beta_scale'] = min(1.0, self.global_state['beta_scale'] * math.sqrt(1.5))\n            self.global_state['init_scale'] = 1\n            return step_size\n\n        # on fail set init_scale to continue decreasing the step size\n        # or set to large step size when it becomes too small\n        if adaptive:\n            finfo = torch.finfo(var.params[0].dtype)\n            if init_scale &lt;= finfo.tiny * 2:\n                self.global_state[\"init_scale\"] = init * 2\n            else:\n                self.global_state['init_scale'] = init_scale * beta**maxiter\n        return 0\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.LineSearchBase","title":"LineSearchBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for line searches.</p> <p>This is an abstract class, to use it, subclass it and override <code>search</code>.</p> <p>Parameters:</p> <ul> <li> <code>defaults</code>               (<code>dict[str, Any] | None</code>)           \u2013            <p>dictionary with defaults.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>if this is specified, the search method will terminate upon evaluating the objective this many times, and step size with the lowest loss value will be used. This is useful when passing <code>make_objective</code> to an external library which doesn't have a maxiter option. Defaults to None.</p> </li> </ul> Other useful methods <ul> <li><code>evaluate_f</code> - returns loss with a given scalar step size</li> <li><code>evaluate_f_d</code> - returns loss and directional derivative with a given scalar step size</li> <li><code>make_objective</code> - creates a function that accepts a scalar step size and returns loss. This can be passed to a scalar solver, such as scipy.optimize.minimize_scalar.</li> <li><code>make_objective_with_derivative</code> - creates a function that accepts a scalar step size and returns a tuple with loss and directional derivative. This can be passed to a scalar solver.</li> </ul> <p>Examples:</p>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.LineSearchBase--basic-line-search","title":"Basic line search","text":"<p>This evaluates all step sizes in a range by using the :code:<code>self.evaluate_step_size</code> method. <pre><code>class GridLineSearch(LineSearch):\n    def __init__(self, start, end, num):\n        defaults = dict(start=start,end=end,num=num)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def search(self, update, var):\n\n        start = self.defaults[\"start\"]\n        end = self.defaults[\"end\"]\n        num = self.defaults[\"num\"]\n\n        lowest_loss = float(\"inf\")\n        best_step_size = best_step_size\n\n        for step_size in torch.linspace(start,end,num):\n            loss = self.evaluate_step_size(step_size.item(), var=var, backward=False)\n            if loss &lt; lowest_loss:\n                lowest_loss = loss\n                best_step_size = step_size\n\n        return best_step_size\n</code></pre></p>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.LineSearchBase--using-external-solver-via-selfmake_objective","title":"Using external solver via self.make_objective","text":"<p>Here we let :code:<code>scipy.optimize.minimize_scalar</code> solver find the best step size via :code:<code>self.make_objective</code></p> <pre><code>class ScipyMinimizeScalar(LineSearch):\n    def __init__(self, method: str | None = None):\n        defaults = dict(method=method)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def search(self, update, var):\n        objective = self.make_objective(var=var)\n        method = self.defaults[\"method\"]\n\n        res = self.scopt.minimize_scalar(objective, method=method)\n        return res.x\n</code></pre> <p>Methods:</p> <ul> <li> <code>evaluate_f</code>             \u2013              <p>evaluate function value at alpha <code>step_size</code>.</p> </li> <li> <code>evaluate_f_d</code>             \u2013              <p>evaluate function value and directional derivative in the direction of the update at step size <code>step_size</code>.</p> </li> <li> <code>evaluate_f_d_g</code>             \u2013              <p>evaluate function value, directional derivative, and gradient list at step size <code>step_size</code>.</p> </li> <li> <code>search</code>             \u2013              <p>Finds the step size to use</p> </li> </ul> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>class LineSearchBase(Module, ABC):\n    \"\"\"Base class for line searches.\n\n    This is an abstract class, to use it, subclass it and override `search`.\n\n    Args:\n        defaults (dict[str, Any] | None): dictionary with defaults.\n        maxiter (int | None, optional):\n            if this is specified, the search method will terminate upon evaluating\n            the objective this many times, and step size with the lowest loss value will be used.\n            This is useful when passing `make_objective` to an external library which\n            doesn't have a maxiter option. Defaults to None.\n\n    Other useful methods:\n        * ``evaluate_f`` - returns loss with a given scalar step size\n        * ``evaluate_f_d`` - returns loss and directional derivative with a given scalar step size\n        * ``make_objective`` - creates a function that accepts a scalar step size and returns loss. This can be passed to a scalar solver, such as scipy.optimize.minimize_scalar.\n        * ``make_objective_with_derivative`` - creates a function that accepts a scalar step size and returns a tuple with loss and directional derivative. This can be passed to a scalar solver.\n\n    Examples:\n\n    #### Basic line search\n\n    This evaluates all step sizes in a range by using the :code:`self.evaluate_step_size` method.\n    ```python\n    class GridLineSearch(LineSearch):\n        def __init__(self, start, end, num):\n            defaults = dict(start=start,end=end,num=num)\n            super().__init__(defaults)\n\n        @torch.no_grad\n        def search(self, update, var):\n\n            start = self.defaults[\"start\"]\n            end = self.defaults[\"end\"]\n            num = self.defaults[\"num\"]\n\n            lowest_loss = float(\"inf\")\n            best_step_size = best_step_size\n\n            for step_size in torch.linspace(start,end,num):\n                loss = self.evaluate_step_size(step_size.item(), var=var, backward=False)\n                if loss &lt; lowest_loss:\n                    lowest_loss = loss\n                    best_step_size = step_size\n\n            return best_step_size\n    ```\n\n    #### Using external solver via self.make_objective\n\n    Here we let :code:`scipy.optimize.minimize_scalar` solver find the best step size via :code:`self.make_objective`\n\n    ```python\n    class ScipyMinimizeScalar(LineSearch):\n        def __init__(self, method: str | None = None):\n            defaults = dict(method=method)\n            super().__init__(defaults)\n\n        @torch.no_grad\n        def search(self, update, var):\n            objective = self.make_objective(var=var)\n            method = self.defaults[\"method\"]\n\n            res = self.scopt.minimize_scalar(objective, method=method)\n            return res.x\n    ```\n    \"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, maxiter: int | None = None):\n        super().__init__(defaults)\n        self._maxiter = maxiter\n        self._reset()\n\n    def _reset(self):\n        self._current_step_size: float = 0\n        self._lowest_loss = float('inf')\n        self._best_step_size: float = 0\n        self._current_iter = 0\n        self._initial_params = None\n\n    def set_step_size_(\n        self,\n        step_size: float,\n        params: list[torch.Tensor],\n        update: list[torch.Tensor],\n    ):\n        if not math.isfinite(step_size): return\n\n         # avoid overflow error\n        step_size = clip_by_finfo(tofloat(step_size), torch.finfo(update[0].dtype))\n\n        # skip is parameters are already at suggested step size\n        if self._current_step_size == step_size: return\n\n        assert self._initial_params is not None\n        if step_size == 0:\n            new_params = [p.clone() for p in self._initial_params]\n        else:\n            new_params = torch._foreach_sub(self._initial_params, update, alpha=step_size)\n\n        for c, n in zip(params, new_params):\n            set_storage_(c, n)\n\n        self._current_step_size = step_size\n\n    def _set_per_parameter_step_size_(\n        self,\n        step_size: Sequence[float],\n        params: list[torch.Tensor],\n        update: list[torch.Tensor],\n    ):\n\n        assert self._initial_params is not None\n        if not np.isfinite(step_size).all(): step_size = [0 for _ in step_size]\n\n        if any(s!=0 for s in step_size):\n            new_params = torch._foreach_sub(self._initial_params, torch._foreach_mul(update, step_size))\n        else:\n            new_params = [p.clone() for p in self._initial_params]\n\n        for c, n in zip(params, new_params):\n            set_storage_(c, n)\n\n    def _loss(self, step_size: float, var: Objective, closure, params: list[torch.Tensor],\n              update: list[torch.Tensor], backward:bool=False) -&gt; float:\n\n        # if step_size is 0, we might already know the loss\n        if (var.loss is not None) and (step_size == 0):\n            return tofloat(var.loss)\n\n        # check max iter\n        if self._maxiter is not None and self._current_iter &gt;= self._maxiter: raise MaxLineSearchItersReached\n        self._current_iter += 1\n\n        # set new lr and evaluate loss with it\n        self.set_step_size_(step_size, params=params, update=update)\n        if backward:\n            with torch.enable_grad(): loss = closure()\n        else:\n            loss = closure(False)\n\n        # if it is the best so far, record it\n        if loss &lt; self._lowest_loss:\n            self._lowest_loss = tofloat(loss)\n            self._best_step_size = step_size\n\n        # if evaluated loss at step size 0, set it to var.loss\n        if step_size == 0:\n            var.loss = loss\n            if backward: var.grads = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n\n        return tofloat(loss)\n\n    def _loss_derivative_gradient(self, step_size: float, var: Objective, closure,\n                         params: list[torch.Tensor], update: list[torch.Tensor]):\n        # if step_size is 0, we might already know the derivative\n        if (var.grads is not None) and (step_size == 0):\n            loss = self._loss(step_size=step_size,var=var,closure=closure,params=params,update=update,backward=False)\n            derivative = - sum(t.sum() for t in torch._foreach_mul(var.grads, update))\n\n        else:\n            # loss with a backward pass sets params.grad\n            loss = self._loss(step_size=step_size,var=var,closure=closure,params=params,update=update,backward=True)\n\n            # directional derivative\n            derivative = - sum(t.sum() for t in torch._foreach_mul([p.grad if p.grad is not None\n                                                                    else torch.zeros_like(p) for p in params], update))\n\n        assert var.grads is not None\n        return loss, tofloat(derivative), var.grads\n\n    def _loss_derivative(self, step_size: float, var: Objective, closure,\n                         params: list[torch.Tensor], update: list[torch.Tensor]):\n        return self._loss_derivative_gradient(step_size=step_size, var=var,closure=closure,params=params,update=update)[:2]\n\n    def evaluate_f(self, step_size: float, var: Objective, backward:bool=False):\n        \"\"\"evaluate function value at alpha `step_size`.\"\"\"\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return self._loss(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates(),backward=backward)\n\n    def evaluate_f_d(self, step_size: float, var: Objective):\n        \"\"\"evaluate function value and directional derivative in the direction of the update at step size `step_size`.\"\"\"\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return self._loss_derivative(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n\n    def evaluate_f_d_g(self, step_size: float, var: Objective):\n        \"\"\"evaluate function value, directional derivative, and gradient list at step size `step_size`.\"\"\"\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return self._loss_derivative_gradient(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n\n    def make_objective(self, var: Objective, backward:bool=False):\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return partial(self._loss, var=var, closure=closure, params=var.params, update=var.get_updates(), backward=backward)\n\n    def make_objective_with_derivative(self, var: Objective):\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return partial(self._loss_derivative, var=var, closure=closure, params=var.params, update=var.get_updates())\n\n    def make_objective_with_derivative_and_gradient(self, var: Objective):\n        closure = var.closure\n        if closure is None: raise RuntimeError('line search requires closure')\n        return partial(self._loss_derivative_gradient, var=var, closure=closure, params=var.params, update=var.get_updates())\n\n    @abstractmethod\n    def search(self, update: list[torch.Tensor], var: Objective) -&gt; float:\n        \"\"\"Finds the step size to use\"\"\"\n\n    @torch.no_grad\n    def apply(self, objective: Objective) -&gt; Objective:\n        self._reset()\n\n        params = objective.params\n        self._initial_params = [p.clone() for p in params]\n        update = objective.get_updates()\n\n        try:\n            step_size = self.search(update=update, var=objective)\n        except MaxLineSearchItersReached:\n            step_size = self._best_step_size\n\n        step_size = clip_by_finfo(step_size, torch.finfo(update[0].dtype))\n\n        # set loss_approx\n        if objective.loss_approx is None: objective.loss_approx = self._lowest_loss\n\n        # if this is last module, directly update parameters to avoid redundant operations\n        if objective.modular is not None and self is objective.modular.modules[-1]:\n            self.set_step_size_(step_size, params=params, update=update)\n\n            objective.stop = True; objective.skip_update = True\n            return objective\n\n        # revert parameters and multiply update by step size\n        self.set_step_size_(0, params=params, update=update)\n        torch._foreach_mul_(objective.updates, step_size)\n        return objective\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.LineSearchBase.evaluate_f","title":"evaluate_f","text":"<pre><code>evaluate_f(step_size: float, var: Objective, backward: bool = False)\n</code></pre> <p>evaluate function value at alpha <code>step_size</code>.</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>def evaluate_f(self, step_size: float, var: Objective, backward:bool=False):\n    \"\"\"evaluate function value at alpha `step_size`.\"\"\"\n    closure = var.closure\n    if closure is None: raise RuntimeError('line search requires closure')\n    return self._loss(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates(),backward=backward)\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.LineSearchBase.evaluate_f_d","title":"evaluate_f_d","text":"<pre><code>evaluate_f_d(step_size: float, var: Objective)\n</code></pre> <p>evaluate function value and directional derivative in the direction of the update at step size <code>step_size</code>.</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>def evaluate_f_d(self, step_size: float, var: Objective):\n    \"\"\"evaluate function value and directional derivative in the direction of the update at step size `step_size`.\"\"\"\n    closure = var.closure\n    if closure is None: raise RuntimeError('line search requires closure')\n    return self._loss_derivative(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.LineSearchBase.evaluate_f_d_g","title":"evaluate_f_d_g","text":"<pre><code>evaluate_f_d_g(step_size: float, var: Objective)\n</code></pre> <p>evaluate function value, directional derivative, and gradient list at step size <code>step_size</code>.</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>def evaluate_f_d_g(self, step_size: float, var: Objective):\n    \"\"\"evaluate function value, directional derivative, and gradient list at step size `step_size`.\"\"\"\n    closure = var.closure\n    if closure is None: raise RuntimeError('line search requires closure')\n    return self._loss_derivative_gradient(step_size=step_size, var=var, closure=closure, params=var.params,update=var.get_updates())\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.LineSearchBase.search","title":"search","text":"<pre><code>search(update: list[Tensor], var: Objective) -&gt; float\n</code></pre> <p>Finds the step size to use</p> Source code in <code>torchzero/modules/line_search/line_search.py</code> <pre><code>@abstractmethod\ndef search(self, update: list[torch.Tensor], var: Objective) -&gt; float:\n    \"\"\"Finds the step size to use\"\"\"\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.ScipyMinimizeScalar","title":"ScipyMinimizeScalar","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Line search via :code:<code>scipy.optimize.minimize_scalar</code> which implements brent, golden search and bounded brent methods.</p> <p>Parameters:</p> <ul> <li> <code>method</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>\"brent\", \"golden\" or \"bounded\". Defaults to None.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of function evaluations the line search is allowed to perform. Defaults to None.</p> </li> <li> <code>bracket</code>               (<code>Sequence | None</code>, default:                   <code>None</code> )           \u2013            <p>Either a triple (xa, xb, xc) satisfying xa &lt; xb &lt; xc and func(xb) &lt; func(xa) and  func(xb) &lt; func(xc), or a pair (xa, xb) to be used as initial points for a downhill bracket search. Defaults to None.</p> </li> <li> <code>bounds</code>               (<code>Sequence | None</code>, default:                   <code>None</code> )           \u2013            <p>For method \u2018bounded\u2019, bounds is mandatory and must have two finite items corresponding to the optimization bounds. Defaults to None.</p> </li> <li> <code>tol</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Tolerance for termination. Defaults to None.</p> </li> <li> <code>prev_init</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>uses previous step size as initial guess for the line search.</p> </li> <li> <code>options</code>               (<code>dict | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary of solver options. Defaults to None.</p> </li> </ul> <p>For more details on methods and arguments refer to https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize_scalar.html</p> Source code in <code>torchzero/modules/line_search/scipy.py</code> <pre><code>class ScipyMinimizeScalar(LineSearchBase):\n    \"\"\"Line search via :code:`scipy.optimize.minimize_scalar` which implements brent, golden search and bounded brent methods.\n\n    Args:\n        method (str | None, optional): \"brent\", \"golden\" or \"bounded\". Defaults to None.\n        maxiter (int | None, optional): maximum number of function evaluations the line search is allowed to perform. Defaults to None.\n        bracket (Sequence | None, optional):\n            Either a triple (xa, xb, xc) satisfying xa &lt; xb &lt; xc and func(xb) &lt; func(xa) and  func(xb) &lt; func(xc), or a pair (xa, xb) to be used as initial points for a downhill bracket search. Defaults to None.\n        bounds (Sequence | None, optional):\n            For method \u2018bounded\u2019, bounds is mandatory and must have two finite items corresponding to the optimization bounds. Defaults to None.\n        tol (float | None, optional): Tolerance for termination. Defaults to None.\n        prev_init (bool, optional): uses previous step size as initial guess for the line search.\n        options (dict | None, optional): A dictionary of solver options. Defaults to None.\n\n    For more details on methods and arguments refer to https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize_scalar.html\n\n    \"\"\"\n    def __init__(\n        self,\n        method: str | None = None,\n        maxiter: int | None = None,\n        bracket=None,\n        bounds=None,\n        tol: float | None = None,\n        prev_init: bool = False,\n        options=None,\n    ):\n        defaults = dict(method=method,bracket=bracket,bounds=bounds,tol=tol,options=options,maxiter=maxiter, prev_init=prev_init)\n        super().__init__(defaults)\n\n        import scipy.optimize\n        self.scopt = scipy.optimize\n\n\n    @torch.no_grad\n    def search(self, update, var):\n        objective = self.make_objective(var=var)\n        method, bracket, bounds, tol, options, maxiter = itemgetter(\n            'method', 'bracket', 'bounds', 'tol', 'options', 'maxiter')(self.defaults)\n\n        if maxiter is not None:\n            options = dict(options) if isinstance(options, Mapping) else {}\n            options['maxiter'] = maxiter\n\n        if self.defaults[\"prev_init\"] and \"x_prev\" in self.global_state:\n            if bracket is None: bracket = (0, 1)\n            bracket = (*bracket[:-1], self.global_state[\"x_prev\"])\n\n        x = self.scopt.minimize_scalar(objective, method=method, bracket=bracket, bounds=bounds, tol=tol, options=options).x # pyright:ignore[reportAttributeAccessIssue]\n\n        max = torch.finfo(var.params[0].dtype).max / 2\n        if (not math.isfinite(x)) or abs(x) &gt;= max: x = 0\n\n        self.global_state['x_prev'] = x\n        return x\n</code></pre>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.StrongWolfe","title":"StrongWolfe","text":"<p>               Bases: <code>torchzero.modules.line_search.line_search.LineSearchBase</code></p> <p>Interpolation line search satisfying Strong Wolfe condition.</p> <p>Parameters:</p> <ul> <li> <code>c1</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>sufficient descent condition. Defaults to 1e-4.</p> </li> <li> <code>c2</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>strong curvature condition. For CG set to 0.1. Defaults to 0.9.</p> </li> <li> <code>a_init</code>               (<code>str</code>, default:                   <code>'fixed'</code> )           \u2013            <p>strategy for initializing the initial step size guess. - \"fixed\" - uses a fixed value specified in <code>init_value</code> argument. - \"first-order\" - assumes first-order change in the function at iterate will be the same as that obtained at the previous step. - \"quadratic\" - interpolates quadratic to f(x_{-1}) and f_x. - \"quadratic-clip\" - same as quad, but uses min(1, 1.01*alpha) as described in Numerical Optimization. - \"previous\" - uses final step size found on previous iteration.</p> <p>For 2nd order methods it is usually best to leave at \"fixed\". For methods that do not produce well scaled search directions, e.g. conjugate gradient, \"first-order\" or \"quadratic-clip\" are recommended. Defaults to 'init'.</p> </li> <li> <code>a_max</code>               (<code>float</code>, default:                   <code>1000000000000.0</code> )           \u2013            <p>upper bound for the proposed step sizes. Defaults to 1e12.</p> </li> <li> <code>init_value</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>initial step size. Used when <code>a_init</code>=\"fixed\", and with other strategies as fallback value. Defaults to 1.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>25</code> )           \u2013            <p>maximum number of line search iterations. Defaults to 25.</p> </li> <li> <code>maxzoom</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of zoom iterations. Defaults to 10.</p> </li> <li> <code>maxeval</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of function evaluations. Defaults to None.</p> </li> <li> <code>tol_change</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>tolerance, terminates on small brackets. Defaults to 1e-9.</p> </li> <li> <code>interpolation</code>               (<code>str</code>, default:                   <code>'cubic'</code> )           \u2013            <p>What type of interpolation to use. - \"bisection\" - uses the middle point. This is robust, especially if the objective function is non-smooth, however it may need more function evaluations. - \"quadratic\" - minimizes a quadratic model, generally outperformed by \"cubic\". - \"cubic\" - minimizes a cubic model - this is the most widely used interpolation strategy. - \"polynomial\" - fits a a polynomial to all points obtained during line search. - \"polynomial2\" - alternative polynomial fit, where if a point is outside of bounds, a lower degree polynomial is tried. This may have faster convergence than \"cubic\" and \"polynomial\".</p> <p>Defaults to 'cubic'.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, the initial step size will be halved when line search failed to find a good direction. When a good direction is found, initial step size is reset to the original value. Defaults to True.</p> </li> <li> <code>fallback</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, when no point satisfied strong wolfe criteria, returns a point with value lower than initial value that doesn't satisfy the criteria. Defaults to False.</p> </li> <li> <code>plus_minus</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, enables the plus-minus variant, where if curvature is negative, line search is performed in the opposite direction. Defaults to False.</p> </li> </ul>"},{"location":"API/modules/line_search/#torchzero.modules.line_search.StrongWolfe--examples","title":"Examples:","text":"<p>Conjugate gradient method with strong wolfe line search. Nocedal, Wright recommend setting c2 to 0.1 for CG. Since CG doesn't produce well scaled directions, initial alpha can be determined from function values by <code>a_init=\"first-order\"</code>.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.PolakRibiere(),\n    tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")\n)\n</code></pre> <p>LBFGS strong wolfe line search: <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(),\n    tz.m.StrongWolfe()\n)\n</code></pre></p> Source code in <code>torchzero/modules/line_search/strong_wolfe.py</code> <pre><code>class StrongWolfe(LineSearchBase):\n    \"\"\"Interpolation line search satisfying Strong Wolfe condition.\n\n    Args:\n        c1 (float, optional): sufficient descent condition. Defaults to 1e-4.\n        c2 (float, optional): strong curvature condition. For CG set to 0.1. Defaults to 0.9.\n        a_init (str, optional):\n            strategy for initializing the initial step size guess.\n            - \"fixed\" - uses a fixed value specified in `init_value` argument.\n            - \"first-order\" - assumes first-order change in the function at iterate will be the same as that obtained at the previous step.\n            - \"quadratic\" - interpolates quadratic to f(x_{-1}) and f_x.\n            - \"quadratic-clip\" - same as quad, but uses min(1, 1.01*alpha) as described in Numerical Optimization.\n            - \"previous\" - uses final step size found on previous iteration.\n\n            For 2nd order methods it is usually best to leave at \"fixed\".\n            For methods that do not produce well scaled search directions, e.g. conjugate gradient,\n            \"first-order\" or \"quadratic-clip\" are recommended. Defaults to 'init'.\n        a_max (float, optional): upper bound for the proposed step sizes. Defaults to 1e12.\n        init_value (float, optional):\n            initial step size. Used when ``a_init``=\"fixed\", and with other strategies as fallback value. Defaults to 1.\n        maxiter (int, optional): maximum number of line search iterations. Defaults to 25.\n        maxzoom (int, optional): maximum number of zoom iterations. Defaults to 10.\n        maxeval (int | None, optional): maximum number of function evaluations. Defaults to None.\n        tol_change (float, optional): tolerance, terminates on small brackets. Defaults to 1e-9.\n        interpolation (str, optional):\n            What type of interpolation to use.\n            - \"bisection\" - uses the middle point. This is robust, especially if the objective function is non-smooth, however it may need more function evaluations.\n            - \"quadratic\" - minimizes a quadratic model, generally outperformed by \"cubic\".\n            - \"cubic\" - minimizes a cubic model - this is the most widely used interpolation strategy.\n            - \"polynomial\" - fits a a polynomial to all points obtained during line search.\n            - \"polynomial2\" - alternative polynomial fit, where if a point is outside of bounds, a lower degree polynomial is tried.\n            This may have faster convergence than \"cubic\" and \"polynomial\".\n\n            Defaults to 'cubic'.\n        adaptive (bool, optional):\n            if True, the initial step size will be halved when line search failed to find a good direction.\n            When a good direction is found, initial step size is reset to the original value. Defaults to True.\n        fallback (bool, optional):\n            if True, when no point satisfied strong wolfe criteria,\n            returns a point with value lower than initial value that doesn't satisfy the criteria. Defaults to False.\n        plus_minus (bool, optional):\n            if True, enables the plus-minus variant, where if curvature is negative, line search is performed\n            in the opposite direction. Defaults to False.\n\n\n    ## Examples:\n\n    Conjugate gradient method with strong wolfe line search. Nocedal, Wright recommend setting c2 to 0.1 for CG. Since CG doesn't produce well scaled directions, initial alpha can be determined from function values by ``a_init=\"first-order\"``.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.PolakRibiere(),\n        tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\")\n    )\n    ```\n\n    LBFGS strong wolfe line search:\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(),\n        tz.m.StrongWolfe()\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        c1: float = 1e-4,\n        c2: float = 0.9,\n        a_init: Literal['first-order', 'quadratic', 'quadratic-clip', 'previous', 'fixed'] = 'fixed',\n        a_max: float = 1e12,\n        init_value: float = 1,\n        maxiter: int = 25,\n        maxzoom: int = 10,\n        maxeval: int | None = None,\n        tol_change: float = 1e-9,\n        interpolation: Literal[\"quadratic\", \"cubic\", \"bisection\", \"polynomial\", 'polynomial2'] = 'cubic',\n        adaptive = True,\n        fallback:bool = False,\n        plus_minus = False,\n    ):\n        defaults=dict(init_value=init_value,init=a_init,a_max=a_max,c1=c1,c2=c2,maxiter=maxiter,maxzoom=maxzoom, fallback=fallback,\n                      maxeval=maxeval, adaptive=adaptive, interpolation=interpolation, plus_minus=plus_minus, tol_change=tol_change)\n        super().__init__(defaults=defaults)\n\n        self.global_state['initial_scale'] = 1.0\n\n    @torch.no_grad\n    def search(self, update, var):\n        self._g_prev = self._f_prev = None\n        objective = self.make_objective_with_derivative(var=var)\n\n        init_value, init, c1, c2, a_max, maxiter, maxzoom, maxeval, interpolation, adaptive, plus_minus, fallback, tol_change = itemgetter(\n            'init_value', 'init', 'c1', 'c2', 'a_max', 'maxiter', 'maxzoom',\n            'maxeval', 'interpolation', 'adaptive', 'plus_minus', 'fallback', 'tol_change')(self.defaults)\n\n        dir = as_tensorlist(var.get_updates())\n        grad_list = var.get_grads()\n\n        g_0 = -sum(t.sum() for t in torch._foreach_mul(grad_list, dir))\n        f_0 = var.get_loss(False)\n        dir_norm = dir.global_vector_norm()\n\n        inverted = False\n        if plus_minus and g_0 &gt; 0:\n            original_objective = objective\n            def inverted_objective(a):\n                l, g_a = original_objective(-a)\n                return l, -g_a\n            objective = inverted_objective\n            inverted = True\n\n        # --------------------- determine initial step size guess -------------------- #\n        init = init.lower().strip()\n\n        a_init = init_value\n        if init == 'fixed':\n            pass # use init_value\n\n        elif init == 'previous':\n            if 'a_prev' in self.global_state:\n                a_init = self.global_state['a_prev']\n\n        elif init == 'first-order':\n            if 'g_prev' in self.global_state and g_0 &lt; -torch.finfo(dir[0].dtype).tiny * 2:\n                a_prev = self.global_state['a_prev']\n                g_prev = self.global_state['g_prev']\n                if g_prev &lt; 0:\n                    a_init = a_prev * g_prev / g_0\n\n        elif init in ('quadratic', 'quadratic-clip'):\n            if 'f_prev' in self.global_state and g_0 &lt; -torch.finfo(dir[0].dtype).tiny * 2:\n                f_prev = self.global_state['f_prev']\n                if f_0 &lt; f_prev:\n                    a_init = 2 * (f_0 - f_prev) / g_0\n                    if init == 'quadratic-clip': a_init = min(1, 1.01*a_init)\n        else:\n            raise ValueError(init)\n\n        if adaptive:\n            a_init *= self.global_state.get('initial_scale', 1)\n\n        strong_wolfe = _StrongWolfe(\n            f=objective,\n            f_0=f_0,\n            g_0=g_0,\n            d_norm=dir_norm,\n            a_init=a_init,\n            a_max=a_max,\n            c1=c1,\n            c2=c2,\n            maxiter=maxiter,\n            maxzoom=maxzoom,\n            maxeval=maxeval,\n            tol_change=tol_change,\n            interpolation=interpolation,\n        )\n\n        a, f_a, g_a = strong_wolfe.search()\n        if inverted and a is not None: a = -a\n        if f_a is not None and (f_a &gt; f_0 or not math.isfinite(f_a)): a = None\n\n        if fallback:\n            if a is None or a==0 or not math.isfinite(a):\n                lowest = min(strong_wolfe.history.items(), key=lambda x: x[1][0])\n                if lowest[1][0] &lt; f_0:\n                    a = lowest[0]\n                    f_a, g_a = lowest[1]\n                    if inverted: a = -a\n\n        if a is not None and a != 0 and math.isfinite(a):\n            self.global_state['initial_scale'] = 1\n            self.global_state['a_prev'] = a\n            self.global_state['f_prev'] = f_0\n            self.global_state['g_prev'] = g_0\n            return a\n\n        # fail\n        if adaptive:\n            self.global_state['initial_scale'] = self.global_state.get('initial_scale', 1) * 0.5\n            finfo = torch.finfo(dir[0].dtype)\n            if self.global_state['initial_scale'] &lt; finfo.tiny * 2:\n                self.global_state['initial_scale'] = init_value * 2\n\n        return 0\n</code></pre>"},{"location":"API/modules/misc/","title":"Miscellaneous","text":"<p>This subpackage contains a lot of uncategorized modules, notably gradient accumulation, switching, automatic resetting, random restarts.</p> <p>Classes:</p> <ul> <li> <code>Alternate</code>           \u2013            <p>Alternates between stepping with :code:<code>modules</code>.</p> </li> <li> <code>DivByLoss</code>           \u2013            <p>Divides update by loss times <code>alpha</code></p> </li> <li> <code>Dropout</code>           \u2013            <p>Applies dropout to the update.</p> </li> <li> <code>EscapeAnnealing</code>           \u2013            <p>If parameters stop changing, this runs a backward annealing random search</p> </li> <li> <code>ExpHomotopy</code>           \u2013            </li> <li> <code>FillLoss</code>           \u2013            <p>Outputs tensors filled with loss value times <code>alpha</code></p> </li> <li> <code>GradSign</code>           \u2013            <p>Copies gradient sign to update.</p> </li> <li> <code>GradientAccumulation</code>           \u2013            <p>Uses <code>n</code> steps to accumulate gradients, after <code>n</code> gradients have been accumulated, they are passed to :code:<code>modules</code> and parameters are updates.</p> </li> <li> <code>GraftGradToUpdate</code>           \u2013            <p>Outputs gradient grafted to update, that is gradient rescaled to have the same norm as the update.</p> </li> <li> <code>GraftToGrad</code>           \u2013            <p>Grafts update to the gradient, that is update is rescaled to have the same norm as the gradient.</p> </li> <li> <code>GraftToParams</code>           \u2013            <p>Grafts update to the parameters, that is update is rescaled to have the same norm as the parameters, but no smaller than <code>eps</code>.</p> </li> <li> <code>HpuEstimate</code>           \u2013            <p>returns <code>y/||s||</code>, where <code>y</code> is difference between current and previous update (gradient), <code>s</code> is difference between current and previous parameters. The returned tensors are a finite difference approximation to hessian times previous update.</p> </li> <li> <code>LambdaHomotopy</code>           \u2013            </li> <li> <code>LastAbsoluteRatio</code>           \u2013            <p>Outputs ratio between absolute values of past two updates the numerator is determined by <code>numerator</code> argument.</p> </li> <li> <code>LastDifference</code>           \u2013            <p>Outputs difference between past two updates.</p> </li> <li> <code>LastGradDifference</code>           \u2013            <p>Outputs difference between past two gradients.</p> </li> <li> <code>LastProduct</code>           \u2013            <p>Outputs difference between past two updates.</p> </li> <li> <code>LastRatio</code>           \u2013            <p>Outputs ratio between past two updates, the numerator is determined by <code>numerator</code> argument.</p> </li> <li> <code>LogHomotopy</code>           \u2013            </li> <li> <code>MulByLoss</code>           \u2013            <p>Multiplies update by loss times <code>alpha</code></p> </li> <li> <code>Multistep</code>           \u2013            <p>Performs <code>steps</code> inner steps with <code>module</code> per each step.</p> </li> <li> <code>NegateOnLossIncrease</code>           \u2013            <p>Uses an extra forward pass to evaluate loss at <code>parameters+update</code>,</p> </li> <li> <code>NoiseSign</code>           \u2013            <p>Outputs random tensors with sign copied from the update.</p> </li> <li> <code>Online</code>           \u2013            <p>Allows certain modules to be used for mini-batch optimization.</p> </li> <li> <code>PerturbWeights</code>           \u2013            <p>Changes the closure so that it evaluates loss and gradients at weights perturbed by a random perturbation.</p> </li> <li> <code>Previous</code>           \u2013            <p>Maintains an update from n steps back, for example if n=1, returns previous update</p> </li> <li> <code>PrintLoss</code>           \u2013            <p>Prints var.get_loss().</p> </li> <li> <code>PrintParams</code>           \u2013            <p>Prints current update.</p> </li> <li> <code>PrintShape</code>           \u2013            <p>Prints shapes of the update.</p> </li> <li> <code>PrintUpdate</code>           \u2013            <p>Prints current update.</p> </li> <li> <code>RandomHvp</code>           \u2013            <p>Returns a hessian-vector product with a random vector, optionally times vector</p> </li> <li> <code>Relative</code>           \u2013            <p>Multiplies update by absolute parameter values to make it relative to their magnitude, <code>min_value</code> is minimum allowed value to avoid getting stuck at 0.</p> </li> <li> <code>SaveBest</code>           \u2013            <p>Saves best parameters found so far, ones that have lowest loss. Put this as the last module.</p> </li> <li> <code>Sequential</code>           \u2013            <p>On each step, this sequentially steps with <code>modules</code> <code>steps</code> times.</p> </li> <li> <code>Split</code>           \u2013            <p>Apply <code>true</code> modules to all parameters filtered by <code>filter</code>, apply <code>false</code> modules to all other parameters.</p> </li> <li> <code>SqrtHomotopy</code>           \u2013            </li> <li> <code>SquareHomotopy</code>           \u2013            </li> <li> <code>Switch</code>           \u2013            <p>After <code>steps</code> steps switches to the next module.</p> </li> <li> <code>UpdateSign</code>           \u2013            <p>Outputs gradient with sign copied from the update.</p> </li> <li> <code>WeightDropout</code>           \u2013            <p>Changes the closure so that it evaluates loss and gradients with random weights replaced with 0.</p> </li> </ul>"},{"location":"API/modules/misc/#torchzero.modules.misc.Alternate","title":"Alternate","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Alternates between stepping with :code:<code>modules</code>.</p> <p>That is, first step is performed with 1st module, second step with second module, etc.</p> <p>Parameters:</p> <ul> <li> <code>steps</code>               (<code>int | Iterable[int]</code>, default:                   <code>1</code> )           \u2013            <p>number of steps to perform with each module. Defaults to 1.</p> </li> </ul>"},{"location":"API/modules/misc/#torchzero.modules.misc.Alternate--examples","title":"Examples:","text":"<p>Alternate between Adam, SignSGD and RMSprop</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Alternate(\n        tz.m.Adam(),\n        [tz.m.SignSGD(), tz.m.Mul(0.5)],\n        tz.m.RMSprop(),\n    ),\n    tz.m.LR(1e-3),\n)\n</code></pre> Source code in <code>torchzero/modules/misc/switch.py</code> <pre><code>class Alternate(Module):\n    \"\"\"Alternates between stepping with :code:`modules`.\n\n    That is, first step is performed with 1st module, second step with second module, etc.\n\n    Args:\n        steps (int | Iterable[int], optional): number of steps to perform with each module. Defaults to 1.\n\n    ### Examples:\n    Alternate between Adam, SignSGD and RMSprop\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Alternate(\n            tz.m.Adam(),\n            [tz.m.SignSGD(), tz.m.Mul(0.5)],\n            tz.m.RMSprop(),\n        ),\n        tz.m.LR(1e-3),\n    )\n    ```\n    \"\"\"\n    LOOP = True\n    def __init__(self, *modules: Chainable, steps: int | Iterable[int] = 1):\n        if isinstance(steps, Iterable):\n            steps = list(steps)\n            if len(steps) != len(modules):\n                raise ValueError(f\"steps must be the same length as modules, got {len(modules) = }, {len(steps) = }\")\n\n        defaults = dict(steps=steps)\n        super().__init__(defaults)\n\n        self.set_children_sequence(modules)\n        self.global_state['current_module_idx'] = 0\n        self.global_state['steps_to_next'] = steps[0] if isinstance(steps, list) else steps\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective):\n        # get current module\n        current_module_idx = self.global_state.setdefault('current_module_idx', 0)\n        module = self.children[f'module_{current_module_idx}']\n\n        # step\n        objective = module.step(objective.clone(clone_updates=False))\n\n        # number of steps until next module\n        steps = self.defaults['steps']\n        if isinstance(steps, int): steps = [steps]*len(self.children)\n\n        if 'steps_to_next' not in self.global_state:\n            self.global_state['steps_to_next'] = steps[0] if isinstance(steps, list) else steps\n\n        self.global_state['steps_to_next'] -= 1\n\n        # switch to next module\n        if self.global_state['steps_to_next'] == 0:\n            self.global_state['current_module_idx'] += 1\n\n            # loop to first module (or keep using last module on Switch)\n            if self.global_state['current_module_idx'] &gt; len(self.children) - 1:\n                if self.LOOP: self.global_state['current_module_idx'] = 0\n                else: self.global_state['current_module_idx'] = len(self.children) - 1\n\n            self.global_state['steps_to_next'] = steps[self.global_state['current_module_idx']]\n\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Alternate.LOOP","title":"LOOP  <code>class-attribute</code>","text":"<pre><code>LOOP = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/misc/#torchzero.modules.misc.DivByLoss","title":"DivByLoss","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Divides update by loss times <code>alpha</code></p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class DivByLoss(TensorTransform):\n    \"\"\"Divides update by loss times ``alpha``\"\"\"\n    def __init__(self, alpha: float = 1, min_value:float = 1e-16, backward: bool = True):\n        defaults = dict(alpha=alpha, min_value=min_value, backward=backward)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        alpha, min_value = unpack_dicts(settings, 'alpha', 'min_value')\n        denom = [max(loss*a, mv) for a,mv in zip(alpha, min_value)]\n        torch._foreach_div_(tensors, denom)\n        return tensors\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Dropout","title":"Dropout","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Applies dropout to the update.</p> <p>For each weight the update to that weight has <code>p</code> probability to be set to 0. This can be used to implement gradient dropout or update dropout depending on placement.</p> <p>Parameters:</p> <ul> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>probability that update for a weight is replaced with 0. Defaults to 0.5.</p> </li> <li> <code>graft</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, update after dropout is rescaled to have the same norm as before dropout. Defaults to False.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var, refer to documentation. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/modules/misc/#torchzero.modules.misc.Dropout--examples","title":"Examples:","text":"<p>Gradient dropout.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Dropout(0.5),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre> <p>Update dropout.</p> <p>``python opt = tz.Optimizer(     model.parameters(),     tz.m.Adam(),     tz.m.Dropout(0.5),     tz.m.LR(1e-3) ) ```</p> Source code in <code>torchzero/modules/misc/regularization.py</code> <pre><code>class Dropout(Transform):\n    \"\"\"Applies dropout to the update.\n\n    For each weight the update to that weight has ``p`` probability to be set to 0.\n    This can be used to implement gradient dropout or update dropout depending on placement.\n\n    Args:\n        p (float, optional): probability that update for a weight is replaced with 0. Defaults to 0.5.\n        graft (bool, optional):\n            if True, update after dropout is rescaled to have the same norm as before dropout. Defaults to False.\n        target (Target, optional): what to set on var, refer to documentation. Defaults to 'update'.\n\n\n    ### Examples:\n\n    Gradient dropout.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Dropout(0.5),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Update dropout.\n\n    ``python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.Dropout(0.5),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, p: float = 0.5, graft: bool=False):\n        defaults = dict(p=p, graft=graft)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensors = TensorList(tensors)\n        p = NumberList(s['p'] for s in settings)\n        graft = settings[0]['graft']\n\n        if graft:\n            target_norm = tensors.global_vector_norm()\n            tensors.mul_(tensors.rademacher_like(1-p).add_(1).div_(2))\n            return tensors.mul_(target_norm / tensors.global_vector_norm()) # graft\n\n        return tensors.mul_(tensors.rademacher_like(1-p).add_(1).div_(2))\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.EscapeAnnealing","title":"EscapeAnnealing","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>If parameters stop changing, this runs a backward annealing random search</p> Source code in <code>torchzero/modules/misc/escape.py</code> <pre><code>class EscapeAnnealing(Module):\n    \"\"\"If parameters stop changing, this runs a backward annealing random search\"\"\"\n    def __init__(self, max_region:float = 1, max_iter:int = 1000, tol=1e-6, n_tol: int = 10):\n        defaults = dict(max_region=max_region, max_iter=max_iter, tol=tol, n_tol=n_tol)\n        super().__init__(defaults)\n\n\n    @torch.no_grad\n    def apply(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError(\"Escape requries closure\")\n\n        params = TensorList(objective.params)\n        settings = self.settings[params[0]]\n        max_region = self.get_settings(params, 'max_region', cls=NumberList)\n        max_iter = settings['max_iter']\n        tol = settings['tol']\n        n_tol = settings['n_tol']\n\n        n_bad = self.global_state.get('n_bad', 0)\n\n        prev_params = self.get_state(params, 'prev_params', cls=TensorList)\n        diff = params-prev_params\n        prev_params.copy_(params)\n\n        if diff.abs().global_max() &lt;= tol:\n            n_bad += 1\n\n        else:\n            n_bad = 0\n\n        self.global_state['n_bad'] = n_bad\n\n        # no progress\n        f_0 = objective.get_loss(False)\n        if n_bad &gt;= n_tol:\n            for i in range(1, max_iter+1):\n                alpha = max_region * (i / max_iter)\n                pert = params.sphere_like(radius=alpha)\n\n                params.add_(pert)\n                f_star = closure(False)\n\n                if math.isfinite(f_star) and f_star &lt; f_0-1e-12:\n                    objective.updates = None\n                    objective.stop = True\n                    objective.skip_update = True\n                    return objective\n\n                params.sub_(pert)\n\n            self.global_state['n_bad'] = 0\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.ExpHomotopy","title":"ExpHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class ExpHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return loss.exp()\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.FillLoss","title":"FillLoss","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with loss value times <code>alpha</code></p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class FillLoss(Module):\n    \"\"\"Outputs tensors filled with loss value times ``alpha``\"\"\"\n    def __init__(self, alpha: float = 1, backward: bool = True):\n        defaults = dict(alpha=alpha, backward=backward)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        alpha = self.get_settings(objective.params, 'alpha')\n        loss = objective.get_loss(backward=self.defaults['backward'])\n        objective.updates = [torch.full_like(p, loss*a) for p,a in zip(objective.params, alpha)]\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.GradSign","title":"GradSign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Copies gradient sign to update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GradSign(TensorTransform):\n    \"\"\"Copies gradient sign to update.\"\"\"\n    def __init__(self):\n        super().__init__(uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        return [t.copysign_(g) for t,g in zip(tensors, grads)]\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.GradientAccumulation","title":"GradientAccumulation","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Uses <code>n</code> steps to accumulate gradients, after <code>n</code> gradients have been accumulated, they are passed to :code:<code>modules</code> and parameters are updates.</p> <p>Accumulating gradients for <code>n</code> steps is equivalent to increasing batch size by <code>n</code>. Increasing the batch size is more computationally efficient, but sometimes it is not feasible due to memory constraints.</p> Note <p>Technically this can accumulate any inputs, including updates generated by previous modules. As long as this module is first, it will accumulate the gradients.</p> <p>Parameters:</p> <ul> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>number of gradients to accumulate.</p> </li> <li> <code>mean</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, uses mean of accumulated gradients, otherwise uses sum. Defaults to True.</p> </li> <li> <code>stop</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>this module prevents next modules from stepping unless <code>n</code> gradients have been accumulate. Setting this argument to False disables that. Defaults to True.</p> </li> </ul>"},{"location":"API/modules/misc/#torchzero.modules.misc.GradientAccumulation--examples","title":"Examples:","text":"<p>Adam with gradients accumulated for 16 batches.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GradientAccumulation(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/misc/gradient_accumulation.py</code> <pre><code>class GradientAccumulation(Module):\n    \"\"\"Uses ``n`` steps to accumulate gradients, after ``n`` gradients have been accumulated, they are passed to :code:`modules` and parameters are updates.\n\n    Accumulating gradients for ``n`` steps is equivalent to increasing batch size by ``n``. Increasing the batch size\n    is more computationally efficient, but sometimes it is not feasible due to memory constraints.\n\n    Note:\n        Technically this can accumulate any inputs, including updates generated by previous modules. As long as this module is first, it will accumulate the gradients.\n\n    Args:\n        n (int): number of gradients to accumulate.\n        mean (bool, optional): if True, uses mean of accumulated gradients, otherwise uses sum. Defaults to True.\n        stop (bool, optional):\n            this module prevents next modules from stepping unless ``n`` gradients have been accumulate. Setting this argument to False disables that. Defaults to True.\n\n    ## Examples:\n\n    Adam with gradients accumulated for 16 batches.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GradientAccumulation(),\n        tz.m.Adam(),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(self, n: int, mean=True, stop=True):\n        defaults = dict(n=n, mean=mean, stop=stop)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"accumulator\")\n\n\n    @torch.no_grad\n    def apply(self, objective):\n        accumulator = self.get_state(objective.params, 'accumulator')\n        settings = self.defaults\n        n = settings['n']; mean = settings['mean']; stop = settings['stop']\n        step = self.increment_counter(\"step\", 0)\n\n        # add update to accumulator\n        torch._foreach_add_(accumulator, objective.get_updates())\n\n        # step with accumulated updates\n        if (step + 1) % n == 0:\n            if mean:\n                torch._foreach_div_(accumulator, n)\n\n            objective.updates = accumulator\n\n            # zero accumulator\n            self.clear_state_keys('accumulator')\n\n        else:\n            # prevent update\n            if stop:\n                objective.updates = None\n                objective.stop=True\n                objective.skip_update=True\n\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.GraftGradToUpdate","title":"GraftGradToUpdate","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs gradient grafted to update, that is gradient rescaled to have the same norm as the update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GraftGradToUpdate(TensorTransform):\n    \"\"\"Outputs gradient grafted to update, that is gradient rescaled to have the same norm as the update.\"\"\"\n    def __init__(self, tensorwise:bool=False, ord:Metrics=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(settings[0])\n        return TensorList(grads).graft(tensors, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.GraftToGrad","title":"GraftToGrad","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Grafts update to the gradient, that is update is rescaled to have the same norm as the gradient.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GraftToGrad(TensorTransform):\n    \"\"\"Grafts update to the gradient, that is update is rescaled to have the same norm as the gradient.\"\"\"\n    def __init__(self, tensorwise:bool=False, ord:Metrics=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(settings[0])\n        return TensorList(tensors).graft_(grads, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.GraftToParams","title":"GraftToParams","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Grafts update to the parameters, that is update is rescaled to have the same norm as the parameters, but no smaller than <code>eps</code>.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class GraftToParams(TensorTransform):\n    \"\"\"Grafts update to the parameters, that is update is rescaled to have the same norm as the parameters, but no smaller than ``eps``.\"\"\"\n    def __init__(self, tensorwise:bool=False, ord:Metrics=2, eps:float = 1e-4):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(settings[0])\n        return TensorList(tensors).graft_(params, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.HpuEstimate","title":"HpuEstimate","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>returns <code>y/||s||</code>, where <code>y</code> is difference between current and previous update (gradient), <code>s</code> is difference between current and previous parameters. The returned tensors are a finite difference approximation to hessian times previous update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class HpuEstimate(TensorTransform):\n    \"\"\"returns ``y/||s||``, where ``y`` is difference between current and previous update (gradient), ``s`` is difference between current and previous parameters. The returned tensors are a finite difference approximation to hessian times previous update.\"\"\"\n    def __init__(self):\n        defaults = dict()\n        super().__init__(defaults)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_params', 'prev_update')\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        prev_params, prev_update = self.get_state(params, 'prev_params', 'prev_update') # initialized to 0\n        s = torch._foreach_sub(params, prev_params)\n        y = torch._foreach_sub(tensors, prev_update)\n        for p, c in zip(prev_params, params): p.copy_(c)\n        for p, c in zip(prev_update, tensors): p.copy_(c)\n        torch._foreach_div_(y, torch.linalg.norm(torch.cat([t.ravel() for t in s])).clip(min=1e-8)) # pylint:disable=not-callable\n        self.store(params, 'y', y)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return [self.state[p]['y'] for p in params]\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.LambdaHomotopy","title":"LambdaHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class LambdaHomotopy(HomotopyBase):\n    def __init__(self, fn: Callable[[torch.Tensor], torch.Tensor]):\n        defaults = dict(fn=fn)\n        super().__init__(defaults)\n\n    def loss_transform(self, loss): return self.defaults['fn'](loss)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.LastAbsoluteRatio","title":"LastAbsoluteRatio","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs ratio between absolute values of past two updates the numerator is determined by <code>numerator</code> argument.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastAbsoluteRatio(TensorTransform):\n    \"\"\"Outputs ratio between absolute values of past two updates the numerator is determined by ``numerator`` argument.\"\"\"\n    def __init__(self, numerator: Literal['cur', 'prev'] = 'cur', eps:float=1e-8):\n        defaults = dict(numerator=numerator, eps=eps)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', init = torch.ones_like) # initialized to ones\n        numerator = settings[0]['numerator']\n        eps = NumberList(s['eps'] for s in settings)\n\n        torch._foreach_abs_(tensors)\n        torch._foreach_clamp_min_(prev, eps)\n\n        if numerator == 'cur': ratio = torch._foreach_div(tensors, prev)\n        else: ratio = torch._foreach_div(prev, tensors)\n        for p, c in zip(prev, tensors): p.set_(c)\n        return ratio\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.LastDifference","title":"LastDifference","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs difference between past two updates.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastDifference(TensorTransform):\n    \"\"\"Outputs difference between past two updates.\"\"\"\n    def __init__(self,):\n        super().__init__()\n        self.add_projected_keys(\"grad\", \"prev_tensors\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev_tensors = unpack_states(states, tensors, 'prev_tensors') # initialized to 0\n        difference = torch._foreach_sub(tensors, prev_tensors)\n        for p, c in zip(prev_tensors, tensors): p.set_(c)\n        return difference\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.LastGradDifference","title":"LastGradDifference","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs difference between past two gradients.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastGradDifference(Module):\n    \"\"\"Outputs difference between past two gradients.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.add_projected_keys(\"grad\", \"prev_grad\")\n\n    @torch.no_grad\n    def apply(self, objective):\n        grad = objective.get_grads()\n        prev_grad = self.get_state(objective.params, 'prev_grad') # initialized to 0\n        difference = torch._foreach_sub(grad, prev_grad)\n        for p, c in zip(prev_grad, grad): p.copy_(c)\n        objective.updates = list(difference)\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.LastProduct","title":"LastProduct","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs difference between past two updates.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastProduct(TensorTransform):\n    \"\"\"Outputs difference between past two updates.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', init=torch.ones_like) # initialized to 1 for prod\n        prod = torch._foreach_mul(tensors, prev)\n        for p, c in zip(prev, tensors): p.set_(c)\n        return prod\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.LastRatio","title":"LastRatio","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs ratio between past two updates, the numerator is determined by <code>numerator</code> argument.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class LastRatio(TensorTransform):\n    \"\"\"Outputs ratio between past two updates, the numerator is determined by ``numerator`` argument.\"\"\"\n    def __init__(self, numerator: Literal['cur', 'prev'] = 'cur'):\n        defaults = dict(numerator=numerator)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"prev\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prev = unpack_states(states, tensors, 'prev', init = torch.ones_like) # initialized to ones\n        numerator = settings[0]['numerator']\n        if numerator == 'cur': ratio = torch._foreach_div(tensors, prev)\n        else: ratio = torch._foreach_div(prev, tensors)\n        for p, c in zip(prev, tensors): p.set_(c)\n        return ratio\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.LogHomotopy","title":"LogHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class LogHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return (loss+1e-12).log()\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.MulByLoss","title":"MulByLoss","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies update by loss times <code>alpha</code></p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class MulByLoss(TensorTransform):\n    \"\"\"Multiplies update by loss times ``alpha``\"\"\"\n    def __init__(self, alpha: float = 1, min_value:float = 1e-16, backward: bool = True):\n        defaults = dict(alpha=alpha, min_value=min_value, backward=backward)\n        super().__init__(defaults, uses_loss=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert loss is not None\n        alpha, min_value = unpack_dicts(settings, 'alpha', 'min_value')\n        mul = [max(loss*a, mv) for a,mv in zip(alpha, min_value)]\n        torch._foreach_mul_(tensors, mul)\n        return tensors\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Multistep","title":"Multistep","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Performs <code>steps</code> inner steps with <code>module</code> per each step.</p> <p>The update is taken to be the parameter difference between parameters before and after the inner loop.</p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class Multistep(Module):\n    \"\"\"Performs ``steps`` inner steps with ``module`` per each step.\n\n    The update is taken to be the parameter difference between parameters before and after the inner loop.\"\"\"\n    def __init__(self, module: Chainable, steps: int):\n        defaults = dict(steps=steps)\n        super().__init__(defaults)\n        self.set_child('module', module)\n\n    @torch.no_grad\n    def apply(self, objective):\n        return _sequential_step(self, objective, sequential=False)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.NegateOnLossIncrease","title":"NegateOnLossIncrease","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Uses an extra forward pass to evaluate loss at <code>parameters+update</code>, if loss is larger than at <code>parameters</code>, the update is set to 0 if <code>backtrack=False</code> and to <code>-update</code> otherwise</p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class NegateOnLossIncrease(Module):\n    \"\"\"Uses an extra forward pass to evaluate loss at ``parameters+update``,\n    if loss is larger than at ``parameters``,\n    the update is set to 0 if ``backtrack=False`` and to ``-update`` otherwise\"\"\"\n    def __init__(self, backtrack=False):\n        defaults = dict(backtrack=backtrack)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError('NegateOnLossIncrease requires closure')\n        backtrack = self.defaults['backtrack']\n\n        update = objective.get_updates()\n        f_0 = objective.get_loss(backward=False)\n\n        torch._foreach_sub_(objective.params, update)\n        f_1 = closure(False)\n\n        if f_1 &lt;= f_0:\n            # if var.is_last and var.last_module_lrs is None:\n            #     var.stop = True\n            #     var.skip_update = True\n            #     return var\n\n            torch._foreach_add_(objective.params, update)\n            return objective\n\n        torch._foreach_add_(objective.params, update)\n        if backtrack:\n            torch._foreach_neg_(objective.updates)\n        else:\n            torch._foreach_zero_(objective.updates)\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.NoiseSign","title":"NoiseSign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs random tensors with sign copied from the update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class NoiseSign(TensorTransform):\n    \"\"\"Outputs random tensors with sign copied from the update.\"\"\"\n    def __init__(self, distribution:Distributions = 'normal', variance:float | None = None):\n        defaults = dict(distribution=distribution, variance=variance)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        variance = unpack_dicts(settings, 'variance')\n        return TensorList(tensors).sample_like(settings[0]['distribution'], variance=variance).copysign_(tensors)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Online","title":"Online","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Allows certain modules to be used for mini-batch optimization.</p> <p>Examples:</p> <p>Online L-BFGS with Backtracking line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Online(tz.m.LBFGS()),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>Online L-BFGS trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.Online(tz.m.LBFGS()))\n)\n</code></pre></p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class Online(Module):\n    \"\"\"Allows certain modules to be used for mini-batch optimization.\n\n    Examples:\n\n    Online L-BFGS with Backtracking line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Online(tz.m.LBFGS()),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Online L-BFGS trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.Online(tz.m.LBFGS()))\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, module: Module,):\n        super().__init__()\n        self.set_child('module', module)\n\n    @torch.no_grad\n    def update(self, objective):\n        closure = objective.closure\n        if closure is None: raise ValueError(\"Closure must be passed for Online\")\n\n        step = self.increment_counter(\"step\", start = 0)\n\n        params = TensorList(objective.params)\n        p_cur = params.clone()\n        p_prev = self.get_state(params, 'p_prev', cls=TensorList)\n\n        module = self.children['module']\n        var_c = objective.clone(clone_updates=False)\n\n        # on 1st step just step and store previous params\n        if step == 0:\n            p_prev.copy_(params)\n\n            module.update(var_c)\n            objective.update_attrs_from_clone_(var_c)\n            return\n\n        # restore previous params and update\n        prev_objective = Objective(params=params, closure=closure, model=objective.model, current_step=objective.current_step)\n        params.set_(p_prev)\n        module.reset_for_online()\n        module.update(prev_objective)\n\n        # restore current params and update\n        params.set_(p_cur)\n        p_prev.copy_(params)\n        module.update(var_c)\n        objective.update_attrs_from_clone_(var_c)\n\n    @torch.no_grad\n    def apply(self, objective):\n        module = self.children['module']\n        return module.apply(objective.clone(clone_updates=False))\n\n    def get_H(self, objective):\n        return self.children['module'].get_H(objective)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.PerturbWeights","title":"PerturbWeights","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Changes the closure so that it evaluates loss and gradients at weights perturbed by a random perturbation.</p> <p>Can be disabled for a parameter by setting <code>perturb=False</code> in corresponding parameter group.</p> <p>Parameters:</p> <ul> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>multiplier for perturbation magnitude. Defaults to 0.1.</p> </li> <li> <code>relative</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to multiply perturbation by mean absolute value of the parameter. Defaults to True.</p> </li> <li> <code>distribution</code>               (<code>bool</code>, default:                   <code>'normal'</code> )           \u2013            <p>distribution of the random perturbation. Defaults to False.</p> </li> </ul> Source code in <code>torchzero/modules/misc/regularization.py</code> <pre><code>class PerturbWeights(Module):\n    \"\"\"\n    Changes the closure so that it evaluates loss and gradients at weights perturbed by a random perturbation.\n\n    Can be disabled for a parameter by setting ``perturb=False`` in corresponding parameter group.\n\n    Args:\n        alpha (float, optional): multiplier for perturbation magnitude. Defaults to 0.1.\n        relative (bool, optional): whether to multiply perturbation by mean absolute value of the parameter. Defaults to True.\n        distribution (bool, optional):\n            distribution of the random perturbation. Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = 0.1,\n        relative: bool = True,\n        distribution: Distributions = \"normal\",\n        metric: Metrics = \"mad\",\n    ):\n        defaults = dict(alpha=alpha, relative=relative, distribution=distribution, metric=metric, perturb=True)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def update(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError('WeightDropout requires closure')\n        params = TensorList(objective.params)\n\n        # create perturbations\n        perts = []\n        for p in params:\n            settings = self.settings[p]\n            if not settings['perturb']:\n                perts.append(torch.zeros_like(p))\n                continue\n\n            alpha = settings['alpha']\n            if settings['relative']:\n                alpha *= evaluate_metric(p, settings[\"metric\"])\n\n            distribution = self.settings[p]['distribution'].lower()\n            if distribution in ('normal', 'gaussian'):\n                perts.append(torch.randn_like(p).mul_(alpha))\n            elif distribution == 'uniform':\n                perts.append(torch.empty_like(p).uniform_(-alpha,alpha))\n            elif distribution == 'sphere':\n                r = torch.randn_like(p)\n                perts.append((r * alpha) / torch.linalg.vector_norm(r)) # pylint:disable=not-callable\n            else:\n                raise ValueError(distribution)\n\n        @torch.no_grad\n        def perturbed_closure(backward=True):\n            params.add_(perts)\n            if backward:\n                with torch.enable_grad(): loss = closure()\n            else:\n                loss = closure(False)\n            params.sub_(perts)\n            return loss\n\n        objective.closure = perturbed_closure\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Previous","title":"Previous","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an update from n steps back, for example if n=1, returns previous update</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class Previous(TensorTransform):\n    \"\"\"Maintains an update from n steps back, for example if n=1, returns previous update\"\"\"\n    def __init__(self, n=1):\n        defaults = dict(n=n)\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        n = setting['n']\n\n        if 'history' not in state:\n            state['history'] = deque(maxlen=n+1)\n\n        state['history'].append(tensor)\n\n        return state['history'][0]\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.PrintLoss","title":"PrintLoss","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints var.get_loss().</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintLoss(Module):\n    \"\"\"Prints var.get_loss().\"\"\"\n    def __init__(self, text = 'loss = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{objective.get_loss(False)}')\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.PrintParams","title":"PrintParams","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints current update.</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintParams(Module):\n    \"\"\"Prints current update.\"\"\"\n    def __init__(self, text = 'params = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{objective.params}')\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.PrintShape","title":"PrintShape","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints shapes of the update.</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintShape(Module):\n    \"\"\"Prints shapes of the update.\"\"\"\n    def __init__(self, text = 'shapes = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        shapes = [u.shape for u in objective.updates] if objective.updates is not None else None\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{shapes}')\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.PrintUpdate","title":"PrintUpdate","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Prints current update.</p> Source code in <code>torchzero/modules/misc/debug.py</code> <pre><code>class PrintUpdate(Module):\n    \"\"\"Prints current update.\"\"\"\n    def __init__(self, text = 'update = ', print_fn = print):\n        defaults = dict(text=text, print_fn=print_fn)\n        super().__init__(defaults)\n\n    def apply(self, objective):\n        self.defaults[\"print_fn\"](f'{self.defaults[\"text\"]}{objective.updates}')\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.RandomHvp","title":"RandomHvp","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Returns a hessian-vector product with a random vector, optionally times vector</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class RandomHvp(Module):\n    \"\"\"Returns a hessian-vector product with a random vector, optionally times vector\"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 1,\n        distribution: Distributions = \"normal\",\n        update_freq: int = 1,\n        zHz: bool = False,\n        hvp_method: Literal[\"autograd\", \"fd_forward\", \"central\"] = \"autograd\",\n        h=1e-3,\n        seed: int | None = None\n    ):\n        defaults = locals().copy()\n        del defaults['self']\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        params = TensorList(objective.params)\n\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        D = None\n        update_freq = self.defaults['update_freq']\n        if step % update_freq == 0:\n\n            D, _ = objective.hutchinson_hessian(\n                rgrad = None,\n                at_x0 = True,\n                n_samples = self.defaults['n_samples'],\n                distribution = self.defaults['distribution'],\n                hvp_method = self.defaults['hvp_method'],\n                h = self.defaults['h'],\n                zHz = self.defaults[\"zHz\"],\n                generator = self.get_generator(params[0].device, self.defaults[\"seed\"]),\n            )\n\n            if update_freq != 1:\n                assert D is not None\n                D_buf = self.get_state(params, \"D\", cls=TensorList)\n                D_buf.set_(D)\n\n        if D is None:\n            D = self.get_state(params, \"D\", cls=TensorList)\n\n        objective.updates = list(D)\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Relative","title":"Relative","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies update by absolute parameter values to make it relative to their magnitude, <code>min_value</code> is minimum allowed value to avoid getting stuck at 0.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class Relative(TensorTransform):\n    \"\"\"Multiplies update by absolute parameter values to make it relative to their magnitude, ``min_value`` is minimum allowed value to avoid getting stuck at 0.\"\"\"\n    def __init__(self, min_value:float = 1e-4):\n        defaults = dict(min_value=min_value)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        mul = TensorList(params).abs().clamp_([s['min_value'] for s in settings])\n        torch._foreach_mul_(tensors, mul)\n        return tensors\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.SaveBest","title":"SaveBest","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Saves best parameters found so far, ones that have lowest loss. Put this as the last module.</p> <p>Adds the following attrs:</p> <ul> <li><code>best_params</code> - a list of tensors with best parameters.</li> <li><code>best_loss</code> - loss value with <code>best_params</code>.</li> <li><code>load_best_parameters</code> - a function that sets parameters to the best parameters./</li> </ul>"},{"location":"API/modules/misc/#torchzero.modules.misc.SaveBest--examples","title":"Examples","text":"<p>```python def rosenbrock(x, y):     return (1 - x)2 + (100 * (y - x2))**2</p> <p>xy = torch.tensor((-1.1, 2.5), requires_grad=True) opt = tz.Optimizer(     [xy],     tz.m.NAG(0.999),     tz.m.LR(1e-6),     tz.m.SaveBest() )</p>"},{"location":"API/modules/misc/#torchzero.modules.misc.SaveBest--optimize-for-1000-steps","title":"optimize for 1000 steps","text":"<p>for i in range(1000):     loss = rosenbrock(*xy)     opt.zero_grad()     loss.backward()     opt.step(loss=loss) # SaveBest needs closure or loss</p>"},{"location":"API/modules/misc/#torchzero.modules.misc.SaveBest--nag-overshot-but-we-saved-the-best-params","title":"NAG overshot, but we saved the best params","text":"<p>print(f'{rosenbrock(*xy) = }') # &gt;&gt; 3.6583 print(f\"{opt.attrs['best_loss'] = }\") # &gt;&gt; 0.000627</p>"},{"location":"API/modules/misc/#torchzero.modules.misc.SaveBest--load-best-parameters","title":"load best parameters","text":"<p>opt.attrs'load_best_params' print(f'{rosenbrock(*xy) = }') # &gt;&gt; 0.000627</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class SaveBest(Module):\n    \"\"\"Saves best parameters found so far, ones that have lowest loss. Put this as the last module.\n\n    Adds the following attrs:\n\n    - ``best_params`` - a list of tensors with best parameters.\n    - ``best_loss`` - loss value with ``best_params``.\n    - ``load_best_parameters`` - a function that sets parameters to the best parameters./\n\n    ## Examples\n    ```python\n    def rosenbrock(x, y):\n        return (1 - x)**2 + (100 * (y - x**2))**2\n\n    xy = torch.tensor((-1.1, 2.5), requires_grad=True)\n    opt = tz.Optimizer(\n        [xy],\n        tz.m.NAG(0.999),\n        tz.m.LR(1e-6),\n        tz.m.SaveBest()\n    )\n\n    # optimize for 1000 steps\n    for i in range(1000):\n        loss = rosenbrock(*xy)\n        opt.zero_grad()\n        loss.backward()\n        opt.step(loss=loss) # SaveBest needs closure or loss\n\n    # NAG overshot, but we saved the best params\n    print(f'{rosenbrock(*xy) = }') # &gt;&gt; 3.6583\n    print(f\"{opt.attrs['best_loss'] = }\") # &gt;&gt; 0.000627\n\n    # load best parameters\n    opt.attrs['load_best_params']()\n    print(f'{rosenbrock(*xy) = }') # &gt;&gt; 0.000627\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    @torch.no_grad\n    def apply(self, objective):\n        loss = tofloat(objective.get_loss(False))\n        lowest_loss = self.global_state.get('lowest_loss', float(\"inf\"))\n\n        if loss &lt; lowest_loss:\n            self.global_state['lowest_loss'] = loss\n            best_params = objective.attrs['best_params'] = [p.clone() for p in objective.params]\n            objective.attrs['best_loss'] = loss\n            objective.attrs['load_best_params'] = partial(_load_best_parameters, params=objective.params, best_params=best_params)\n\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Sequential","title":"Sequential","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>On each step, this sequentially steps with <code>modules</code> <code>steps</code> times.</p> <p>The update is taken to be the parameter difference between parameters before and after the inner loop.</p> Source code in <code>torchzero/modules/misc/multistep.py</code> <pre><code>class Sequential(Module):\n    \"\"\"On each step, this sequentially steps with ``modules`` ``steps`` times.\n\n    The update is taken to be the parameter difference between parameters before and after the inner loop.\"\"\"\n    def __init__(self, modules: Iterable[Chainable], steps: int=1):\n        defaults = dict(steps=steps)\n        super().__init__(defaults)\n        self.set_children_sequence(modules)\n\n    @torch.no_grad\n    def apply(self, objective):\n        return _sequential_step(self, objective, sequential=True)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Split","title":"Split","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Apply <code>true</code> modules to all parameters filtered by <code>filter</code>, apply <code>false</code> modules to all other parameters.</p> <p>Parameters:</p> <ul> <li> <code>filter</code>               (<code>Filter, bool]</code>)           \u2013            <p>a filter that selects tensors to be optimized by <code>true</code>. - tensor or iterable of tensors (e.g. <code>encoder.parameters()</code>). - function that takes in tensor and outputs a bool (e.g. <code>lambda x: x.ndim &gt;= 2</code>). - a sequence of above (acts as \"or\", so returns true if any of them is true).</p> </li> <li> <code>true</code>               (<code>Chainable | None</code>)           \u2013            <p>modules that are applied to tensors where <code>filter</code> is <code>True</code>.</p> </li> <li> <code>false</code>               (<code>Chainable | None</code>)           \u2013            <p>modules that are applied to tensors where <code>filter</code> is <code>False</code>.</p> </li> </ul>"},{"location":"API/modules/misc/#torchzero.modules.misc.Split--examples","title":"Examples:","text":"<p>Muon with Adam fallback using same hyperparams as https://github.com/KellerJordan/Muon</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NAG(0.95),\n    tz.m.Split(\n        lambda p: p.ndim &gt;= 2,\n        true = tz.m.Orthogonalize(),\n        false = [tz.m.Adam(0.9, 0.95), tz.m.Mul(1/66)],\n    ),\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/misc/split.py</code> <pre><code>class Split(Module):\n    \"\"\"Apply ``true`` modules to all parameters filtered by ``filter``, apply ``false`` modules to all other parameters.\n\n    Args:\n        filter (Filter, bool]):\n            a filter that selects tensors to be optimized by ``true``.\n            - tensor or iterable of tensors (e.g. ``encoder.parameters()``).\n            - function that takes in tensor and outputs a bool (e.g. ``lambda x: x.ndim &gt;= 2``).\n            - a sequence of above (acts as \"or\", so returns true if any of them is true).\n\n        true (Chainable | None): modules that are applied to tensors where ``filter`` is ``True``.\n        false (Chainable | None): modules that are applied to tensors where ``filter`` is ``False``.\n\n    ### Examples:\n\n    Muon with Adam fallback using same hyperparams as https://github.com/KellerJordan/Muon\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NAG(0.95),\n        tz.m.Split(\n            lambda p: p.ndim &gt;= 2,\n            true = tz.m.Orthogonalize(),\n            false = [tz.m.Adam(0.9, 0.95), tz.m.Mul(1/66)],\n        ),\n        tz.m.LR(1e-2),\n    )\n    ```\n    \"\"\"\n    def __init__(self, filter: Filter, true: Chainable | None, false: Chainable | None):\n        defaults = dict(filter=filter)\n        super().__init__(defaults)\n\n        if true is not None: self.set_child('true', true)\n        if false is not None: self.set_child('false', false)\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    def step(self, objective):\n\n        params = objective.params\n        filter = _make_filter(self.settings[params[0]]['filter'])\n\n        true_idxs = []\n        false_idxs = []\n        for i,p in enumerate(params):\n            if filter(p): true_idxs.append(i)\n            else: false_idxs.append(i)\n\n        if 'true' in self.children and len(true_idxs) &gt; 0:\n            true = self.children['true']\n            objective = _split(true, idxs=true_idxs, params=params, objective=objective)\n\n        if 'false' in self.children and len(false_idxs) &gt; 0:\n            false = self.children['false']\n            objective = _split(false, idxs=false_idxs, params=params, objective=objective)\n\n        return objective\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.SqrtHomotopy","title":"SqrtHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class SqrtHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return (loss+1e-12).sqrt()\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.SquareHomotopy","title":"SquareHomotopy","text":"<p>               Bases: <code>torchzero.modules.misc.homotopy.HomotopyBase</code></p> Source code in <code>torchzero/modules/misc/homotopy.py</code> <pre><code>class SquareHomotopy(HomotopyBase):\n    def __init__(self): super().__init__()\n    def loss_transform(self, loss): return loss.square().copysign(loss)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Switch","title":"Switch","text":"<p>               Bases: <code>torchzero.modules.misc.switch.Alternate</code></p> <p>After <code>steps</code> steps switches to the next module.</p> <p>Parameters:</p> <ul> <li> <code>steps</code>               (<code>int | Iterable[int]</code>)           \u2013            <p>Number of steps to perform with each module.</p> </li> </ul>"},{"location":"API/modules/misc/#torchzero.modules.misc.Switch--examples","title":"Examples:","text":"<p>Start with Adam, switch to L-BFGS after 1000th step and Truncated Newton on 2000th step.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Switch(\n        [tz.m.Adam(), tz.m.LR(1e-3)],\n        [tz.m.LBFGS(), tz.m.Backtracking()],\n        [tz.m.NewtonCG(maxiter=20), tz.m.Backtracking()],\n        steps = (1000, 2000)\n    )\n)\n</code></pre> Source code in <code>torchzero/modules/misc/switch.py</code> <pre><code>class Switch(Alternate):\n    \"\"\"After ``steps`` steps switches to the next module.\n\n    Args:\n        steps (int | Iterable[int]): Number of steps to perform with each module.\n\n    ### Examples:\n\n    Start with Adam, switch to L-BFGS after 1000th step and Truncated Newton on 2000th step.\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Switch(\n            [tz.m.Adam(), tz.m.LR(1e-3)],\n            [tz.m.LBFGS(), tz.m.Backtracking()],\n            [tz.m.NewtonCG(maxiter=20), tz.m.Backtracking()],\n            steps = (1000, 2000)\n        )\n    )\n    ```\n    \"\"\"\n\n    LOOP = False\n    def __init__(self, *modules: Chainable, steps: int | Iterable[int]):\n\n        if isinstance(steps, Iterable):\n            steps = list(steps)\n            if len(steps) != len(modules) - 1:\n                raise ValueError(f\"steps must be the same length as modules minus 1, got {len(modules) = }, {len(steps) = }\")\n\n            steps.append(1)\n\n        super().__init__(*modules, steps=steps)\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.Switch.LOOP","title":"LOOP  <code>class-attribute</code>","text":"<pre><code>LOOP = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/misc/#torchzero.modules.misc.UpdateSign","title":"UpdateSign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Outputs gradient with sign copied from the update.</p> Source code in <code>torchzero/modules/misc/misc.py</code> <pre><code>class UpdateSign(TensorTransform):\n    \"\"\"Outputs gradient with sign copied from the update.\"\"\"\n    def __init__(self):\n        super().__init__(uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        return [g.copysign(t) for t,g in zip(tensors, grads)] # no in-place\n</code></pre>"},{"location":"API/modules/misc/#torchzero.modules.misc.WeightDropout","title":"WeightDropout","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Changes the closure so that it evaluates loss and gradients with random weights replaced with 0.</p> <p>Dropout can be disabled for a parameter by setting <code>use_dropout=False</code> in corresponding parameter group.</p> <p>Parameters:</p> <ul> <li> <code>p</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>probability that any weight is replaced with 0. Defaults to 0.5.</p> </li> </ul> Source code in <code>torchzero/modules/misc/regularization.py</code> <pre><code>class WeightDropout(Module):\n    \"\"\"\n    Changes the closure so that it evaluates loss and gradients with random weights replaced with 0.\n\n    Dropout can be disabled for a parameter by setting ``use_dropout=False`` in corresponding parameter group.\n\n    Args:\n        p (float, optional): probability that any weight is replaced with 0. Defaults to 0.5.\n    \"\"\"\n    def __init__(self, p: float = 0.5):\n        defaults = dict(p=p, use_dropout=True)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def update(self, objective):\n        closure = objective.closure\n        if closure is None: raise RuntimeError('WeightDropout requires closure')\n        params = TensorList(objective.params)\n        p = NumberList(self.settings[p]['p'] for p in params)\n\n        # create masks\n        mask = []\n        for p in params:\n            prob = self.settings[p]['p']\n            use_dropout = self.settings[p]['use_dropout']\n            if use_dropout: mask.append(_bernoulli_like(p, prob))\n            else: mask.append(torch.ones_like(p))\n\n        # create a closure that evaluates masked parameters\n        @torch.no_grad\n        def dropout_closure(backward=True):\n            orig_params = params.clone()\n            params.mul_(mask)\n            if backward:\n                with torch.enable_grad(): loss = closure()\n            else:\n                loss = closure(False)\n            params.copy_(orig_params)\n            return loss\n\n        objective.closure = dropout_closure\n</code></pre>"},{"location":"API/modules/momentum/","title":"Momentum","text":"<p>This subpackage contains momentums and exponential moving averages.</p> <p>Classes:</p> <ul> <li> <code>Averaging</code>           \u2013            <p>Average of past <code>history_size</code> updates.</p> </li> <li> <code>Cautious</code>           \u2013            <p>Negates update for parameters where update and gradient sign is inconsistent.</p> </li> <li> <code>EMA</code>           \u2013            <p>Maintains an exponential moving average of update.</p> </li> <li> <code>HeavyBall</code>           \u2013            <p>Polyak's momentum (heavy-ball method).</p> </li> <li> <code>IntermoduleCautious</code>           \u2013            <p>Negaties update on :code:<code>main</code> module where it's sign doesn't match with output of <code>compare</code> module.</p> </li> <li> <code>MedianAveraging</code>           \u2013            <p>Median of past <code>history_size</code> updates.</p> </li> <li> <code>NAG</code>           \u2013            <p>Nesterov accelerated gradient method (nesterov momentum).</p> </li> <li> <code>ScaleByGradCosineSimilarity</code>           \u2013            <p>Multiplies the update by cosine similarity with gradient.</p> </li> <li> <code>ScaleModulesByCosineSimilarity</code>           \u2013            <p>Scales the output of <code>main</code> module by it's cosine similarity to the output</p> </li> <li> <code>UpdateGradientSignConsistency</code>           \u2013            <p>Compares update and gradient signs. Output will have 1s where signs match, and 0s where they don't.</p> </li> <li> <code>WeightedAveraging</code>           \u2013            <p>Weighted average of past <code>len(weights)</code> updates.</p> </li> </ul>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.Averaging","title":"Averaging","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Average of past <code>history_size</code> updates.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>)           \u2013            <p>Number of past updates to average</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/averaging.py</code> <pre><code>class Averaging(TensorTransform):\n    \"\"\"Average of past ``history_size`` updates.\n\n    Args:\n        history_size (int): Number of past updates to average\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, history_size: int):\n        defaults = dict(history_size=history_size)\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\", \"average\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        history_size = setting['history_size']\n        if 'history' not in state:\n            state['history'] = deque(maxlen=history_size)\n            state['average'] = torch.zeros_like(tensor)\n\n        history = state['history']; average = state['average']\n        if len(history) == history_size: average -= history[0]\n        history.append(tensor)\n        average += tensor\n\n        return average / len(history)\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.Cautious","title":"Cautious","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Negates update for parameters where update and gradient sign is inconsistent. Optionally normalizes the update by the number of parameters that are not masked. This is meant to be used after any momentum-based modules.</p> <p>Parameters:</p> <ul> <li> <code>normalize</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>renormalize update after masking. only has effect when mode is 'zero'. Defaults to False.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for normalization. Defaults to 1e-6.</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'zero'</code> )           \u2013            <p>what to do with updates with inconsistent signs. - \"zero\" - set them to zero (as in paper) - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign) - \"backtrack\" - negate them</p> </li> </ul>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.Cautious--examples","title":"Examples:","text":"<p>Cautious Adam</p> <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.Adam(),\n    tz.m.Cautious(),\n    tz.m.LR(1e-2)\n)\n</code></pre> References <p>Cautious Optimizers: Improving Training with One Line of Code. Kaizhao Liang, Lizhang Chen, Bo Liu, Qiang Liu</p> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class Cautious(TensorTransform):\n    \"\"\"Negates update for parameters where update and gradient sign is inconsistent.\n    Optionally normalizes the update by the number of parameters that are not masked.\n    This is meant to be used after any momentum-based modules.\n\n    Args:\n        normalize (bool, optional):\n            renormalize update after masking.\n            only has effect when mode is 'zero'. Defaults to False.\n        eps (float, optional): epsilon for normalization. Defaults to 1e-6.\n        mode (str, optional):\n            what to do with updates with inconsistent signs.\n            - \"zero\" - set them to zero (as in paper)\n            - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign)\n            - \"backtrack\" - negate them\n\n    ## Examples:\n\n    Cautious Adam\n\n    ```python\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.Adam(),\n        tz.m.Cautious(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    References:\n        Cautious Optimizers: Improving Training with One Line of Code. Kaizhao Liang, Lizhang Chen, Bo Liu, Qiang Liu\n    \"\"\"\n\n    def __init__(\n        self,\n        normalize=False,\n        eps=1e-6,\n        mode: Literal[\"zero\", \"grad\", \"backtrack\"] = \"zero\",\n    ):\n        defaults = dict(normalize=normalize, eps=eps, mode=mode)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        mode, normalize, eps = itemgetter('mode', 'normalize', 'eps')(settings[0])\n        return cautious_(TensorList(tensors), TensorList(grads), normalize=normalize, eps=eps, mode=mode)\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.EMA","title":"EMA","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an exponential moving average of update.</p> <p>Parameters:</p> <ul> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>dampening</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>momentum dampening. Defaults to 0.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to debias the EMA like in Adam. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to use linear interpolation. Defaults to True.</p> </li> <li> <code>ema_init</code>               (<code>str</code>, default:                   <code>'zeros'</code> )           \u2013            <p>initial values for the EMA, \"zeros\" or \"update\".</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target to apply EMA to. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/momentum.py</code> <pre><code>class EMA(TensorTransform):\n    \"\"\"Maintains an exponential moving average of update.\n\n    Args:\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        dampening (float, optional): momentum dampening. Defaults to 0.\n        debias (bool, optional): whether to debias the EMA like in Adam. Defaults to False.\n        lerp (bool, optional): whether to use linear interpolation. Defaults to True.\n        ema_init (str, optional): initial values for the EMA, \"zeros\" or \"update\".\n        target (Target, optional): target to apply EMA to. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, momentum:float=0.9, dampening:float=0, debias: bool = False, lerp=True, ema_init: Literal['zeros', 'update'] = 'zeros'):\n        defaults = dict(momentum=momentum,dampening=dampening,debias=debias,lerp=lerp,ema_init=ema_init)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        debias, lerp, ema_init = itemgetter('debias','lerp','ema_init')(settings[0])\n\n        exp_avg = unpack_states(states, tensors, 'exp_avg',\n                                init=torch.zeros_like if ema_init=='zeros' else tensors, cls=TensorList)\n        momentum, dampening = unpack_dicts(settings, 'momentum','dampening', cls=NumberList)\n\n        exp_avg = ema_(TensorList(tensors), exp_avg_=exp_avg,beta=momentum,dampening=dampening,lerp=lerp)\n\n        if debias: return _debias(exp_avg, step=step, beta1=momentum, alpha=1, inplace=False)\n        else: return exp_avg.clone() # this has exp_avg storage so needs to be cloned\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.HeavyBall","title":"HeavyBall","text":"<p>               Bases: <code>torchzero.modules.momentum.momentum.EMA</code></p> <p>Polyak's momentum (heavy-ball method).</p> <p>Parameters:</p> <ul> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>dampening</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>momentum dampening. Defaults to 0.</p> </li> <li> <code>debias</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to debias the EMA like in Adam. Defaults to False.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, this becomes exponential moving average. Defaults to False.</p> </li> <li> <code>ema_init</code>               (<code>str</code>, default:                   <code>'update'</code> )           \u2013            <p>initial values for the EMA, \"zeros\" or \"update\".</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target to apply EMA to. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/momentum.py</code> <pre><code>class HeavyBall(EMA):\n    \"\"\"Polyak's momentum (heavy-ball method).\n\n    Args:\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        dampening (float, optional): momentum dampening. Defaults to 0.\n        debias (bool, optional): whether to debias the EMA like in Adam. Defaults to False.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, this becomes exponential moving average. Defaults to False.\n        ema_init (str, optional): initial values for the EMA, \"zeros\" or \"update\".\n        target (Target, optional): target to apply EMA to. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, momentum:float=0.9, dampening:float=0, debias: bool = False, lerp=False, ema_init: Literal['zeros', 'update'] = 'update'):\n        super().__init__(momentum=momentum, dampening=dampening, debias=debias, lerp=lerp, ema_init=ema_init)\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.IntermoduleCautious","title":"IntermoduleCautious","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Negaties update on :code:<code>main</code> module where it's sign doesn't match with output of <code>compare</code> module.</p> <p>Parameters:</p> <ul> <li> <code>main</code>               (<code>Chainable</code>)           \u2013            <p>main module or sequence of modules whose update will be cautioned.</p> </li> <li> <code>compare</code>               (<code>Chainable</code>)           \u2013            <p>modules or sequence of modules to compare the sign to.</p> </li> <li> <code>normalize</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>renormalize update after masking. Defaults to False.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for normalization. Defaults to 1e-6.</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'zero'</code> )           \u2013            <p>what to do with updates with inconsistent signs. - \"zero\" - set them to zero (as in paper) - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign) - \"backtrack\" - negate them</p> </li> </ul> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class IntermoduleCautious(Module):\n    \"\"\"Negaties update on :code:`main` module where it's sign doesn't match with output of ``compare`` module.\n\n    Args:\n        main (Chainable): main module or sequence of modules whose update will be cautioned.\n        compare (Chainable): modules or sequence of modules to compare the sign to.\n        normalize (bool, optional):\n            renormalize update after masking. Defaults to False.\n        eps (float, optional): epsilon for normalization. Defaults to 1e-6.\n        mode (str, optional):\n            what to do with updates with inconsistent signs.\n            - \"zero\" - set them to zero (as in paper)\n            - \"grad\" - set them to the gradient (same as using update magnitude and gradient sign)\n            - \"backtrack\" - negate them\n    \"\"\"\n    def __init__(\n        self,\n        main: Chainable,\n        compare: Chainable,\n        normalize=False,\n        eps=1e-6,\n        mode: Literal[\"zero\", \"grad\", \"backtrack\"] = \"zero\",\n    ):\n\n        defaults = dict(normalize=normalize, eps=eps, mode=mode)\n        super().__init__(defaults)\n\n        self.set_child('main', main)\n        self.set_child('compare', compare)\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective):\n        main = self.children['main']\n        compare = self.children['compare']\n\n        main_var = main.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(main_var)\n\n        compare_var = compare.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(compare_var)\n\n        mode, normalize, eps = itemgetter('mode', 'normalize', 'eps')(self.defaults)\n        objective.updates = cautious_(\n            TensorList(main_var.get_updates()),\n            TensorList(compare_var.get_updates()),\n            normalize=normalize,\n            mode=mode,\n            eps=eps,\n        )\n\n        return objective\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.MedianAveraging","title":"MedianAveraging","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Median of past <code>history_size</code> updates.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>)           \u2013            <p>Number of past updates to average</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/averaging.py</code> <pre><code>class MedianAveraging(TensorTransform):\n    \"\"\"Median of past ``history_size`` updates.\n\n    Args:\n        history_size (int): Number of past updates to average\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, history_size: int,):\n        defaults = dict(history_size = history_size)\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        history_size = setting['history_size']\n\n        if 'history' not in state:\n            state['history'] = deque(maxlen=history_size)\n\n        history = state['history']\n        history.append(tensor)\n\n        stacked = torch.stack(tuple(history), 0)\n        return torch.quantile(stacked, 0.5, dim = 0)\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.NAG","title":"NAG","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Nesterov accelerated gradient method (nesterov momentum).</p> <p>Parameters:</p> <ul> <li> <code>momentum</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>momentum (beta). Defaults to 0.9.</p> </li> <li> <code>dampening</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>momentum dampening. Defaults to 0.</p> </li> <li> <code>lerp</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target to apply EMA to. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/momentum.py</code> <pre><code>class NAG(TensorTransform):\n    \"\"\"Nesterov accelerated gradient method (nesterov momentum).\n\n    Args:\n        momentum (float, optional): momentum (beta). Defaults to 0.9.\n        dampening (float, optional): momentum dampening. Defaults to 0.\n        lerp (bool, optional):\n            whether to use linear interpolation, if True, this becomes similar to exponential moving average. Defaults to False.\n        target (Target, optional): target to apply EMA to. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, momentum:float=0.9, dampening:float=0, lerp=False):\n        defaults = dict(momentum=momentum,dampening=dampening, lerp=lerp)\n        super().__init__(defaults, uses_grad=False)\n\n        self.add_projected_keys(\"grad\", \"velocity\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        velocity = unpack_states(states, tensors, 'velocity', cls=TensorList)\n        lerp = self.settings[params[0]]['lerp']\n\n        momentum,dampening = unpack_dicts(settings, 'momentum','dampening', cls=NumberList)\n        return nag_(TensorList(tensors), velocity_=velocity,momentum=momentum,dampening=dampening,lerp=lerp)\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.ScaleByGradCosineSimilarity","title":"ScaleByGradCosineSimilarity","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies the update by cosine similarity with gradient. If cosine similarity is negative, naturally the update will be negated as well.</p> <p>Parameters:</p> <ul> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> </ul>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.ScaleByGradCosineSimilarity--examples","title":"Examples:","text":"<p>Scaled Adam <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.Adam(),\n    tz.m.ScaleByGradCosineSimilarity(),\n    tz.m.LR(1e-2)\n)\n</code></pre></p> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class ScaleByGradCosineSimilarity(TensorTransform):\n    \"\"\"Multiplies the update by cosine similarity with gradient.\n    If cosine similarity is negative, naturally the update will be negated as well.\n\n    Args:\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n\n    ## Examples:\n\n    Scaled Adam\n    ```python\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.Adam(),\n        tz.m.ScaleByGradCosineSimilarity(),\n        tz.m.LR(1e-2)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        eps: float = 1e-6,\n    ):\n        defaults = dict(eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        eps = settings[0]['eps']\n        tensors = TensorList(tensors)\n        grads = TensorList(grads)\n        cos_sim = tensors.dot(grads) / (tensors.global_vector_norm() * grads.global_vector_norm()).clip(min=eps)\n\n        return tensors.mul_(cos_sim)\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.ScaleModulesByCosineSimilarity","title":"ScaleModulesByCosineSimilarity","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Scales the output of <code>main</code> module by it's cosine similarity to the output of <code>compare</code> module.</p> <p>Parameters:</p> <ul> <li> <code>main</code>               (<code>Chainable</code>)           \u2013            <p>main module or sequence of modules whose update will be scaled.</p> </li> <li> <code>compare</code>               (<code>Chainable</code>)           \u2013            <p>module or sequence of modules to compare to</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for division. Defaults to 1e-6.</p> </li> </ul>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.ScaleModulesByCosineSimilarity--examples","title":"Examples:","text":"<p>Adam scaled by similarity to RMSprop <pre><code>opt = tz.Optimizer(\n    bench.parameters(),\n    tz.m.ScaleModulesByCosineSimilarity(\n        main = tz.m.Adam(),\n        compare = tz.m.RMSprop(0.999, debiased=True),\n    ),\n    tz.m.LR(1e-2)\n)\n</code></pre></p> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class ScaleModulesByCosineSimilarity(Module):\n    \"\"\"Scales the output of ``main`` module by it's cosine similarity to the output\n    of ``compare`` module.\n\n    Args:\n        main (Chainable): main module or sequence of modules whose update will be scaled.\n        compare (Chainable): module or sequence of modules to compare to\n        eps (float, optional): epsilon for division. Defaults to 1e-6.\n\n    ## Examples:\n\n    Adam scaled by similarity to RMSprop\n    ```python\n    opt = tz.Optimizer(\n        bench.parameters(),\n        tz.m.ScaleModulesByCosineSimilarity(\n            main = tz.m.Adam(),\n            compare = tz.m.RMSprop(0.999, debiased=True),\n        ),\n        tz.m.LR(1e-2)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        main: Chainable,\n        compare: Chainable,\n        eps=1e-6,\n    ):\n        defaults = dict(eps=eps)\n        super().__init__(defaults)\n\n        self.set_child('main', main)\n        self.set_child('compare', compare)\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective):\n        main = self.children['main']\n        compare = self.children['compare']\n\n        main_var = main.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(main_var)\n\n        compare_var = compare.step(objective.clone(clone_updates=True))\n        objective.update_attrs_from_clone_(compare_var)\n\n        m = TensorList(main_var.get_updates())\n        c = TensorList(compare_var.get_updates())\n        eps = self.defaults['eps']\n\n        cos_sim = m.dot(c) / (m.global_vector_norm() * c.global_vector_norm()).clip(min=eps)\n\n        objective.updates = m.mul_(cos_sim)\n        return objective\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.UpdateGradientSignConsistency","title":"UpdateGradientSignConsistency","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Compares update and gradient signs. Output will have 1s where signs match, and 0s where they don't.</p> <p>Parameters:</p> <ul> <li> <code>normalize</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>renormalize update after masking. Defaults to False.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>epsilon for normalization. Defaults to 1e-6.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/cautious.py</code> <pre><code>class UpdateGradientSignConsistency(TensorTransform):\n    \"\"\"Compares update and gradient signs. Output will have 1s where signs match, and 0s where they don't.\n\n    Args:\n        normalize (bool, optional):\n            renormalize update after masking. Defaults to False.\n        eps (float, optional): epsilon for normalization. Defaults to 1e-6.\n    \"\"\"\n    def __init__(self, normalize = False, eps=1e-6):\n\n        defaults = dict(normalize=normalize, eps=eps)\n        super().__init__(defaults, uses_grad=True)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None\n        normalize, eps = itemgetter('normalize', 'eps')(settings[0])\n\n        mask = (TensorList(tensors).mul_(grads)).gt_(0)\n        if normalize: mask = mask / mask.global_mean().clip(min = eps) # pyright: ignore[reportOperatorIssue]\n\n        return mask\n</code></pre>"},{"location":"API/modules/momentum/#torchzero.modules.momentum.WeightedAveraging","title":"WeightedAveraging","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Weighted average of past <code>len(weights)</code> updates.</p> <p>Parameters:</p> <ul> <li> <code>weights</code>               (<code>Sequence[float]</code>)           \u2013            <p>a sequence of weights from oldest to newest.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/momentum/averaging.py</code> <pre><code>class WeightedAveraging(TensorTransform):\n    \"\"\"Weighted average of past ``len(weights)`` updates.\n\n    Args:\n        weights (Sequence[float]): a sequence of weights from oldest to newest.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, weights: Sequence[float] | torch.Tensor | Any):\n        defaults = dict(weights = tolist(weights))\n        super().__init__(defaults=defaults)\n\n        self.add_projected_keys(\"grad\", \"history\")\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        weights = setting['weights']\n\n        if 'history' not in state:\n            state['history'] = deque(maxlen=len(weights))\n\n        history = state['history']\n        history.append(tensor)\n        if len(history) != len(weights):\n            weights = weights[-len(history):]\n\n        average = None\n        for i, (h, w) in enumerate(zip(history, weights)):\n            if average is None: average = h * (w / len(history))\n            else:\n                if w == 0: continue\n                average += h * (w / len(history))\n\n        assert average is not None\n        return average\n</code></pre>"},{"location":"API/modules/ops/","title":"Operations","text":"<p>This subpackage contains operations like adding modules, subtracting, grafting, tracking the maximum, etc.</p> <p>Classes:</p> <ul> <li> <code>Abs</code>           \u2013            <p>Returns <code>abs(input)</code></p> </li> <li> <code>AccumulateMaximum</code>           \u2013            <p>Accumulates maximum of all past updates.</p> </li> <li> <code>AccumulateMean</code>           \u2013            <p>Accumulates mean of all past updates.</p> </li> <li> <code>AccumulateMinimum</code>           \u2013            <p>Accumulates minimum of all past updates.</p> </li> <li> <code>AccumulateProduct</code>           \u2013            <p>Accumulates product of all past updates.</p> </li> <li> <code>AccumulateSum</code>           \u2013            <p>Accumulates sum of all past updates.</p> </li> <li> <code>Add</code>           \u2013            <p>Add <code>other</code> to tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>BinaryOperationBase</code>           \u2013            <p>Base class for operations that use update as the first operand. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> </li> <li> <code>CenteredEMASquared</code>           \u2013            <p>Maintains a centered exponential moving average of squared updates. This also maintains an additional</p> </li> <li> <code>CenteredSqrtEMASquared</code>           \u2013            <p>Maintains a centered exponential moving average of squared updates, outputs optionally debiased square root.</p> </li> <li> <code>Clip</code>           \u2013            <p>clip tensors to be in  <code>(min, max)</code> range. <code>min</code> and <code>`max</code>: can be None, numbers or modules.</p> </li> <li> <code>ClipModules</code>           \u2013            <p>Calculates <code>input(tensors).clip(min, max)</code>. <code>min</code> and <code>max</code> can be numbers or modules.</p> </li> <li> <code>Clone</code>           \u2013            <p>Clones input. May be useful to store some intermediate result and make sure it doesn't get affected by in-place operations</p> </li> <li> <code>CopyMagnitude</code>           \u2013            <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> </li> <li> <code>CopySign</code>           \u2013            <p>Returns tensors with sign copied from <code>other(tensors)</code>.</p> </li> <li> <code>CustomUnaryOperation</code>           \u2013            <p>Applies <code>getattr(tensor, name)</code> to each tensor</p> </li> <li> <code>Debias</code>           \u2013            <p>Multiplies the update by an Adam debiasing term based first and/or second momentum.</p> </li> <li> <code>Debias2</code>           \u2013            <p>Multiplies the update by an Adam debiasing term based on the second momentum.</p> </li> <li> <code>Div</code>           \u2013            <p>Divide tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> </li> <li> <code>DivModules</code>           \u2013            <p>Calculates <code>input / other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> </li> <li> <code>EMASquared</code>           \u2013            <p>Maintains an exponential moving average of squared updates.</p> </li> <li> <code>Exp</code>           \u2013            <p>Returns <code>exp(input)</code></p> </li> <li> <code>Fill</code>           \u2013            <p>Outputs tensors filled with <code>value</code></p> </li> <li> <code>Grad</code>           \u2013            <p>Outputs the gradient</p> </li> <li> <code>GradToNone</code>           \u2013            <p>Sets <code>grad</code> attribute to None on <code>objective</code>.</p> </li> <li> <code>Graft</code>           \u2013            <p>Outputs <code>direction</code> output rescaled to have the same norm as <code>magnitude</code> output.</p> </li> <li> <code>GraftInputToOutput</code>           \u2013            <p>Outputs <code>tensors</code> rescaled to have the same norm as <code>magnitude(tensors)</code>.</p> </li> <li> <code>GraftOutputToInput</code>           \u2013            <p>Outputs <code>magnitude(tensors)</code> rescaled to have the same norm as <code>tensors</code></p> </li> <li> <code>GramSchimdt</code>           \u2013            <p>outputs tensors made orthogonal to <code>other(tensors)</code> via Gram-Schmidt.</p> </li> <li> <code>Identity</code>           \u2013            <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> </li> <li> <code>LerpModules</code>           \u2013            <p>Does a linear interpolation of <code>input(tensors)</code> and <code>end(tensors)</code> based on a scalar <code>weight</code>.</p> </li> <li> <code>Maximum</code>           \u2013            <p>Outputs <code>maximum(tensors, other(tensors))</code></p> </li> <li> <code>MaximumModules</code>           \u2013            <p>Outputs elementwise maximum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>Mean</code>           \u2013            <p>Outputs a mean of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>Minimum</code>           \u2013            <p>Outputs <code>minimum(tensors, other(tensors))</code></p> </li> <li> <code>MinimumModules</code>           \u2013            <p>Outputs elementwise minimum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>Mul</code>           \u2013            <p>Multiply tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> </li> <li> <code>MultiOperationBase</code>           \u2013            <p>Base class for operations that use operands. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> </li> <li> <code>NanToNum</code>           \u2013            <p>Convert <code>nan</code>, <code>inf</code> and <code>-</code>inf`` to numbers.</p> </li> <li> <code>Negate</code>           \u2013            <p>Returns <code>- input</code></p> </li> <li> <code>Noop</code>           \u2013            <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> </li> <li> <code>Ones</code>           \u2013            <p>Outputs ones</p> </li> <li> <code>Params</code>           \u2013            <p>Outputs parameters</p> </li> <li> <code>Pow</code>           \u2013            <p>Take tensors to the power of <code>exponent</code>. <code>exponent</code> can be a number or a module.</p> </li> <li> <code>PowModules</code>           \u2013            <p>Calculates <code>input ** exponent</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> </li> <li> <code>Prod</code>           \u2013            <p>Outputs product of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>RCopySign</code>           \u2013            <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> </li> <li> <code>RDiv</code>           \u2013            <p>Divide <code>other</code> by tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>RPow</code>           \u2013            <p>Take <code>other</code> to the power of tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>RSub</code>           \u2013            <p>Subtract tensors from <code>other</code>. <code>other</code> can be a number or a module.</p> </li> <li> <code>Randn</code>           \u2013            <p>Outputs tensors filled with random numbers from a normal distribution with mean 0 and variance 1.</p> </li> <li> <code>RandomSample</code>           \u2013            <p>Outputs tensors filled with random numbers from distribution depending on value of <code>distribution</code>.</p> </li> <li> <code>Reciprocal</code>           \u2013            <p>Returns <code>1 / input</code></p> </li> <li> <code>ReduceOperationBase</code>           \u2013            <p>Base class for reduction operations like Sum, Prod, Maximum. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> </li> <li> <code>Sign</code>           \u2013            <p>Returns <code>sign(input)</code></p> </li> <li> <code>Sqrt</code>           \u2013            <p>Returns <code>sqrt(input)</code></p> </li> <li> <code>SqrtEMASquared</code>           \u2013            <p>Maintains an exponential moving average of squared updates, outputs optionally debiased square root.</p> </li> <li> <code>Sub</code>           \u2013            <p>Subtract <code>other</code> from tensors. <code>other</code> can be a number or a module.</p> </li> <li> <code>SubModules</code>           \u2013            <p>Calculates <code>input - other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> </li> <li> <code>Sum</code>           \u2013            <p>Outputs sum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>Threshold</code>           \u2013            <p>Outputs tensors thresholded such that values above <code>threshold</code> are set to <code>value</code>.</p> </li> <li> <code>UnaryLambda</code>           \u2013            <p>Applies <code>fn</code> to input tensors.</p> </li> <li> <code>UnaryParameterwiseLambda</code>           \u2013            <p>Applies <code>fn</code> to each input tensor.</p> </li> <li> <code>Uniform</code>           \u2013            <p>Outputs tensors filled with random numbers from uniform distribution between <code>low</code> and <code>high</code>.</p> </li> <li> <code>UpdateToNone</code>           \u2013            <p>Sets <code>update</code> attribute to None on <code>var</code>.</p> </li> <li> <code>WeightedMean</code>           \u2013            <p>Outputs weighted mean of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>WeightedSum</code>           \u2013            <p>Outputs a weighted sum of <code>inputs</code> that can be modules or numbers.</p> </li> <li> <code>Zeros</code>           \u2013            <p>Outputs zeros</p> </li> </ul>"},{"location":"API/modules/ops/#torchzero.modules.ops.Abs","title":"Abs","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>abs(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Abs(TensorTransform):\n    \"\"\"Returns ``abs(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_abs_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.AccumulateMaximum","title":"AccumulateMaximum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates maximum of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateMaximum(TensorTransform):\n    \"\"\"Accumulates maximum of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"maximum\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        maximum = unpack_states(states, tensors, 'maximum', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return maximum.maximum_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.AccumulateMean","title":"AccumulateMean","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates mean of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateMean(TensorTransform):\n    \"\"\"Accumulates mean of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"mean\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n        mean = unpack_states(states, tensors, 'mean', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return mean.add_(tensors).lazy_mul(decay, clone=True).div_(step)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.AccumulateMinimum","title":"AccumulateMinimum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates minimum of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateMinimum(TensorTransform):\n    \"\"\"Accumulates minimum of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"minimum\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        minimum = unpack_states(states, tensors, 'minimum', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return minimum.minimum_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.AccumulateProduct","title":"AccumulateProduct","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates product of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>, default:                   <code>'update'</code> )           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateProduct(TensorTransform):\n    \"\"\"Accumulates product of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0, target = 'update',):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        prod = unpack_states(states, tensors, 'prod', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return prod.mul_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.AccumulateSum","title":"AccumulateSum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Accumulates sum of all past updates.</p> <p>Parameters:</p> <ul> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>decays the accumulator. Defaults to 0.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/accumulate.py</code> <pre><code>class AccumulateSum(TensorTransform):\n    \"\"\"Accumulates sum of all past updates.\n\n    Args:\n        decay (float, optional): decays the accumulator. Defaults to 0.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, decay: float = 0):\n        defaults = dict(decay=decay)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad\", \"sum\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        sum = unpack_states(states, tensors, 'sum', cls=TensorList)\n        decay = [1-s['decay'] for s in settings]\n        return sum.add_(tensors).lazy_mul(decay, clone=True)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Add","title":"Add","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Add <code>other</code> to tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>tensors + other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Add(BinaryOperationBase):\n    \"\"\"Add ``other`` to tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``tensors + other(tensors)``\n    \"\"\"\n    def __init__(self, other: Chainable | float, alpha: float = 1):\n        defaults = dict(alpha=alpha)\n        super().__init__(defaults, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        if isinstance(other, (int,float)): torch._foreach_add_(update, other * self.defaults['alpha'])\n        else: torch._foreach_add_(update, other, alpha=self.defaults['alpha'])\n        return update\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.BinaryOperationBase","title":"BinaryOperationBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for operations that use update as the first operand. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> <p>Methods:</p> <ul> <li> <code>transform</code>             \u2013              <p>applies the operation to operands</p> </li> </ul> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class BinaryOperationBase(Module, ABC):\n    \"\"\"Base class for operations that use update as the first operand. This is an abstract class, subclass it and override `transform` method to use it.\"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, **operands: Chainable | Any):\n        super().__init__(defaults=defaults)\n\n        self.operands = {}\n        for k,v in operands.items():\n\n            if isinstance(v, (Module, Sequence)):\n                self.set_child(k, v)\n                self.operands[k] = self.children[k]\n            else:\n                self.operands[k] = v\n\n    @abstractmethod\n    def transform(self, objective: Objective, update: list[torch.Tensor], **operands: Any | list[torch.Tensor]) -&gt; Iterable[torch.Tensor]:\n        \"\"\"applies the operation to operands\"\"\"\n        raise NotImplementedError\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective: Objective) -&gt; Objective:\n        # pass cloned update to all module operands\n        processed_operands: dict[str, Any | list[torch.Tensor]] = self.operands.copy()\n\n        for k,v in self.operands.items():\n            if k in self.children:\n                v: Module\n                updated_obj = v.step(objective.clone(clone_updates=True))\n                processed_operands[k] = updated_obj.get_updates()\n                objective.update_attrs_from_clone_(updated_obj) # update loss, grad, etc if this module calculated them\n\n        transformed = self.transform(objective, update=objective.get_updates(), **processed_operands)\n        objective.updates = list(transformed)\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.BinaryOperationBase.transform","title":"transform","text":"<pre><code>transform(objective: Objective, update: list[Tensor], **operands: Any | list[Tensor]) -&gt; Iterable[Tensor]\n</code></pre> <p>applies the operation to operands</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>@abstractmethod\ndef transform(self, objective: Objective, update: list[torch.Tensor], **operands: Any | list[torch.Tensor]) -&gt; Iterable[torch.Tensor]:\n    \"\"\"applies the operation to operands\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.CenteredEMASquared","title":"CenteredEMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains a centered exponential moving average of squared updates. This also maintains an additional exponential moving average of un-squared updates, square of which is subtracted from the EMA.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class CenteredEMASquared(TensorTransform):\n    \"\"\"Maintains a centered exponential moving average of squared updates. This also maintains an additional\n    exponential moving average of un-squared updates, square of which is subtracted from the EMA.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    def __init__(self, beta: float = 0.99, amsgrad=False, pow:float=2):\n        defaults = dict(beta=beta, amsgrad=amsgrad, pow=pow)\n        super().__init__(defaults, uses_grad=False)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        amsgrad, pow = itemgetter('amsgrad', 'pow')(settings[0])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg, exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return centered_ema_sq_(\n            TensorList(tensors),\n            exp_avg_=exp_avg,\n            exp_avg_sq_=exp_avg_sq,\n            beta=beta,\n            max_exp_avg_sq_=max_exp_avg_sq,\n            pow=pow,\n        ).clone()\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.CenteredSqrtEMASquared","title":"CenteredSqrtEMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains a centered exponential moving average of squared updates, outputs optionally debiased square root. This also maintains an additional exponential moving average of un-squared updates, square of which is subtracted from the EMA.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>debiased</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to multiply the output by a debiasing term from the Adam method. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class CenteredSqrtEMASquared(TensorTransform):\n    \"\"\"Maintains a centered exponential moving average of squared updates, outputs optionally debiased square root.\n    This also maintains an additional exponential moving average of un-squared updates, square of which is subtracted from the EMA.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        debiased (bool, optional): whether to multiply the output by a debiasing term from the Adam method. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    def __init__(self, beta: float = 0.99, amsgrad=False, debiased: bool = False, pow:float=2):\n        defaults = dict(beta=beta, amsgrad=amsgrad, debiased=debiased, pow=pow)\n        super().__init__(defaults, uses_grad=False)\n        self.add_projected_keys(\"grad\", \"exp_avg\")\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        amsgrad, pow, debiased = itemgetter('amsgrad', 'pow', 'debiased')(settings[0])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg, exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg, exp_avg_sq = unpack_states(states, tensors, 'exp_avg', 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return sqrt_centered_ema_sq_(\n            TensorList(tensors),\n            exp_avg_=exp_avg,\n            exp_avg_sq_=exp_avg_sq,\n            beta=beta,\n            debiased=debiased,\n            step=step,\n            max_exp_avg_sq_=max_exp_avg_sq,\n            pow=pow,\n        )\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Clip","title":"Clip","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>clip tensors to be in  <code>(min, max)</code> range. <code>min</code> and <code>`max</code>: can be None, numbers or modules.</p> <p>If <code>min</code> and <code>max</code>  are modules, this calculates <code>tensors.clip(min(tensors), max(tensors))</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Clip(BinaryOperationBase):\n    \"\"\"clip tensors to be in  ``(min, max)`` range. ``min`` and ``max`: can be None, numbers or modules.\n\n    If ``min`` and ``max``  are modules, this calculates ``tensors.clip(min(tensors), max(tensors))``.\n    \"\"\"\n    def __init__(self, min: float | Chainable | None = None, max: float | Chainable | None = None):\n        super().__init__({}, min=min, max=max)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], min: float | list[torch.Tensor] | None, max: float | list[torch.Tensor] | None):\n        return TensorList(update).clamp_(min=min,  max=max)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.ClipModules","title":"ClipModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input(tensors).clip(min, max)</code>. <code>min</code> and <code>max</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class ClipModules(MultiOperationBase):\n    \"\"\"Calculates ``input(tensors).clip(min, max)``. ``min`` and ``max`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable, min: float | Chainable | None = None, max: float | Chainable | None = None):\n        defaults = {}\n        super().__init__(defaults, input=input, min=min, max=max)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: list[torch.Tensor], min: float | list[torch.Tensor], max: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        return TensorList(input).clamp_(min=min, max=max)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Clone","title":"Clone","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Clones input. May be useful to store some intermediate result and make sure it doesn't get affected by in-place operations</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Clone(Module):\n    \"\"\"Clones input. May be useful to store some intermediate result and make sure it doesn't get affected by in-place operations\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [u.clone() for u in objective.get_updates()]\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.CopyMagnitude","title":"CopyMagnitude","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RCopySign(BinaryOperationBase):\n    \"\"\"Returns ``other(tensors)`` with sign copied from tensors.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        return [o.copysign_(u) for u, o in zip(update, other)]\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.CopySign","title":"CopySign","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Returns tensors with sign copied from <code>other(tensors)</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class CopySign(BinaryOperationBase):\n    \"\"\"Returns tensors with sign copied from ``other(tensors)``.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        return [u.copysign_(o) for u, o in zip(update, other)]\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.CustomUnaryOperation","title":"CustomUnaryOperation","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies <code>getattr(tensor, name)</code> to each tensor</p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class CustomUnaryOperation(TensorTransform):\n    \"\"\"Applies ``getattr(tensor, name)`` to each tensor\n    \"\"\"\n    def __init__(self, name: str):\n        defaults = dict(name=name)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return getattr(tensors, settings[0]['name'])()\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Debias","title":"Debias","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies the update by an Adam debiasing term based first and/or second momentum.</p> <p>Parameters:</p> <ul> <li> <code>beta1</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>first momentum, should be the same as first momentum used in modules before. Defaults to None.</p> </li> <li> <code>beta2</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>learning rate. Defaults to 1.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, assumes absolute value is used. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class Debias(TensorTransform):\n    \"\"\"Multiplies the update by an Adam debiasing term based first and/or second momentum.\n\n    Args:\n        beta1 (float | None, optional):\n            first momentum, should be the same as first momentum used in modules before. Defaults to None.\n        beta2 (float | None, optional):\n            second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.\n        alpha (float, optional): learning rate. Defaults to 1.\n        pow (float, optional): power, assumes absolute value is used. Defaults to 2.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, beta1: float | None = None, beta2: float | None = None, alpha: float = 1, pow:float=2):\n        defaults = dict(beta1=beta1, beta2=beta2, alpha=alpha, pow=pow)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        pow = settings[0]['pow']\n        alpha, beta1, beta2 = unpack_dicts(settings, 'alpha', 'beta1', 'beta2', cls=NumberList)\n\n        return debias(TensorList(tensors), step=step, beta1=beta1, beta2=beta2, alpha=alpha, pow=pow, inplace=True)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Debias2","title":"Debias2","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies the update by an Adam debiasing term based on the second momentum.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>0.999</code> )           \u2013            <p>second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, assumes absolute value is used. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>target. Defaults to 'update'.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class Debias2(TensorTransform):\n    \"\"\"Multiplies the update by an Adam debiasing term based on the second momentum.\n\n    Args:\n        beta (float | None, optional):\n            second (squared) momentum, should be the same as second momentum used in modules before. Defaults to None.\n        pow (float, optional): power, assumes absolute value is used. Defaults to 2.\n        target (Target, optional): target. Defaults to 'update'.\n    \"\"\"\n    def __init__(self, beta: float = 0.999, pow: float = 2,):\n        defaults = dict(beta=beta, pow=pow)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        pow = settings[0]['pow']\n        beta = NumberList(s['beta'] for s in settings)\n        return debias_second_momentum(TensorList(tensors), step=step, beta=beta, pow=pow, inplace=True)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Div","title":"Div","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Divide tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>tensors / other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Div(BinaryOperationBase):\n    \"\"\"Divide tensors by ``other``. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``tensors / other(tensors)``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        torch._foreach_div_(update, other)\n        return update\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.DivModules","title":"DivModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input / other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class DivModules(MultiOperationBase):\n    \"\"\"Calculates ``input / other``. ``input`` and ``other`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable | float, other: Chainable | float, other_first:bool=False):\n        defaults = {}\n        if other_first: super().__init__(defaults, other=other, input=input)\n        else: super().__init__(defaults, input=input, other=other)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: float | list[torch.Tensor], other: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        if isinstance(input, (int,float)):\n            assert isinstance(other, list)\n            return input / TensorList(other)\n\n        torch._foreach_div_(input, other)\n        return input\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.EMASquared","title":"EMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an exponential moving average of squared updates.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>EMA_SQ_FN</code>             \u2013              <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code>, if <code>max_exp_avg_sq_</code> is not None, updates it with maximum of EMA.</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class EMASquared(TensorTransform):\n    \"\"\"Maintains an exponential moving average of squared updates.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    EMA_SQ_FN: staticmethod = staticmethod(ema_sq_)\n\n    def __init__(self, beta:float=0.999, amsgrad=False, pow:float=2):\n        defaults = dict(beta=beta,pow=pow,amsgrad=amsgrad)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        amsgrad, pow = itemgetter('amsgrad', 'pow')(self.settings[params[0]])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return self.EMA_SQ_FN(TensorList(tensors), exp_avg_sq_=exp_avg_sq, beta=beta, max_exp_avg_sq_=max_exp_avg_sq, pow=pow).clone()\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.EMASquared.EMA_SQ_FN","title":"EMA_SQ_FN","text":"<pre><code>EMA_SQ_FN(tensors: TensorList, exp_avg_sq_: TensorList, beta: float | NumberList, max_exp_avg_sq_: TensorList | None, pow: float = 2)\n</code></pre> <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code>, if <code>max_exp_avg_sq_</code> is not None, updates it with maximum of EMA.</p> <p>Returns <code>exp_avg_sq_</code> or <code>max_exp_avg_sq_</code>.</p> Source code in <code>torchzero/modules/opt_utils.py</code> <pre><code>def ema_sq_(\n    tensors: TensorList,\n    exp_avg_sq_: TensorList,\n    beta: float | NumberList,\n    max_exp_avg_sq_: TensorList | None,\n    pow: float = 2,\n):\n    \"\"\"\n    Updates `exp_avg_sq_` with EMA of squared `tensors`, if `max_exp_avg_sq_` is not None, updates it with maximum of EMA.\n\n    Returns `exp_avg_sq_` or `max_exp_avg_sq_`.\n    \"\"\"\n    lerp_power_(tensors=tensors, exp_avg_pow_=exp_avg_sq_,beta=beta,pow=pow)\n\n    # AMSGrad\n    if max_exp_avg_sq_ is not None:\n        max_exp_avg_sq_.maximum_(exp_avg_sq_)\n        exp_avg_sq_ = max_exp_avg_sq_\n\n    return exp_avg_sq_\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Exp","title":"Exp","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>exp(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Exp(TensorTransform):\n    \"\"\"Returns ``exp(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_exp_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Fill","title":"Fill","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with <code>value</code></p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Fill(Module):\n    \"\"\"Outputs tensors filled with ``value``\"\"\"\n    def __init__(self, value: float):\n        defaults = dict(value=value)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.full_like(p, self.settings[p]['value']) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Grad","title":"Grad","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs the gradient</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Grad(Module):\n    \"\"\"Outputs the gradient\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [g.clone() for g in objective.get_grads()]\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.GradToNone","title":"GradToNone","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Sets <code>grad</code> attribute to None on <code>objective</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class GradToNone(Module):\n    \"\"\"Sets ``grad`` attribute to None on ``objective``.\"\"\"\n    def __init__(self): super().__init__()\n    def apply(self, objective):\n        objective.grads = None\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Graft","title":"Graft","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Outputs <code>direction</code> output rescaled to have the same norm as <code>magnitude</code> output.</p> <p>Parameters:</p> <ul> <li> <code>direction</code>               (<code>Chainable</code>)           \u2013            <p>module to use the direction from</p> </li> <li> <code>magnitude</code>               (<code>Chainable</code>)           \u2013            <p>module to use the magnitude from</p> </li> <li> <code>tensorwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to calculate norm per-tensor or globally. Defaults to True.</p> </li> <li> <code>ord</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>norm order. Defaults to 2.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>clips denominator to be no less than this value. Defaults to 1e-6.</p> </li> <li> <code>strength</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>strength of grafting. Defaults to 1.</p> </li> </ul>"},{"location":"API/modules/ops/#torchzero.modules.ops.Graft--example","title":"Example:","text":"<p>Shampoo grafted to Adam <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.GraftModules(\n        direction = tz.m.Shampoo(),\n        magnitude = tz.m.Adam(),\n    ),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Reference <p>Agarwal, N., Anil, R., Hazan, E., Koren, T., &amp; Zhang, C. (2020). Disentangling adaptive gradient methods from learning rates. arXiv preprint arXiv:2002.11803.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class Graft(MultiOperationBase):\n    \"\"\"Outputs ``direction`` output rescaled to have the same norm as ``magnitude`` output.\n\n    Args:\n        direction (Chainable): module to use the direction from\n        magnitude (Chainable): module to use the magnitude from\n        tensorwise (bool, optional): whether to calculate norm per-tensor or globally. Defaults to True.\n        ord (float, optional): norm order. Defaults to 2.\n        eps (float, optional): clips denominator to be no less than this value. Defaults to 1e-6.\n        strength (float, optional): strength of grafting. Defaults to 1.\n\n    ### Example:\n\n    Shampoo grafted to Adam\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.GraftModules(\n            direction = tz.m.Shampoo(),\n            magnitude = tz.m.Adam(),\n        ),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Reference:\n        [Agarwal, N., Anil, R., Hazan, E., Koren, T., &amp; Zhang, C. (2020). Disentangling adaptive gradient methods from learning rates. arXiv preprint arXiv:2002.11803.](https://arxiv.org/pdf/2002.11803)\n    \"\"\"\n    def __init__(self, direction: Chainable, magnitude: Chainable, tensorwise:bool=True, ord:Metrics=2, eps:float = 1e-6, strength:float=1):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps, strength=strength)\n        super().__init__(defaults, direction=direction, magnitude=magnitude)\n\n    @torch.no_grad\n    def transform(self, objective, magnitude: list[torch.Tensor], direction:list[torch.Tensor]):\n        tensorwise, ord, eps, strength = itemgetter('tensorwise','ord','eps', 'strength')(self.defaults)\n        return TensorList(direction).graft_(magnitude, tensorwise=tensorwise, ord=ord, eps=eps, strength=strength)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.GraftInputToOutput","title":"GraftInputToOutput","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>tensors</code> rescaled to have the same norm as <code>magnitude(tensors)</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class GraftInputToOutput(BinaryOperationBase):\n    \"\"\"Outputs ``tensors`` rescaled to have the same norm as ``magnitude(tensors)``.\"\"\"\n    def __init__(self, magnitude: Chainable, tensorwise:bool=True, ord:float=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, magnitude=magnitude)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], magnitude: list[torch.Tensor]):\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(self.defaults)\n        return TensorList(update).graft_(magnitude, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.GraftOutputToInput","title":"GraftOutputToInput","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>magnitude(tensors)</code> rescaled to have the same norm as <code>tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class GraftOutputToInput(BinaryOperationBase):\n    \"\"\"Outputs ``magnitude(tensors)`` rescaled to have the same norm as ``tensors``\"\"\"\n\n    def __init__(self, direction: Chainable, tensorwise:bool=True, ord:float=2, eps:float = 1e-6):\n        defaults = dict(tensorwise=tensorwise, ord=ord, eps=eps)\n        super().__init__(defaults, direction=direction)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], direction: list[torch.Tensor]):\n        tensorwise, ord, eps = itemgetter('tensorwise','ord','eps')(self.defaults)\n        return TensorList(direction).graft_(update, tensorwise=tensorwise, ord=ord, eps=eps)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.GramSchimdt","title":"GramSchimdt","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>outputs tensors made orthogonal to <code>other(tensors)</code> via Gram-Schmidt.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class GramSchimdt(BinaryOperationBase):\n    \"\"\"outputs tensors made orthogonal to ``other(tensors)`` via Gram-Schmidt.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        update = TensorList(update); other = TensorList(other)\n        min = torch.finfo(update[0].dtype).tiny * 2\n        return update - (other*update) / (other*other).clip(min=min)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Identity","title":"Identity","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Identity(Module):\n    \"\"\"Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.\"\"\"\n    def __init__(self, *args, **kwargs): super().__init__()\n    def update(self, objective): pass\n    def apply(self, objective): return objective\n    def get_H(self, objective):\n        n = sum(p.numel() for p in objective.params)\n        p = objective.params[0]\n        return ScaledIdentity(shape=(n,n), device=p.device, dtype=p.dtype)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.LerpModules","title":"LerpModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Does a linear interpolation of <code>input(tensors)</code> and <code>end(tensors)</code> based on a scalar <code>weight</code>.</p> <p>The output is given by <code>output = input(tensors) + weight * (end(tensors) - input(tensors))</code></p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class LerpModules(MultiOperationBase):\n    \"\"\"Does a linear interpolation of ``input(tensors)`` and ``end(tensors)`` based on a scalar ``weight``.\n\n    The output is given by ``output = input(tensors) + weight * (end(tensors) - input(tensors))``\n    \"\"\"\n    def __init__(self, input: Chainable, end: Chainable, weight: float):\n        defaults = dict(weight=weight)\n        super().__init__(defaults, input=input, end=end)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: list[torch.Tensor], end: list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        torch._foreach_lerp_(input, end, weight=self.defaults['weight'])\n        return input\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Maximum","title":"Maximum","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>maximum(tensors, other(tensors))</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Maximum(BinaryOperationBase):\n    \"\"\"Outputs ``maximum(tensors, other(tensors))``\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        torch._foreach_maximum_(update, other)\n        return update\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.MaximumModules","title":"MaximumModules","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs elementwise maximum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class MaximumModules(ReduceOperationBase):\n    \"\"\"Outputs elementwise maximum of ``inputs`` that can be modules or numbers.\"\"\"\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        maximum = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_maximum_(maximum, v)\n\n        return maximum\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Mean","title":"Mean","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.Sum</code></p> <p>Outputs a mean of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class Mean(Sum):\n    \"\"\"Outputs a mean of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = True\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Mean.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/ops/#torchzero.modules.ops.Minimum","title":"Minimum","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs <code>minimum(tensors, other(tensors))</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Minimum(BinaryOperationBase):\n    \"\"\"Outputs ``minimum(tensors, other(tensors))``\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        torch._foreach_minimum_(update, other)\n        return update\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.MinimumModules","title":"MinimumModules","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs elementwise minimum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class MinimumModules(ReduceOperationBase):\n    \"\"\"Outputs elementwise minimum of ``inputs`` that can be modules or numbers.\"\"\"\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        minimum = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_minimum_(minimum, v)\n\n        return minimum\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Mul","title":"Mul","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Multiply tensors by <code>other</code>. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>tensors * other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Mul(BinaryOperationBase):\n    \"\"\"Multiply tensors by ``other``. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``tensors * other(tensors)``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        torch._foreach_mul_(update, other)\n        return update\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.MultiOperationBase","title":"MultiOperationBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for operations that use operands. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> <p>Methods:</p> <ul> <li> <code>transform</code>             \u2013              <p>applies the operation to operands</p> </li> </ul> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class MultiOperationBase(Module, ABC):\n    \"\"\"Base class for operations that use operands. This is an abstract class, subclass it and override `transform` method to use it.\"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, **operands: Chainable | Any):\n        super().__init__(defaults=defaults)\n\n        self.operands = {}\n        for k,v in operands.items():\n\n            if isinstance(v, (Module, Sequence)):\n                self.set_child(k, v)\n                self.operands[k] = self.children[k]\n            else:\n                self.operands[k] = v\n\n        if not self.children:\n            raise ValueError('At least one operand must be a module')\n\n    @abstractmethod\n    def transform(self, objective: Objective, **operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        \"\"\"applies the operation to operands\"\"\"\n        raise NotImplementedError\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective: Objective) -&gt; Objective:\n        # pass cloned update to all module operands\n        processed_operands: dict[str, Any | list[torch.Tensor]] = self.operands.copy()\n\n        for k,v in self.operands.items():\n            if k in self.children:\n                v: Module\n                updated_obj = v.step(objective.clone(clone_updates=True))\n                processed_operands[k] = updated_obj.get_updates()\n                objective.update_attrs_from_clone_(updated_obj) # update loss, grad, etc if this module calculated them\n\n        transformed = self.transform(objective, **processed_operands)\n        objective.updates = transformed\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.MultiOperationBase.transform","title":"transform","text":"<pre><code>transform(objective: Objective, **operands: Any | list[Tensor]) -&gt; list[Tensor]\n</code></pre> <p>applies the operation to operands</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>@abstractmethod\ndef transform(self, objective: Objective, **operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n    \"\"\"applies the operation to operands\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.NanToNum","title":"NanToNum","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Convert <code>nan</code>, <code>inf</code> and <code>-</code>inf`` to numbers.</p> <p>Parameters:</p> <ul> <li> <code>nan</code>               (<code>optional</code>, default:                   <code>None</code> )           \u2013            <p>the value to replace NaNs with. Default is zero.</p> </li> <li> <code>posinf</code>               (<code>optional</code>, default:                   <code>None</code> )           \u2013            <p>if a Number, the value to replace positive infinity values with. If None, positive infinity values are replaced with the greatest finite value representable by input's dtype. Default is None.</p> </li> <li> <code>neginf</code>               (<code>optional</code>, default:                   <code>None</code> )           \u2013            <p>if a Number, the value to replace negative infinity values with. If None, negative infinity values are replaced with the lowest finite value representable by input's dtype. Default is None.</p> </li> </ul> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class NanToNum(TensorTransform):\n    \"\"\"Convert ``nan``, ``inf`` and `-`inf`` to numbers.\n\n    Args:\n        nan (optional): the value to replace NaNs with. Default is zero.\n        posinf (optional): if a Number, the value to replace positive infinity values with.\n            If None, positive infinity values are replaced with the greatest finite value\n            representable by input's dtype. Default is None.\n        neginf (optional): if a Number, the value to replace negative infinity values with.\n            If None, negative infinity values are replaced with the lowest finite value\n            representable by input's dtype. Default is None.\n    \"\"\"\n    def __init__(self, nan=None, posinf=None, neginf=None):\n        defaults = dict(nan=nan, posinf=posinf, neginf=neginf)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        nan, posinf, neginf = unpack_dicts(settings, 'nan', 'posinf', 'neginf')\n        return [t.nan_to_num_(nan_i, posinf_i, neginf_i) for t, nan_i, posinf_i, neginf_i in zip(tensors, nan, posinf, neginf)]\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Negate","title":"Negate","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>- input</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Negate(TensorTransform):\n    \"\"\"Returns ``- input``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_neg_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Noop","title":"Noop","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Identity(Module):\n    \"\"\"Identity operator that is argument-insensitive. This also can be used as identity hessian for trust region methods.\"\"\"\n    def __init__(self, *args, **kwargs): super().__init__()\n    def update(self, objective): pass\n    def apply(self, objective): return objective\n    def get_H(self, objective):\n        n = sum(p.numel() for p in objective.params)\n        p = objective.params[0]\n        return ScaledIdentity(shape=(n,n), device=p.device, dtype=p.dtype)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Ones","title":"Ones","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs ones</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Ones(Module):\n    \"\"\"Outputs ones\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.ones_like(p) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Params","title":"Params","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs parameters</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Params(Module):\n    \"\"\"Outputs parameters\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [p.clone() for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Pow","title":"Pow","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Take tensors to the power of <code>exponent</code>. <code>exponent</code> can be a number or a module.</p> <p>If <code>exponent</code> is a module, this calculates <code>tensors ^ exponent(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Pow(BinaryOperationBase):\n    \"\"\"Take tensors to the power of ``exponent``. ``exponent`` can be a number or a module.\n\n    If ``exponent`` is a module, this calculates ``tensors ^ exponent(tensors)``\n    \"\"\"\n    def __init__(self, exponent: Chainable | float):\n        super().__init__({}, exponent=exponent)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], exponent: float | list[torch.Tensor]):\n        torch._foreach_pow_(update, exponent)\n        return update\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.PowModules","title":"PowModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input ** exponent</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class PowModules(MultiOperationBase):\n    \"\"\"Calculates ``input ** exponent``. ``input`` and ``other`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable | float, exponent: Chainable | float):\n        defaults = {}\n        super().__init__(defaults, input=input, exponent=exponent)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: float | list[torch.Tensor], exponent: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        if isinstance(input, (int,float)):\n            assert isinstance(exponent, list)\n            return input ** TensorList(exponent)\n\n        torch._foreach_div_(input, exponent)\n        return input\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Prod","title":"Prod","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs product of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class Prod(ReduceOperationBase):\n    \"\"\"Outputs product of ``inputs`` that can be modules or numbers.\"\"\"\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        prod = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_mul_(prod, v)\n\n        return prod\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.RCopySign","title":"RCopySign","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Returns <code>other(tensors)</code> with sign copied from tensors.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RCopySign(BinaryOperationBase):\n    \"\"\"Returns ``other(tensors)`` with sign copied from tensors.\"\"\"\n    def __init__(self, other: Chainable):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: list[torch.Tensor]):\n        return [o.copysign_(u) for u, o in zip(update, other)]\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.RDiv","title":"RDiv","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Divide <code>other</code> by tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>other(tensors) / tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RDiv(BinaryOperationBase):\n    \"\"\"Divide ``other`` by tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``other(tensors) / tensors``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        return other / TensorList(update)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.RPow","title":"RPow","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Take <code>other</code> to the power of tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>other(tensors) ^ tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RPow(BinaryOperationBase):\n    \"\"\"Take ``other`` to the power of tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``other(tensors) ^ tensors``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        if isinstance(other, (int, float)): return torch._foreach_pow(other, update) # no in-place\n        torch._foreach_pow_(other, update)\n        return other\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.RSub","title":"RSub","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Subtract tensors from <code>other</code>. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates <code>other(tensors) - tensors</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class RSub(BinaryOperationBase):\n    \"\"\"Subtract tensors from ``other``. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates ``other(tensors) - tensors``\n    \"\"\"\n    def __init__(self, other: Chainable | float):\n        super().__init__({}, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        return other - TensorList(update)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Randn","title":"Randn","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with random numbers from a normal distribution with mean 0 and variance 1.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Randn(Module):\n    \"\"\"Outputs tensors filled with random numbers from a normal distribution with mean 0 and variance 1.\"\"\"\n    def __init__(self):\n        super().__init__({})\n\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.randn_like(p) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.RandomSample","title":"RandomSample","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with random numbers from distribution depending on value of <code>distribution</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class RandomSample(Module):\n    \"\"\"Outputs tensors filled with random numbers from distribution depending on value of ``distribution``.\"\"\"\n    def __init__(self, distribution: Distributions = 'normal', variance:float | None = None):\n        defaults = dict(distribution=distribution, variance=variance)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        distribution = self.defaults['distribution']\n        variance = self.get_settings(objective.params, 'variance')\n        objective.updates = TensorList(objective.params).sample_like(distribution=distribution, variance=variance)\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Reciprocal","title":"Reciprocal","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>1 / input</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Reciprocal(TensorTransform):\n    \"\"\"Returns ``1 / input``\"\"\"\n    def __init__(self, eps = 0):\n        defaults = dict(eps = eps)\n        super().__init__(defaults)\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        eps = [s['eps'] for s in settings]\n        if any(e != 0 for e in eps): torch._foreach_add_(tensors, eps)\n        torch._foreach_reciprocal_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.ReduceOperationBase","title":"ReduceOperationBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for reduction operations like Sum, Prod, Maximum. This is an abstract class, subclass it and override <code>transform</code> method to use it.</p> <p>Methods:</p> <ul> <li> <code>transform</code>             \u2013              <p>applies the operation to operands</p> </li> </ul> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class ReduceOperationBase(Module, ABC):\n    \"\"\"Base class for reduction operations like Sum, Prod, Maximum. This is an abstract class, subclass it and override `transform` method to use it.\"\"\"\n    def __init__(self, defaults: dict[str, Any] | None, *operands: Chainable | Any):\n        super().__init__(defaults=defaults)\n\n        self.operands = []\n        for i, v in enumerate(operands):\n\n            if isinstance(v, (Module, Sequence)):\n                self.set_child(f'operand_{i}', v)\n                self.operands.append(self.children[f'operand_{i}'])\n            else:\n                self.operands.append(v)\n\n        if not self.children:\n            raise ValueError('At least one operand must be a module')\n\n    @abstractmethod\n    def transform(self, objective: Objective, *operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        \"\"\"applies the operation to operands\"\"\"\n        raise NotImplementedError\n\n    def update(self, objective): raise RuntimeError\n    def apply(self, objective): raise RuntimeError\n\n    @torch.no_grad\n    def step(self, objective: Objective) -&gt; Objective:\n        # pass cloned update to all module operands\n        processed_operands: list[Any | list[torch.Tensor]] = self.operands.copy()\n\n        for i, v in enumerate(self.operands):\n            if f'operand_{i}' in self.children:\n                v: Module\n                updated_obj = v.step(objective.clone(clone_updates=True))\n                processed_operands[i] = updated_obj.get_updates()\n                objective.update_attrs_from_clone_(updated_obj) # update loss, grad, etc if this module calculated them\n\n        transformed = self.transform(objective, *processed_operands)\n        objective.updates = transformed\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.ReduceOperationBase.transform","title":"transform","text":"<pre><code>transform(objective: Objective, *operands: Any | list[Tensor]) -&gt; list[Tensor]\n</code></pre> <p>applies the operation to operands</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>@abstractmethod\ndef transform(self, objective: Objective, *operands: Any | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n    \"\"\"applies the operation to operands\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Sign","title":"Sign","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>sign(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Sign(TensorTransform):\n    \"\"\"Returns ``sign(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_sign_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Sqrt","title":"Sqrt","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Returns <code>sqrt(input)</code></p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class Sqrt(TensorTransform):\n    \"\"\"Returns ``sqrt(input)``\"\"\"\n    def __init__(self): super().__init__()\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        torch._foreach_sqrt_(tensors)\n        return tensors\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.SqrtEMASquared","title":"SqrtEMASquared","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Maintains an exponential moving average of squared updates, outputs optionally debiased square root.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0.999</code> )           \u2013            <p>momentum value. Defaults to 0.999.</p> </li> <li> <code>amsgrad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to maintain maximum of the exponential moving average. Defaults to False.</p> </li> <li> <code>debiased</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to multiply the output by a debiasing term from the Adam method. Defaults to False.</p> </li> <li> <code>pow</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>power, absolute value is always used. Defaults to 2.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>SQRT_EMA_SQ_FN</code>             \u2013              <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code> and calculates it's square root,</p> </li> </ul> Source code in <code>torchzero/modules/ops/higher_level.py</code> <pre><code>class SqrtEMASquared(TensorTransform):\n    \"\"\"Maintains an exponential moving average of squared updates, outputs optionally debiased square root.\n\n    Args:\n        beta (float, optional): momentum value. Defaults to 0.999.\n        amsgrad (bool, optional): whether to maintain maximum of the exponential moving average. Defaults to False.\n        debiased (bool, optional): whether to multiply the output by a debiasing term from the Adam method. Defaults to False.\n        pow (float, optional): power, absolute value is always used. Defaults to 2.\n    \"\"\"\n    SQRT_EMA_SQ_FN: staticmethod = staticmethod(sqrt_ema_sq_)\n    def __init__(self, beta:float=0.999, amsgrad=False, debiased: bool = False, pow:float=2,):\n        defaults = dict(beta=beta,pow=pow,amsgrad=amsgrad,debiased=debiased)\n        super().__init__(defaults)\n        self.add_projected_keys(\"grad_sq\", \"exp_avg_sq\", \"max_exp_avg_sq\")\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state['step'] = self.global_state.get('step', 0) + 1\n\n        amsgrad, pow, debiased = itemgetter('amsgrad', 'pow', 'debiased')(settings[0])\n        beta = NumberList(s['beta'] for s in settings)\n\n        if amsgrad:\n            exp_avg_sq, max_exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', 'max_exp_avg_sq', cls=TensorList)\n        else:\n            exp_avg_sq = unpack_states(states, tensors, 'exp_avg_sq', cls=TensorList)\n            max_exp_avg_sq = None\n\n        return self.SQRT_EMA_SQ_FN(\n            TensorList(tensors),\n            exp_avg_sq_=exp_avg_sq,\n            beta=beta,\n            max_exp_avg_sq_=max_exp_avg_sq,\n            debiased=debiased,\n            step=step,\n            pow=pow,\n        )\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.SqrtEMASquared.SQRT_EMA_SQ_FN","title":"SQRT_EMA_SQ_FN","text":"<pre><code>SQRT_EMA_SQ_FN(tensors: TensorList, exp_avg_sq_: TensorList, beta: float | NumberList, max_exp_avg_sq_: TensorList | None, debiased: bool, step: int, pow: float = 2, ema_sq_fn: Callable = ema_sq_)\n</code></pre> <p>Updates <code>exp_avg_sq_</code> with EMA of squared <code>tensors</code> and calculates it's square root, with optional AMSGrad and debiasing.</p> <p>Returns new tensors.</p> Source code in <code>torchzero/modules/opt_utils.py</code> <pre><code>def sqrt_ema_sq_(\n    tensors: TensorList,\n    exp_avg_sq_: TensorList,\n    beta: float | NumberList,\n    max_exp_avg_sq_: TensorList | None,\n    debiased: bool,\n    step: int,\n    pow: float = 2,\n    ema_sq_fn: Callable = ema_sq_,\n):\n    \"\"\"\n    Updates `exp_avg_sq_` with EMA of squared `tensors` and calculates it's square root,\n    with optional AMSGrad and debiasing.\n\n    Returns new tensors.\n    \"\"\"\n    exp_avg_sq_=ema_sq_fn(\n        tensors=tensors,\n        exp_avg_sq_=exp_avg_sq_,\n        beta=beta,\n        max_exp_avg_sq_=max_exp_avg_sq_,\n        pow=pow,\n    )\n\n    sqrt_exp_avg_sq = root(exp_avg_sq_, pow, inplace=False)\n\n    if debiased: sqrt_exp_avg_sq = debias_second_momentum(sqrt_exp_avg_sq, step=step, beta=beta, pow=pow, inplace=True)\n    return sqrt_exp_avg_sq\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Sub","title":"Sub","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Subtract <code>other</code> from tensors. <code>other</code> can be a number or a module.</p> <p>If <code>other</code> is a module, this calculates :code:<code>tensors - other(tensors)</code></p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Sub(BinaryOperationBase):\n    \"\"\"Subtract ``other`` from tensors. ``other`` can be a number or a module.\n\n    If ``other`` is a module, this calculates :code:`tensors - other(tensors)`\n    \"\"\"\n    def __init__(self, other: Chainable | float, alpha: float = 1):\n        defaults = dict(alpha=alpha)\n        super().__init__(defaults, other=other)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], other: float | list[torch.Tensor]):\n        if isinstance(other, (int,float)): torch._foreach_sub_(update, other * self.defaults['alpha'])\n        else: torch._foreach_sub_(update, other, alpha=self.defaults['alpha'])\n        return update\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.SubModules","title":"SubModules","text":"<p>               Bases: <code>torchzero.modules.ops.multi.MultiOperationBase</code></p> <p>Calculates <code>input - other</code>. <code>input</code> and <code>other</code> can be numbers or modules.</p> Source code in <code>torchzero/modules/ops/multi.py</code> <pre><code>class SubModules(MultiOperationBase):\n    \"\"\"Calculates ``input - other``. ``input`` and ``other`` can be numbers or modules.\"\"\"\n    def __init__(self, input: Chainable | float, other: Chainable | float, alpha: float = 1):\n        defaults = dict(alpha=alpha)\n        super().__init__(defaults, input=input, other=other)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, input: float | list[torch.Tensor], other: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        alpha = self.defaults['alpha']\n\n        if isinstance(input, (int,float)):\n            assert isinstance(other, list)\n            return input - TensorList(other).mul_(alpha)\n\n        if isinstance(other, (int, float)): torch._foreach_sub_(input, other * alpha)\n        else: torch._foreach_sub_(input, other, alpha=alpha)\n        return input\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Sum","title":"Sum","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs sum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class Sum(ReduceOperationBase):\n    \"\"\"Outputs sum of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = False\n    def __init__(self, *inputs: Chainable | float):\n        super().__init__({}, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        sum = cast(list, sorted_inputs[0])\n        if len(sorted_inputs) &gt; 1:\n            for v in sorted_inputs[1:]:\n                torch._foreach_add_(sum, v)\n\n        if self.USE_MEAN and len(sorted_inputs) &gt; 1: torch._foreach_div_(sum, len(sorted_inputs))\n        return sum\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Sum.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/ops/#torchzero.modules.ops.Threshold","title":"Threshold","text":"<p>               Bases: <code>torchzero.modules.ops.binary.BinaryOperationBase</code></p> <p>Outputs tensors thresholded such that values above <code>threshold</code> are set to <code>value</code>.</p> Source code in <code>torchzero/modules/ops/binary.py</code> <pre><code>class Threshold(BinaryOperationBase):\n    \"\"\"Outputs tensors thresholded such that values above ``threshold`` are set to ``value``.\"\"\"\n    def __init__(self, threshold: Chainable | float, value: Chainable | float, update_above: bool):\n        defaults = dict(update_above=update_above)\n        super().__init__(defaults, threshold=threshold, value=value)\n\n    @torch.no_grad\n    def transform(self, objective, update: list[torch.Tensor], threshold: list[torch.Tensor] | float, value: list[torch.Tensor] | float):\n        update_above = self.defaults['update_above']\n        update = TensorList(update)\n        if update_above:\n            if isinstance(value, list): return update.where(update&gt;threshold, value)\n            return update.masked_fill_(update&lt;=threshold, value)\n\n        if isinstance(value, list): return update.where(update&lt;threshold, value)\n        return update.masked_fill_(update&gt;=threshold, value)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.UnaryLambda","title":"UnaryLambda","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies <code>fn</code> to input tensors.</p> <p><code>fn</code> must accept and return a list of tensors.</p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class UnaryLambda(TensorTransform):\n    \"\"\"Applies ``fn`` to input tensors.\n\n    ``fn`` must accept and return a list of tensors.\n    \"\"\"\n    def __init__(self, fn):\n        defaults = dict(fn=fn)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return settings[0]['fn'](tensors)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.UnaryParameterwiseLambda","title":"UnaryParameterwiseLambda","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies <code>fn</code> to each input tensor.</p> <p><code>fn</code> must accept and return a tensor.</p> Source code in <code>torchzero/modules/ops/unary.py</code> <pre><code>class UnaryParameterwiseLambda(TensorTransform):\n    \"\"\"Applies ``fn`` to each input tensor.\n\n    ``fn`` must accept and return a tensor.\n    \"\"\"\n    def __init__(self, fn):\n        defaults = dict(fn=fn)\n        super().__init__(defaults=defaults)\n\n    @torch.no_grad\n    def single_tensor_apply(self, tensor, param, grad, loss, state, setting):\n        return setting['fn'](tensor)\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.Uniform","title":"Uniform","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs tensors filled with random numbers from uniform distribution between <code>low</code> and <code>high</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Uniform(Module):\n    \"\"\"Outputs tensors filled with random numbers from uniform distribution between ``low`` and ``high``.\"\"\"\n    def __init__(self, low: float, high: float):\n        defaults = dict(low=low, high=high)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        low,high = self.get_settings(objective.params, 'low','high')\n        objective.updates = [torch.empty_like(t).uniform_(l,h) for t,l,h in zip(objective.params, low, high)]\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.UpdateToNone","title":"UpdateToNone","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Sets <code>update</code> attribute to None on <code>var</code>.</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class UpdateToNone(Module):\n    \"\"\"Sets ``update`` attribute to None on ``var``.\"\"\"\n    def __init__(self): super().__init__()\n    def apply(self, objective):\n        objective.updates = None\n        return objective\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.WeightedMean","title":"WeightedMean","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.WeightedSum</code></p> <p>Outputs weighted mean of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class WeightedMean(WeightedSum):\n    \"\"\"Outputs weighted mean of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = True\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.WeightedMean.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = True\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/ops/#torchzero.modules.ops.WeightedSum","title":"WeightedSum","text":"<p>               Bases: <code>torchzero.modules.ops.reduce.ReduceOperationBase</code></p> <p>Outputs a weighted sum of <code>inputs</code> that can be modules or numbers.</p> Source code in <code>torchzero/modules/ops/reduce.py</code> <pre><code>class WeightedSum(ReduceOperationBase):\n    \"\"\"Outputs a weighted sum of ``inputs`` that can be modules or numbers.\"\"\"\n    USE_MEAN = False\n    def __init__(self, *inputs: Chainable | float, weights: Iterable[float]):\n        weights = list(weights)\n        if len(inputs) != len(weights):\n            raise ValueError(f'Number of inputs {len(inputs)} must match number of weights {len(weights)}')\n        defaults = dict(weights=weights)\n        super().__init__(defaults=defaults, *inputs)\n\n    @torch.no_grad\n    def transform(self, objective: Objective, *inputs: float | list[torch.Tensor]) -&gt; list[torch.Tensor]:\n        sorted_inputs = sorted(inputs, key=lambda x: isinstance(x, float))\n        weights = self.defaults['weights']\n        sum = cast(list, sorted_inputs[0])\n        torch._foreach_mul_(sum, weights[0])\n        if len(sorted_inputs) &gt; 1:\n            for v, w in zip(sorted_inputs[1:], weights[1:]):\n                if isinstance(v, (int, float)): torch._foreach_add_(sum, v*w)\n                else: torch._foreach_add_(sum, v, alpha=w)\n\n        if self.USE_MEAN and len(sorted_inputs) &gt; 1: torch._foreach_div_(sum, len(sorted_inputs))\n        return sum\n</code></pre>"},{"location":"API/modules/ops/#torchzero.modules.ops.WeightedSum.USE_MEAN","title":"USE_MEAN  <code>class-attribute</code>","text":"<pre><code>USE_MEAN = False\n</code></pre> <p>bool(x) -&gt; bool</p> <p>Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.</p>"},{"location":"API/modules/ops/#torchzero.modules.ops.Zeros","title":"Zeros","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Outputs zeros</p> Source code in <code>torchzero/modules/ops/utility.py</code> <pre><code>class Zeros(Module):\n    \"\"\"Outputs zeros\"\"\"\n    def __init__(self):\n        super().__init__({})\n    @torch.no_grad\n    def apply(self, objective):\n        objective.updates = [torch.zeros_like(p) for p in objective.params]\n        return objective\n</code></pre>"},{"location":"API/modules/projections/","title":"Projections","text":"<p>This subpackage contains projections that allow any other modules to be used in some projected space. This has multiple uses, one is to save memory by projecting into a smaller subspace, another is splitting parameters into smaller blocks or merging them into a single vector. This can also do things like optimize in fourier domain.</p> <p>Classes:</p> <ul> <li> <code>ProjectionBase</code>           \u2013            <p>Base class for projections.</p> </li> <li> <code>ScalarProjection</code>           \u2013            <p>projetion that splits all parameters into individual scalars</p> </li> <li> <code>To</code>           \u2013            <p>Cast modules to specified device and dtype</p> </li> <li> <code>VectorProjection</code>           \u2013            <p>projection that concatenates all parameters into a vector</p> </li> <li> <code>ViewAsReal</code>           \u2013            <p>View complex tensors as real tensors. Doesn't affect tensors that are already.</p> </li> </ul>"},{"location":"API/modules/projections/#torchzero.modules.projections.ProjectionBase","title":"ProjectionBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Base class for projections. This is an abstract class, to use it, subclass it and override <code>project</code> and <code>unproject</code>.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable</code>)           \u2013            <p>modules that will be applied in the projected domain.</p> </li> <li> <code>project_update</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to project the update. Defaults to True.</p> </li> <li> <code>project_params</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to project the params. This is necessary for modules that use closure. Defaults to False.</p> </li> <li> <code>project_grad</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to project the gradients (separately from update). Defaults to False.</p> </li> <li> <code>defaults</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>dictionary with defaults. Defaults to None.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>project</code>             \u2013              <p>projects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> </li> <li> <code>unproject</code>             \u2013              <p>unprojects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> </li> </ul> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>class ProjectionBase(Module, ABC):\n    \"\"\"\n    Base class for projections.\n    This is an abstract class, to use it, subclass it and override ``project`` and ``unproject``.\n\n    Args:\n        modules (Chainable): modules that will be applied in the projected domain.\n        project_update (bool, optional): whether to project the update. Defaults to True.\n        project_params (bool, optional):\n            whether to project the params. This is necessary for modules that use closure. Defaults to False.\n        project_grad (bool, optional): whether to project the gradients (separately from update). Defaults to False.\n        defaults (dict[str, Any] | None, optional): dictionary with defaults. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        modules: Chainable,\n        project_update=True,\n        project_params=False,\n        project_grad=False,\n        defaults: dict[str, Any] | None = None,\n    ):\n        super().__init__(defaults)\n        self.set_child('modules', modules)\n        self.global_state['current_step'] = 0\n        self._project_update = project_update\n        self._project_params = project_params\n        self._project_grad = project_grad\n        self._projected_params = None\n\n        self._states: dict[str, list[dict[str, Any]]] = {}\n        \"\"\"per-parameter states for each projection target\"\"\"\n\n    @abstractmethod\n    def project(\n        self,\n        tensors: list[torch.Tensor],\n        params: list[torch.Tensor],\n        grads: list[torch.Tensor] | None,\n        loss: torch.Tensor | None,\n        states: list[dict[str, Any]],\n        settings: list[ChainMap[str, Any]],\n        current: str,\n    ) -&gt; Iterable[torch.Tensor]:\n        \"\"\"projects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\"\"\"\n\n    @abstractmethod\n    def unproject(\n        self,\n        projected_tensors: list[torch.Tensor],\n        params: list[torch.Tensor],\n        grads: list[torch.Tensor] | None,\n        loss: torch.Tensor | None,\n        states: list[dict[str, Any]],\n        settings: list[ChainMap[str, Any]],\n        current: str,\n    ) -&gt; Iterable[torch.Tensor]:\n        \"\"\"unprojects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\n\n        Args:\n            projected_tensors (list[torch.Tensor]): projected tensors to unproject.\n            params (list[torch.Tensor]): original, unprojected parameters.\n            grads (list[torch.Tensor] | None): original, unprojected gradients\n            loss (torch.Tensor | None): loss at initial point.\n            states (list[dict[str, Any]]): list of state dictionaries per each UNPROJECTED tensor.\n            settings (list[ChainMap[str, Any]]): list of setting dictionaries per each UNPROJECTED tensor.\n            current (str): string representing what is being unprojected, e.g. \"params\", \"grads\" or \"update\".\n\n        Returns:\n            Iterable[torch.Tensor]: unprojected tensors of the same shape as params\n        \"\"\"\n\n    def update(self, objective: Objective): raise RuntimeError(\"projections don't support update/apply\")\n    def apply(self, objective: Objective): raise RuntimeError(\"projections don't support update/apply\")\n\n    @torch.no_grad\n    def step(self, objective: Objective):\n        params = objective.params\n        settings = [self.settings[p] for p in params]\n\n        def _project(tensors: list[torch.Tensor], current: Literal['params', 'grads', 'update']):\n            states = self._states.setdefault(current, [{} for _ in params])\n            return list(self.project(\n                tensors=tensors,\n                params=params,\n                grads=objective.grads,\n                loss=objective.loss,\n                states=states,\n                settings=settings,\n                current=current,\n            ))\n\n        projected_obj = objective.clone(clone_updates=False, parent=objective)\n\n        closure = objective.closure\n\n        # if this is True, update and grad were projected simultaneously under current=\"grads\"\n        # so update will have to be unprojected with current=\"grads\"\n        update_is_grad = False\n\n        # if closure is provided and project_params=True, make new closure that evaluates projected params\n        # that also means projected modules can evaluate grad/update at will, it shouldn't be computed here\n        # but if it has already been computed, it should be projected\n        if self._project_params and closure is not None:\n\n            if self._project_update and objective.updates is not None:\n                # project update only if it already exists\n                projected_obj.updates = _project(objective.updates, current='update')\n\n            else:\n                # update will be set to gradients on var.get_grad()\n                # therefore projection will happen with current=\"grads\"\n                update_is_grad = True\n\n            # project grad only if it already exists\n            if self._project_grad and objective.grads is not None:\n                projected_obj.grads = _project(objective.grads, current='grads')\n\n        # otherwise update/grad needs to be calculated and projected here\n        else:\n            if self._project_update:\n                if objective.updates is None:\n                    # update is None, meaning it will be set to `grad`.\n                    # we can project grad and use it for update\n                    grad = objective.get_grads()\n                    projected_obj.grads = _project(grad, current='grads')\n                    projected_obj.updates = [g.clone() for g in projected_obj.grads]\n                    del objective.updates\n                    update_is_grad = True\n\n                else:\n                    # update exists so it needs to be projected\n                    update = objective.get_updates()\n                    projected_obj.updates = _project(update, current='update')\n                    del update, objective.updates\n\n            if self._project_grad and projected_obj.grads is None:\n                # projected_vars.grad may have been projected simultaneously with update\n                # but if that didn't happen, it is projected here\n                grad = objective.get_grads()\n                projected_obj.grads = _project(grad, current='grads')\n\n\n        original_params = None\n        if self._project_params:\n            original_params = [p.clone() for p in objective.params]\n            projected_params = _project(objective.params, current='params')\n\n        else:\n            # make fake params for correct shapes and state storage\n            # they reuse update or grad storage for memory efficiency\n            projected_params = projected_obj.updates if projected_obj.updates is not None else projected_obj.grads\n            assert projected_params is not None\n\n        if self._projected_params is None:\n            # 1st step - create objects for projected_params. They have to remain the same python objects\n            # to support per-parameter states which are stored by ids.\n            self._projected_params = [p.view_as(p).requires_grad_() for p in projected_params]\n        else:\n            # set storage to new fake params while ID remains the same\n            for empty_p, new_p in zip(self._projected_params, projected_params):\n                empty_p.set_(new_p.view_as(new_p).requires_grad_()) # pyright: ignore[reportArgumentType]\n\n        projected_params = self._projected_params\n        # projected_settings = [self.settings[p] for p in projected_params]\n\n        def _unproject(projected_tensors: list[torch.Tensor], current: Literal['params', 'grads', 'update']):\n            states = self._states.setdefault(current, [{} for _ in params])\n            return list(self.unproject(\n                projected_tensors=projected_tensors,\n                params=params,\n                grads=objective.grads,\n                loss=objective.loss,\n                states=states,\n                settings=settings,\n                current=current,\n            ))\n\n        # project closure\n        if self._project_params:\n            projected_obj.closure = _make_projected_closure(closure, project_fn=_project, unproject_fn=_unproject,\n                                                            params=params, projected_params=projected_params)\n\n        elif closure is not None:\n            projected_obj.closure = _FakeProjectedClosure(closure, project_fn=_project,\n                                                          params=params, fake_params=projected_params)\n\n        else:\n            projected_obj.closure = None\n\n        # ----------------------------------- step ----------------------------------- #\n        projected_obj.params = projected_params\n        projected_obj = self.children['modules'].step(projected_obj)\n\n        # empty fake params storage\n        # this doesn't affect update/grad because it is a different python object, set_ changes storage on an object\n        if not self._project_params:\n            for p in self._projected_params:\n                set_storage_(p, torch.empty(0, device=p.device, dtype=p.dtype))\n\n        # --------------------------------- unproject -------------------------------- #\n        unprojected_obj = projected_obj.clone(clone_updates=False)\n        unprojected_obj.closure = objective.closure\n        unprojected_obj.params = objective.params\n        unprojected_obj.grads = objective.grads # this may also be set by projected_var since it has var as parent\n\n        if self._project_update:\n            assert projected_obj.updates is not None\n            unprojected_obj.updates = _unproject(projected_obj.updates, current='grads' if update_is_grad else 'update')\n            del projected_obj.updates\n\n        del projected_obj\n\n        # original params are stored if params are projected\n        if original_params is not None:\n            for p, o in zip(unprojected_obj.params, original_params):\n                p.set_(o) # pyright: ignore[reportArgumentType]\n\n        return unprojected_obj\n</code></pre>"},{"location":"API/modules/projections/#torchzero.modules.projections.ProjectionBase.project","title":"project","text":"<pre><code>project(tensors: list[Tensor], params: list[Tensor], grads: list[Tensor] | None, loss: Tensor | None, states: list[dict[str, Any]], settings: list[ChainMap[str, Any]], current: str) -&gt; Iterable[Tensor]\n</code></pre> <p>projects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>@abstractmethod\ndef project(\n    self,\n    tensors: list[torch.Tensor],\n    params: list[torch.Tensor],\n    grads: list[torch.Tensor] | None,\n    loss: torch.Tensor | None,\n    states: list[dict[str, Any]],\n    settings: list[ChainMap[str, Any]],\n    current: str,\n) -&gt; Iterable[torch.Tensor]:\n    \"\"\"projects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\"\"\"\n</code></pre>"},{"location":"API/modules/projections/#torchzero.modules.projections.ProjectionBase.unproject","title":"unproject","text":"<pre><code>unproject(projected_tensors: list[Tensor], params: list[Tensor], grads: list[Tensor] | None, loss: Tensor | None, states: list[dict[str, Any]], settings: list[ChainMap[str, Any]], current: str) -&gt; Iterable[Tensor]\n</code></pre> <p>unprojects <code>tensors</code>. Note that this can be called multiple times per step with <code>params</code>, <code>grads</code>, and <code>update</code>.</p> <p>Parameters:</p> <ul> <li> <code>projected_tensors</code>               (<code>list[Tensor]</code>)           \u2013            <p>projected tensors to unproject.</p> </li> <li> <code>params</code>               (<code>list[Tensor]</code>)           \u2013            <p>original, unprojected parameters.</p> </li> <li> <code>grads</code>               (<code>list[Tensor] | None</code>)           \u2013            <p>original, unprojected gradients</p> </li> <li> <code>loss</code>               (<code>Tensor | None</code>)           \u2013            <p>loss at initial point.</p> </li> <li> <code>states</code>               (<code>list[dict[str, Any]]</code>)           \u2013            <p>list of state dictionaries per each UNPROJECTED tensor.</p> </li> <li> <code>settings</code>               (<code>list[ChainMap[str, Any]]</code>)           \u2013            <p>list of setting dictionaries per each UNPROJECTED tensor.</p> </li> <li> <code>current</code>               (<code>str</code>)           \u2013            <p>string representing what is being unprojected, e.g. \"params\", \"grads\" or \"update\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterable[Tensor]</code>           \u2013            <p>Iterable[torch.Tensor]: unprojected tensors of the same shape as params</p> </li> </ul> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>@abstractmethod\ndef unproject(\n    self,\n    projected_tensors: list[torch.Tensor],\n    params: list[torch.Tensor],\n    grads: list[torch.Tensor] | None,\n    loss: torch.Tensor | None,\n    states: list[dict[str, Any]],\n    settings: list[ChainMap[str, Any]],\n    current: str,\n) -&gt; Iterable[torch.Tensor]:\n    \"\"\"unprojects `tensors`. Note that this can be called multiple times per step with `params`, `grads`, and `update`.\n\n    Args:\n        projected_tensors (list[torch.Tensor]): projected tensors to unproject.\n        params (list[torch.Tensor]): original, unprojected parameters.\n        grads (list[torch.Tensor] | None): original, unprojected gradients\n        loss (torch.Tensor | None): loss at initial point.\n        states (list[dict[str, Any]]): list of state dictionaries per each UNPROJECTED tensor.\n        settings (list[ChainMap[str, Any]]): list of setting dictionaries per each UNPROJECTED tensor.\n        current (str): string representing what is being unprojected, e.g. \"params\", \"grads\" or \"update\".\n\n    Returns:\n        Iterable[torch.Tensor]: unprojected tensors of the same shape as params\n    \"\"\"\n</code></pre>"},{"location":"API/modules/projections/#torchzero.modules.projections.ScalarProjection","title":"ScalarProjection","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>projetion that splits all parameters into individual scalars</p> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>class ScalarProjection(ProjectionBase):\n    \"\"\"projetion that splits all parameters into individual scalars\"\"\"\n    def __init__(\n        self,\n        modules: Chainable,\n        project_update=True,\n        project_params=True,\n        project_grad=True,\n    ):\n        super().__init__(modules, project_update=project_update, project_params=project_params, project_grad=project_grad)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        return [s for t in tensors for s in t.ravel().unbind(0)]\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        return vec_to_tensors(vec=torch.stack(projected_tensors), reference=params)\n</code></pre>"},{"location":"API/modules/projections/#torchzero.modules.projections.To","title":"To","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>Cast modules to specified device and dtype</p> Source code in <code>torchzero/modules/projections/cast.py</code> <pre><code>class To(ProjectionBase):\n    \"\"\"Cast modules to specified device and dtype\"\"\"\n    def __init__(self, modules: Chainable, dtype: torch.dtype | None, device:torch.types.Device | None = None):\n        defaults = dict(dtype=dtype, device=device)\n        super().__init__(modules, project_update=True, project_params=True, project_grad=True, defaults=defaults)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        casted = []\n        for tensor, state, setting in zip(tensors,states, settings):\n            state['dtype'] = tensor.dtype\n            state['device'] = tensor.device\n            tensor = tensor.to(dtype=setting['dtype'], device=setting['device'])\n            casted.append(tensor)\n        return casted\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        uncasted = []\n        for tensor, state in zip(projected_tensors, states):\n            tensor = tensor.to(dtype=state['dtype'], device=state['device'])\n            uncasted.append(tensor)\n        return uncasted\n</code></pre>"},{"location":"API/modules/projections/#torchzero.modules.projections.VectorProjection","title":"VectorProjection","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>projection that concatenates all parameters into a vector</p> Source code in <code>torchzero/modules/projections/projection.py</code> <pre><code>class VectorProjection(ProjectionBase):\n    \"\"\"projection that concatenates all parameters into a vector\"\"\"\n    def __init__(\n        self,\n        modules: Chainable,\n        project_update=True,\n        project_params=True,\n        project_grad=True,\n    ):\n        super().__init__(modules, project_update=project_update, project_params=project_params, project_grad=project_grad)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        return [torch.cat([t.ravel() for t in tensors])]\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        return vec_to_tensors(vec=projected_tensors[0], reference=params)\n</code></pre>"},{"location":"API/modules/projections/#torchzero.modules.projections.ViewAsReal","title":"ViewAsReal","text":"<p>               Bases: <code>torchzero.modules.projections.projection.ProjectionBase</code></p> <p>View complex tensors as real tensors. Doesn't affect tensors that are already.</p> Source code in <code>torchzero/modules/projections/cast.py</code> <pre><code>class ViewAsReal(ProjectionBase):\n    \"\"\"View complex tensors as real tensors. Doesn't affect tensors that are already.\"\"\"\n    def __init__(self, modules: Chainable):\n        super().__init__(modules, project_update=True, project_params=True, project_grad=True, defaults=None)\n\n    @torch.no_grad\n    def project(self, tensors, params, grads, loss, states, settings, current):\n        views = []\n        for tensor, state in zip(tensors,states):\n            is_complex = torch.is_complex(tensor)\n            state['is_complex'] = is_complex\n            if is_complex: tensor = torch.view_as_real(tensor)\n            views.append(tensor)\n        return views\n\n    @torch.no_grad\n    def unproject(self, projected_tensors, params, grads, loss, states, settings, current):\n        un_views = []\n        for tensor, state in zip(projected_tensors, states):\n            if state['is_complex']: tensor = torch.view_as_complex(tensor)\n            un_views.append(tensor)\n        return un_views\n</code></pre>"},{"location":"API/modules/quasi_newton/","title":"Quasi-newton methods","text":"<p>This subpackage contains Quasi-newton methods that estimate the hessian using gradient information.</p>"},{"location":"API/modules/quasi_newton/#see-also","title":"See also","text":"<ul> <li>Conjugate gradient - computationally cheaper alternative to quasi-newton methods.</li> <li>Second order - \"true\" second order methods.</li> <li>Line search - quasi-newton methods usually require either a line search or a trust region.</li> <li>Trust region - trust regions can use hessian estimated by any of the quasi-newton methods.</li> </ul> <p>Classes:</p> <ul> <li> <code>BFGS</code>           \u2013            <p>Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno Quasi-Newton method. This is usually the most stable quasi-newton method.</p> </li> <li> <code>BroydenBad</code>           \u2013            <p>Broyden's \"bad\" Quasi-Newton method.</p> </li> <li> <code>BroydenGood</code>           \u2013            <p>Broyden's \"good\" Quasi-Newton method.</p> </li> <li> <code>DFP</code>           \u2013            <p>Davidon\u2013Fletcher\u2013Powell Quasi-Newton method.</p> </li> <li> <code>DNRTR</code>           \u2013            <p>Diagonal quasi-newton method.</p> </li> <li> <code>DiagonalBFGS</code>           \u2013            <p>Diagonal BFGS. This is simply BFGS with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> </li> <li> <code>DiagonalQuasiCauchi</code>           \u2013            <p>Diagonal quasi-cauchi method.</p> </li> <li> <code>DiagonalSR1</code>           \u2013            <p>Diagonal SR1. This is simply SR1 with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> </li> <li> <code>DiagonalWeightedQuasiCauchi</code>           \u2013            <p>Diagonal quasi-cauchi method.</p> </li> <li> <code>FletcherVMM</code>           \u2013            <p>Fletcher's variable metric Quasi-Newton method.</p> </li> <li> <code>GradientCorrection</code>           \u2013            <p>Estimates gradient at minima along search direction assuming function is quadratic.</p> </li> <li> <code>Greenstadt1</code>           \u2013            <p>Greenstadt's first Quasi-Newton method.</p> </li> <li> <code>Greenstadt2</code>           \u2013            <p>Greenstadt's second Quasi-Newton method.</p> </li> <li> <code>Horisho</code>           \u2013            <p>Horisho's variable metric Quasi-Newton method.</p> </li> <li> <code>ICUM</code>           \u2013            <p>Inverse Column-updating Quasi-Newton method. This is computationally cheaper than other Quasi-Newton methods</p> </li> <li> <code>LBFGS</code>           \u2013            <p>Limited-memory BFGS algorithm. A line search or trust region is recommended.</p> </li> <li> <code>LSR1</code>           \u2013            <p>Limited-memory SR1 algorithm. A line search or trust region is recommended.</p> </li> <li> <code>McCormick</code>           \u2013            <p>McCormicks's Quasi-Newton method.</p> </li> <li> <code>NewDQN</code>           \u2013            <p>Diagonal quasi-newton method.</p> </li> <li> <code>NewSSM</code>           \u2013            <p>Self-scaling Quasi-Newton method.</p> </li> <li> <code>PSB</code>           \u2013            <p>Powell's Symmetric Broyden Quasi-Newton method.</p> </li> <li> <code>Pearson</code>           \u2013            <p>Pearson's Quasi-Newton method.</p> </li> <li> <code>ProjectedNewtonRaphson</code>           \u2013            <p>Projected Newton Raphson method.</p> </li> <li> <code>SG2</code>           \u2013            <p>second-order stochastic gradient</p> </li> <li> <code>SR1</code>           \u2013            <p>Symmetric Rank 1. This works best with a trust region:</p> </li> <li> <code>SSVM</code>           \u2013            <p>Self-scaling variable metric Quasi-Newton method.</p> </li> <li> <code>ShorR</code>           \u2013            <p>Shor\u2019s r-algorithm.</p> </li> <li> <code>ThomasOptimalMethod</code>           \u2013            <p>Thomas's \"optimal\" Quasi-Newton method.</p> </li> </ul>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.BFGS","title":"BFGS","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno Quasi-Newton method. This is usually the most stable quasi-newton method.</p> Note <p>a line search or a trust region is recommended</p> Warning <p>this uses at least O(N^2) memory.</p> <p>Parameters:</p> <ul> <li> <code>init_scale</code>               (<code>float | Literal['auto']</code>, default:                   <code>'auto'</code> )           \u2013            <p>initial hessian matrix is set to identity times this.</p> <p>\"auto\" corresponds to a heuristic from Nocedal. Stephen J. Wright. Numerical Optimization p.142-143.</p> <p>Defaults to \"auto\".</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-32</code> )           \u2013            <p>tolerance on curvature condition. Defaults to 1e-32.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips update if maximum difference between current and previous gradients is less than this, to avoid instability. Defaults to 1e-32.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.</p> </li> <li> <code>restart_interval</code>               (<code>int | None | Literal['auto']</code>, default:                   <code>None</code> )           \u2013            <p>interval between resetting the hessian approximation.</p> <p>\"auto\" corresponds to number of decision variables + 1.</p> <p>None - no resets.</p> <p>Defaults to None.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>momentum on H or B. Defaults to None.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating H or B. Defaults to 1.</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to downscale first step before hessian approximation becomes available. Defaults to True.</p> </li> <li> <code>scale_second</code>               (<code>bool</code>)           \u2013            <p>whether to downscale second step. Defaults to False.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If true, all parameters are treated as a single vector. If False, the update rule is applied to each parameter separately. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to the output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.BFGS--examples","title":"Examples:","text":"<p>BFGS with backtracking line search:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.BFGS(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>BFGS with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.BFGS(inverse=False)),\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class BFGS(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno Quasi-Newton method. This is usually the most stable quasi-newton method.\n\n    Note:\n        a line search or a trust region is recommended\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Args:\n        init_scale (float | Literal[\"auto\"], optional):\n            initial hessian matrix is set to identity times this.\n\n            \"auto\" corresponds to a heuristic from Nocedal. Stephen J. Wright. Numerical Optimization p.142-143.\n\n            Defaults to \"auto\".\n        tol (float, optional):\n            tolerance on curvature condition. Defaults to 1e-32.\n        ptol (float | None, optional):\n            skips update if maximum difference between current and previous gradients is less than this, to avoid instability.\n            Defaults to 1e-32.\n        ptol_restart (bool, optional): whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.\n        restart_interval (int | None | Literal[\"auto\"], optional):\n            interval between resetting the hessian approximation.\n\n            \"auto\" corresponds to number of decision variables + 1.\n\n            None - no resets.\n\n            Defaults to None.\n        beta (float | None, optional): momentum on H or B. Defaults to None.\n        update_freq (int, optional): frequency of updating H or B. Defaults to 1.\n        scale_first (bool, optional):\n            whether to downscale first step before hessian approximation becomes available. Defaults to True.\n        scale_second (bool, optional): whether to downscale second step. Defaults to False.\n        concat_params (bool, optional):\n            If true, all parameters are treated as a single vector.\n            If False, the update rule is applied to each parameter separately. Defaults to True.\n        inner (Chainable | None, optional): preconditioning is applied to the output of this module. Defaults to None.\n\n    ## Examples:\n\n    BFGS with backtracking line search:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.BFGS(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    BFGS with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.BFGS(inverse=False)),\n    )\n    ```\n    \"\"\"\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return bfgs_H_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return bfgs_B_(B=B, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.BroydenBad","title":"BroydenBad","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Broyden's \"bad\" Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class BroydenBad(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Broyden's \"bad\" Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_bad_H_(H=H, s=s, y=y)\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_bad_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.BroydenGood","title":"BroydenGood","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Broyden's \"good\" Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class BroydenGood(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Broyden's \"good\" Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_good_H_(H=H, s=s, y=y)\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return broyden_good_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.DFP","title":"DFP","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Davidon\u2013Fletcher\u2013Powell Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class DFP(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Davidon\u2013Fletcher\u2013Powell Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return dfp_H_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return dfp_B(B=B, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.DNRTR","title":"DNRTR","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Diagonal quasi-newton method.</p> Reference <p>Andrei, Neculai. \"A diagonal quasi-Newton updating method for unconstrained optimization.\" Numerical Algorithms 81.2 (2019): 575-590.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DNRTR(HessianUpdateStrategy):\n    \"\"\"Diagonal quasi-newton method.\n\n    Reference:\n        Andrei, Neculai. \"A diagonal quasi-Newton updating method for unconstrained optimization.\" Numerical Algorithms 81.2 (2019): 575-590.\n    \"\"\"\n    def __init__(\n        self,\n        lb: float = 1e-2,\n        ub: float = 1e5,\n        init_scale: float | Literal[\"auto\"] = \"auto\",\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(lb=lb, ub=ub)\n        super().__init__(\n            defaults=defaults,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=False,\n            inner=inner,\n        )\n\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_wqc_B_(B=B, s=s, y=y)\n\n    def modify_B(self, B, state, setting):\n        return _truncate(B, setting['lb'], setting['ub'])\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.DiagonalBFGS","title":"DiagonalBFGS","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Diagonal BFGS. This is simply BFGS with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalBFGS(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Diagonal BFGS. This is simply BFGS with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.\"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_bfgs_H_(H=H, s=s, y=y, tol=setting['tol'])\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.DiagonalQuasiCauchi","title":"DiagonalQuasiCauchi","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._HessianUpdateStrategyDefaults</code></p> <p>Diagonal quasi-cauchi method.</p> Reference <p>Zhu M., Nazareth J. L., Wolkowicz H. The quasi-Cauchy relation and diagonal updating //SIAM Journal on Optimization. \u2013 1999. \u2013 \u0422. 9. \u2013 \u2116. 4. \u2013 \u0421. 1192-1204.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalQuasiCauchi(_HessianUpdateStrategyDefaults):\n    \"\"\"Diagonal quasi-cauchi method.\n\n    Reference:\n        Zhu M., Nazareth J. L., Wolkowicz H. The quasi-Cauchy relation and diagonal updating //SIAM Journal on Optimization. \u2013 1999. \u2013 \u0422. 9. \u2013 \u2116. 4. \u2013 \u0421. 1192-1204.\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_qc_B_(B=B, s=s, y=y)\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.DiagonalSR1","title":"DiagonalSR1","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Diagonal SR1. This is simply SR1 with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalSR1(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Diagonal SR1. This is simply SR1 with only the diagonal being updated and used. It doesn't satisfy the secant equation but may still be useful.\"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_sr1_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_sr1_(H=B, s=y, y=s, tol=setting['tol'])\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.DiagonalWeightedQuasiCauchi","title":"DiagonalWeightedQuasiCauchi","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._HessianUpdateStrategyDefaults</code></p> <p>Diagonal quasi-cauchi method.</p> Reference <p>Leong, Wah June, Sharareh Enshaei, and Sie Long Kek. \"Diagonal quasi-Newton methods via least change updating principle with weighted Frobenius norm.\" Numerical Algorithms 86 (2021): 1225-1241.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class DiagonalWeightedQuasiCauchi(_HessianUpdateStrategyDefaults):\n    \"\"\"Diagonal quasi-cauchi method.\n\n    Reference:\n        Leong, Wah June, Sharareh Enshaei, and Sie Long Kek. \"Diagonal quasi-Newton methods via least change updating principle with weighted Frobenius norm.\" Numerical Algorithms 86 (2021): 1225-1241.\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return diagonal_wqc_B_(B=B, s=s, y=y)\n\n    def initialize_P(self, size:int, device, dtype, is_inverse:bool): return torch.ones(size, device=device, dtype=dtype)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.FletcherVMM","title":"FletcherVMM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Fletcher's variable metric Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Fletcher, R. (1970). A new approach to variable metric algorithms. The Computer Journal, 13(3), 317\u2013322. doi:10.1093/comjnl/13.3.317</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class FletcherVMM(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Fletcher's variable metric Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Fletcher, R. (1970). A new approach to variable metric algorithms. The Computer Journal, 13(3), 317\u2013322. doi:10.1093/comjnl/13.3.317\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return fletcher_vmm_H_(H=H, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.GradientCorrection","title":"GradientCorrection","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Estimates gradient at minima along search direction assuming function is quadratic.</p> <p>This can useful as inner module for second order methods with inexact line search.</p>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.GradientCorrection--example","title":"Example:","text":"<p>L-BFGS with gradient correction</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(inner=tz.m.GradientCorrection()),\n    tz.m.Backtracking()\n)\n</code></pre> Reference <p>HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class GradientCorrection(TensorTransform):\n    \"\"\"\n    Estimates gradient at minima along search direction assuming function is quadratic.\n\n    This can useful as inner module for second order methods with inexact line search.\n\n    ## Example:\n    L-BFGS with gradient correction\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(inner=tz.m.GradientCorrection()),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Reference:\n        HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394\n\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        if 'p_prev' not in states[0]:\n            p_prev = unpack_states(states, tensors, 'p_prev', init=params)\n            g_prev = unpack_states(states, tensors, 'g_prev', init=tensors)\n            return tensors\n\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', cls=TensorList)\n        g_hat = gradient_correction(TensorList(tensors), params-p_prev, tensors-g_prev)\n\n        p_prev.copy_(params)\n        g_prev.copy_(tensors)\n        return g_hat\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.Greenstadt1","title":"Greenstadt1","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Greenstadt's first Quasi-Newton method.</p> Note <p>a trust region or an accurate line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Greenstadt1(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Greenstadt's first Quasi-Newton method.\n\n    Note:\n        a trust region or an accurate line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return greenstadt1_H_(H=H, s=s, y=y, g_prev=g_prev)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.Greenstadt2","title":"Greenstadt2","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Greenstadt's second Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Greenstadt2(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Greenstadt's second Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return greenstadt2_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.Horisho","title":"Horisho","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Horisho's variable metric Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Horisho(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Horisho's variable metric Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        HOSHINO, S. (1972). A Formulation of Variable Metric Methods. IMA Journal of Applied Mathematics, 10(3), 394\u2013403. doi:10.1093/imamat/10.3.394\n    \"\"\"\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return hoshino_H_(H=H, s=s, y=y, tol=setting['tol'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.ICUM","title":"ICUM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Inverse Column-updating Quasi-Newton method. This is computationally cheaper than other Quasi-Newton methods due to only updating one column of the inverse hessian approximation per step.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Lopes, V. L., &amp; Mart\u00ednez, J. M. (1995). Convergence properties of the inverse column-updating method. Optimization Methods &amp; Software, 6(2), 127\u2013144. from https://www.ime.unicamp.br/sites/default/files/pesquisa/relatorios/rp-1993-76.pdf</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ICUM(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Inverse Column-updating Quasi-Newton method. This is computationally cheaper than other Quasi-Newton methods\n    due to only updating one column of the inverse hessian approximation per step.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Lopes, V. L., &amp; Mart\u00ednez, J. M. (1995). Convergence properties of the inverse column-updating method. Optimization Methods &amp; Software, 6(2), 127\u2013144. from https://www.ime.unicamp.br/sites/default/files/pesquisa/relatorios/rp-1993-76.pdf\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return icum_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.LBFGS","title":"LBFGS","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Limited-memory BFGS algorithm. A line search or trust region is recommended.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>number of past parameter differences and gradient differences to store. Defaults to 10.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips updating the history if maximum absolute value of parameter difference is less than this value. Defaults to 1e-10.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever parameter difference is less then <code>ptol</code>, L-BFGS state will be reset. Defaults to None.</p> </li> <li> <code>gtol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips updating the history if if maximum absolute value of gradient difference is less than this value. Defaults to 1e-10.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever gradient difference is less then <code>gtol</code>, L-BFGS state will be reset. Defaults to None.</p> </li> <li> <code>sy_tol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>history will not be updated whenever s\u22c5y is less than this value (negative s\u22c5y means negative curvature)</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>makes first step, when hessian approximation is not available, small to reduce number of line search iterations. Defaults to True.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>how often to update L-BFGS history. Larger values may be better for stochastic optimization. Defaults to 1.</p> </li> <li> <code>damping</code>               (<code>Union</code>, default:                   <code>None</code> )           \u2013            <p>damping to use, can be \"powell\" or \"double\". Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional inner modules applied after updating L-BFGS history and before preconditioning. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.LBFGS--examples","title":"Examples:","text":"<p>L-BFGS with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(100),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>L-BFGS with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.LBFGS())\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/lbfgs.py</code> <pre><code>class LBFGS(TensorTransform):\n    \"\"\"Limited-memory BFGS algorithm. A line search or trust region is recommended.\n\n    Args:\n        history_size (int, optional):\n            number of past parameter differences and gradient differences to store. Defaults to 10.\n        ptol (float | None, optional):\n            skips updating the history if maximum absolute value of\n            parameter difference is less than this value. Defaults to 1e-10.\n        ptol_restart (bool, optional):\n            If true, whenever parameter difference is less then ``ptol``,\n            L-BFGS state will be reset. Defaults to None.\n        gtol (float | None, optional):\n            skips updating the history if if maximum absolute value of\n            gradient difference is less than this value. Defaults to 1e-10.\n        ptol_restart (bool, optional):\n            If true, whenever gradient difference is less then ``gtol``,\n            L-BFGS state will be reset. Defaults to None.\n        sy_tol (float | None, optional):\n            history will not be updated whenever s\u22c5y is less than this value (negative s\u22c5y means negative curvature)\n        scale_first (bool, optional):\n            makes first step, when hessian approximation is not available,\n            small to reduce number of line search iterations. Defaults to True.\n        update_freq (int, optional):\n            how often to update L-BFGS history. Larger values may be better for stochastic optimization. Defaults to 1.\n        damping (DampingStrategyType, optional):\n            damping to use, can be \"powell\" or \"double\". Defaults to None.\n        inner (Chainable | None, optional):\n            optional inner modules applied after updating L-BFGS history and before preconditioning. Defaults to None.\n\n    ## Examples:\n\n    L-BFGS with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LBFGS(100),\n        tz.m.Backtracking()\n    )\n    ```\n\n    L-BFGS with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.LBFGS())\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        history_size=10,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        gtol_restart: bool = False,\n        sy_tol: float = 1e-32,\n        scale_first:bool=True,\n        update_freq = 1,\n        damping: DampingStrategyType = None,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(\n            history_size=history_size,\n            scale_first=scale_first,\n            ptol=ptol,\n            gtol=gtol,\n            ptol_restart=ptol_restart,\n            gtol_restart=gtol_restart,\n            sy_tol=sy_tol,\n            damping = damping,\n        )\n        super().__init__(defaults, inner=inner, update_freq=update_freq)\n\n        self.global_state['s_history'] = deque(maxlen=history_size)\n        self.global_state['y_history'] = deque(maxlen=history_size)\n        self.global_state['sy_history'] = deque(maxlen=history_size)\n\n    def _reset_self(self):\n        self.state.clear()\n        self.global_state['step'] = 0\n        self.global_state['s_history'].clear()\n        self.global_state['y_history'].clear()\n        self.global_state['sy_history'].clear()\n\n    def reset(self):\n        self._reset_self()\n        for c in self.children.values(): c.reset()\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('p_prev', 'g_prev')\n        self.global_state.pop('step', None)\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        p = as_tensorlist(params)\n        g = as_tensorlist(tensors)\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        # history of s and k\n        s_history: deque[TensorList] = self.global_state['s_history']\n        y_history: deque[TensorList] = self.global_state['y_history']\n        sy_history: deque[torch.Tensor] = self.global_state['sy_history']\n\n        ptol = self.defaults['ptol']\n        gtol = self.defaults['gtol']\n        ptol_restart = self.defaults['ptol_restart']\n        gtol_restart = self.defaults['gtol_restart']\n        sy_tol = self.defaults['sy_tol']\n        damping = self.defaults['damping']\n\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', cls=TensorList)\n\n        # 1st step - there are no previous params and grads, lbfgs will do normalized SGD step\n        if step == 0:\n            s = None; y = None; sy = None\n        else:\n            s = p - p_prev\n            y = g - g_prev\n\n            if damping is not None:\n                s, y = apply_damping(damping, s=s, y=y, g=g, H=self.get_H())\n\n            sy = s.dot(y)\n            # damping to be added here\n\n        below_tol = False\n        # tolerance on parameter difference to avoid exploding after converging\n        if ptol is not None:\n            if s is not None and s.abs().global_max() &lt;= ptol:\n                if ptol_restart:\n                    self._reset_self()\n                sy = None\n                below_tol = True\n\n        # tolerance on gradient difference to avoid exploding when there is no curvature\n        if gtol is not None:\n            if y is not None and y.abs().global_max() &lt;= gtol:\n                if gtol_restart: self._reset_self()\n                sy = None\n                below_tol = True\n\n        # store previous params and grads\n        if not below_tol:\n            p_prev.copy_(p)\n            g_prev.copy_(g)\n\n        # update effective preconditioning state\n        if sy is not None and sy &gt; sy_tol:\n            assert s is not None and y is not None and sy is not None\n\n            s_history.append(s)\n            y_history.append(y)\n            sy_history.append(sy)\n\n    def get_H(self, objective=...):\n        s_history = [tl.to_vec() for tl in self.global_state['s_history']]\n        y_history = [tl.to_vec() for tl in self.global_state['y_history']]\n        sy_history = self.global_state['sy_history']\n        return LBFGSLinearOperator(s_history, y_history, sy_history)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        scale_first = self.defaults['scale_first']\n\n        tensors = as_tensorlist(tensors)\n\n        s_history = self.global_state['s_history']\n        y_history = self.global_state['y_history']\n        sy_history = self.global_state['sy_history']\n\n        # precondition\n        dir = lbfgs_Hx(\n            x=tensors,\n            s_history=s_history,\n            y_history=y_history,\n            sy_history=sy_history,\n        )\n\n        # scale 1st step\n        if scale_first and self.global_state.get('step', 1) == 1:\n            dir *= initial_step_size(dir, eps=1e-7)\n\n        return dir\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.LSR1","title":"LSR1","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Limited-memory SR1 algorithm. A line search or trust region is recommended.</p> <p>Parameters:</p> <ul> <li> <code>history_size</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>number of past parameter differences and gradient differences to store. Defaults to 10.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>skips updating the history if maximum absolute value of parameter difference is less than this value. Defaults to None.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever parameter difference is less then <code>ptol</code>, L-SR1 state will be reset. Defaults to None.</p> </li> <li> <code>gtol</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>skips updating the history if if maximum absolute value of gradient difference is less than this value. Defaults to None.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If true, whenever gradient difference is less then <code>gtol</code>, L-SR1 state will be reset. Defaults to None.</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>makes first step, when hessian approximation is not available, small to reduce number of line search iterations. Defaults to False.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>how often to update L-SR1 history. Larger values may be better for stochastic optimization. Defaults to 1.</p> </li> <li> <code>damping</code>               (<code>Union</code>, default:                   <code>None</code> )           \u2013            <p>damping to use, can be \"powell\" or \"double\". Defaults to None.</p> </li> <li> <code>compact</code>               (<code>bool</code>)           \u2013            <p>if True, uses a compact representation verstion of L-SR1. It is much faster computationally, but less stable.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional inner modules applied after updating L-SR1 history and before preconditioning. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.LSR1--examples","title":"Examples:","text":"<p>L-SR1 with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SR1(),\n    tz.m.StrongWolfe(c2=0.1, fallback=True)\n)\n</code></pre></p> <p>L-SR1 with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(tz.m.LSR1())\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/lsr1.py</code> <pre><code>class LSR1(TensorTransform):\n    \"\"\"Limited-memory SR1 algorithm. A line search or trust region is recommended.\n\n    Args:\n        history_size (int, optional):\n            number of past parameter differences and gradient differences to store. Defaults to 10.\n        ptol (float | None, optional):\n            skips updating the history if maximum absolute value of\n            parameter difference is less than this value. Defaults to None.\n        ptol_restart (bool, optional):\n            If true, whenever parameter difference is less then ``ptol``,\n            L-SR1 state will be reset. Defaults to None.\n        gtol (float | None, optional):\n            skips updating the history if if maximum absolute value of\n            gradient difference is less than this value. Defaults to None.\n        ptol_restart (bool, optional):\n            If true, whenever gradient difference is less then ``gtol``,\n            L-SR1 state will be reset. Defaults to None.\n        scale_first (bool, optional):\n            makes first step, when hessian approximation is not available,\n            small to reduce number of line search iterations. Defaults to False.\n        update_freq (int, optional):\n            how often to update L-SR1 history. Larger values may be better for stochastic optimization. Defaults to 1.\n        damping (DampingStrategyType, optional):\n            damping to use, can be \"powell\" or \"double\". Defaults to None.\n        compact (bool, optional):\n            if True, uses a compact representation verstion of L-SR1. It is much faster computationally, but less stable.\n        inner (Chainable | None, optional):\n            optional inner modules applied after updating L-SR1 history and before preconditioning. Defaults to None.\n\n    ## Examples:\n\n    L-SR1 with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SR1(),\n        tz.m.StrongWolfe(c2=0.1, fallback=True)\n    )\n    ```\n\n    L-SR1 with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.TrustCG(tz.m.LSR1())\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        history_size=10,\n        ptol: float | None = None,\n        ptol_restart: bool = False,\n        gtol: float | None = None,\n        gtol_restart: bool = False,\n        scale_first:bool=False,\n        update_freq = 1,\n        damping: DampingStrategyType = None,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(\n            history_size=history_size,\n            scale_first=scale_first,\n            ptol=ptol,\n            gtol=gtol,\n            ptol_restart=ptol_restart,\n            gtol_restart=gtol_restart,\n            damping = damping,\n        )\n        super().__init__(defaults, inner=inner, update_freq=update_freq)\n\n        self.global_state['s_history'] = deque(maxlen=history_size)\n        self.global_state['y_history'] = deque(maxlen=history_size)\n\n    def _reset_self(self):\n        self.state.clear()\n        self.global_state['step'] = 0\n        self.global_state['s_history'].clear()\n        self.global_state['y_history'].clear()\n\n    def reset(self):\n        self._reset_self()\n        for c in self.children.values(): c.reset()\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('p_prev', 'g_prev')\n        self.global_state.pop('step', None)\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        p = as_tensorlist(params)\n        g = as_tensorlist(tensors)\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        # history of s and k\n        s_history: deque = self.global_state['s_history']\n        y_history: deque = self.global_state['y_history']\n\n        ptol = self.defaults['ptol']\n        gtol = self.defaults['gtol']\n        ptol_restart = self.defaults['ptol_restart']\n        gtol_restart = self.defaults['gtol_restart']\n        damping = self.defaults['damping']\n\n        p_prev, g_prev = unpack_states(states, tensors, 'p_prev', 'g_prev', cls=TensorList)\n\n        # 1st step - there are no previous params and grads, lsr1 will do normalized SGD step\n        if step == 0:\n            s = None; y = None; sy = None\n        else:\n            s = p - p_prev\n            y = g - g_prev\n\n            if damping is not None:\n                s, y = apply_damping(damping, s=s, y=y, g=g, H=self.get_H())\n\n            sy = s.dot(y)\n            # damping to be added here\n\n        below_tol = False\n        # tolerance on parameter difference to avoid exploding after converging\n        if ptol is not None:\n            if s is not None and s.abs().global_max() &lt;= ptol:\n                if ptol_restart: self._reset_self()\n                sy = None\n                below_tol = True\n\n        # tolerance on gradient difference to avoid exploding when there is no curvature\n        if gtol is not None:\n            if y is not None and y.abs().global_max() &lt;= gtol:\n                if gtol_restart: self._reset_self()\n                sy = None\n                below_tol = True\n\n        # store previous params and grads\n        if not below_tol:\n            p_prev.copy_(p)\n            g_prev.copy_(g)\n\n        # update effective preconditioning state\n        if sy is not None:\n            assert s is not None and y is not None and sy is not None\n\n            s_history.append(s)\n            y_history.append(y)\n\n    def get_H(self, objective=...):\n        s_history = [tl.to_vec() for tl in self.global_state['s_history']]\n        y_history = [tl.to_vec() for tl in self.global_state['y_history']]\n        return LSR1LinearOperator(s_history, y_history)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        scale_first = self.defaults['scale_first']\n\n        tensors = as_tensorlist(tensors)\n\n        s_history = self.global_state['s_history']\n        y_history = self.global_state['y_history']\n\n        # precondition\n        dir = lsr1_Hx(\n            x=tensors,\n            s_history=s_history,\n            y_history=y_history,\n        )\n\n        # scale 1st step\n        if scale_first and self.global_state.get('step', 1) == 1:\n            dir *= initial_step_size(dir, eps=1e-7)\n\n        return dir\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.McCormick","title":"McCormick","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>McCormicks's Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.</p> <p>This is \"Algorithm 2\", attributed to McCormick in this paper. However for some reason this method is also called Pearson's 2nd method in other sources.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class McCormick(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"McCormicks's Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.\n\n        This is \"Algorithm 2\", attributed to McCormick in this paper. However for some reason this method is also called Pearson's 2nd method in other sources.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return mccormick_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.NewDQN","title":"NewDQN","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.diagonal_quasi_newton.DNRTR</code></p> <p>Diagonal quasi-newton method.</p> Reference <p>Nosrati, Mahsa, and Keyvan Amini. \"A new diagonal quasi-Newton algorithm for unconstrained optimization problems.\" Applications of Mathematics 69.4 (2024): 501-512.</p> Source code in <code>torchzero/modules/quasi_newton/diagonal_quasi_newton.py</code> <pre><code>class NewDQN(DNRTR):\n    \"\"\"Diagonal quasi-newton method.\n\n    Reference:\n        Nosrati, Mahsa, and Keyvan Amini. \"A new diagonal quasi-Newton algorithm for unconstrained optimization problems.\" Applications of Mathematics 69.4 (2024): 501-512.\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return new_dqn_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.NewSSM","title":"NewSSM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Self-scaling Quasi-Newton method.</p> Note <p>a line search such as <code>tz.m.StrongWolfe()</code> is required.</p> Warning <p>this uses roughly O(N^2) memory.</p> Reference <p>Moghrabi, I. A., Hassan, B. A., &amp; Askar, A. (2022). New self-scaling quasi-newton methods for unconstrained optimization. Int. J. Math. Comput. Sci., 17, 1061U.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class NewSSM(HessianUpdateStrategy):\n    \"\"\"Self-scaling Quasi-Newton method.\n\n    Note:\n        a line search such as ``tz.m.StrongWolfe()`` is required.\n\n    Warning:\n        this uses roughly O(N^2) memory.\n\n    Reference:\n        Moghrabi, I. A., Hassan, B. A., &amp; Askar, A. (2022). New self-scaling quasi-newton methods for unconstrained optimization. Int. J. Math. Comput. Sci., 17, 1061U.\n    \"\"\"\n    def __init__(\n        self,\n        type: Literal[1, 2] = 1,\n        init_scale: float | Literal[\"auto\"] = \"auto\",\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        super().__init__(\n            defaults=dict(type=type),\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            uses_loss=True,\n            inner=inner,\n        )\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        f = state['f']\n        f_prev = state['f_prev']\n        return new_ssm1(H=H, s=s, y=y, f=f, f_prev=f_prev, type=setting['type'], tol=setting['tol'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.PSB","title":"PSB","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._HessianUpdateStrategyDefaults</code></p> <p>Powell's Symmetric Broyden Quasi-Newton method.</p> Note <p>a line search or a trust region is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class PSB(_HessianUpdateStrategyDefaults):\n    \"\"\"Powell's Symmetric Broyden Quasi-Newton method.\n\n    Note:\n        a line search or a trust region is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Spedicato, E., &amp; Huang, Z. (1997). Numerical experience with newton-like methods for nonlinear algebraic systems. Computing, 58(1), 69\u201389. doi:10.1007/bf02684472\n    \"\"\"\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return psb_B_(B=B, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.Pearson","title":"Pearson","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Pearson's Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class Pearson(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Pearson's Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return pearson_H_(H=H, s=s, y=y)\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.ProjectedNewtonRaphson","title":"ProjectedNewtonRaphson","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Projected Newton Raphson method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.</p> <p>This one is Algorithm 7.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ProjectedNewtonRaphson(HessianUpdateStrategy):\n    \"\"\"\n    Projected Newton Raphson method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.\n\n        This one is Algorithm 7.\n    \"\"\"\n    def __init__(\n        self,\n        init_scale: float | Literal[\"auto\"] = 'auto',\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = 'auto',\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        super().__init__(\n            init_scale=init_scale,\n            tol=tol,\n            ptol = ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        if 'R' not in state: state['R'] = torch.eye(H.size(-1), device=H.device, dtype=H.dtype)\n        H, R = projected_newton_raphson_H_(H=H, R=state['R'], s=s, y=y)\n        state[\"R\"] = R\n        return H\n\n    def reset_P(self, P, s, y, inverse, init_scale, state):\n        assert inverse\n        if 'R' not in state: state['R'] = torch.eye(P.size(-1), device=P.device, dtype=P.dtype)\n        P.copy_(state[\"R\"])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.SG2","title":"SG2","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>second-order stochastic gradient</p> <p>2SPSA (second-order SPSA) <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SPSA(),\n    tz.m.SG2(),\n    tz.m.LR(1e-2),\n)\n</code></pre></p> <p>SG2 with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SG2(),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>SG2 with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.SG2(beta=0.75. n_samples=4)),\n)\n</code></pre></p> Source code in <code>torchzero/modules/quasi_newton/sg2.py</code> <pre><code>class SG2(Transform):\n    \"\"\"second-order stochastic gradient\n\n    2SPSA (second-order SPSA)\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SPSA(),\n        tz.m.SG2(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    SG2 with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.SG2(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    SG2 with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.SG2(beta=0.75. n_samples=4)),\n    )\n    ```\n\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 1,\n        n_first_step_samples: int = 10,\n        start_step: int = 10,\n        beta: float | None = None,\n        damping: float = 1e-4,\n        h: float = 1e-2,\n        seed=None,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(n_samples=n_samples, h=h, beta=beta, damping=damping, seed=seed, start_step=start_step, n_first_step_samples=n_first_step_samples)\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        k = self.increment_counter(\"step\", 0)\n\n        params = TensorList(objective.params)\n        closure = objective.closure\n        if closure is None:\n            raise RuntimeError(\"closure is required for SG2\")\n        generator = self.get_generator(params[0].device, self.defaults[\"seed\"])\n\n        h = unpack_dicts(settings, \"h\")\n        x_0 = params.clone()\n        n_samples = fs[\"n_samples\"]\n        if k == 0: n_samples = fs[\"n_first_step_samples\"]\n        H_hat = None\n\n        # compute new approximation\n        for i in range(n_samples):\n            # generate perturbation\n            cd = params.rademacher_like(generator=generator).mul_(h)\n\n            # two sided hessian approximation\n            params.add_(cd)\n            closure()\n            g_p = params.grad.fill_none_(params)\n\n            params.copy_(x_0)\n            params.sub_(cd)\n            closure()\n            g_n = params.grad.fill_none_(params)\n\n            delta_g = g_p - g_n\n\n            # restore params\n            params.set_(x_0)\n\n            # compute H hat\n            H_i = sg2_(\n                delta_g = delta_g.to_vec(),\n                cd = cd.to_vec(),\n            )\n\n            if H_hat is None: H_hat = H_i\n            else: H_hat += H_i\n\n        assert H_hat is not None\n        if n_samples &gt; 1: H_hat /= n_samples\n\n        # add damping\n        if fs[\"damping\"] != 0:\n            reg = torch.eye(H_hat.size(0), device=H_hat.device, dtype=H_hat.dtype).mul_(fs[\"damping\"])\n            H_hat += reg\n\n        # update H\n        H = self.global_state.get(\"H\", None)\n        if H is None: H = H_hat\n        else:\n            beta = fs[\"beta\"]\n            if beta is None: beta = (k+1) / (k+2)\n            H.lerp_(H_hat, 1-beta)\n\n        self.global_state[\"H\"] = H\n\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        fs = settings[0]\n        updates = objective.get_updates()\n\n        H: torch.Tensor = self.global_state[\"H\"]\n        k = self.global_state[\"step\"]\n        if k &lt; fs[\"start_step\"]:\n            # don't precondition yet\n            # I guess we can try using trace to scale the update\n            # because it will have horrible scaling otherwise\n            torch._foreach_div_(updates, H.trace())\n            return objective\n\n        b = torch.cat([t.ravel() for t in updates])\n        sol = torch.linalg.lstsq(H, b).solution # pylint:disable=not-callable\n\n        vec_to_tensors_(sol, updates)\n        return objective\n\n    def get_H(self, objective=...):\n        return Dense(self.global_state[\"H\"])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.SR1","title":"SR1","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Symmetric Rank 1. This works best with a trust region: <pre><code>tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False))\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>init_scale</code>               (<code>float | Literal['auto']</code>, default:                   <code>'auto'</code> )           \u2013            <p>initial hessian matrix is set to identity times this.</p> <p>\"auto\" corresponds to a heuristic from [1] p.142-143.</p> <p>Defaults to \"auto\".</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-32</code> )           \u2013            <p>tolerance for denominator in SR1 update rule as in [1] p.146. Defaults to 1e-32.</p> </li> <li> <code>ptol</code>               (<code>float | None</code>, default:                   <code>1e-32</code> )           \u2013            <p>skips update if maximum difference between current and previous gradients is less than this, to avoid instability. Defaults to 1e-32.</p> </li> <li> <code>ptol_restart</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.</p> </li> <li> <code>restart_interval</code>               (<code>int | None | Literal['auto']</code>, default:                   <code>None</code> )           \u2013            <p>interval between resetting the hessian approximation.</p> <p>\"auto\" corresponds to number of decision variables + 1.</p> <p>None - no resets.</p> <p>Defaults to None.</p> </li> <li> <code>beta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>momentum on H or B. Defaults to None.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating H or B. Defaults to 1.</p> </li> <li> <code>scale_first</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to downscale first step before hessian approximation becomes available. Defaults to True.</p> </li> <li> <code>scale_second</code>               (<code>bool</code>)           \u2013            <p>whether to downscale second step. Defaults to False.</p> </li> <li> <code>concat_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If true, all parameters are treated as a single vector. If False, the update rule is applied to each parameter separately. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to the output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.SR1--examples","title":"Examples:","text":"<p>SR1 with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n)\n</code></pre></p>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.SR1--references","title":"References:","text":"<pre><code>[1]. Nocedal. Stephen J. Wright. Numerical Optimization\n</code></pre> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class SR1(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"Symmetric Rank 1. This works best with a trust region:\n    ```python\n    tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False))\n    ```\n\n    Args:\n        init_scale (float | Literal[\"auto\"], optional):\n            initial hessian matrix is set to identity times this.\n\n            \"auto\" corresponds to a heuristic from [1] p.142-143.\n\n            Defaults to \"auto\".\n        tol (float, optional):\n            tolerance for denominator in SR1 update rule as in [1] p.146. Defaults to 1e-32.\n        ptol (float | None, optional):\n            skips update if maximum difference between current and previous gradients is less than this, to avoid instability.\n            Defaults to 1e-32.\n        ptol_restart (bool, optional): whether to reset the hessian approximation when ptol tolerance is not met. Defaults to False.\n        restart_interval (int | None | Literal[\"auto\"], optional):\n            interval between resetting the hessian approximation.\n\n            \"auto\" corresponds to number of decision variables + 1.\n\n            None - no resets.\n\n            Defaults to None.\n        beta (float | None, optional): momentum on H or B. Defaults to None.\n        update_freq (int, optional): frequency of updating H or B. Defaults to 1.\n        scale_first (bool, optional):\n            whether to downscale first step before hessian approximation becomes available. Defaults to True.\n        scale_second (bool, optional): whether to downscale second step. Defaults to False.\n        concat_params (bool, optional):\n            If true, all parameters are treated as a single vector.\n            If False, the update rule is applied to each parameter separately. Defaults to True.\n        inner (Chainable | None, optional): preconditioning is applied to the output of this module. Defaults to None.\n\n    ### Examples:\n\n    SR1 with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n    )\n    ```\n\n    ###  References:\n        [1]. Nocedal. Stephen J. Wright. Numerical Optimization\n    \"\"\"\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return sr1_(H=H, s=s, y=y, tol=setting['tol'])\n    def update_B(self, B, s, y, p, g, p_prev, g_prev, state, setting):\n        return sr1_(H=B, s=y, y=s, tol=setting['tol'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.SSVM","title":"SSVM","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Self-scaling variable metric Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Oren, S. S., &amp; Spedicato, E. (1976). Optimal conditioning of self-scaling variable Metric algorithms. Mathematical Programming, 10(1), 70\u201390. doi:10.1007/bf01580654</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class SSVM(HessianUpdateStrategy):\n    \"\"\"\n    Self-scaling variable metric Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Oren, S. S., &amp; Spedicato, E. (1976). Optimal conditioning of self-scaling variable Metric algorithms. Mathematical Programming, 10(1), 70\u201390. doi:10.1007/bf01580654\n    \"\"\"\n    def __init__(\n        self,\n        switch: tuple[float,float] | Literal[1,2,3,4] = 3,\n        init_scale: float | Literal[\"auto\"] = 'auto',\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(switch=switch)\n        super().__init__(\n            defaults=defaults,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return ssvm_H_(H=H, s=s, y=y, g=g, switch=setting['switch'], tol=setting['tol'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.ShorR","title":"ShorR","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton.HessianUpdateStrategy</code></p> <p>Shor\u2019s r-algorithm.</p> Note <ul> <li> <p>A line search such as <code>[tz.m.StrongWolfe(a_init=\"quadratic\", fallback=True), tz.m.Mul(1.2)]</code> is required. Similarly to conjugate gradient, ShorR doesn't have an automatic step size scaling, so setting <code>a_init</code> in the line search is recommended.</p> </li> <li> <p>The line search should try to overstep by a little, therefore it can help to multiply direction given by a line search by some value slightly larger than 1 such as 1.2.</p> </li> </ul> References <p>Those are the original references, but neither seem to be available online:     - Shor, N. Z., Utilization of the Operation of Space Dilatation in the Minimization of Convex Functions, Kibernetika, No. 1, pp. 6-12, 1970.</p> <pre><code>- Skokov, V. A., Note on Minimization Methods Employing Space Stretching, Kibernetika, No. 4, pp. 115-117, 1974.\n</code></pre> <p>An overview is available in Burke, James V., Adrian S. Lewis, and Michael L. Overton. \"The Speed of Shor's R-algorithm.\" IMA Journal of numerical analysis 28.4 (2008): 711-720.</p> <p>Reference by Skokov, V. A. describes a more efficient formula which can be found here Ansari, Zafar A. Limited Memory Space Dilation and Reduction Algorithms. Diss. Virginia Tech, 1998.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ShorR(HessianUpdateStrategy):\n    \"\"\"Shor\u2019s r-algorithm.\n\n    Note:\n        - A line search such as ``[tz.m.StrongWolfe(a_init=\"quadratic\", fallback=True), tz.m.Mul(1.2)]`` is required. Similarly to conjugate gradient, ShorR doesn't have an automatic step size scaling, so setting ``a_init`` in the line search is recommended.\n\n        - The line search should try to overstep by a little, therefore it can help to multiply direction given by a line search by some value slightly larger than 1 such as 1.2.\n\n    References:\n        Those are the original references, but neither seem to be available online:\n            - Shor, N. Z., Utilization of the Operation of Space Dilatation in the Minimization of Convex Functions, Kibernetika, No. 1, pp. 6-12, 1970.\n\n            - Skokov, V. A., Note on Minimization Methods Employing Space Stretching, Kibernetika, No. 4, pp. 115-117, 1974.\n\n        An overview is available in [Burke, James V., Adrian S. Lewis, and Michael L. Overton. \"The Speed of Shor's R-algorithm.\" IMA Journal of numerical analysis 28.4 (2008): 711-720](https://sites.math.washington.edu/~burke/papers/reprints/60-speed-Shor-R.pdf).\n\n        Reference by Skokov, V. A. describes a more efficient formula which can be found here [Ansari, Zafar A. Limited Memory Space Dilation and Reduction Algorithms. Diss. Virginia Tech, 1998.](https://camo.ici.ro/books/thesis/th.pdf)\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha=0.5,\n        init_scale: float | Literal[\"auto\"] = 1,\n        tol: float = 1e-32,\n        ptol: float | None = 1e-32,\n        ptol_restart: bool = False,\n        gtol: float | None = 1e-32,\n        restart_interval: int | None | Literal['auto'] = None,\n        beta: float | None = None,\n        update_freq: int = 1,\n        scale_first: bool = False,\n        concat_params: bool = True,\n        # inverse: bool = True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(alpha=alpha)\n        super().__init__(\n            defaults=defaults,\n            init_scale=init_scale,\n            tol=tol,\n            ptol=ptol,\n            ptol_restart=ptol_restart,\n            gtol=gtol,\n            restart_interval=restart_interval,\n            beta=beta,\n            update_freq=update_freq,\n            scale_first=scale_first,\n            concat_params=concat_params,\n            inverse=True,\n            inner=inner,\n        )\n\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        return shor_r_(H=H, y=y, alpha=setting['alpha'])\n</code></pre>"},{"location":"API/modules/quasi_newton/#torchzero.modules.quasi_newton.ThomasOptimalMethod","title":"ThomasOptimalMethod","text":"<p>               Bases: <code>torchzero.modules.quasi_newton.quasi_newton._InverseHessianUpdateStrategyDefaults</code></p> <p>Thomas's \"optimal\" Quasi-Newton method.</p> Note <p>a line search is recommended.</p> Warning <p>this uses at least O(N^2) memory.</p> Reference <p>Thomas, Stephen Walter. Sequential estimation techniques for quasi-Newton algorithms. Cornell University, 1975.</p> Source code in <code>torchzero/modules/quasi_newton/quasi_newton.py</code> <pre><code>class ThomasOptimalMethod(_InverseHessianUpdateStrategyDefaults):\n    \"\"\"\n    Thomas's \"optimal\" Quasi-Newton method.\n\n    Note:\n        a line search is recommended.\n\n    Warning:\n        this uses at least O(N^2) memory.\n\n    Reference:\n        Thomas, Stephen Walter. Sequential estimation techniques for quasi-Newton algorithms. Cornell University, 1975.\n    \"\"\"\n    def update_H(self, H, s, y, p, g, p_prev, g_prev, state, setting):\n        if 'R' not in state: state['R'] = torch.eye(H.size(-1), device=H.device, dtype=H.dtype)\n        H, state['R'] = thomas_H_(H=H, R=state['R'], s=s, y=y)\n        return H\n\n    def reset_P(self, P, s, y, inverse, init_scale, state):\n        super().reset_P(P, s, y, inverse, init_scale, state)\n        for st in self.state.values():\n            st.pop(\"R\", None)\n</code></pre>"},{"location":"API/modules/second_order/","title":"Second order","text":"<p>This subpackage contains \"True\" second order methods that use exact second order information.</p>"},{"location":"API/modules/second_order/#see-also","title":"See also","text":"<ul> <li>Quasi-newton - quasi-newton methods that estimate the hessian using gradient information.</li> </ul> <p>Classes:</p> <ul> <li> <code>ImprovedNewton</code>           \u2013            <p>Improved Newton's Method (INM).</p> </li> <li> <code>InverseFreeNewton</code>           \u2013            <p>Inverse-free newton's method</p> </li> <li> <code>Newton</code>           \u2013            <p>Exact Newton's method via autograd.</p> </li> <li> <code>NewtonCG</code>           \u2013            <p>Newton's method with a matrix-free conjugate gradient or minimial-residual solver.</p> </li> <li> <code>NewtonCGSteihaug</code>           \u2013            <p>Newton's method with trust region and a matrix-free Steihaug-Toint conjugate gradient solver.</p> </li> <li> <code>NystromPCG</code>           \u2013            <p>Newton's method with a Nystr\u00f6m-preconditioned conjugate gradient solver.</p> </li> <li> <code>NystromSketchAndSolve</code>           \u2013            <p>Newton's method with a Nystr\u00f6m sketch-and-solve solver.</p> </li> <li> <code>SixthOrder3P</code>           \u2013            <p>Sixth-order iterative method.</p> </li> <li> <code>SixthOrder3PM2</code>           \u2013            <p>Wang, Xiaofeng, and Yang Li. \"An efficient sixth-order Newton-type method for solving nonlinear systems.\" Algorithms 10.2 (2017): 45.</p> </li> <li> <code>SixthOrder5P</code>           \u2013            <p>Argyros, Ioannis K., et al. \"Extended convergence for two sixth order methods under the same weak conditions.\" Foundations 3.1 (2023): 127-139.</p> </li> <li> <code>SubspaceNewton</code>           \u2013            <p>Subspace Newton. Performs a Newton step in a subspace (random or spanned by past gradients).</p> </li> <li> <code>TwoPointNewton</code>           \u2013            <p>two-point Newton method with frozen derivative with third order convergence.</p> </li> </ul>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.ImprovedNewton","title":"ImprovedNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Improved Newton's Method (INM).</p> Reference <p>Saheya, B., et al. \"A new Newton-like method for solving nonlinear equations.\" SpringerPlus 5.1 (2016): 1269.</p> Source code in <code>torchzero/modules/second_order/inm.py</code> <pre><code>class ImprovedNewton(Transform):\n    \"\"\"Improved Newton's Method (INM).\n\n    Reference:\n        [Saheya, B., et al. \"A new Newton-like method for solving nonlinear equations.\" SpringerPlus 5.1 (2016): 1269.](https://d-nb.info/1112813721/34)\n    \"\"\"\n\n    def __init__(\n        self,\n        damping: float = 0,\n        eigval_fn: Callable[[torch.Tensor], torch.Tensor] | None = None,\n        eigv_tol: float | None = None,\n        truncate: int | None = None,\n        update_freq: int = 1,\n        precompute_inverse: bool | None = None,\n        use_lstsq: bool = False,\n        hessian_method: HessianMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"update_freq\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner, )\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        _, f_list, J = objective.hessian(\n            hessian_method=fs['hessian_method'],\n            h=fs['h'],\n            at_x0=True\n        )\n        if f_list is None: f_list = objective.get_grads()\n\n        f = torch.cat([t.ravel() for t in f_list])\n        J = _eigval_fn(J, fs[\"eigval_fn\"])\n\n        x_list = TensorList(objective.params)\n        f_list = TensorList(objective.get_grads())\n        x_prev, f_prev = unpack_states(states, objective.params, \"x_prev\", \"f_prev\", cls=TensorList)\n\n        # initialize on 1st step, do Newton step\n        if \"H\" not in self.global_state:\n            x_prev.copy_(x_list)\n            f_prev.copy_(f_list)\n            P = J\n\n        # INM update\n        else:\n            s_list = x_list - x_prev\n            y_list = f_list - f_prev\n            x_prev.copy_(x_list)\n            f_prev.copy_(f_list)\n\n            P = inm(f, J, s=s_list.to_vec(), y=y_list.to_vec())\n\n        # update state\n        precompute_inverse = fs[\"precompute_inverse\"]\n        if precompute_inverse is None:\n            precompute_inverse = fs[\"__update_freq\"] &gt;= 10\n\n        _newton_update_state_(\n            H=P,\n            state = self.global_state,\n            damping = fs[\"damping\"],\n            eigval_fn = fs[\"eigval_fn\"],\n            eigv_tol = fs[\"eigv_tol\"],\n            truncate = fs[\"truncate\"],\n            precompute_inverse = precompute_inverse,\n            use_lstsq = fs[\"use_lstsq\"]\n        )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n        fs = settings[0]\n\n        b = torch.cat([t.ravel() for t in updates])\n        sol = _newton_solve(b=b, state=self.global_state, use_lstsq=fs[\"use_lstsq\"])\n\n        vec_to_tensors_(sol, updates)\n        return objective\n\n\n    def get_H(self,objective=...):\n        return _newton_get_H(self.global_state)\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.InverseFreeNewton","title":"InverseFreeNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Inverse-free newton's method</p> <p>Reference     Massalski, Marcin, and Magdalena Nockowska-Rosiak. \"INVERSE-FREE NEWTON'S METHOD.\" Journal of Applied Analysis &amp; Computation 15.4 (2025): 2238-2257.</p> Source code in <code>torchzero/modules/second_order/ifn.py</code> <pre><code>class InverseFreeNewton(Transform):\n    \"\"\"Inverse-free newton's method\n\n    Reference\n        [Massalski, Marcin, and Magdalena Nockowska-Rosiak. \"INVERSE-FREE NEWTON'S METHOD.\" Journal of Applied Analysis &amp; Computation 15.4 (2025): 2238-2257.](https://www.jaac-online.com/article/doi/10.11948/20240428)\n    \"\"\"\n    def __init__(\n        self,\n        update_freq: int = 1,\n        hessian_method: HessianMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(hessian_method=hessian_method, h=h)\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        _, _, H = objective.hessian(\n            hessian_method=fs['hessian_method'],\n            h=fs['h'],\n            at_x0=True\n        )\n\n        self.global_state[\"H\"] = H\n\n        # inverse free part\n        if 'Y' not in self.global_state:\n            num = H.T\n            denom = (torch.linalg.norm(H, 1) * torch.linalg.norm(H, float('inf'))) # pylint:disable=not-callable\n\n            finfo = torch.finfo(H.dtype)\n            self.global_state['Y'] = num.div_(denom.clip(min=finfo.tiny * 2, max=finfo.max / 2))\n\n        else:\n            Y = self.global_state['Y']\n            I2 = torch.eye(Y.size(0), device=Y.device, dtype=Y.dtype).mul_(2)\n            I2 -= H @ Y\n            self.global_state['Y'] = Y @ I2\n\n\n    def apply_states(self, objective, states, settings):\n        Y = self.global_state[\"Y\"]\n        g = torch.cat([t.ravel() for t in objective.get_updates()])\n        objective.updates = vec_to_tensors(Y@g, objective.params)\n        return objective\n\n    def get_H(self,objective=...):\n        return DenseWithInverse(A = self.global_state[\"H\"], A_inv=self.global_state[\"Y\"])\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.Newton","title":"Newton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Exact Newton's method via autograd.</p> <p>Newton's method produces a direction jumping to the stationary point of quadratic approximation of the target function. The update rule is given by <code>(H + yI)\u207b\u00b9g</code>, where <code>H</code> is the hessian and <code>g</code> is the gradient, <code>y</code> is the <code>damping</code> parameter.</p> <p><code>g</code> can be output of another module, if it is specifed in <code>inner</code> argument.</p> Note <p>In most cases Newton should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> Note <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating the hessian. The closure must accept a <code>backward</code> argument (refer to documentation).</p> <p>Parameters:</p> <ul> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>tikhonov regularizer value. Defaults to 0.</p> </li> <li> <code>eigval_fn</code>               (<code>Callable | None</code>, default:                   <code>None</code> )           \u2013            <p>function to apply to eigenvalues, for example <code>torch.abs</code> or <code>lambda L: torch.clip(L, min=1e-8)</code>. If this is specified, eigendecomposition will be used to invert the hessian.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>updates hessian every <code>update_freq</code> steps.</p> </li> <li> <code>precompute_inverse</code>               (<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>if <code>True</code>, whenever hessian is computed, also computes the inverse. This is more efficient when <code>update_freq</code> is large. If <code>None</code>, this is <code>True</code> if <code>update_freq &gt;= 10</code>.</p> </li> <li> <code>use_lstsq</code>               (<code>(bool, Optional)</code>, default:                   <code>False</code> )           \u2013            <p>if True, least squares will be used to solve the linear system, this can prevent it from exploding when hessian is indefinite. If False, tries cholesky, if it fails tries LU, and then least squares. If <code>eigval_fn</code> is specified, eigendecomposition is always used and this argument is ignored.</p> </li> <li> <code>hessian_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>Determines how hessian is computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd to compute <code>ndim</code> batched hessian-vector products. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd to compute <code>ndim</code> hessian-vector products using for loop. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"functional_revrev\"</code> - uses <code>torch.autograd.functional</code> with \"reverse-over-reverse\" strategy and a for-loop. This is generally equivalent to <code>\"autograd\"</code>.</li> <li><code>\"functional_fwdrev\"</code> - uses <code>torch.autograd.functional</code> with vectorized \"forward-over-reverse\" strategy. Faster than <code>\"functional_fwdrev\"</code> but uses more memory (<code>\"batched_autograd\"</code> seems to be faster)</li> <li><code>\"func\"</code> - uses <code>torch.func.hessian</code> which uses \"forward-over-reverse\" strategy. This method is the fastest and is recommended, however it is more restrictive and fails with some operators which is why it isn't the default.</li> <li><code>\"gfd_forward\"</code> - computes <code>ndim</code> hessian-vector products via gradient finite difference using a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"gfd_central\"</code> - computes <code>ndim</code> hessian-vector products via gradient finite difference using a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> <li><code>\"fd\"</code> - uses function values to estimate gradient and hessian via finite difference. This uses less evaluations than chaining <code>\"gfd_*\"</code> after <code>tz.m.FDM</code>.</li> <li><code>\"thoad\"</code> - uses <code>thoad</code> library, can be significantly faster than pytorch but limited operator coverage.</li> </ul> <p>Defaults to <code>\"batched_autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size if hessian is compute via finite-difference.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules to apply hessian preconditioner to. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.Newton--see-also","title":"See also","text":"<ul> <li><code>tz.m.NewtonCG</code>: uses a matrix-free conjugate gradient solver and hessian-vector products. useful for large scale problems as it doesn't form the full hessian.</li> <li><code>tz.m.NewtonCGSteihaug</code>: trust region version of <code>tz.m.NewtonCG</code>.</li> <li><code>tz.m.ImprovedNewton</code>: Newton with additional rank one correction to the hessian, can be faster than Newton.</li> <li><code>tz.m.InverseFreeNewton</code>: an inverse-free variant of Newton's method.</li> <li><code>tz.m.quasi_newton</code>: large collection of quasi-newton methods that estimate the hessian.</li> </ul>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.Newton--notes","title":"Notes","text":""},{"location":"API/modules/second_order/#torchzero.modules.second_order.Newton--implementation-details","title":"Implementation details","text":"<p><code>(H + yI)\u207b\u00b9g</code> is calculated by solving the linear system <code>(H + yI)x = g</code>. The linear system is solved via cholesky decomposition, if that fails, LU decomposition, and if that fails, least squares. Least squares can be forced by setting <code>use_lstsq=True</code>.</p> <p>Additionally, if <code>eigval_fn</code> is specified, eigendecomposition of the hessian is computed, <code>eigval_fn</code> is applied to the eigenvalues, and <code>(H + yI)\u207b\u00b9</code> is computed using the computed eigenvectors and transformed eigenvalues. This is more generally more computationally expensive but not by much.</p>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.Newton--handling-non-convexity","title":"Handling non-convexity","text":"<p>Standard Newton's method does not handle non-convexity well without some modifications. This is because it jumps to the stationary point, which may be the maxima of the quadratic approximation.</p> <p>A modification to handle non-convexity is to modify the eignevalues to be positive, for example by setting <code>eigval_fn = lambda L: L.abs().clip(min=1e-4)</code>.</p>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.Newton--examples","title":"Examples:","text":"<p>Newton's method with backtracking line search</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Newton(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Newton's method for non-convex optimization.</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Newton(eigval_fn = lambda L: L.abs().clip(min=1e-4)),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Newton preconditioning applied to momentum</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Newton(inner=tz.m.EMA(0.9)),\n    tz.m.LR(0.1)\n)\n</code></pre> Source code in <code>torchzero/modules/second_order/newton.py</code> <pre><code>class Newton(Transform):\n    \"\"\"Exact Newton's method via autograd.\n\n    Newton's method produces a direction jumping to the stationary point of quadratic approximation of the target function.\n    The update rule is given by ``(H + yI)\u207b\u00b9g``, where ``H`` is the hessian and ``g`` is the gradient, ``y`` is the ``damping`` parameter.\n\n    ``g`` can be output of another module, if it is specifed in ``inner`` argument.\n\n    Note:\n        In most cases Newton should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n    Note:\n        This module requires the a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients for calculating the hessian.\n        The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        damping (float, optional): tikhonov regularizer value. Defaults to 0.\n        eigval_fn (Callable | None, optional):\n            function to apply to eigenvalues, for example ``torch.abs`` or ``lambda L: torch.clip(L, min=1e-8)``.\n            If this is specified, eigendecomposition will be used to invert the hessian.\n        update_freq (int, optional):\n            updates hessian every ``update_freq`` steps.\n        precompute_inverse (bool, optional):\n            if ``True``, whenever hessian is computed, also computes the inverse. This is more efficient\n            when ``update_freq`` is large. If ``None``, this is ``True`` if ``update_freq &gt;= 10``.\n        use_lstsq (bool, Optional):\n            if True, least squares will be used to solve the linear system, this can prevent it from exploding\n            when hessian is indefinite. If False, tries cholesky, if it fails tries LU, and then least squares.\n            If ``eigval_fn`` is specified, eigendecomposition is always used and this argument is ignored.\n        hessian_method (str):\n            Determines how hessian is computed.\n\n            - ``\"batched_autograd\"`` - uses autograd to compute ``ndim`` batched hessian-vector products. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd to compute ``ndim`` hessian-vector products using for loop. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"functional_revrev\"`` - uses ``torch.autograd.functional`` with \"reverse-over-reverse\" strategy and a for-loop. This is generally equivalent to ``\"autograd\"``.\n            - ``\"functional_fwdrev\"`` - uses ``torch.autograd.functional`` with vectorized \"forward-over-reverse\" strategy. Faster than ``\"functional_fwdrev\"`` but uses more memory (``\"batched_autograd\"`` seems to be faster)\n            - ``\"func\"`` - uses ``torch.func.hessian`` which uses \"forward-over-reverse\" strategy. This method is the fastest and is recommended, however it is more restrictive and fails with some operators which is why it isn't the default.\n            - ``\"gfd_forward\"`` - computes ``ndim`` hessian-vector products via gradient finite difference using a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"gfd_central\"`` - computes ``ndim`` hessian-vector products via gradient finite difference using a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n            - ``\"fd\"`` - uses function values to estimate gradient and hessian via finite difference. This uses less evaluations than chaining ``\"gfd_*\"`` after ``tz.m.FDM``.\n            - ``\"thoad\"`` - uses ``thoad`` library, can be significantly faster than pytorch but limited operator coverage.\n\n            Defaults to ``\"batched_autograd\"``.\n        h (float, optional):\n            finite difference step size if hessian is compute via finite-difference.\n        inner (Chainable | None, optional): modules to apply hessian preconditioner to. Defaults to None.\n\n    # See also\n\n    * ``tz.m.NewtonCG``: uses a matrix-free conjugate gradient solver and hessian-vector products.\n    useful for large scale problems as it doesn't form the full hessian.\n    * ``tz.m.NewtonCGSteihaug``: trust region version of ``tz.m.NewtonCG``.\n    * ``tz.m.ImprovedNewton``: Newton with additional rank one correction to the hessian, can be faster than Newton.\n    * ``tz.m.InverseFreeNewton``: an inverse-free variant of Newton's method.\n    * ``tz.m.quasi_newton``: large collection of quasi-newton methods that estimate the hessian.\n\n    # Notes\n\n    ## Implementation details\n\n    ``(H + yI)\u207b\u00b9g`` is calculated by solving the linear system ``(H + yI)x = g``.\n    The linear system is solved via cholesky decomposition, if that fails, LU decomposition, and if that fails, least squares. Least squares can be forced by setting ``use_lstsq=True``.\n\n    Additionally, if ``eigval_fn`` is specified, eigendecomposition of the hessian is computed,\n    ``eigval_fn`` is applied to the eigenvalues, and ``(H + yI)\u207b\u00b9`` is computed using the computed eigenvectors and transformed eigenvalues. This is more generally more computationally expensive but not by much.\n\n    ## Handling non-convexity\n\n    Standard Newton's method does not handle non-convexity well without some modifications.\n    This is because it jumps to the stationary point, which may be the maxima of the quadratic approximation.\n\n    A modification to handle non-convexity is to modify the eignevalues to be positive,\n    for example by setting ``eigval_fn = lambda L: L.abs().clip(min=1e-4)``.\n\n    # Examples:\n\n    Newton's method with backtracking line search\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Newton(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Newton's method for non-convex optimization.\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Newton(eigval_fn = lambda L: L.abs().clip(min=1e-4)),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Newton preconditioning applied to momentum\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Newton(inner=tz.m.EMA(0.9)),\n        tz.m.LR(0.1)\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        damping: float = 0,\n        eigval_fn: Callable[[torch.Tensor], torch.Tensor] | None = None,\n        eigv_tol: float | None = None,\n        truncate: int | None = None,\n        update_freq: int = 1,\n        precompute_inverse: bool | None = None,\n        use_lstsq: bool = False,\n        hessian_method: HessianMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['update_freq'], defaults[\"inner\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        precompute_inverse = fs[\"precompute_inverse\"]\n        if precompute_inverse is None:\n            precompute_inverse = fs[\"__update_freq\"] &gt;= 10\n\n        __, _, H = objective.hessian(hessian_method=fs[\"hessian_method\"], h=fs[\"h\"], at_x0=True)\n\n        _newton_update_state_(\n            state = self.global_state,\n            H=H,\n            damping = fs[\"damping\"],\n            eigval_fn = fs[\"eigval_fn\"],\n            eigv_tol = fs[\"eigv_tol\"],\n            truncate = fs[\"truncate\"],\n            precompute_inverse = precompute_inverse,\n            use_lstsq = fs[\"use_lstsq\"]\n        )\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n        fs = settings[0]\n\n        b = torch.cat([t.ravel() for t in updates])\n        sol = _newton_solve(b=b, state=self.global_state, use_lstsq=fs[\"use_lstsq\"])\n\n        vec_to_tensors_(sol, updates)\n        return objective\n\n    def get_H(self,objective=...):\n        return _newton_get_H(self.global_state)\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.NewtonCG","title":"NewtonCG","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with a matrix-free conjugate gradient or minimial-residual solver.</p> Notes <ul> <li> <p>In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> Warning <p>CG may fail if hessian is not positive-definite.</p> <p>Parameters:</p> <ul> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Maximum number of iterations for the conjugate gradient solver. By default, this is set to the number of dimensions in the objective function, which is the theoretical upper bound for CG convergence. Setting this to a smaller value (truncated Newton) can still generate good search directions. Defaults to None.</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>Relative tolerance for the conjugate gradient solver to determine convergence. Defaults to 1e-4.</p> </li> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>Regularization parameter (damping) added to the Hessian diagonal. This helps ensure the system is positive-definite. Defaults to 1e-8.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are evaluated.</p> <ul> <li><code>\"autograd\"</code> - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>For NewtonCG <code>\"batched_autograd\"</code> is equivalent to <code>\"autograd\"</code>. Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>warm_start</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, the conjugate gradient solver is initialized with the solution from the previous optimization step. This can accelerate convergence, especially in truncated Newton methods. Defaults to False.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>NewtonCG will attempt to apply preconditioning to the output of this module.</p> </li> </ul> <p>Examples: Newton-CG with a backtracking line search:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NewtonCG(),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Truncated Newton method (useful for large-scale problems): <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NewtonCG(maxiter=10),\n    tz.m.Backtracking()\n)\n</code></pre></p> Source code in <code>torchzero/modules/second_order/newton_cg.py</code> <pre><code>class NewtonCG(Transform):\n    \"\"\"Newton's method with a matrix-free conjugate gradient or minimial-residual solver.\n\n    Notes:\n        * In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n        * This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Warning:\n        CG may fail if hessian is not positive-definite.\n\n    Args:\n        maxiter (int | None, optional):\n            Maximum number of iterations for the conjugate gradient solver.\n            By default, this is set to the number of dimensions in the\n            objective function, which is the theoretical upper bound for CG\n            convergence. Setting this to a smaller value (truncated Newton)\n            can still generate good search directions. Defaults to None.\n        tol (float, optional):\n            Relative tolerance for the conjugate gradient solver to determine\n            convergence. Defaults to 1e-4.\n        reg (float, optional):\n            Regularization parameter (damping) added to the Hessian diagonal.\n            This helps ensure the system is positive-definite. Defaults to 1e-8.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are evaluated.\n\n            - ``\"autograd\"`` - uses autograd hessian-vector products. If multiple hessian-vector products are evaluated, uses a for-loop.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            For NewtonCG ``\"batched_autograd\"`` is equivalent to ``\"autograd\"``. Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        warm_start (bool, optional):\n            If ``True``, the conjugate gradient solver is initialized with the\n            solution from the previous optimization step. This can accelerate\n            convergence, especially in truncated Newton methods.\n            Defaults to False.\n        inner (Chainable | None, optional):\n            NewtonCG will attempt to apply preconditioning to the output of this module.\n\n    Examples:\n    Newton-CG with a backtracking line search:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NewtonCG(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Truncated Newton method (useful for large-scale problems):\n    ```\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NewtonCG(maxiter=10),\n        tz.m.Backtracking()\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        maxiter: int | None = None,\n        tol: float = 1e-8,\n        reg: float = 1e-8,\n        hvp_method: HVPMethod = \"autograd\",\n        solver: Literal['cg', 'minres'] = 'cg',\n        npc_terminate: bool = False,\n        h: float = 1e-3, # tuned 1e-4 or 1e-3\n        miniter:int = 1,\n        warm_start=False,\n        warm_beta:float=0,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults, inner=inner)\n\n        self._num_hvps = 0\n        self._num_hvps_last_step = 0\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n\n        # ---------------------- Hessian vector product function --------------------- #\n        _, H_mv = objective.list_Hvp_function(hvp_method=hvp_method, h=h, at_x0=True)\n        objective.temp = H_mv\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        self._num_hvps_last_step = 0\n        H_mv = objective.poptemp()\n\n        fs = settings[0]\n        tol = fs['tol']\n        reg = fs['reg']\n        maxiter = fs['maxiter']\n        solver = fs['solver'].lower().strip()\n        warm_start = fs['warm_start']\n        npc_terminate = fs[\"npc_terminate\"]\n\n        # ---------------------------------- run cg ---------------------------------- #\n        x0 = None\n        if warm_start:\n            x0 = unpack_states(states, objective.params, 'prev_x', cls=TensorList)\n\n        b = TensorList(objective.get_updates())\n\n        if solver == 'cg':\n            d, _ = cg(A_mv=H_mv, b=b, x0=x0, tol=tol, maxiter=maxiter,\n                      miniter=fs[\"miniter\"], reg=reg, npc_terminate=npc_terminate)\n\n        elif solver == 'minres':\n            d = minres(A_mv=H_mv, b=b, x0=x0, tol=tol, maxiter=maxiter, reg=reg, npc_terminate=npc_terminate)\n\n        else:\n            raise ValueError(f\"Unknown solver {solver}\")\n\n        if warm_start:\n            assert x0 is not None\n            x0.lerp_(d, weight = 1-fs[\"warm_beta\"])\n\n        objective.updates = d\n        self._num_hvps += self._num_hvps_last_step\n        return objective\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.NewtonCGSteihaug","title":"NewtonCGSteihaug","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with trust region and a matrix-free Steihaug-Toint conjugate gradient solver.</p> Notes <ul> <li> <p>In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. Defaults to 0.0.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>100</code> )           \u2013            <p>maximum number of trust radius reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>max_history</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>CG will store this many intermediate solutions, reusing them when trust radius is reduced instead of re-running CG. Each solution storage requires 2N memory. Defaults to 100.</p> </li> <li> <code>boundary_tol</code>               (<code>float | None</code>, default:                   <code>1e-06</code> )           \u2013            <p>The trust region only increases when suggested step's norm is at least <code>(1-boundary_tol)*trust_region</code>. This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of CG iterations per step. Each iteration requies one backward pass if <code>hvp_method=\"forward\"</code>, two otherwise. Defaults to None.</p> </li> <li> <code>miniter</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimal number of CG iterations. This prevents making no progress</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>terminates CG when norm of the residual is less than this value. Defaults to 1e-8. when initial guess is below tolerance. Defaults to 1.</p> </li> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>hessian regularization. Defaults to 1e-8.</p> </li> <li> <code>solver</code>               (<code>str</code>, default:                   <code>'cg'</code> )           \u2013            <p>solver, \"cg\" or \"minres\". \"cg\" is recommended. Defaults to 'cg'.</p> </li> <li> <code>adapt_tol</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, whenever trust radius collapses to smallest representable number, the tolerance is multiplied by 0.1. Defaults to True.</p> </li> <li> <code>npc_terminate</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to terminate CG/MINRES whenever negative curvature is detected. Defaults to False.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'fd_central'</code> )           \u2013            <p>either <code>\"fd_forward\"</code> to use forward formula which requires one backward pass per hessian-vector product, or <code>\"fd_central\"</code> to use a more accurate central formula which requires two backward passes. <code>\"fd_forward\"</code> is usually accurate enough. Defaults to <code>\"fd_forward\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>finite difference step size. Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>applies preconditioning to output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.NewtonCGSteihaug--examples","title":"Examples:","text":"<p>Trust-region Newton-CG:</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NewtonCGSteihaug(),\n)\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.NewtonCGSteihaug--reference","title":"Reference:","text":"<pre><code>Steihaug, Trond. \"The conjugate gradient method and trust regions in large scale optimization.\" SIAM Journal on Numerical Analysis 20.3 (1983): 626-637.\n</code></pre> Source code in <code>torchzero/modules/second_order/newton_cg.py</code> <pre><code>class NewtonCGSteihaug(Transform):\n    \"\"\"Newton's method with trust region and a matrix-free Steihaug-Toint conjugate gradient solver.\n\n    Notes:\n        * In most cases NewtonCGSteihaug should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n        * This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n    Args:\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted. Defaults to 0.0.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust radius reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        max_history (int, optional):\n            CG will store this many intermediate solutions, reusing them when trust radius is reduced\n            instead of re-running CG. Each solution storage requires 2N memory. Defaults to 100.\n        boundary_tol (float | None, optional):\n            The trust region only increases when suggested step's norm is at least `(1-boundary_tol)*trust_region`.\n            This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.\n\n        maxiter (int | None, optional):\n            maximum number of CG iterations per step. Each iteration requies one backward pass if `hvp_method=\"forward\"`, two otherwise. Defaults to None.\n        miniter (int, optional):\n            minimal number of CG iterations. This prevents making no progress\n        tol (float, optional):\n            terminates CG when norm of the residual is less than this value. Defaults to 1e-8.\n            when initial guess is below tolerance. Defaults to 1.\n        reg (float, optional): hessian regularization. Defaults to 1e-8.\n        solver (str, optional): solver, \"cg\" or \"minres\". \"cg\" is recommended. Defaults to 'cg'.\n        adapt_tol (bool, optional):\n            if True, whenever trust radius collapses to smallest representable number,\n            the tolerance is multiplied by 0.1. Defaults to True.\n        npc_terminate (bool, optional):\n            whether to terminate CG/MINRES whenever negative curvature is detected. Defaults to False.\n\n        hvp_method (str, optional):\n            either ``\"fd_forward\"`` to use forward formula which requires one backward pass per hessian-vector product, or ``\"fd_central\"`` to use a more accurate central formula which requires two backward passes. ``\"fd_forward\"`` is usually accurate enough. Defaults to ``\"fd_forward\"``.\n        h (float, optional): finite difference step size. Defaults to 1e-3.\n\n        inner (Chainable | None, optional):\n            applies preconditioning to output of this module. Defaults to None.\n\n    ### Examples:\n    Trust-region Newton-CG:\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NewtonCGSteihaug(),\n    )\n    ```\n\n    ### Reference:\n        Steihaug, Trond. \"The conjugate gradient method and trust regions in large scale optimization.\" SIAM Journal on Numerical Analysis 20.3 (1983): 626-637.\n    \"\"\"\n    def __init__(\n        self,\n        # trust region settings\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        init: float = 1,\n        max_attempts: int = 100,\n        max_history: int = 100,\n        boundary_tol: float = 1e-6, # tuned\n\n        # cg settings\n        maxiter: int | None = None,\n        miniter: int = 1,\n        tol: float = 1e-8,\n        reg: float = 1e-8,\n        solver: Literal['cg', \"minres\"] = 'cg',\n        adapt_tol: bool = False,\n        terminate_on_tr: bool = True,\n        npc_terminate: bool = False,\n\n        # hvp settings\n        hvp_method: Literal[\"fd_forward\", \"fd_central\"] = \"fd_central\",\n        h: float = 1e-3, # tuned 1e-4 or 1e-3\n\n        # inner\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults, inner=inner)\n\n        self._num_hvps = 0\n        self._num_hvps_last_step = 0\n\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n\n        # ---------------------- Hessian vector product function --------------------- #\n        _, H_mv = objective.list_Hvp_function(hvp_method=hvp_method, h=h, at_x0=True)\n        objective.temp = H_mv\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        self._num_hvps_last_step = 0\n\n        H_mv = objective.poptemp()\n        params = TensorList(objective.params)\n        fs = settings[0]\n\n        tol = fs['tol'] * self.global_state.get('tol_mul', 1)\n        solver = fs['solver'].lower().strip()\n\n        reg=fs[\"reg\"]\n        maxiter=fs[\"maxiter\"]\n        max_attempts=fs[\"max_attempts\"]\n        init=fs[\"init\"]\n        npc_terminate=fs[\"npc_terminate\"]\n        miniter=fs[\"miniter\"]\n        max_history=fs[\"max_history\"]\n\n\n        # ------------------------------- trust region ------------------------------- #\n        success = False\n        d = None\n        orig_params = [p.clone() for p in params]\n        b = TensorList(objective.get_updates())\n        solution = None\n        closure = objective.closure\n        assert closure is not None\n\n        while not success:\n            max_attempts -= 1\n            if max_attempts &lt; 0: break\n\n            trust_radius = self.global_state.get('trust_radius', init)\n\n            # -------------- make sure trust radius isn't too small or large ------------- #\n            finfo = torch.finfo(orig_params[0].dtype)\n            if trust_radius &lt; finfo.tiny * 2:\n                trust_radius = self.global_state['trust_radius'] = init\n\n                if fs[\"adapt_tol\"]:\n                    self.global_state[\"tol_mul\"] = self.global_state.get(\"tol_mul\", 1) * 0.1\n\n                if fs[\"terminate_on_tr\"]:\n                    objective.should_terminate = True\n\n            elif trust_radius &gt; finfo.max / 2:\n                trust_radius = self.global_state['trust_radius'] = init\n\n            # ----------------------------------- solve ---------------------------------- #\n            d = None\n            if solution is not None and solution.history is not None:\n                d = find_within_trust_radius(solution.history, trust_radius)\n\n            if d is None:\n                if solver == 'cg':\n                    d, solution = cg(\n                        A_mv=H_mv,\n                        b=b,\n                        tol=tol,\n                        maxiter=maxiter,\n                        reg=reg,\n                        trust_radius=trust_radius,\n                        miniter=miniter,\n                        npc_terminate=npc_terminate,\n                        history_size=max_history,\n                    )\n\n                elif solver == 'minres':\n                    d = minres(A_mv=H_mv, b=b, trust_radius=trust_radius, tol=tol, maxiter=maxiter, reg=reg, npc_terminate=npc_terminate)\n\n                else:\n                    raise ValueError(f\"unknown solver {solver}\")\n\n            # ---------------------------- update trust radius --------------------------- #\n            self.global_state[\"trust_radius\"], success = default_radius(\n                params = params,\n                closure = closure,\n                f = tofloat(objective.get_loss(False)),\n                g = b,\n                H = H_mv,\n                d = d,\n                trust_radius = trust_radius,\n                eta = fs[\"eta\"],\n                nplus = fs[\"nplus\"],\n                nminus = fs[\"nminus\"],\n                rho_good = fs[\"rho_good\"],\n                rho_bad = fs[\"rho_bad\"],\n                boundary_tol = fs[\"boundary_tol\"],\n\n                init = cast(int, None), # init isn't used because check_overflow=False\n                state = cast(dict, None), # not used\n                settings = cast(dict, None), # not used\n                check_overflow = False, # this is checked manually to adapt tolerance\n            )\n\n        # --------------------------- assign new direction --------------------------- #\n        assert d is not None\n        if success:\n            objective.updates = d\n\n        else:\n            objective.updates = params.zeros_like()\n\n        self._num_hvps += self._num_hvps_last_step\n        return objective\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.NystromPCG","title":"NystromPCG","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with a Nystr\u00f6m-preconditioned conjugate gradient solver.</p> Notes <ul> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> <li> <p>In most cases NystromPCG should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>size of the sketch for preconditioning, this many hessian-vector products will be evaluated before running the conjugate gradient solver. Larger value improves the preconditioning and speeds up conjugate gradient.</p> </li> <li> <code>maxiter</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum number of iterations. By default this is set to the number of dimensions in the objective function, which is supposed to be enough for conjugate gradient to have guaranteed convergence. Setting this to a small value can still generate good enough directions. Defaults to None.</p> </li> <li> <code>tol</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>relative tolerance for conjugate gradient solver. Defaults to 1e-4.</p> </li> <li> <code>reg</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>regularization parameter. Defaults to 1e-8.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules to apply hessian preconditioner to. Defaults to None.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random generator. Defaults to None.</p> </li> </ul> <p>Examples:</p> <p>NystromPCG with backtracking line search</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NystromPCG(10),\n    tz.m.Backtracking()\n)\n</code></pre> Reference <p>Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752. https://arxiv.org/abs/2110.02820</p> Source code in <code>torchzero/modules/second_order/nystrom.py</code> <pre><code>class NystromPCG(Transform):\n    \"\"\"Newton's method with a Nystr\u00f6m-preconditioned conjugate gradient solver.\n\n    Notes:\n        - This module requires the a closure passed to the optimizer step,\n        as it needs to re-evaluate the loss and gradients for calculating HVPs.\n        The closure must accept a ``backward`` argument (refer to documentation).\n\n        - In most cases NystromPCG should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n    Args:\n        rank (int):\n            size of the sketch for preconditioning, this many hessian-vector products will be evaluated before\n            running the conjugate gradient solver. Larger value improves the preconditioning and speeds up\n            conjugate gradient.\n        maxiter (int | None, optional):\n            maximum number of iterations. By default this is set to the number of dimensions\n            in the objective function, which is supposed to be enough for conjugate gradient\n            to have guaranteed convergence. Setting this to a small value can still generate good enough directions.\n            Defaults to None.\n        tol (float, optional): relative tolerance for conjugate gradient solver. Defaults to 1e-4.\n        reg (float, optional): regularization parameter. Defaults to 1e-8.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        inner (Chainable | None, optional): modules to apply hessian preconditioner to. Defaults to None.\n        seed (int | None, optional): seed for random generator. Defaults to None.\n\n    Examples:\n\n    NystromPCG with backtracking line search\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NystromPCG(10),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Reference:\n        Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752. https://arxiv.org/abs/2110.02820\n\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 100,\n        maxiter=None,\n        tol=1e-8,\n        reg: float = 1e-6,\n        update_freq: int = 1, # here update_freq is within update_states\n        eigv_tol: float = 0,\n        orthogonalize_method: OrthogonalizeMethod = 'qr',\n        hvp_method: HVPMethod = \"batched_autograd\",\n        h=1e-3,\n        inner: Chainable | None = None,\n        seed: int | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner']\n        super().__init__(defaults, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n\n        # ---------------------- Hessian vector product function --------------------- #\n        # this should run on every update_states\n        _, H_mv, H_mm = objective.tensor_Hvp_function(hvp_method=fs['hvp_method'], h=fs['h'], at_x0=True)\n        objective.temp = H_mv\n\n        # --------------------------- update preconditioner -------------------------- #\n        step = self.increment_counter(\"step\", 0)\n        if step % fs[\"update_freq\"] == 0:\n\n            ndim = sum(t.numel() for t in objective.params)\n            device = objective.params[0].device\n            dtype = objective.params[0].dtype\n            generator = self.get_generator(device, seed=fs['seed'])\n\n            try:\n                Omega = torch.randn(ndim, min(fs[\"rank\"], ndim), device=device, dtype=dtype, generator=generator)\n                HOmega = H_mm(orthogonalize(Omega, fs[\"orthogonalize_method\"]))\n                # compute the approximation\n                L, Q = nystrom_approximation(\n                    Omega=Omega,\n                    AOmega=HOmega,\n                    eigv_tol=fs[\"eigv_tol\"],\n                )\n\n                self.global_state[\"L\"] = L\n                self.global_state[\"Q\"] = Q\n\n            except torch.linalg.LinAlgError as e:\n                warnings.warn(f\"Nystrom approximation failed with: {e}\")\n\n    @torch.no_grad\n    def apply_states(self, objective, states, settings):\n        b = objective.get_updates()\n        H_mv = objective.poptemp()\n        fs = self.settings[objective.params[0]]\n\n        # ----------------------------------- solve ---------------------------------- #\n        if \"L\" not in self.global_state:\n            # fallback on cg\n            sol = cg(A_mv=H_mv, b=TensorList(b), tol=fs[\"tol\"], reg=fs[\"reg\"], maxiter=fs[\"maxiter\"])\n            objective.updates = sol.x\n            return objective\n\n        L = self.global_state[\"L\"]\n        Q = self.global_state[\"Q\"]\n\n        x = nystrom_pcg(L=L, Q=Q, A_mv=H_mv, b=torch.cat([t.ravel() for t in b]),\n                        reg=fs['reg'], tol=fs[\"tol\"], maxiter=fs[\"maxiter\"])\n\n        # -------------------------------- set update -------------------------------- #\n        objective.updates = vec_to_tensors(x, reference=objective.params)\n        return objective\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.NystromSketchAndSolve","title":"NystromSketchAndSolve","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Newton's method with a Nystr\u00f6m sketch-and-solve solver.</p> Notes <ul> <li> <p>This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a <code>backward</code> argument (refer to documentation).</p> </li> <li> <p>In most cases NystromSketchAndSolve should be the first module in the chain because it relies on autograd. Use the <code>inner</code> argument if you wish to apply Newton preconditioning to another module's output.</p> </li> <li> <p>If this is unstable, increase the <code>reg</code> parameter and tune the rank.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>rank</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>size of the sketch, this many hessian-vector products will be evaluated per step.</p> </li> <li> <code>reg</code>               (<code>float | None</code>, default:                   <code>0.01</code> )           \u2013            <p>scale of identity matrix added to hessian. Note that if this is specified, nystrom sketch-and-solve is used to compute <code>(Q diag(L) Q.T + reg*I)x = b</code>. It is very unstable when <code>reg</code> is small, i.e. smaller than 1e-4. If this is None,<code>(Q diag(L) Q.T)x = b</code> is computed by simply taking reciprocal of eigenvalues. Defaults to 1e-3.</p> </li> <li> <code>eigv_tol</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>all eigenvalues smaller than largest eigenvalue times <code>eigv_tol</code> are removed. Defaults to None.</p> </li> <li> <code>truncate</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>keeps top <code>truncate</code> eigenvalues. Defaults to None.</p> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>scalar added to eigenvalues. Defaults to 0.</p> </li> <li> <code>rdamping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>scalar multiplied by largest eigenvalue and added to eigenvalues. Defaults to 0.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating preconditioner. Defaults to 1.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>Determines how Hessian-vector products are computed.</p> <ul> <li><code>\"batched_autograd\"</code> - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than <code>\"autograd\"</code> but uses more memory.</li> <li><code>\"autograd\"</code> - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than <code>\"batched_autograd\"</code> but uses less memory.</li> <li><code>\"fd_forward\"</code> - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.</li> <li><code>\"fd_central\"</code> - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.</li> </ul> <p>Defaults to <code>\"autograd\"</code>.</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The step size for finite difference if <code>hvp_method</code> is <code>\"fd_forward\"</code> or <code>\"fd_central\"</code>. Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules to apply hessian preconditioner to. Defaults to None.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random generator. Defaults to None.</p> </li> </ul> <p>Examples: NystromSketchAndSolve with backtracking line search</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NystromSketchAndSolve(100),\n    tz.m.Backtracking()\n)\n</code></pre> <p>Trust region NystromSketchAndSolve</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquadt(tz.m.NystromSketchAndSolve(100)),\n)\n</code></pre> <p>References: - Frangella, Z., Rathore, P., Zhao, S., &amp; Udell, M. (2024). SketchySGD: Reliable Stochastic Optimization via Randomized Curvature Estimates. SIAM Journal on Mathematics of Data Science, 6(4), 1173-1204. - Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752</p> Source code in <code>torchzero/modules/second_order/nystrom.py</code> <pre><code>class NystromSketchAndSolve(Transform):\n    \"\"\"Newton's method with a Nystr\u00f6m sketch-and-solve solver.\n\n    Notes:\n        - This module requires the a closure passed to the optimizer step, as it needs to re-evaluate the loss and gradients for calculating HVPs. The closure must accept a ``backward`` argument (refer to documentation).\n\n        - In most cases NystromSketchAndSolve should be the first module in the chain because it relies on autograd. Use the ``inner`` argument if you wish to apply Newton preconditioning to another module's output.\n\n        - If this is unstable, increase the ``reg`` parameter and tune the rank.\n\n    Args:\n        rank (int): size of the sketch, this many hessian-vector products will be evaluated per step.\n        reg (float | None, optional):\n            scale of identity matrix added to hessian. Note that if this is specified, nystrom sketch-and-solve\n            is used to compute ``(Q diag(L) Q.T + reg*I)x = b``. It is very unstable when ``reg`` is small,\n            i.e. smaller than 1e-4. If this is None,``(Q diag(L) Q.T)x = b`` is computed by simply taking\n            reciprocal of eigenvalues. Defaults to 1e-3.\n        eigv_tol (float, optional):\n            all eigenvalues smaller than largest eigenvalue times ``eigv_tol`` are removed. Defaults to None.\n        truncate (int | None, optional):\n            keeps top ``truncate`` eigenvalues. Defaults to None.\n        damping (float, optional): scalar added to eigenvalues. Defaults to 0.\n        rdamping (float, optional): scalar multiplied by largest eigenvalue and added to eigenvalues. Defaults to 0.\n        update_freq (int, optional): frequency of updating preconditioner. Defaults to 1.\n        hvp_method (str, optional):\n            Determines how Hessian-vector products are computed.\n\n            - ``\"batched_autograd\"`` - uses autograd with batched hessian-vector products to compute the preconditioner. Faster than ``\"autograd\"`` but uses more memory.\n            - ``\"autograd\"`` - uses autograd hessian-vector products, uses a for loop to compute the preconditioner. Slower than ``\"batched_autograd\"`` but uses less memory.\n            - ``\"fd_forward\"`` - uses gradient finite difference approximation with a less accurate forward formula which requires one extra gradient evaluation per hessian-vector product.\n            - ``\"fd_central\"`` - uses gradient finite difference approximation with a more accurate central formula which requires two gradient evaluations per hessian-vector product.\n\n            Defaults to ``\"autograd\"``.\n        h (float, optional):\n            The step size for finite difference if ``hvp_method`` is\n            ``\"fd_forward\"`` or ``\"fd_central\"``. Defaults to 1e-3.\n        inner (Chainable | None, optional): modules to apply hessian preconditioner to. Defaults to None.\n        seed (int | None, optional): seed for random generator. Defaults to None.\n\n\n    Examples:\n    NystromSketchAndSolve with backtracking line search\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.NystromSketchAndSolve(100),\n        tz.m.Backtracking()\n    )\n    ```\n\n    Trust region NystromSketchAndSolve\n\n    ```py\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquadt(tz.m.NystromSketchAndSolve(100)),\n    )\n    ```\n\n    References:\n    - [Frangella, Z., Rathore, P., Zhao, S., &amp; Udell, M. (2024). SketchySGD: Reliable Stochastic Optimization via Randomized Curvature Estimates. SIAM Journal on Mathematics of Data Science, 6(4), 1173-1204.](https://arxiv.org/pdf/2211.08597)\n    - [Frangella, Z., Tropp, J. A., &amp; Udell, M. (2023). Randomized nystr\u00f6m preconditioning. SIAM Journal on Matrix Analysis and Applications, 44(2), 718-752](https://arxiv.org/abs/2110.02820)\n\n    \"\"\"\n    def __init__(\n        self,\n        rank: int = 100,\n        reg: float | None = 1e-2,\n        eigv_tol: float = 0,\n        truncate: int | None = None,\n        damping: float = 0,\n        rdamping: float = 0,\n        update_freq: int = 1,\n        orthogonalize_method: OrthogonalizeMethod = 'qr',\n        hvp_method: HVPMethod = \"batched_autograd\",\n        h: float = 1e-3,\n        inner: Chainable | None = None,\n        seed: int | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"update_freq\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        params = TensorList(objective.params)\n        fs = settings[0]\n\n        # ---------------------- Hessian vector product function --------------------- #\n        hvp_method = fs['hvp_method']\n        h = fs['h']\n        _, H_mv, H_mm = objective.tensor_Hvp_function(hvp_method=hvp_method, h=h, at_x0=True)\n\n        # ---------------------------------- sketch ---------------------------------- #\n        ndim = sum(t.numel() for t in objective.params)\n        device = params[0].device\n        dtype = params[0].dtype\n\n        generator = self.get_generator(params[0].device, seed=fs['seed'])\n        try:\n            Omega = torch.randn([ndim, min(fs[\"rank\"], ndim)], device=device, dtype=dtype, generator=generator)\n            Omega = orthogonalize(Omega, fs[\"orthogonalize_method\"])\n            HOmega = H_mm(Omega)\n\n            # compute the approximation\n            L, Q = nystrom_approximation(\n                Omega=Omega,\n                AOmega=HOmega,\n                eigv_tol=fs[\"eigv_tol\"],\n            )\n\n            # regularize\n            L, Q = regularize_eigh(\n                L=L,\n                Q=Q,\n                truncate=fs[\"truncate\"],\n                tol=fs[\"eigv_tol\"],\n                damping=fs[\"damping\"],\n                rdamping=fs[\"rdamping\"],\n            )\n\n            # store\n            if L is not None:\n                self.global_state[\"L\"] = L\n                self.global_state[\"Q\"] = Q\n\n        except torch.linalg.LinAlgError as e:\n            warnings.warn(f\"Nystrom approximation failed with: {e}\")\n\n    def apply_states(self, objective, states, settings):\n        if \"L\" not in self.global_state:\n            return objective\n\n        fs = settings[0]\n        updates = objective.get_updates()\n        b=torch.cat([t.ravel() for t in updates])\n\n        # ----------------------------------- solve ---------------------------------- #\n        L = self.global_state[\"L\"]\n        Q = self.global_state[\"Q\"]\n\n        if fs[\"reg\"] is None:\n            x = Q @ ((Q.mH @ b) / L)\n        else:\n            x = nystrom_sketch_and_solve(L=L, Q=Q, b=b, reg=fs[\"reg\"])\n\n        # -------------------------------- set update -------------------------------- #\n        objective.updates = vec_to_tensors(x, reference=objective.params)\n        return objective\n\n    def get_H(self, objective=...):\n        if \"L\" not in self.global_state:\n            return ScaledIdentity()\n\n        L = self.global_state[\"L\"]\n        Q = self.global_state[\"Q\"]\n        return Eigendecomposition(L, Q)\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.SixthOrder3P","title":"SixthOrder3P","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>Sixth-order iterative method.</p> <p>Abro, Hameer Akhtar, and Muhammad Mujtaba Shaikh. \"A new time-efficient and convergent nonlinear solver.\" Applied Mathematics and Computation 355 (2019): 516-536.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class SixthOrder3P(HigherOrderMethodBase):\n    \"\"\"Sixth-order iterative method.\n\n    Abro, Hameer Akhtar, and Muhammad Mujtaba Shaikh. \"A new time-efficient and convergent nonlinear solver.\" Applied Mathematics and Computation 355 (2019): 516-536.\n    \"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f(x): return evaluate(x, 1)[1]\n        def f_j(x): return evaluate(x, 2)[1:]\n        x_star = sixth_order_3p(x, f, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.SixthOrder3PM2","title":"SixthOrder3PM2","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>Wang, Xiaofeng, and Yang Li. \"An efficient sixth-order Newton-type method for solving nonlinear systems.\" Algorithms 10.2 (2017): 45.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class SixthOrder3PM2(HigherOrderMethodBase):\n    \"\"\"Wang, Xiaofeng, and Yang Li. \"An efficient sixth-order Newton-type method for solving nonlinear systems.\" Algorithms 10.2 (2017): 45.\"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f_j(x): return evaluate(x, 2)[1:]\n        def f(x): return evaluate(x, 1)[1]\n        x_star = sixth_order_3pm2(x, f, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.SixthOrder5P","title":"SixthOrder5P","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>Argyros, Ioannis K., et al. \"Extended convergence for two sixth order methods under the same weak conditions.\" Foundations 3.1 (2023): 127-139.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class SixthOrder5P(HigherOrderMethodBase):\n    \"\"\"Argyros, Ioannis K., et al. \"Extended convergence for two sixth order methods under the same weak conditions.\" Foundations 3.1 (2023): 127-139.\"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f_j(x): return evaluate(x, 2)[1:]\n        x_star = sixth_order_5p(x, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.SubspaceNewton","title":"SubspaceNewton","text":"<p>               Bases: <code>torchzero.core.transform.Transform</code></p> <p>Subspace Newton. Performs a Newton step in a subspace (random or spanned by past gradients).</p> <p>Parameters:</p> <ul> <li> <code>sketch_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>size of the random sketch. This many hessian-vector products will need to be evaluated each step.</p> </li> <li> <code>sketch_type</code>               (<code>str</code>, default:                   <code>'common_directions'</code> )           \u2013            <ul> <li>\"common_directions\" - uses history steepest descent directions as the basis[2]. It is orthonormalized on-line using Gram-Schmidt (default).</li> <li>\"orthonormal\" - random orthonormal basis. Orthonormality is necessary to use linear operator based modules such as trust region, but it can be slower to compute.</li> <li>\"rows\" - samples random rows.</li> <li>\"topk\" - samples top-rank rows with largest gradient magnitude.</li> <li>\"rademacher\" - approximately orthonormal (if dimension is large) scaled random rademacher basis.</li> <li>\"mixed\" - random orthonormal basis but with four directions set to gradient, slow and fast gradient EMAs, and previous update direction.</li> </ul> </li> <li> <code>damping</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>hessian damping (scale of identity matrix added to hessian). Defaults to 0.</p> </li> <li> <code>hvp_method</code>               (<code>str</code>, default:                   <code>'batched_autograd'</code> )           \u2013            <p>How to compute hessian-matrix product: - \"batched_autograd\" - uses batched autograd - \"autograd\" - uses unbatched autograd - \"forward\" - uses finite difference with forward formula, performing 1 backward pass per Hvp. - \"central\" - uses finite difference with a more accurate central formula, performing 2 backward passes per Hvp.</p> <p>. Defaults to \"batched_autograd\".</p> </li> <li> <code>h</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>finite difference step size. Defaults to 1e-2.</p> </li> <li> <code>use_lstsq</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to use least squares to solve <code>Hx=g</code>. Defaults to False.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>H_tfm</code>               (<code>Callable | None</code>)           \u2013            <p>optional hessian transforms, takes in two arguments - <code>(hessian, gradient)</code>.</p> <p>must return either a tuple: <code>(hessian, is_inverted)</code> with transformed hessian and a boolean value which must be True if transform inverted the hessian and False otherwise.</p> <p>Or it returns a single tensor which is used as the update.</p> <p>Defaults to None.</p> </li> <li> <code>eigval_fn</code>               (<code>Callable | None</code>, default:                   <code>None</code> )           \u2013            <p>optional eigenvalues transform, for example <code>torch.abs</code> or <code>lambda L: torch.clip(L, min=1e-8)</code>. If this is specified, eigendecomposition will be used to invert the hessian.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed for random generator. Defaults to None.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditions output of this module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.SubspaceNewton--examples","title":"Examples","text":"<p>RSN with line search <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.RSN(),\n    tz.m.Backtracking()\n)\n</code></pre></p> <p>RSN with trust region <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.RSN()),\n)\n</code></pre></p> References <ol> <li>Gower, Robert, et al. \"RSN: randomized subspace Newton.\" Advances in Neural Information Processing Systems 32 (2019).</li> <li>Wang, Po-Wei, Ching-pei Lee, and Chih-Jen Lin. \"The common-directions method for regularized empirical risk minimization.\" Journal of Machine Learning Research 20.58 (2019): 1-49.</li> </ol> Source code in <code>torchzero/modules/second_order/rsn.py</code> <pre><code>class SubspaceNewton(Transform):\n    \"\"\"Subspace Newton. Performs a Newton step in a subspace (random or spanned by past gradients).\n\n    Args:\n        sketch_size (int):\n            size of the random sketch. This many hessian-vector products will need to be evaluated each step.\n        sketch_type (str, optional):\n            - \"common_directions\" - uses history steepest descent directions as the basis[2]. It is orthonormalized on-line using Gram-Schmidt (default).\n            - \"orthonormal\" - random orthonormal basis. Orthonormality is necessary to use linear operator based modules such as trust region, but it can be slower to compute.\n            - \"rows\" - samples random rows.\n            - \"topk\" - samples top-rank rows with largest gradient magnitude.\n            - \"rademacher\" - approximately orthonormal (if dimension is large) scaled random rademacher basis.\n            - \"mixed\" - random orthonormal basis but with four directions set to gradient, slow and fast gradient EMAs, and previous update direction.\n        damping (float, optional): hessian damping (scale of identity matrix added to hessian). Defaults to 0.\n        hvp_method (str, optional):\n            How to compute hessian-matrix product:\n            - \"batched_autograd\" - uses batched autograd\n            - \"autograd\" - uses unbatched autograd\n            - \"forward\" - uses finite difference with forward formula, performing 1 backward pass per Hvp.\n            - \"central\" - uses finite difference with a more accurate central formula, performing 2 backward passes per Hvp.\n\n            . Defaults to \"batched_autograd\".\n        h (float, optional): finite difference step size. Defaults to 1e-2.\n        use_lstsq (bool, optional): whether to use least squares to solve ``Hx=g``. Defaults to False.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        H_tfm (Callable | None, optional):\n            optional hessian transforms, takes in two arguments - `(hessian, gradient)`.\n\n            must return either a tuple: `(hessian, is_inverted)` with transformed hessian and a boolean value\n            which must be True if transform inverted the hessian and False otherwise.\n\n            Or it returns a single tensor which is used as the update.\n\n            Defaults to None.\n        eigval_fn (Callable | None, optional):\n            optional eigenvalues transform, for example ``torch.abs`` or ``lambda L: torch.clip(L, min=1e-8)``.\n            If this is specified, eigendecomposition will be used to invert the hessian.\n        seed (int | None, optional): seed for random generator. Defaults to None.\n        inner (Chainable | None, optional): preconditions output of this module. Defaults to None.\n\n    ### Examples\n\n    RSN with line search\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.RSN(),\n        tz.m.Backtracking()\n    )\n    ```\n\n    RSN with trust region\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.RSN()),\n    )\n    ```\n\n\n    References:\n        1. [Gower, Robert, et al. \"RSN: randomized subspace Newton.\" Advances in Neural Information Processing Systems 32 (2019).](https://arxiv.org/abs/1905.10874)\n        2. Wang, Po-Wei, Ching-pei Lee, and Chih-Jen Lin. \"The common-directions method for regularized empirical risk minimization.\" Journal of Machine Learning Research 20.58 (2019): 1-49.\n    \"\"\"\n\n    def __init__(\n        self,\n        sketch_size: int = 100,\n        sketch_type: Literal[\"orthonormal\", \"common_directions\", \"mixed\", \"rademacher\", \"rows\", \"topk\"] = \"common_directions\",\n        damping:float=0,\n        eigval_fn: Callable[[torch.Tensor], torch.Tensor] | None = None,\n        eigv_tol: float | None = None,\n        truncate: int | None = None,\n        update_freq: int = 1,\n        precompute_inverse: bool = False,\n        use_lstsq: bool = False,\n        hvp_method: HVPMethod = \"batched_autograd\",\n        h: float = 1e-2,\n        seed: int | None = None,\n        inner: Chainable | None = None,\n    ):\n        defaults = locals().copy()\n        del defaults['self'], defaults['inner'], defaults[\"update_freq\"]\n        super().__init__(defaults, update_freq=update_freq, inner=inner)\n\n    @torch.no_grad\n    def update_states(self, objective, states, settings):\n        fs = settings[0]\n        params = objective.params\n        generator = self.get_generator(params[0].device, fs[\"seed\"])\n\n        ndim = sum(p.numel() for p in params)\n\n        device=params[0].device\n        dtype=params[0].dtype\n\n        # sample sketch matrix S: (ndim, sketch_size)\n        sketch_size = min(fs[\"sketch_size\"], ndim)\n        sketch_type = fs[\"sketch_type\"]\n        hvp_method = fs[\"hvp_method\"]\n\n        if sketch_type == \"rademacher\":\n            S = _rademacher_sketch(ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == 'orthonormal':\n            S = _orthonormal_sketch(ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == \"rows\":\n            S = _row_sketch(ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == \"topk\":\n            g_list = objective.get_grads(create_graph=hvp_method in (\"batched_autograd\", \"autograd\"))\n            g = torch.cat([t.ravel() for t in g_list])\n            S = _topk_rows(g, ndim, sketch_size, device=device, dtype=dtype, generator=generator)\n\n        elif sketch_type == 'common_directions':\n            # Wang, Po-Wei, Ching-pei Lee, and Chih-Jen Lin. \"The common-directions method for regularized empirical risk minimization.\" Journal of Machine Learning Research 20.58 (2019): 1-49.\n            g_list = objective.get_grads(create_graph=hvp_method in (\"batched_autograd\", \"autograd\"))\n            g = torch.cat([t.ravel() for t in g_list])\n\n            # initialize directions deque\n            if \"directions\" not in self.global_state:\n\n                g_norm = torch.linalg.vector_norm(g) # pylint:disable=not-callable\n                if g_norm &lt; torch.finfo(g.dtype).tiny * 2:\n                    g = torch.randn_like(g)\n                    g_norm = torch.linalg.vector_norm(g) # pylint:disable=not-callable\n\n                self.global_state[\"directions\"] = deque([g / g_norm], maxlen=sketch_size)\n                S = self.global_state[\"directions\"][0].unsqueeze(1)\n\n            # add new steepest descent direction orthonormal to existing columns\n            else:\n                S = torch.stack(tuple(self.global_state[\"directions\"]), dim=1)\n                p = g - S @ (S.T @ g)\n                p_norm = torch.linalg.vector_norm(p) # pylint:disable=not-callable\n                if p_norm &gt; torch.finfo(p.dtype).tiny * 2:\n                    p = p / p_norm\n                    self.global_state[\"directions\"].append(p)\n                    S = torch.cat([S, p.unsqueeze(1)], dim=1)\n\n        elif sketch_type == \"mixed\":\n            g_list = objective.get_grads(create_graph=hvp_method in (\"batched_autograd\", \"autograd\"))\n            g = torch.cat([t.ravel() for t in g_list])\n\n            # initialize state\n            if \"slow_ema\" not in self.global_state:\n                self.global_state[\"slow_ema\"] = torch.randn_like(g) * 1e-2\n                self.global_state[\"fast_ema\"] = torch.randn_like(g) * 1e-2\n                self.global_state[\"p_prev\"] = torch.randn_like(g)\n\n            # previous update direction\n            p_cur = torch.cat([t.ravel() for t in params])\n            prev_dir = p_cur - self.global_state[\"p_prev\"]\n            self.global_state[\"p_prev\"] = p_cur\n\n            # EMAs\n            slow_ema = self.global_state[\"slow_ema\"]\n            fast_ema = self.global_state[\"fast_ema\"]\n            slow_ema.lerp_(g, 0.001)\n            fast_ema.lerp_(g, 0.1)\n\n            # form and orthogonalize sketching matrix\n            S = torch.stack([g, slow_ema, fast_ema, prev_dir], dim=1)\n            if sketch_size &gt; 4:\n                S_random = torch.randn(ndim, sketch_size - 3, device=device, dtype=dtype, generator=generator) / math.sqrt(ndim)\n                S = torch.cat([S, S_random], dim=1)\n\n            S = _qr_orthonormalize(S)\n\n        else:\n            raise ValueError(f'Unknown sketch_type {sketch_type}')\n\n        # print(f'{S.shape = }')\n        # I = torch.eye(S.size(1), device=S.device, dtype=S.dtype)\n        # print(f'{torch.nn.functional.mse_loss(S.T @ S, I) = }')\n\n        # form sketched hessian\n        HS, _ = objective.hessian_matrix_product(S, rgrad=None, at_x0=True,\n                                                 hvp_method=fs[\"hvp_method\"], h=fs[\"h\"])\n        H_sketched = S.T @ HS\n\n        # update state\n        _newton_update_state_(\n            state = self.global_state,\n            H = H_sketched,\n            damping = fs[\"damping\"],\n            eigval_fn = fs[\"eigval_fn\"],\n            eigv_tol = fs[\"eigv_tol\"],\n            truncate = fs[\"truncate\"],\n            precompute_inverse = fs[\"precompute_inverse\"],\n            use_lstsq = fs[\"use_lstsq\"]\n        )\n\n        self.global_state[\"S\"] = S\n\n    def apply_states(self, objective, states, settings):\n        updates = objective.get_updates()\n        fs = settings[0]\n\n        S = self.global_state[\"S\"]\n        b = torch.cat([t.ravel() for t in updates])\n        b_proj = S.T @ b\n\n        d_proj = _newton_solve(b=b_proj, state=self.global_state, use_lstsq=fs[\"use_lstsq\"])\n\n        d = S @ d_proj\n        vec_to_tensors_(d, updates)\n        return objective\n\n    def get_H(self, objective=...):\n        if \"H\" in self.global_state:\n            H_sketched = self.global_state[\"H\"]\n\n        else:\n            L = self.global_state[\"L\"]\n            Q = self.global_state[\"Q\"]\n            H_sketched = Q @ L.diag_embed() @ Q.mH\n\n        S: torch.Tensor = self.global_state[\"S\"]\n        return Sketched(S, H_sketched)\n</code></pre>"},{"location":"API/modules/second_order/#torchzero.modules.second_order.TwoPointNewton","title":"TwoPointNewton","text":"<p>               Bases: <code>torchzero.modules.second_order.multipoint.HigherOrderMethodBase</code></p> <p>two-point Newton method with frozen derivative with third order convergence.</p> <p>Sharma, Janak Raj, and Deepak Kumar. \"A fast and efficient composite Newton\u2013Chebyshev method for systems of nonlinear equations.\" Journal of Complexity 49 (2018): 56-73.</p> Source code in <code>torchzero/modules/second_order/multipoint.py</code> <pre><code>class TwoPointNewton(HigherOrderMethodBase):\n    \"\"\"two-point Newton method with frozen derivative with third order convergence.\n\n    Sharma, Janak Raj, and Deepak Kumar. \"A fast and efficient composite Newton\u2013Chebyshev method for systems of nonlinear equations.\" Journal of Complexity 49 (2018): 56-73.\"\"\"\n    def __init__(self, lstsq: bool=False, derivatives_method: DerivativesMethod = 'batched_autograd'):\n        defaults=dict(lstsq=lstsq)\n        super().__init__(defaults=defaults, derivatives_method=derivatives_method)\n\n    @torch.no_grad\n    def one_iteration(self, x, evaluate, objective, setting):\n        def f(x): return evaluate(x, 1)[1]\n        def f_j(x): return evaluate(x, 2)[1:]\n        x_star = two_point_newton(x, f, f_j, setting['lstsq'])\n        return x - x_star\n</code></pre>"},{"location":"API/modules/smoothing/","title":"Smoothing","text":"<p>This subpackage contains smoothing-based optimization modules, currently laplacian and gaussian smoothing.</p> <p>Classes:</p> <ul> <li> <code>GradientSampling</code>           \u2013            <p>Samples and aggregates gradients and values at perturbed points.</p> </li> <li> <code>LaplacianSmoothing</code>           \u2013            <p>Applies laplacian smoothing via a fast Fourier transform solver which can improve generalization.</p> </li> </ul>"},{"location":"API/modules/smoothing/#torchzero.modules.smoothing.GradientSampling","title":"GradientSampling","text":"<p>               Bases: <code>torchzero.core.reformulation.Reformulation</code></p> <p>Samples and aggregates gradients and values at perturbed points.</p> <p>This module can be used for gaussian homotopy and gradient sampling methods.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>modules that will be optimizing the modified objective. if None, returns gradient of the modified objective as the update. Defaults to None.</p> </li> <li> <code>sigma</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>initial magnitude of the perturbations. Defaults to 1.</p> </li> <li> <code>n</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of perturbations per step. Defaults to 100.</p> </li> <li> <code>aggregate</code>               (<code>str</code>, default:                   <code>'mean'</code> )           \u2013            <p>how to aggregate values and gradients - \"mean\" - uses mean of the gradients, as in gaussian homotopy. - \"max\" - uses element-wise maximum of the gradients. - \"min\" - uses element-wise minimum of the gradients. - \"min-norm\" - picks gradient with the lowest norm.</p> <p>Defaults to 'mean'.</p> </li> <li> <code>distribution</code>               (<code>Literal</code>, default:                   <code>'gaussian'</code> )           \u2013            <p>distribution for random perturbations. Defaults to 'gaussian'.</p> </li> <li> <code>include_x0</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to include gradient at un-perturbed point. Defaults to True.</p> </li> <li> <code>fixed</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, perturbations do not get replaced by new random perturbations until termination criteria is satisfied. Defaults to True.</p> </li> <li> <code>pre_generate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, perturbations are pre-generated before each step. This requires more memory to store all of them, but ensures they do not change when closure is evaluated multiple times. Defaults to True.</p> </li> <li> <code>termination</code>               (<code>TerminationCriteriaBase | Sequence[TerminationCriteriaBase] | None</code>, default:                   <code>None</code> )           \u2013            <p>a termination criteria module, sigma will be multiplied by <code>decay</code> when termination criteria is satisfied, and new perturbations will be generated if <code>fixed</code>. Defaults to None.</p> </li> <li> <code>decay</code>               (<code>float</code>, default:                   <code>0.6666666666666666</code> )           \u2013            <p>sigma multiplier on termination criteria. Defaults to 2/3.</p> </li> <li> <code>reset_on_termination</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to reset states of all other modules on termination. Defaults to True.</p> </li> <li> <code>sigma_strategy</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>strategy for adapting sigma. If condition is satisfied, sigma is multiplied by <code>sigma_nplus</code>, otherwise it is multiplied by <code>sigma_nminus</code>. - \"grad-norm\" - at least <code>sigma_target</code> gradients should have lower norm than at un-perturbed point. - \"value\" - at least <code>sigma_target</code> values (losses) should be lower than at un-perturbed point. - None - doesn't use adaptive sigma.</p> <p>This introduces a side-effect to the closure, so it should be left at None of you use trust region or line search to optimize the modified objective. Defaults to None.</p> </li> <li> <code>sigma_target</code>               (<code>int</code>, default:                   <code>0.2</code> )           \u2013            <p>number of elements to satisfy the condition in <code>sigma_strategy</code>. Defaults to 1.</p> </li> <li> <code>sigma_nplus</code>               (<code>float</code>, default:                   <code>1.3333333333333333</code> )           \u2013            <p>sigma multiplier when <code>sigma_strategy</code> condition is satisfied. Defaults to 4/3.</p> </li> <li> <code>sigma_nminus</code>               (<code>float</code>, default:                   <code>0.6666666666666666</code> )           \u2013            <p>sigma multiplier when <code>sigma_strategy</code> condition is not satisfied. Defaults to 2/3.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>seed. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/smoothing/sampling.py</code> <pre><code>class GradientSampling(Reformulation):\n    \"\"\"Samples and aggregates gradients and values at perturbed points.\n\n    This module can be used for gaussian homotopy and gradient sampling methods.\n\n    Args:\n        modules (Chainable | None, optional):\n            modules that will be optimizing the modified objective.\n            if None, returns gradient of the modified objective as the update. Defaults to None.\n        sigma (float, optional): initial magnitude of the perturbations. Defaults to 1.\n        n (int, optional): number of perturbations per step. Defaults to 100.\n        aggregate (str, optional):\n            how to aggregate values and gradients\n            - \"mean\" - uses mean of the gradients, as in gaussian homotopy.\n            - \"max\" - uses element-wise maximum of the gradients.\n            - \"min\" - uses element-wise minimum of the gradients.\n            - \"min-norm\" - picks gradient with the lowest norm.\n\n            Defaults to 'mean'.\n        distribution (Distributions, optional): distribution for random perturbations. Defaults to 'gaussian'.\n        include_x0 (bool, optional): whether to include gradient at un-perturbed point. Defaults to True.\n        fixed (bool, optional):\n            if True, perturbations do not get replaced by new random perturbations until termination criteria is satisfied. Defaults to True.\n        pre_generate (bool, optional):\n            if True, perturbations are pre-generated before each step.\n            This requires more memory to store all of them,\n            but ensures they do not change when closure is evaluated multiple times.\n            Defaults to True.\n        termination (TerminationCriteriaBase | Sequence[TerminationCriteriaBase] | None, optional):\n            a termination criteria module, sigma will be multiplied by ``decay`` when termination criteria is satisfied,\n            and new perturbations will be generated if ``fixed``. Defaults to None.\n        decay (float, optional): sigma multiplier on termination criteria. Defaults to 2/3.\n        reset_on_termination (bool, optional): whether to reset states of all other modules on termination. Defaults to True.\n        sigma_strategy (str | None, optional):\n            strategy for adapting sigma. If condition is satisfied, sigma is multiplied by ``sigma_nplus``,\n            otherwise it is multiplied by ``sigma_nminus``.\n            - \"grad-norm\" - at least ``sigma_target`` gradients should have lower norm than at un-perturbed point.\n            - \"value\" - at least ``sigma_target`` values (losses) should be lower than at un-perturbed point.\n            - None - doesn't use adaptive sigma.\n\n            This introduces a side-effect to the closure, so it should be left at None of you use\n            trust region or line search to optimize the modified objective.\n            Defaults to None.\n        sigma_target (int, optional):\n            number of elements to satisfy the condition in ``sigma_strategy``. Defaults to 1.\n        sigma_nplus (float, optional): sigma multiplier when ``sigma_strategy`` condition is satisfied. Defaults to 4/3.\n        sigma_nminus (float, optional): sigma multiplier when ``sigma_strategy`` condition is not satisfied. Defaults to 2/3.\n        seed (int | None, optional): seed. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        modules: Chainable | None = None,\n        sigma: float = 1.,\n        n:int = 100,\n        aggregate: Literal['mean', 'max', 'min', 'min-norm', 'min-value'] = 'mean',\n        distribution: Distributions = 'gaussian',\n        include_x0: bool = True,\n\n        fixed: bool=True,\n        pre_generate: bool = True,\n        termination: TerminationCriteriaBase | Sequence[TerminationCriteriaBase] | None = None,\n        decay: float = 2/3,\n        reset_on_termination: bool = True,\n\n        sigma_strategy: Literal['grad-norm', 'value'] | None = None,\n        sigma_target: int | float = 0.2,\n        sigma_nplus: float = 4/3,\n        sigma_nminus: float = 2/3,\n\n        seed: int | None = None,\n    ):\n\n        defaults = dict(sigma=sigma, n=n, aggregate=aggregate, distribution=distribution, seed=seed, include_x0=include_x0, fixed=fixed, decay=decay, reset_on_termination=reset_on_termination, sigma_strategy=sigma_strategy, sigma_target=sigma_target, sigma_nplus=sigma_nplus, sigma_nminus=sigma_nminus, pre_generate=pre_generate)\n        super().__init__(defaults, modules)\n\n        if termination is not None:\n            self.set_child('termination', make_termination_criteria(extra=termination))\n\n    @torch.no_grad\n    def pre_step(self, objective):\n        params = TensorList(objective.params)\n\n        fixed = self.defaults['fixed']\n\n        # check termination criteria\n        if 'termination' in self.children:\n            termination = cast(TerminationCriteriaBase, self.children['termination'])\n            if termination.should_terminate(objective):\n\n                # decay sigmas\n                states = [self.state[p] for p in params]\n                settings = [self.settings[p] for p in params]\n\n                for state, setting in zip(states, settings):\n                    if 'sigma' not in state: state['sigma'] = setting['sigma']\n                    state['sigma'] *= setting['decay']\n\n                # reset on sigmas decay\n                if self.defaults['reset_on_termination']:\n                    objective.post_step_hooks.append(partial(_reset_except_self, self=self))\n\n                # clear perturbations\n                self.global_state.pop('perts', None)\n\n        # pre-generate perturbations if not already pre-generated or not fixed\n        if self.defaults['pre_generate'] and (('perts' not in self.global_state) or (not fixed)):\n            states = [self.state[p] for p in params]\n            settings = [self.settings[p] for p in params]\n\n            n = self.defaults['n'] - self.defaults['include_x0']\n            generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n            perts = [params.sample_like(self.defaults['distribution'], generator=generator) for _ in range(n)]\n\n            self.global_state['perts'] = perts\n\n    @torch.no_grad\n    def closure(self, backward, closure, params, objective):\n        params = TensorList(params)\n        loss_agg = None\n        grad_agg = None\n\n        states = [self.state[p] for p in params]\n        settings = [self.settings[p] for p in params]\n        sigma_inits = [s['sigma'] for s in settings]\n        sigmas = [s.setdefault('sigma', si) for s, si in zip(states, sigma_inits)]\n\n        include_x0 = self.defaults['include_x0']\n        pre_generate = self.defaults['pre_generate']\n        aggregate: Literal['mean', 'max', 'min', 'min-norm', 'min-value'] = self.defaults['aggregate']\n        sigma_strategy: Literal['grad-norm', 'value'] | None = self.defaults['sigma_strategy']\n        distribution = self.defaults['distribution']\n        generator = self.get_generator(params[0].device, self.defaults['seed'])\n\n\n        n_finite = 0\n        n_good = 0\n        f_0 = None; g_0 = None\n\n        # evaluate at x_0\n        if include_x0:\n            f_0 = objective.get_loss(backward=backward)\n\n            isfinite = math.isfinite(f_0)\n            if isfinite:\n                n_finite += 1\n                loss_agg = f_0\n\n            if backward:\n                g_0 = objective.get_grads()\n                if isfinite: grad_agg = g_0\n\n        # evaluate at x_0 + p for each perturbation\n        if pre_generate:\n            perts = self.global_state['perts']\n        else:\n            perts = [None] * (self.defaults['n'] - include_x0)\n\n        x_0 = [p.clone() for p in params]\n\n        for pert in perts:\n            loss = None; grad = None\n\n            # generate if not pre-generated\n            if pert is None:\n                pert = params.sample_like(distribution, generator=generator)\n\n            # add perturbation and evaluate\n            pert = pert * sigmas\n            torch._foreach_add_(params, pert)\n\n            with torch.enable_grad() if backward else nullcontext():\n                loss = closure(backward)\n\n            if math.isfinite(loss):\n                n_finite += 1\n\n                # add loss\n                if loss_agg is None:\n                    loss_agg = loss\n                else:\n                    if aggregate == 'mean':\n                        loss_agg += loss\n\n                    elif (aggregate=='min') or (aggregate=='min-value') or (aggregate=='min-norm' and not backward):\n                        loss_agg = loss_agg.clamp(max=loss)\n\n                    elif aggregate == 'max':\n                        loss_agg = loss_agg.clamp(min=loss)\n\n                # add grad\n                if backward:\n                    grad = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n                    if grad_agg is None:\n                        grad_agg = grad\n                    else:\n                        if aggregate == 'mean':\n                            torch._foreach_add_(grad_agg, grad)\n\n                        elif aggregate == 'min':\n                            grad_agg_abs = torch._foreach_abs(grad_agg)\n                            torch._foreach_minimum_(grad_agg_abs, torch._foreach_abs(grad))\n                            grad_agg = [g_abs.copysign(g) for g_abs, g in zip(grad_agg_abs, grad_agg)]\n\n                        elif aggregate == 'max':\n                            grad_agg_abs = torch._foreach_abs(grad_agg)\n                            torch._foreach_maximum_(grad_agg_abs, torch._foreach_abs(grad))\n                            grad_agg = [g_abs.copysign(g) for g_abs, g in zip(grad_agg_abs, grad_agg)]\n\n                        elif aggregate == 'min-norm':\n                            if TensorList(grad).global_vector_norm() &lt; TensorList(grad_agg).global_vector_norm():\n                                grad_agg = grad\n                                loss_agg = loss\n\n                        elif aggregate == 'min-value':\n                            if loss &lt; loss_agg:\n                                grad_agg = grad\n                                loss_agg = loss\n\n            # undo perturbation\n            torch._foreach_copy_(params, x_0)\n\n            # adaptive sigma\n            # by value\n            if sigma_strategy == 'value':\n                if f_0 is None:\n                    with torch.enable_grad() if backward else nullcontext():\n                        f_0 = closure(False)\n\n                if loss &lt; f_0:\n                    n_good += 1\n\n            # by gradient norm\n            elif sigma_strategy == 'grad-norm' and backward and math.isfinite(loss):\n                assert grad is not None\n                if g_0 is None:\n                    with torch.enable_grad() if backward else nullcontext():\n                        closure()\n                        g_0 = [p.grad if p.grad is not None else torch.zeros_like(p) for p in params]\n\n                if TensorList(grad).global_vector_norm() &lt; TensorList(g_0).global_vector_norm():\n                    n_good += 1\n\n        # update sigma if strategy is enabled\n        if sigma_strategy is not None:\n\n            sigma_target = self.defaults['sigma_target']\n            if isinstance(sigma_target, float):\n                sigma_target = int(max(1, n_finite * sigma_target))\n\n            if n_good &gt;= sigma_target:\n                key = 'sigma_nplus'\n            else:\n                key = 'sigma_nminus'\n\n            for p in params:\n                self.state[p]['sigma'] *= self.settings[p][key]\n\n        # if no finite losses, just return inf\n        if n_finite == 0:\n            assert loss_agg is None and grad_agg is None\n            loss = torch.tensor(torch.inf, dtype=params[0].dtype, device=params[0].device)\n            grad = [torch.full_like(p, torch.inf) for p in params]\n            return loss, grad\n\n        assert loss_agg is not None\n\n        # no post processing needed when aggregate is 'max', 'min', 'min-norm', 'min-value'\n        if aggregate != 'mean':\n            return loss_agg, grad_agg\n\n        # on mean divide by number of evals\n        loss_agg /= n_finite\n\n        if backward:\n            assert grad_agg is not None\n            torch._foreach_div_(grad_agg, n_finite)\n\n        return loss_agg, grad_agg\n</code></pre>"},{"location":"API/modules/smoothing/#torchzero.modules.smoothing.LaplacianSmoothing","title":"LaplacianSmoothing","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Applies laplacian smoothing via a fast Fourier transform solver which can improve generalization.</p> <p>Parameters:</p> <ul> <li> <code>sigma</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>controls the amount of smoothing. Defaults to 1.</p> </li> <li> <code>layerwise</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, applies smoothing to each parameter's gradient separately, Otherwise applies it to all gradients, concatenated into a single vector. Defaults to True.</p> </li> <li> <code>min_numel</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>minimum number of elements in a parameter to apply laplacian smoothing to. Only has effect if <code>layerwise</code> is True. Defaults to 4.</p> </li> <li> <code>target</code>               (<code>str</code>)           \u2013            <p>what to set on var.</p> </li> </ul> <p>Examples: Laplacian Smoothing Gradient Descent optimizer as in the paper</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LaplacianSmoothing(),\n    tz.m.LR(1e-2),\n)\n</code></pre> Reference <p>Osher, S., Wang, B., Yin, P., Luo, X., Barekat, F., Pham, M., &amp; Lin, A. (2022). Laplacian smoothing gradient descent. Research in the Mathematical Sciences, 9(3), 55.</p> Source code in <code>torchzero/modules/smoothing/laplacian.py</code> <pre><code>class LaplacianSmoothing(TensorTransform):\n    \"\"\"Applies laplacian smoothing via a fast Fourier transform solver which can improve generalization.\n\n    Args:\n        sigma (float, optional): controls the amount of smoothing. Defaults to 1.\n        layerwise (bool, optional):\n            If True, applies smoothing to each parameter's gradient separately,\n            Otherwise applies it to all gradients, concatenated into a single vector. Defaults to True.\n        min_numel (int, optional):\n            minimum number of elements in a parameter to apply laplacian smoothing to.\n            Only has effect if `layerwise` is True. Defaults to 4.\n        target (str, optional):\n            what to set on var.\n\n    Examples:\n    Laplacian Smoothing Gradient Descent optimizer as in the paper\n\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LaplacianSmoothing(),\n        tz.m.LR(1e-2),\n    )\n    ```\n\n    Reference:\n        Osher, S., Wang, B., Yin, P., Luo, X., Barekat, F., Pham, M., &amp; Lin, A. (2022). Laplacian smoothing gradient descent. Research in the Mathematical Sciences, 9(3), 55.\n\n    \"\"\"\n    def __init__(self, sigma:float = 1, layerwise=True, min_numel = 4):\n        defaults = dict(sigma = sigma, layerwise=layerwise, min_numel=min_numel)\n        super().__init__(defaults)\n        # precomputed denominator for when layerwise=False\n        self.global_state['full_denominator'] = None\n\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        layerwise = settings[0]['layerwise']\n\n        # layerwise laplacian smoothing\n        if layerwise:\n\n            # precompute the denominator for each layer and store it in each parameters state\n            smoothed_target = TensorList()\n            for p, t, state, setting in zip(params, tensors, states, settings):\n                if p.numel() &gt; setting['min_numel']:\n                    if 'denominator' not in state: state['denominator'] = _precompute_denominator(p, setting['sigma'])\n                    smoothed_target.append(torch.fft.ifft(torch.fft.fft(t.view(-1)) / state['denominator']).real.view_as(t)) #pylint:disable=not-callable\n                else:\n                    smoothed_target.append(t)\n\n            return smoothed_target\n\n        # else\n        # full laplacian smoothing\n        # precompute full denominator\n        tensors = TensorList(tensors)\n        if self.global_state.get('full_denominator', None) is None:\n            self.global_state['full_denominator'] = _precompute_denominator(tensors.to_vec(), settings[0]['sigma'])\n\n        # apply the smoothing\n        vec = tensors.to_vec()\n        return tensors.from_vec(torch.fft.ifft(torch.fft.fft(vec) / self.global_state['full_denominator']).real)#pylint:disable=not-callable\n</code></pre>"},{"location":"API/modules/step_size/","title":"Step size","text":"<p>This subpackage contains step size selection methods like Barzilai-Borwein and Polyak's step size.</p>"},{"location":"API/modules/step_size/#see-also","title":"See also","text":"<ul> <li>Line search - line search methods.</li> <li>Trust region - trust region methods.</li> </ul> <p>Classes:</p> <ul> <li> <code>AdGD</code>           \u2013            <p>AdGD and AdGD-2 (https://arxiv.org/abs/2308.02261)</p> </li> <li> <code>BBStab</code>           \u2013            <p>Stabilized Barzilai-Borwein method (https://arxiv.org/abs/1907.06409).</p> </li> <li> <code>BarzilaiBorwein</code>           \u2013            <p>Barzilai-Borwein step size method.</p> </li> <li> <code>BoldDriver</code>           \u2013            <p>Multiplies step size by <code>nplus</code> if loss decreased compared to last iteration, otherwise multiplies by <code>nminus</code>.</p> </li> <li> <code>LR</code>           \u2013            <p>Learning rate. Adding this module also adds support for LR schedulers.</p> </li> <li> <code>PolyakStepSize</code>           \u2013            <p>Polyak's subgradient method with known or unknown f*.</p> </li> <li> <code>RandomStepSize</code>           \u2013            <p>Uses random global or layer-wise step size from <code>low</code> to <code>high</code>.</p> </li> <li> <code>StepSize</code>           \u2013            <p>this is exactly the same as LR, except the <code>lr</code> parameter can be renamed to any other name to avoid clashes</p> </li> <li> <code>Warmup</code>           \u2013            <p>Learning rate warmup, linearly increases learning rate multiplier from <code>start_lr</code> to <code>end_lr</code> over <code>steps</code> steps.</p> </li> <li> <code>WarmupNormClip</code>           \u2013            <p>Warmup via clipping of the update norm.</p> </li> </ul>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.AdGD","title":"AdGD","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>AdGD and AdGD-2 (https://arxiv.org/abs/2308.02261)</p> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class AdGD(TensorTransform):\n    \"\"\"AdGD and AdGD-2 (https://arxiv.org/abs/2308.02261)\"\"\"\n    def __init__(self, variant:Literal[1,2]=2, alpha_0:float = 1e-7, sqrt:bool=True, use_grad=True, inner: Chainable | None = None,):\n        defaults = dict(variant=variant, alpha_0=alpha_0, sqrt=sqrt)\n        super().__init__(defaults, uses_grad=use_grad, inner=inner,)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_g')\n        self.global_state['reset'] = True\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        variant = settings[0]['variant']\n        theta_0 = 0 if variant == 1 else 1/3\n        theta = self.global_state.get('theta', theta_0)\n\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        p = TensorList(params)\n        g = grads if self._uses_grad else tensors\n        assert g is not None\n        g = TensorList(g)\n\n        prev_p, prev_g = unpack_states(states, tensors, 'prev_p', 'prev_g', cls=TensorList)\n\n        # online\n        if self.global_state.get('reset', False):\n            del self.global_state['reset']\n            prev_p.copy_(p)\n            prev_g.copy_(g)\n            return\n\n        if step == 0:\n            alpha_0 = settings[0]['alpha_0']\n            if alpha_0 is None: alpha_0 = epsilon_step_size(g)\n            self.global_state['alpha']  = alpha_0\n            prev_p.copy_(p)\n            prev_g.copy_(g)\n            return\n\n        sqrt = settings[0]['sqrt']\n        alpha = self.global_state.get('alpha', math.inf)\n        L = (g - prev_g).global_vector_norm() / (p - prev_p).global_vector_norm()\n        eps = torch.finfo(L.dtype).tiny * 2\n\n        if variant == 1:\n            a1 = math.sqrt(1 + theta)*alpha\n            val = math.sqrt(2) if sqrt else 2\n            if L &gt; eps: a2 = 1 / (val*L)\n            else: a2 = math.inf\n\n        elif variant == 2:\n            a1 = math.sqrt(2/3 + theta)*alpha\n            a2 = alpha / math.sqrt(max(eps, 2 * alpha**2 * L**2 - 1))\n\n        else:\n            raise ValueError(variant)\n\n        alpha_new = min(a1, a2)\n        if alpha_new &lt; 0: alpha_new = max(a1, a2)\n        if alpha_new &gt; eps:\n            self.global_state['theta'] = alpha_new/alpha\n            self.global_state['alpha'] = alpha_new\n\n        prev_p.copy_(p)\n        prev_g.copy_(g)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            # alpha isn't None on 1st step\n            self.state.clear()\n            self.global_state.clear()\n            alpha = epsilon_step_size(TensorList(tensors), settings[0]['alpha_0'])\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.BBStab","title":"BBStab","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Stabilized Barzilai-Borwein method (https://arxiv.org/abs/1907.06409).</p> <p>This clips the norm of the Barzilai-Borwein update by <code>delta</code>, where <code>delta</code> can be adaptive if <code>c</code> is specified.</p> <p>Parameters:</p> <ul> <li> <code>c</code>               (<code>float</code>, default:                   <code>0.2</code> )           \u2013            <p>adaptive delta parameter. If <code>delta</code> is set to None, first <code>inf_iters</code> updates are performed with non-stabilized Barzilai-Borwein step size. Then delta is set to norm of the update that had the smallest norm, and multiplied by <code>c</code>. Defaults to 0.2.</p> </li> <li> <code>delta</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Barzilai-Borwein update is clipped to this value. Set to <code>None</code> to use an adaptive choice. Defaults to None.</p> </li> <li> <code>type</code>               (<code>str</code>, default:                   <code>'geom'</code> )           \u2013            <p>one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long. Defaults to \"geom\". Note that \"long\" corresponds to BB1stab and \"short\" to BB2stab, however I found that \"geom\" works really well.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>step size will be applied to outputs of this module. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class BBStab(TensorTransform):\n    \"\"\"Stabilized Barzilai-Borwein method (https://arxiv.org/abs/1907.06409).\n\n    This clips the norm of the Barzilai-Borwein update by ``delta``, where ``delta`` can be adaptive if ``c`` is specified.\n\n    Args:\n        c (float, optional):\n            adaptive delta parameter. If ``delta`` is set to None, first ``inf_iters`` updates are performed\n            with non-stabilized Barzilai-Borwein step size. Then delta is set to norm of\n            the update that had the smallest norm, and multiplied by ``c``. Defaults to 0.2.\n        delta (float | None, optional):\n            Barzilai-Borwein update is clipped to this value. Set to ``None`` to use an adaptive choice. Defaults to None.\n        type (str, optional):\n            one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long.\n            Defaults to \"geom\". Note that \"long\" corresponds to BB1stab and \"short\" to BB2stab,\n            however I found that \"geom\" works really well.\n        inner (Chainable | None, optional):\n            step size will be applied to outputs of this module. Defaults to None.\n\n    \"\"\"\n    def __init__(\n        self,\n        c=0.2,\n        delta:float | None = None,\n        type: Literal[\"long\", \"short\", \"geom\", \"geom-fallback\"] = \"geom\",\n        alpha_0: float = 1e-7,\n        use_grad=True,\n        inf_iters: int = 3,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(type=type,alpha_0=alpha_0, c=c, delta=delta, inf_iters=inf_iters)\n        super().__init__(defaults, uses_grad=use_grad, inner=inner)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_g')\n        self.global_state['reset'] = True\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        prev_p, prev_g = unpack_states(states, tensors, 'prev_p', 'prev_g', cls=TensorList)\n        type = self.defaults['type']\n        c = self.defaults['c']\n        delta = self.defaults['delta']\n        inf_iters = self.defaults['inf_iters']\n\n        g = grads if self._uses_grad else tensors\n        assert g is not None\n        g = TensorList(g)\n\n        reset = self.global_state.get('reset', False)\n        self.global_state.pop('reset', None)\n\n        if step != 0 and not reset:\n            s = params-prev_p\n            y = g-prev_g\n            sy = s.dot(y)\n            eps = torch.finfo(sy.dtype).tiny\n\n            if type == 'short': alpha = _bb_short(s, y, sy, eps)\n            elif type == 'long': alpha = _bb_long(s, y, sy, eps)\n            elif type == 'geom': alpha = _bb_geom(s, y, sy, eps, fallback=False)\n            elif type == 'geom-fallback': alpha = _bb_geom(s, y, sy, eps, fallback=True)\n            else: raise ValueError(type)\n\n            if alpha is not None:\n\n                # adaptive delta\n                if delta is None:\n                    niters = self.global_state.get('niters', 0) # this accounts for skipped negative curvature steps\n                    self.global_state['niters'] = niters + 1\n\n\n                    if niters == 0: pass # 1st iteration is scaled GD step, shouldn't be used to find s_norm_min\n                    elif niters &lt;= inf_iters:\n                        s_norm_min = self.global_state.get('s_norm_min', None)\n                        if s_norm_min is None: s_norm_min = s.global_vector_norm()\n                        else: s_norm_min = min(s_norm_min, s.global_vector_norm())\n                        self.global_state['s_norm_min'] = s_norm_min\n                        # first few steps use delta=inf, so delta remains None\n\n                    else:\n                        delta = c * self.global_state['s_norm_min']\n\n                if delta is None: # delta is inf for first few steps\n                    self.global_state['alpha'] = alpha\n\n                # BBStab step size\n                else:\n                    a_stab = delta / g.global_vector_norm()\n                    self.global_state['alpha'] = min(alpha, a_stab)\n\n        prev_p.copy_(params)\n        prev_g.copy_(g)\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            alpha = epsilon_step_size(TensorList(tensors), settings[0]['alpha_0'])\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.BarzilaiBorwein","title":"BarzilaiBorwein","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Barzilai-Borwein step size method.</p> <p>Parameters:</p> <ul> <li> <code>type</code>               (<code>str</code>, default:                   <code>'geom'</code> )           \u2013            <p>one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long. Defaults to \"geom\".</p> </li> <li> <code>fallback</code>               (<code>float</code>)           \u2013            <p>step size when denominator is less than 0 (will happen on negative curvature). Defaults to 1e-3.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>step size will be applied to outputs of this module. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class BarzilaiBorwein(TensorTransform):\n    \"\"\"Barzilai-Borwein step size method.\n\n    Args:\n        type (str, optional):\n            one of \"short\" with formula s\u1d40y/y\u1d40y, \"long\" with formula s\u1d40s/s\u1d40y, or \"geom\" to use geometric mean of short and long.\n            Defaults to \"geom\".\n        fallback (float, optional): step size when denominator is less than 0 (will happen on negative curvature). Defaults to 1e-3.\n        inner (Chainable | None, optional):\n            step size will be applied to outputs of this module. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        type: Literal[\"long\", \"short\", \"geom\", \"geom-fallback\"] = \"geom\",\n        alpha_0: float = 1e-7,\n        use_grad=True,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(type=type, alpha_0=alpha_0)\n        super().__init__(defaults, uses_grad=use_grad, inner=inner)\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('prev_g')\n        self.global_state['reset'] = True\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        prev_p, prev_g = unpack_states(states, tensors, 'prev_p', 'prev_g', cls=TensorList)\n        type = self.defaults['type']\n\n        g = grads if self._uses_grad else tensors\n        assert g is not None\n\n        reset = self.global_state.get('reset', False)\n        self.global_state.pop('reset', None)\n\n        if step != 0 and not reset:\n            s = params-prev_p\n            y = g-prev_g\n            sy = s.dot(y)\n            eps = torch.finfo(sy.dtype).tiny * 2\n\n            if type == 'short': alpha = _bb_short(s, y, sy, eps)\n            elif type == 'long': alpha = _bb_long(s, y, sy, eps)\n            elif type == 'geom': alpha = _bb_geom(s, y, sy, eps, fallback=False)\n            elif type == 'geom-fallback': alpha = _bb_geom(s, y, sy, eps, fallback=True)\n            else: raise ValueError(type)\n\n            # if alpha is not None:\n            self.global_state['alpha'] = alpha\n\n        prev_p.copy_(params)\n        prev_g.copy_(g)\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            alpha = epsilon_step_size(TensorList(tensors), settings[0]['alpha_0'])\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.BoldDriver","title":"BoldDriver","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Multiplies step size by <code>nplus</code> if loss decreased compared to last iteration, otherwise multiplies by <code>nminus</code>.</p> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class BoldDriver(TensorTransform):\n    \"\"\"Multiplies step size by ``nplus`` if loss decreased compared to last iteration, otherwise multiplies by ``nminus``.\"\"\"\n    def __init__(self, a_init=1e-3, nplus=1.1, nminus=0.1, inner: Chainable | None = None):\n        defaults = dict(a_init=a_init, nplus=nplus, nminus=nminus)\n        super().__init__(defaults, uses_loss=True, inner=inner)\n        self.global_state[\"alpha\"] = a_init\n\n    def reset_for_online(self):\n        super().reset_for_online()\n        self.clear_state_keys('f_prev')\n\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        fs = settings[0]\n        if \"f_prev\" not in self.global_state:\n            self.global_state[\"f_prev\"] = tofloat(loss)\n            return\n\n        if self.global_state[\"f_prev\"] &lt;= loss:\n            self.global_state[\"alpha\"] *= fs[\"nminus\"]\n\n        else:\n            self.global_state[\"alpha\"] *= fs[\"nplus\"]\n\n        self.global_state[\"f_prev\"] = tofloat(loss)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', None)\n\n        if not _acceptable_alpha(alpha, tensors[0]):\n            self.state.clear()\n            self.global_state.clear()\n            self.global_state[\"alpha\"] = settings[0][\"a_init\"]\n            alpha = epsilon_step_size(TensorList(tensors), 1e-7)\n\n        torch._foreach_mul_(tensors, alpha)\n        return tensors\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.LR","title":"LR","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Learning rate. Adding this module also adds support for LR schedulers.</p> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class LR(TensorTransform):\n    \"\"\"Learning rate. Adding this module also adds support for LR schedulers.\"\"\"\n    def __init__(self, lr: float):\n        defaults=dict(lr=lr)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return lazy_lr(TensorList(tensors), lr=[s['lr'] for s in settings], inplace=True)\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.PolyakStepSize","title":"PolyakStepSize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Polyak's subgradient method with known or unknown f*.</p> <p>Parameters:</p> <ul> <li> <code>f_star</code>               (<code>float | Mone</code>, default:                   <code>0</code> )           \u2013            <p>minimal possible value of the objective function. If not known, set to <code>None</code>. Defaults to 0.</p> </li> <li> <code>y</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>when <code>f_star</code> is set to None, it is calculated as <code>f_best - y</code>.</p> </li> <li> <code>y_decay</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p><code>y</code> is multiplied by <code>(1 - y_decay)</code> after each step. Defaults to 1e-3.</p> </li> <li> <code>max</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>maximum possible step size. Defaults to None.</p> </li> <li> <code>use_grad</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, uses dot product of update and gradient to compute the step size. Otherwise, dot product of update with itself is used.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>multiplier to Polyak step-size. Defaults to 1.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/adaptive.py</code> <pre><code>class PolyakStepSize(TensorTransform):\n    \"\"\"Polyak's subgradient method with known or unknown f*.\n\n    Args:\n        f_star (float | Mone, optional):\n            minimal possible value of the objective function. If not known, set to ``None``. Defaults to 0.\n        y (float, optional):\n            when ``f_star`` is set to None, it is calculated as ``f_best - y``.\n        y_decay (float, optional):\n            ``y`` is multiplied by ``(1 - y_decay)`` after each step. Defaults to 1e-3.\n        max (float | None, optional): maximum possible step size. Defaults to None.\n        use_grad (bool, optional):\n            if True, uses dot product of update and gradient to compute the step size.\n            Otherwise, dot product of update with itself is used.\n        alpha (float, optional): multiplier to Polyak step-size. Defaults to 1.\n    \"\"\"\n    def __init__(self, f_star: float | None = 0, y: float = 1, y_decay: float = 1e-3, max: float | None = None, use_grad=True, alpha: float = 1, inner: Chainable | None = None):\n\n        defaults = dict(alpha=alpha, max=max, f_star=f_star, y=y, y_decay=y_decay)\n        super().__init__(defaults, uses_grad=use_grad, uses_loss=True, inner=inner)\n\n    @torch.no_grad\n    def multi_tensor_update(self, tensors, params, grads, loss, states, settings):\n        assert grads is not None and loss is not None\n        tensors = TensorList(tensors)\n        grads = TensorList(grads)\n\n        # load variables\n        max, f_star, y, y_decay = itemgetter('max', 'f_star', 'y', 'y_decay')(settings[0])\n        y_val = self.global_state.get('y_val', y)\n        f_best = self.global_state.get('f_best', None)\n\n        # gg\n        if self._uses_grad: gg = tensors.dot(grads)\n        else: gg = tensors.dot(tensors)\n\n        # store loss\n        if f_best is None or loss &lt; f_best: f_best = tofloat(loss)\n        if f_star is None: f_star = f_best - y_val\n\n        # calculate the step size\n        if gg &lt;= torch.finfo(gg.dtype).tiny * 2: alpha = 0 # converged\n        else: alpha = (loss - f_star) / gg\n\n        # clip\n        if max is not None:\n            if alpha &gt; max: alpha = max\n\n        # store state\n        self.global_state['f_best'] = f_best\n        self.global_state['y_val'] = y_val * (1 - y_decay)\n        self.global_state['alpha'] = alpha\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        alpha = self.global_state.get('alpha', 1)\n        if not _acceptable_alpha(alpha, tensors[0]): alpha = epsilon_step_size(TensorList(tensors))\n\n        torch._foreach_mul_(tensors, alpha * unpack_dicts(settings, 'alpha', cls=NumberList))\n        return tensors\n\n    def get_H(self, objective):\n        return _get_scaled_identity_H(self, objective)\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.RandomStepSize","title":"RandomStepSize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Uses random global or layer-wise step size from <code>low</code> to <code>high</code>.</p> <p>Parameters:</p> <ul> <li> <code>low</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>minimum learning rate. Defaults to 0.</p> </li> <li> <code>high</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>maximum learning rate. Defaults to 1.</p> </li> <li> <code>parameterwise</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, generate random step size for each parameter separately, if False generate one global random step size. Defaults to False.</p> </li> </ul> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class RandomStepSize(TensorTransform):\n    \"\"\"Uses random global or layer-wise step size from ``low`` to ``high``.\n\n    Args:\n        low (float, optional): minimum learning rate. Defaults to 0.\n        high (float, optional): maximum learning rate. Defaults to 1.\n        parameterwise (bool, optional):\n            if True, generate random step size for each parameter separately,\n            if False generate one global random step size. Defaults to False.\n    \"\"\"\n    def __init__(self, low: float = 0, high: float = 1, parameterwise=False, seed:int|None=None):\n        defaults = dict(low=low, high=high, parameterwise=parameterwise,seed=seed)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        s = settings[0]\n        parameterwise = s['parameterwise']\n\n        seed = s['seed']\n        if 'generator' not in self.global_state:\n            self.global_state['generator'] = random.Random(seed)\n        generator: random.Random = self.global_state['generator']\n\n        if parameterwise:\n            low, high = unpack_dicts(settings, 'low', 'high')\n            lr = [generator.uniform(l, h) for l, h in zip(low, high)]\n        else:\n            low = s['low']\n            high = s['high']\n            lr = generator.uniform(low, high)\n\n        torch._foreach_mul_(tensors, lr)\n        return tensors\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.StepSize","title":"StepSize","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>this is exactly the same as LR, except the <code>lr</code> parameter can be renamed to any other name to avoid clashes</p> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class StepSize(TensorTransform):\n    \"\"\"this is exactly the same as LR, except the `lr` parameter can be renamed to any other name to avoid clashes\"\"\"\n    def __init__(self, step_size: float, key = 'step_size'):\n        defaults={\"key\": key, key: step_size}\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        return lazy_lr(TensorList(tensors), lr=[s[s['key']] for s in settings], inplace=True)\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.Warmup","title":"Warmup","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Learning rate warmup, linearly increases learning rate multiplier from <code>start_lr</code> to <code>end_lr</code> over <code>steps</code> steps.</p> <p>Parameters:</p> <ul> <li> <code>steps</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of steps to perform warmup for. Defaults to 100.</p> </li> <li> <code>start_lr</code>               (<code>_type_</code>, default:                   <code>1e-05</code> )           \u2013            <p>initial learning rate multiplier on first step. Defaults to 1e-5.</p> </li> <li> <code>end_lr</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>learning rate multiplier at the end and after warmup. Defaults to 1.</p> </li> </ul> Example <p>Adam with 1000 steps warmup</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.LR(1e-2),\n    tz.m.Warmup(steps=1000)\n)\n</code></pre> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class Warmup(TensorTransform):\n    \"\"\"Learning rate warmup, linearly increases learning rate multiplier from ``start_lr`` to ``end_lr`` over ``steps`` steps.\n\n    Args:\n        steps (int, optional): number of steps to perform warmup for. Defaults to 100.\n        start_lr (_type_, optional): initial learning rate multiplier on first step. Defaults to 1e-5.\n        end_lr (float, optional): learning rate multiplier at the end and after warmup. Defaults to 1.\n\n    Example:\n        Adam with 1000 steps warmup\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.Adam(),\n                tz.m.LR(1e-2),\n                tz.m.Warmup(steps=1000)\n            )\n\n    \"\"\"\n    def __init__(self, steps = 100, start_lr = 1e-5, end_lr:float = 1):\n        defaults = dict(start_lr=start_lr,end_lr=end_lr, steps=steps)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        start_lr, end_lr = unpack_dicts(settings, 'start_lr', 'end_lr', cls = NumberList)\n        num_steps = settings[0]['steps']\n        step = self.global_state.get('step', 0)\n\n        tensors = lazy_lr(\n            TensorList(tensors),\n            lr=_warmup_lr(step=step, start_lr=start_lr, end_lr=end_lr, steps=num_steps),\n            inplace=True\n        )\n        self.global_state['step'] = step + 1\n        return tensors\n</code></pre>"},{"location":"API/modules/step_size/#torchzero.modules.step_size.WarmupNormClip","title":"WarmupNormClip","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Warmup via clipping of the update norm.</p> <p>Parameters:</p> <ul> <li> <code>start_norm</code>               (<code>_type_</code>, default:                   <code>1e-05</code> )           \u2013            <p>maximal norm on the first step. Defaults to 1e-5.</p> </li> <li> <code>end_norm</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>maximal norm on the last step. After that, norm clipping is disabled. Defaults to 1.</p> </li> <li> <code>steps</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>number of steps to perform warmup for. Defaults to 100.</p> </li> </ul> Example <p>Adam with 1000 steps norm clip warmup</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.WarmupNormClip(steps=1000)\n    tz.m.LR(1e-2),\n)\n</code></pre> Source code in <code>torchzero/modules/step_size/lr.py</code> <pre><code>class WarmupNormClip(TensorTransform):\n    \"\"\"Warmup via clipping of the update norm.\n\n    Args:\n        start_norm (_type_, optional): maximal norm on the first step. Defaults to 1e-5.\n        end_norm (float, optional): maximal norm on the last step. After that, norm clipping is disabled. Defaults to 1.\n        steps (int, optional): number of steps to perform warmup for. Defaults to 100.\n\n    Example:\n        Adam with 1000 steps norm clip warmup\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.Adam(),\n                tz.m.WarmupNormClip(steps=1000)\n                tz.m.LR(1e-2),\n            )\n    \"\"\"\n    def __init__(self, steps = 100, start_norm = 1e-5, end_norm:float = 1):\n        defaults = dict(start_norm=start_norm,end_norm=end_norm, steps=steps)\n        super().__init__(defaults, uses_grad=False)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        start_norm, end_norm = unpack_dicts(settings, 'start_norm', 'end_norm', cls = NumberList)\n        num_steps = settings[0]['steps']\n        step = self.global_state.get('step', 0)\n        if step &gt; num_steps: return tensors\n\n        tensors = TensorList(tensors)\n        norm = tensors.global_vector_norm()\n        current_max_norm = _warmup_lr(step, start_norm[0], end_norm[0], num_steps)\n        if norm &gt; current_max_norm:\n            tensors.mul_(current_max_norm / norm)\n\n        self.global_state['step'] = step + 1\n        return tensors\n</code></pre>"},{"location":"API/modules/trust_region/","title":"Trust region","text":"<p>This subpackage contains trust region methods.</p>"},{"location":"API/modules/trust_region/#see-also","title":"See also","text":"<ul> <li>Step size - step size selection methods like Barzilai-Borwein and Polyak's step size.</li> <li>Line search - line search methods.</li> </ul> <p>Classes:</p> <ul> <li> <code>CubicRegularization</code>           \u2013            <p>Cubic regularization.</p> </li> <li> <code>Dogleg</code>           \u2013            <p>Dogleg trust region algorithm.</p> </li> <li> <code>LevenbergMarquardt</code>           \u2013            <p>Levenberg-Marquardt trust region algorithm.</p> </li> <li> <code>TrustCG</code>           \u2013            <p>Trust region via Steihaug-Toint Conjugate Gradient method.</p> </li> <li> <code>TrustRegionBase</code>           \u2013            </li> </ul>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.CubicRegularization","title":"CubicRegularization","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Cubic regularization.</p> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When :code:<code>hess_module</code> is GaussNewton, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>maxiter</code>               (<code>float</code>, default:                   <code>100</code> )           \u2013            <p>maximum iterations when solving cubic subproblem, defaults to 1e-7.</p> </li> <li> <code>eps</code>               (<code>float</code>, default:                   <code>1e-08</code> )           \u2013            <p>epsilon for the solver, defaults to 1e-8.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>fallback</code>               (<code>bool</code>)           \u2013            <p>if <code>True</code>, when <code>hess_module</code> maintains hessian inverse which can't be inverted efficiently, it will be inverted anyway. When <code>False</code> (default), a <code>RuntimeError</code> will be raised instead.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul> <p>Examples:</p> <p>Cubic regularized newton</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.CubicRegularization(tz.m.Newton()),\n)\n</code></pre> Source code in <code>torchzero/modules/trust_region/cubic_regularization.py</code> <pre><code>class CubicRegularization(TrustRegionBase):\n    \"\"\"Cubic regularization.\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set `inverse=False` when constructing them.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When :code:`hess_module` is GaussNewton, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        maxiter (float, optional): maximum iterations when solving cubic subproblem, defaults to 1e-7.\n        eps (float, optional): epsilon for the solver, defaults to 1e-8.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        fallback (bool, optional):\n            if ``True``, when ``hess_module`` maintains hessian inverse which can't be inverted efficiently, it will\n            be inverted anyway. When ``False`` (default), a ``RuntimeError`` will be raised instead.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n\n    Examples:\n        Cubic regularized newton\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.CubicRegularization(tz.m.Newton()),\n            )\n\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        maxiter: int = 100,\n        eps: float = 1e-8,\n        check_decrease:bool=False,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(maxiter=maxiter, eps=eps, check_decrease=check_decrease)\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            boundary_tol=None,\n            radius_fn=None,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        params = TensorList(params)\n\n        loss_at_params_plus_x_fn = None\n        if settings['check_decrease']:\n            def closure_plus_x(x):\n                x_unflat = vec_to_tensors(x, params)\n                params.add_(x_unflat)\n                loss_x = closure(False)\n                params.sub_(x_unflat)\n                return loss_x\n            loss_at_params_plus_x_fn = closure_plus_x\n\n\n        d, _ = ls_cubic_solver(f=f, g=g, H=H, M=1/radius, loss_at_params_plus_x_fn=loss_at_params_plus_x_fn,\n                               it_max=settings['maxiter'], epsilon=settings['eps'])\n        return d.neg_()\n</code></pre>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.Dogleg","title":"Dogleg","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Dogleg trust region algorithm.</p> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When :code:<code>hess_module</code> is GaussNewton, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.75</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul> Source code in <code>torchzero/modules/trust_region/dogleg.py</code> <pre><code>class Dogleg(TrustRegionBase):\n    \"\"\"Dogleg trust region algorithm.\n\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set `inverse=False` when constructing them.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When :code:`hess_module` is GaussNewton, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 2,\n        nminus: float = 0.25,\n        rho_good: float = 0.75,\n        rho_bad: float = 0.25,\n        boundary_tol: float | None = None,\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict()\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            boundary_tol=boundary_tol,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            radius_fn=torch.linalg.vector_norm,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        if radius &gt; 2: radius = self.global_state['radius'] = 2\n        eps = torch.finfo(g.dtype).tiny * 2\n\n        gHg = g.dot(H.matvec(g))\n        if gHg &lt;= eps:\n            return (radius / torch.linalg.vector_norm(g)) * g # pylint:disable=not-callable\n\n        p_cauchy = (g.dot(g) / gHg) * g\n        p_newton = H.solve(g)\n\n        a = p_newton - p_cauchy\n        b = p_cauchy\n\n        aa = a.dot(a)\n        if aa &lt; eps:\n            return (radius / torch.linalg.vector_norm(g)) * g # pylint:disable=not-callable\n\n        ab = a.dot(b)\n        bb = b.dot(b)\n        c = bb - radius**2\n        discriminant = (2*ab)**2 - 4*aa*c\n        beta = (-2*ab + torch.sqrt(discriminant.clip(min=0))) / (2 * aa)\n        return p_cauchy + beta * (p_newton - p_cauchy)\n</code></pre>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.LevenbergMarquardt","title":"LevenbergMarquardt","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Levenberg-Marquardt trust region algorithm.</p> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>y</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>when <code>y=0</code>, identity matrix is added to hessian, when <code>y=1</code>, diagonal of the hessian approximation is added. Values between interpolate. This should only be used with Gauss-Newton. Defaults to 0.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When <code>hess_module</code> is <code>Newton</code> or <code>GaussNewton</code>, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>adaptive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, trust radius is multiplied by square root of gradient norm.</p> </li> <li> <code>fallback</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if <code>True</code>, when <code>hess_module</code> maintains hessian inverse which can't be inverted efficiently, it will be inverted anyway. When <code>False</code> (default), a <code>RuntimeError</code> will be raised instead.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.LevenbergMarquardt--examples","title":"Examples:","text":"<p>Gauss-Newton with Levenberg-Marquardt trust-region</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.GaussNewton()),\n)\n</code></pre> <p>LM-SR1 <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n)\n</code></pre></p> Source code in <code>torchzero/modules/trust_region/levenberg_marquardt.py</code> <pre><code>class LevenbergMarquardt(TrustRegionBase):\n    \"\"\"Levenberg-Marquardt trust region algorithm.\n\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set ``inverse=False`` when constructing them.\n        y (float, optional):\n            when ``y=0``, identity matrix is added to hessian, when ``y=1``, diagonal of the hessian approximation\n            is added. Values between interpolate. This should only be used with Gauss-Newton. Defaults to 0.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When ``hess_module`` is ``Newton`` or ``GaussNewton``, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        adaptive (bool, optional):\n            if True, trust radius is multiplied by square root of gradient norm.\n        fallback (bool, optional):\n            if ``True``, when ``hess_module`` maintains hessian inverse which can't be inverted efficiently, it will\n            be inverted anyway. When ``False`` (default), a ``RuntimeError`` will be raised instead.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n    ### Examples:\n\n    Gauss-Newton with Levenberg-Marquardt trust-region\n\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.GaussNewton()),\n    )\n    ```\n\n    LM-SR1\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)),\n    )\n    ```\n\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        y: float = 0,\n        adaptive: bool = False,\n        fallback: bool = False,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(y=y, fallback=fallback, adaptive=adaptive)\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            boundary_tol=None,\n            radius_fn=None,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        y = settings['y']\n        adaptive = settings[\"adaptive\"]\n\n        if isinstance(H, linear_operator.DenseInverse):\n            if settings['fallback']:\n                H = H.to_dense()\n            else:\n                raise RuntimeError(\n                    f\"{self.children['hess_module']} maintains a hessian inverse. \"\n                    \"LevenbergMarquardt requires the hessian, not the inverse. \"\n                    \"If that module is a quasi-newton module, pass `inverse=False` on initialization. \"\n                    \"Or pass `fallback=True` to LevenbergMarquardt to allow inverting the hessian inverse, \"\n                    \"however that can be inefficient and unstable.\"\n                )\n\n        reg = 1/radius\n        if adaptive: reg = reg * torch.linalg.vector_norm(g).sqrt()\n\n        if y == 0:\n            return H.solve_plus_diag(g, reg) # pyright:ignore[reportAttributeAccessIssue]\n\n        diag = H.diagonal()\n        diag = torch.where(diag &lt; torch.finfo(diag.dtype).tiny * 2, 1, diag)\n        if y != 1: diag = (diag*y) + (1-y)\n        return H.solve_plus_diag(g, diag*reg)\n</code></pre>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.TrustCG","title":"TrustCG","text":"<p>               Bases: <code>torchzero.modules.trust_region.trust_region.TrustRegionBase</code></p> <p>Trust region via Steihaug-Toint Conjugate Gradient method.</p> <p>.. note::</p> <pre><code>If you wish to use exact hessian, use the matrix-free :code:`tz.m.NewtonCGSteihaug`\nwhich only uses hessian-vector products. While passing ``tz.m.Newton`` to this\nis possible, it is usually less efficient.\n</code></pre> <p>Parameters:</p> <ul> <li> <code>hess_module</code>               (<code>Module | None</code>)           \u2013            <p>A module that maintains a hessian approximation (not hessian inverse!). This includes all full-matrix quasi-newton methods, <code>tz.m.Newton</code> and <code>tz.m.GaussNewton</code>. When using quasi-newton methods, set <code>inverse=False</code> when constructing them.</p> </li> <li> <code>eta</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, step is accepted. When :code:<code>hess_module</code> is GaussNewton, this can be set to 0. Defaults to 0.15.</p> </li> <li> <code>nplus</code>               (<code>float</code>, default:                   <code>3.5</code> )           \u2013            <p>increase factor on successful steps. Defaults to 1.5.</p> </li> <li> <code>nminus</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>decrease factor on unsuccessful steps. Defaults to 0.75.</p> </li> <li> <code>rho_good</code>               (<code>float</code>, default:                   <code>0.99</code> )           \u2013            <p>if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by <code>nplus</code>.</p> </li> <li> <code>rho_bad</code>               (<code>float</code>, default:                   <code>0.0001</code> )           \u2013            <p>if ratio of actual to predicted rediction is less than this, trust region size is multiplied by <code>nminus</code>.</p> </li> <li> <code>init</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Initial trust region value. Defaults to 1.</p> </li> <li> <code>update_freq</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>frequency of updating the hessian. Defaults to 1.</p> </li> <li> <code>reg</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>regularization parameter for conjugate gradient. Defaults to 0.</p> </li> <li> <code>max_attempts</code>               (<code>max_attempts</code>, default:                   <code>10</code> )           \u2013            <p>maximum number of trust region size size reductions per step. A zero update vector is returned when this limit is exceeded. Defaults to 10.</p> </li> <li> <code>boundary_tol</code>               (<code>float | None</code>, default:                   <code>1e-06</code> )           \u2013            <p>The trust region only increases when suggested step's norm is at least <code>(1-boundary_tol)*trust_region</code>. This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.</p> </li> <li> <code>prefer_exact</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>when exact solution can be easily calculated without CG (e.g. hessian is stored as scaled identity), uses the exact solution. If False, always uses CG. Defaults to True.</p> </li> <li> <code>inner</code>               (<code>Chainable | None</code>, default:                   <code>None</code> )           \u2013            <p>preconditioning is applied to output of thise module. Defaults to None.</p> </li> </ul> <p>Examples:</p> <p>Trust-SR1</p> <p>.. code-block:: python</p> <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.TrustCG(hess_module=tz.m.SR1(inverse=False)),\n)\n</code></pre> Source code in <code>torchzero/modules/trust_region/trust_cg.py</code> <pre><code>class TrustCG(TrustRegionBase):\n    \"\"\"Trust region via Steihaug-Toint Conjugate Gradient method.\n\n    .. note::\n\n        If you wish to use exact hessian, use the matrix-free :code:`tz.m.NewtonCGSteihaug`\n        which only uses hessian-vector products. While passing ``tz.m.Newton`` to this\n        is possible, it is usually less efficient.\n\n    Args:\n        hess_module (Module | None, optional):\n            A module that maintains a hessian approximation (not hessian inverse!).\n            This includes all full-matrix quasi-newton methods, ``tz.m.Newton`` and ``tz.m.GaussNewton``.\n            When using quasi-newton methods, set `inverse=False` when constructing them.\n        eta (float, optional):\n            if ratio of actual to predicted rediction is larger than this, step is accepted.\n            When :code:`hess_module` is GaussNewton, this can be set to 0. Defaults to 0.15.\n        nplus (float, optional): increase factor on successful steps. Defaults to 1.5.\n        nminus (float, optional): decrease factor on unsuccessful steps. Defaults to 0.75.\n        rho_good (float, optional):\n            if ratio of actual to predicted rediction is larger than this, trust region size is multiplied by `nplus`.\n        rho_bad (float, optional):\n            if ratio of actual to predicted rediction is less than this, trust region size is multiplied by `nminus`.\n        init (float, optional): Initial trust region value. Defaults to 1.\n        update_freq (int, optional): frequency of updating the hessian. Defaults to 1.\n        reg (int, optional): regularization parameter for conjugate gradient. Defaults to 0.\n        max_attempts (max_attempts, optional):\n            maximum number of trust region size size reductions per step. A zero update vector is returned when\n            this limit is exceeded. Defaults to 10.\n        boundary_tol (float | None, optional):\n            The trust region only increases when suggested step's norm is at least `(1-boundary_tol)*trust_region`.\n            This prevents increasing trust region when solution is not on the boundary. Defaults to 1e-2.\n        prefer_exact (bool, optional):\n            when exact solution can be easily calculated without CG (e.g. hessian is stored as scaled identity),\n            uses the exact solution. If False, always uses CG. Defaults to True.\n        inner (Chainable | None, optional): preconditioning is applied to output of thise module. Defaults to None.\n\n    Examples:\n        Trust-SR1\n\n        .. code-block:: python\n\n            opt = tz.Optimizer(\n                model.parameters(),\n                tz.m.TrustCG(hess_module=tz.m.SR1(inverse=False)),\n            )\n    \"\"\"\n    def __init__(\n        self,\n        hess_module: Chainable,\n        eta: float= 0.0,\n        nplus: float = 3.5,\n        nminus: float = 0.25,\n        rho_good: float = 0.99,\n        rho_bad: float = 1e-4,\n        boundary_tol: float | None = 1e-6, # tuned\n        init: float = 1,\n        max_attempts: int = 10,\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS = 'default',\n        reg: float = 0,\n        maxiter: int | None = None,\n        miniter: int = 1,\n        cg_tol: float = 1e-8,\n        prefer_exact: bool = True,\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        defaults = dict(reg=reg, prefer_exact=prefer_exact, cg_tol=cg_tol, maxiter=maxiter, miniter=miniter)\n        super().__init__(\n            defaults=defaults,\n            hess_module=hess_module,\n            eta=eta,\n            nplus=nplus,\n            nminus=nminus,\n            rho_good=rho_good,\n            rho_bad=rho_bad,\n            boundary_tol=boundary_tol,\n            init=init,\n            max_attempts=max_attempts,\n            radius_strategy=radius_strategy,\n            update_freq=update_freq,\n            inner=inner,\n\n            radius_fn=torch.linalg.vector_norm,\n        )\n\n    def trust_solve(self, f, g, H, radius, params, closure, settings):\n        if settings['prefer_exact'] and isinstance(H, linear_operator.ScaledIdentity):\n            return H.solve_bounded(g, radius)\n\n        x, _ = cg(H.matvec, g, trust_radius=radius, reg=settings['reg'], maxiter=settings[\"maxiter\"], miniter=settings[\"miniter\"], tol=settings[\"cg_tol\"])\n        return x\n</code></pre>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.TrustRegionBase","title":"TrustRegionBase","text":"<p>               Bases: <code>torchzero.core.module.Module</code>, <code>abc.ABC</code></p> <p>Methods:</p> <ul> <li> <code>trust_region_apply</code>             \u2013              <p>Solves the trust region subproblem and outputs <code>Objective</code> with the solution direction.</p> </li> <li> <code>trust_region_update</code>             \u2013              <p>updates the state of this module after H or B have been updated, if necessary</p> </li> <li> <code>trust_solve</code>             \u2013              <p>Solve Hx=g with a trust region penalty/bound defined by <code>radius</code></p> </li> </ul> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>class TrustRegionBase(Module, ABC):\n    def __init__(\n        self,\n        defaults: dict | None,\n        hess_module: Chainable,\n        # suggested default values:\n        # Gould, Nicholas IM, et al. \"Sensitivity of trust-region algorithms to their parameters.\" 4OR 3.3 (2005): 227-241.\n        # which I found from https://github.com/patrick-kidger/optimistix/blob/c1dad7e75fc35bd5a4977ac3a872991e51e83d2c/optimistix/_solver/trust_region.py#L113-200\n        eta: float, # 0.0\n        nplus: float, # 3.5\n        nminus: float, # 0.25\n        rho_good: float, # 0.99\n        rho_bad: float, # 1e-4\n        boundary_tol: float | None, # None or 1e-1\n        init: float, # 1\n        max_attempts: int, # 10\n        radius_strategy: _RadiusStrategy | _RADIUS_KEYS, # \"default\"\n        radius_fn: Callable | None, # torch.linalg.vector_norm\n        update_freq: int = 1,\n        inner: Chainable | None = None,\n    ):\n        if isinstance(radius_strategy, str): radius_strategy = _RADIUS_STRATEGIES[radius_strategy]\n        if defaults is None: defaults = {}\n\n        safe_dict_update_(\n            defaults,\n            dict(eta=eta, nplus=nplus, nminus=nminus, rho_good=rho_good, rho_bad=rho_bad, init=init,\n                 update_freq=update_freq, max_attempts=max_attempts, radius_strategy=radius_strategy,\n                 boundary_tol=boundary_tol)\n        )\n\n        super().__init__(defaults)\n\n        self._radius_fn = radius_fn\n        self.set_child('hess_module', hess_module)\n\n        if inner is not None:\n            self.set_child('inner', inner)\n\n    @abstractmethod\n    def trust_solve(\n        self,\n        f: float,\n        g: torch.Tensor,\n        H: LinearOperator,\n        radius: float,\n        params: list[torch.Tensor],\n        closure: Callable,\n        settings: Mapping[str, Any],\n    ) -&gt; torch.Tensor:\n        \"\"\"Solve Hx=g with a trust region penalty/bound defined by `radius`\"\"\"\n        ... # pylint:disable=unnecessary-ellipsis\n\n    def trust_region_update(self, objective: Objective, H: LinearOperator | None) -&gt; None:\n        \"\"\"updates the state of this module after H or B have been updated, if necessary\"\"\"\n\n    def trust_region_apply(self, objective: Objective, tensors:list[torch.Tensor], H: LinearOperator | None) -&gt; Objective:\n        \"\"\"Solves the trust region subproblem and outputs ``Objective`` with the solution direction.\"\"\"\n        assert H is not None\n\n        params = TensorList(objective.params)\n        settings = self.settings[params[0]]\n        g = _flatten_tensors(tensors)\n\n        max_attempts = settings['max_attempts']\n\n        # loss at x_0\n        loss = objective.loss\n        closure = objective.closure\n        if closure is None: raise RuntimeError(\"Trust region requires closure\")\n        if loss is None: loss = objective.get_loss(False)\n        loss = tofloat(loss)\n\n        # trust region step and update\n        success = False\n        d = None\n        while not success:\n            max_attempts -= 1\n            if max_attempts &lt; 0: break\n\n            trust_radius = self.global_state.get('trust_radius', settings['init'])\n\n            # solve Hx=g\n            d = self.trust_solve(f=loss, g=g, H=H, radius=trust_radius, params=params, closure=closure, settings=settings)\n\n            # update trust radius\n            radius_strategy: _RadiusStrategy = settings['radius_strategy']\n            self.global_state[\"trust_radius\"], success = radius_strategy(\n                params=params,\n                closure=closure,\n                d=d,\n                f=loss,\n                g=g,\n                H=H,\n                trust_radius=trust_radius,\n\n                eta=settings[\"eta\"],\n                nplus=settings[\"nplus\"],\n                nminus=settings[\"nminus\"],\n                rho_good=settings[\"rho_good\"],\n                rho_bad=settings[\"rho_bad\"],\n                boundary_tol=settings[\"boundary_tol\"],\n                init=settings[\"init\"],\n\n                state=self.global_state,\n                settings=settings,\n                radius_fn=self._radius_fn,\n            )\n\n        assert d is not None\n        if success: objective.updates = vec_to_tensors(d, params)\n        else: objective.updates = params.zeros_like()\n\n        return objective\n\n\n    @final\n    @torch.no_grad\n    def update(self, objective):\n        step = self.global_state.get('step', 0)\n        self.global_state['step'] = step + 1\n\n        if step % self.defaults[\"update_freq\"] == 0:\n\n            hessian_module = self.children['hess_module']\n            hessian_module.update(objective)\n            H = hessian_module.get_H(objective)\n            self.global_state[\"H\"] = H\n\n            self.trust_region_update(objective, H=H)\n\n\n    @final\n    @torch.no_grad\n    def apply(self, objective):\n        H = self.global_state.get('H', None)\n\n        # -------------------------------- inner step -------------------------------- #\n        objective = self.inner_step(\"inner\", objective, must_exist=False)\n\n        # ----------------------------------- apply ---------------------------------- #\n        return self.trust_region_apply(objective=objective, tensors=objective.get_updates(), H=H)\n</code></pre>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.TrustRegionBase.trust_region_apply","title":"trust_region_apply","text":"<pre><code>trust_region_apply(objective: Objective, tensors: list[Tensor], H: LinearOperator | None) -&gt; Objective\n</code></pre> <p>Solves the trust region subproblem and outputs <code>Objective</code> with the solution direction.</p> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>def trust_region_apply(self, objective: Objective, tensors:list[torch.Tensor], H: LinearOperator | None) -&gt; Objective:\n    \"\"\"Solves the trust region subproblem and outputs ``Objective`` with the solution direction.\"\"\"\n    assert H is not None\n\n    params = TensorList(objective.params)\n    settings = self.settings[params[0]]\n    g = _flatten_tensors(tensors)\n\n    max_attempts = settings['max_attempts']\n\n    # loss at x_0\n    loss = objective.loss\n    closure = objective.closure\n    if closure is None: raise RuntimeError(\"Trust region requires closure\")\n    if loss is None: loss = objective.get_loss(False)\n    loss = tofloat(loss)\n\n    # trust region step and update\n    success = False\n    d = None\n    while not success:\n        max_attempts -= 1\n        if max_attempts &lt; 0: break\n\n        trust_radius = self.global_state.get('trust_radius', settings['init'])\n\n        # solve Hx=g\n        d = self.trust_solve(f=loss, g=g, H=H, radius=trust_radius, params=params, closure=closure, settings=settings)\n\n        # update trust radius\n        radius_strategy: _RadiusStrategy = settings['radius_strategy']\n        self.global_state[\"trust_radius\"], success = radius_strategy(\n            params=params,\n            closure=closure,\n            d=d,\n            f=loss,\n            g=g,\n            H=H,\n            trust_radius=trust_radius,\n\n            eta=settings[\"eta\"],\n            nplus=settings[\"nplus\"],\n            nminus=settings[\"nminus\"],\n            rho_good=settings[\"rho_good\"],\n            rho_bad=settings[\"rho_bad\"],\n            boundary_tol=settings[\"boundary_tol\"],\n            init=settings[\"init\"],\n\n            state=self.global_state,\n            settings=settings,\n            radius_fn=self._radius_fn,\n        )\n\n    assert d is not None\n    if success: objective.updates = vec_to_tensors(d, params)\n    else: objective.updates = params.zeros_like()\n\n    return objective\n</code></pre>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.TrustRegionBase.trust_region_update","title":"trust_region_update","text":"<pre><code>trust_region_update(objective: Objective, H: LinearOperator | None) -&gt; None\n</code></pre> <p>updates the state of this module after H or B have been updated, if necessary</p> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>def trust_region_update(self, objective: Objective, H: LinearOperator | None) -&gt; None:\n    \"\"\"updates the state of this module after H or B have been updated, if necessary\"\"\"\n</code></pre>"},{"location":"API/modules/trust_region/#torchzero.modules.trust_region.TrustRegionBase.trust_solve","title":"trust_solve","text":"<pre><code>trust_solve(f: float, g: Tensor, H: LinearOperator, radius: float, params: list[Tensor], closure: Callable, settings: Mapping[str, Any]) -&gt; Tensor\n</code></pre> <p>Solve Hx=g with a trust region penalty/bound defined by <code>radius</code></p> Source code in <code>torchzero/modules/trust_region/trust_region.py</code> <pre><code>@abstractmethod\ndef trust_solve(\n    self,\n    f: float,\n    g: torch.Tensor,\n    H: LinearOperator,\n    radius: float,\n    params: list[torch.Tensor],\n    closure: Callable,\n    settings: Mapping[str, Any],\n) -&gt; torch.Tensor:\n    \"\"\"Solve Hx=g with a trust region penalty/bound defined by `radius`\"\"\"\n    ... # pylint:disable=unnecessary-ellipsis\n</code></pre>"},{"location":"API/modules/weight_decay/","title":"Weight decay","text":"<p>This subpackage contains weight decay modules.</p> <p>Classes:</p> <ul> <li> <code>CautiousWeightDecay</code>           \u2013            <p>Cautious weight decay (https://arxiv.org/pdf/2510.12402).</p> </li> <li> <code>DirectWeightDecay</code>           \u2013            <p>Directly applies weight decay to parameters.</p> </li> <li> <code>RandomReinitialize</code>           \u2013            <p>On each step with probability <code>p_reinit</code> trigger reinitialization,</p> </li> <li> <code>RelativeWeightDecay</code>           \u2013            <p>Weight decay relative to the mean absolute value of update, gradient or parameters depending on value of <code>norm_input</code> argument.</p> </li> <li> <code>WeightDecay</code>           \u2013            <p>Weight decay.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>decay_weights_</code>             \u2013              <p>directly decays weights in-place</p> </li> </ul>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.CautiousWeightDecay","title":"CautiousWeightDecay","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Cautious weight decay (https://arxiv.org/pdf/2510.12402).</p> <p>Weight decay but only applied to updates where update sign matches weight decay sign.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>)           \u2013            <p>weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.CautiousWeightDecay--examples","title":"Examples:","text":"<p>Adam with non-decoupled cautious weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.CautiousWeightDecay(1e-3),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with decoupled cautious weight decay that still scales with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.CautiousWeightDecay(1e-3),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with fully decoupled cautious weight decay that doesn't scale with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.LR(1e-3),\n    tz.m.CautiousWeightDecay(1e-6)\n)\n</code></pre></p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class CautiousWeightDecay(TensorTransform):\n    \"\"\"Cautious weight decay (https://arxiv.org/pdf/2510.12402).\n\n    Weight decay but only applied to updates where update sign matches weight decay sign.\n\n    Args:\n        weight_decay (float): weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n        target (Target, optional): what to set on var. Defaults to 'update'.\n\n    ### Examples:\n\n    Adam with non-decoupled cautious weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.CautiousWeightDecay(1e-3),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with decoupled cautious weight decay that still scales with learning rate\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.CautiousWeightDecay(1e-3),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with fully decoupled cautious weight decay that doesn't scale with learning rate\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.LR(1e-3),\n        tz.m.CautiousWeightDecay(1e-6)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, weight_decay: float, ord: int = 2):\n\n        defaults = dict(weight_decay=weight_decay, ord=ord)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        weight_decay = NumberList(s['weight_decay'] for s in settings)\n        ord = settings[0]['ord']\n\n        return cautious_weight_decay_(as_tensorlist(tensors), as_tensorlist(params), weight_decay, ord)\n</code></pre>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.DirectWeightDecay","title":"DirectWeightDecay","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Directly applies weight decay to parameters.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>)           \u2013            <p>weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> </ul> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class DirectWeightDecay(Module):\n    \"\"\"Directly applies weight decay to parameters.\n\n    Args:\n        weight_decay (float): weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n    \"\"\"\n    def __init__(self, weight_decay: float, ord: int = 2,):\n        defaults = dict(weight_decay=weight_decay, ord=ord)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def apply(self, objective):\n        weight_decay = self.get_settings(objective.params, 'weight_decay', cls=NumberList)\n        ord = self.defaults['ord']\n\n        decay_weights_(objective.params, weight_decay, ord)\n        return objective\n</code></pre>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.RandomReinitialize","title":"RandomReinitialize","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>On each step with probability <code>p_reinit</code> trigger reinitialization, whereby <code>p_weights</code> weights are reset to their initial values.</p> <p>This modifies the parameters directly. Place it as the first module.</p> <p>Parameters:</p> <ul> <li> <code>p_reinit</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>probability to trigger reinitialization on each step. Defaults to 0.01.</p> </li> <li> <code>p_weights</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>probability for each weight to be set to initial value when reinitialization is triggered. Defaults to 0.1.</p> </li> <li> <code>store_every</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>if set, stores new initial values every this many steps. Defaults to None.</p> </li> <li> <code>beta</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>whenever <code>store_every</code> is triggered, uses linear interpolation with this beta. If <code>store_every=1</code>, this can be set to some value close to 1 such as 0.999 to reinitialize to slow parameter EMA. Defaults to 0.</p> </li> <li> <code>reset</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to reset states of other modules on reinitialization. Defaults to False.</p> </li> <li> <code>seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>random seed.</p> </li> </ul> Source code in <code>torchzero/modules/weight_decay/reinit.py</code> <pre><code>class RandomReinitialize(Module):\n    \"\"\"On each step with probability ``p_reinit`` trigger reinitialization,\n    whereby ``p_weights`` weights are reset to their initial values.\n\n    This modifies the parameters directly. Place it as the first module.\n\n    Args:\n        p_reinit (float, optional): probability to trigger reinitialization on each step. Defaults to 0.01.\n        p_weights (float, optional): probability for each weight to be set to initial value when reinitialization is triggered. Defaults to 0.1.\n        store_every (int | None, optional): if set, stores new initial values every this many steps. Defaults to None.\n        beta (float, optional):\n            whenever ``store_every`` is triggered, uses linear interpolation with this beta.\n            If ``store_every=1``, this can be set to some value close to 1 such as 0.999\n            to reinitialize to slow parameter EMA. Defaults to 0.\n        reset (bool, optional): whether to reset states of other modules on reinitialization. Defaults to False.\n        seed (int | None, optional): random seed.\n    \"\"\"\n\n    def __init__(\n        self,\n        p_reinit: float = 0.01,\n        p_weights: float = 0.1,\n        store_every: int | None = None,\n        beta: float = 0,\n        reset: bool = False,\n        seed: int | None = None,\n    ):\n        defaults = dict(p_weights=p_weights, p_reinit=p_reinit, store_every=store_every, beta=beta, reset=reset, seed=seed)\n        super().__init__(defaults)\n\n    def update(self, objective):\n        # this stores initial values to per-parameter states\n        p_init = self.get_state(objective.params, \"p_init\", init=\"params\", cls=TensorList)\n\n        # store new params every store_every steps\n        step = self.global_state.get(\"step\", 0)\n        self.global_state[\"step\"] = step + 1\n\n        store_every = self.defaults[\"store_every\"]\n        if (store_every is not None and step % store_every == 0):\n            beta = self.get_settings(objective.params, \"beta\", cls=NumberList)\n            p_init.lerp_(objective.params, weight=(1 - beta))\n\n    @torch.no_grad\n    def apply(self, objective):\n        p_reinit = self.defaults[\"p_reinit\"]\n        device = objective.params[0].device\n        generator = self.get_generator(device, self.defaults[\"seed\"])\n\n        # determine whether to trigger reinitialization\n        reinitialize = torch.rand(1, generator=generator, device=device) &lt; p_reinit\n\n        # reinitialize\n        if reinitialize:\n            params = TensorList(objective.params)\n            p_init = self.get_state(params, \"p_init\", init=params)\n\n\n            # mask with p_weights entries being True\n            p_weights = self.get_settings(params, \"p_weights\")\n            mask = params.bernoulli_like(p_weights, generator=generator).as_bool()\n\n            # set weights at mask to their initialization\n            params.masked_set_(mask, p_init)\n\n            # reset\n            if self.defaults[\"reset\"]:\n                objective.post_step_hooks.append(partial(_reset_except_self, self=self))\n\n        return objective\n</code></pre>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.RelativeWeightDecay","title":"RelativeWeightDecay","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Weight decay relative to the mean absolute value of update, gradient or parameters depending on value of <code>norm_input</code> argument.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>relative weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> <li> <code>norm_input</code>               (<code>str</code>, default:                   <code>'update'</code> )           \u2013            <p>determines what should weight decay be relative to. \"update\", \"grad\" or \"params\". Defaults to \"update\".</p> </li> <li> <code>metric</code>               (<code>Ords</code>, default:                   <code>'mad'</code> )           \u2013            <p>metric (norm, etc) that weight decay should be relative to. defaults to 'mad' (mean absolute deviation).</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.RelativeWeightDecay--examples","title":"Examples:","text":"<p>Adam with non-decoupled relative weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.RelativeWeightDecay(1e-1),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with decoupled relative weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.RelativeWeightDecay(1e-1),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class RelativeWeightDecay(TensorTransform):\n    \"\"\"Weight decay relative to the mean absolute value of update, gradient or parameters depending on value of ``norm_input`` argument.\n\n    Args:\n        weight_decay (float): relative weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n        norm_input (str, optional):\n            determines what should weight decay be relative to. \"update\", \"grad\" or \"params\".\n            Defaults to \"update\".\n        metric (Ords, optional):\n            metric (norm, etc) that weight decay should be relative to.\n            defaults to 'mad' (mean absolute deviation).\n        target (Target, optional): what to set on var. Defaults to 'update'.\n\n    ### Examples:\n\n    Adam with non-decoupled relative weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.RelativeWeightDecay(1e-1),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with decoupled relative weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.RelativeWeightDecay(1e-1),\n        tz.m.LR(1e-3)\n    )\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        weight_decay: float = 0.1,\n        ord: int  = 2,\n        norm_input: Literal[\"update\", \"grad\", \"params\"] = \"update\",\n        metric: Metrics = 'mad',\n        cautious: bool = False,\n    ):\n        defaults = dict(weight_decay=weight_decay, ord=ord, norm_input=norm_input, metric=metric, cautious=cautious)\n        super().__init__(defaults, uses_grad=norm_input == 'grad')\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        weight_decay = NumberList(s['weight_decay'] for s in settings)\n\n        fs = settings[0]\n        norm_input = fs['norm_input']\n\n        if norm_input == 'update': src = TensorList(tensors)\n        elif norm_input == 'grad':\n            assert grads is not None\n            src = TensorList(grads)\n        elif norm_input == 'params':\n            src = TensorList(params)\n        else:\n            raise ValueError(norm_input)\n\n        norm = src.global_metric(fs['metric'])\n\n        if fs[\"cautious\"]:\n            wd_ = cautious_weight_decay_\n        else:\n            wd_ = weight_decay_\n        return wd_(as_tensorlist(tensors), as_tensorlist(params), weight_decay * norm, fs[\"ord\"])\n</code></pre>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.WeightDecay","title":"WeightDecay","text":"<p>               Bases: <code>torchzero.core.transform.TensorTransform</code></p> <p>Weight decay.</p> <p>Parameters:</p> <ul> <li> <code>weight_decay</code>               (<code>float</code>)           \u2013            <p>weight decay scale.</p> </li> <li> <code>ord</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.</p> </li> <li> <code>target</code>               (<code>Target</code>)           \u2013            <p>what to set on var. Defaults to 'update'.</p> </li> </ul>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.WeightDecay--examples","title":"Examples:","text":"<p>Adam with non-decoupled weight decay <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.WeightDecay(1e-3),\n    tz.m.Adam(),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with decoupled weight decay that still scales with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.WeightDecay(1e-3),\n    tz.m.LR(1e-3)\n)\n</code></pre></p> <p>Adam with fully decoupled weight decay that doesn't scale with learning rate <pre><code>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Adam(),\n    tz.m.LR(1e-3),\n    tz.m.WeightDecay(1e-6)\n)\n</code></pre></p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>class WeightDecay(TensorTransform):\n    \"\"\"Weight decay.\n\n    Args:\n        weight_decay (float): weight decay scale.\n        ord (int, optional): order of the penalty, e.g. 1 for L1 and 2 for L2. Defaults to 2.\n        target (Target, optional): what to set on var. Defaults to 'update'.\n\n    ### Examples:\n\n    Adam with non-decoupled weight decay\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.WeightDecay(1e-3),\n        tz.m.Adam(),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with decoupled weight decay that still scales with learning rate\n    ```python\n\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.WeightDecay(1e-3),\n        tz.m.LR(1e-3)\n    )\n    ```\n\n    Adam with fully decoupled weight decay that doesn't scale with learning rate\n    ```python\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Adam(),\n        tz.m.LR(1e-3),\n        tz.m.WeightDecay(1e-6)\n    )\n    ```\n\n    \"\"\"\n    def __init__(self, weight_decay: float, ord: int = 2):\n\n        defaults = dict(weight_decay=weight_decay, ord=ord)\n        super().__init__(defaults)\n\n    @torch.no_grad\n    def multi_tensor_apply(self, tensors, params, grads, loss, states, settings):\n        weight_decay = NumberList(s['weight_decay'] for s in settings)\n        ord = settings[0]['ord']\n\n        return weight_decay_(as_tensorlist(tensors), as_tensorlist(params), weight_decay, ord)\n</code></pre>"},{"location":"API/modules/weight_decay/#torchzero.modules.weight_decay.decay_weights_","title":"decay_weights_","text":"<pre><code>decay_weights_(params: Iterable[Tensor], weight_decay: float | NumberList, ord: int = 2)\n</code></pre> <p>directly decays weights in-place</p> Source code in <code>torchzero/modules/weight_decay/weight_decay.py</code> <pre><code>@torch.no_grad\ndef decay_weights_(params: Iterable[torch.Tensor], weight_decay: float | NumberList, ord:int=2):\n    \"\"\"directly decays weights in-place\"\"\"\n    params = TensorList(params)\n    weight_decay_(params, params, -weight_decay, ord)\n</code></pre>"},{"location":"API/modules/wrappers/","title":"Wrappers","text":"<p>This subpackage contains wrappers for other libraries.</p> <p>Classes:</p> <ul> <li> <code>Wrap</code>           \u2013            <p>Wraps a pytorch optimizer to use it as a module.</p> </li> </ul>"},{"location":"API/modules/wrappers/#torchzero.modules.wrappers.Wrap","title":"Wrap","text":"<p>               Bases: <code>torchzero.core.module.Module</code></p> <p>Wraps a pytorch optimizer to use it as a module.</p> Note <p>Custom param groups are supported only by <code>set_param_groups</code>, settings passed to Optimizer will be applied to all parameters.</p> <p>Parameters:</p> <ul> <li> <code>opt_fn</code>               (<code>Callable[..., Optimizer] | Optimizer</code>)           \u2013            <p>function that takes in parameters and returns the optimizer, for example <code>torch.optim.Adam</code> or <code>lambda parameters: torch.optim.Adam(parameters, lr=1e-3)</code></p> </li> <li> <code>*args</code>           \u2013            </li> <li> <code>**kwargs</code>           \u2013            <p>Extra args to be passed to opt_fn. The function is called as <code>opt_fn(parameters, *args, **kwargs)</code>.</p> </li> <li> <code>use_param_groups</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to pass settings passed to Optimizer to the wrapped optimizer.</p> <p>Note that settings to the first parameter are used for all parameters, so if you specified per-parameter settings, they will be ignored.</p> </li> </ul>"},{"location":"API/modules/wrappers/#torchzero.modules.wrappers.Wrap--example","title":"Example:","text":"<p>wrapping pytorch_optimizer.StableAdamW</p> <pre><code>from pytorch_optimizer import StableAdamW\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.Wrap(StableAdamW, lr=1),\n    tz.m.Cautious(),\n    tz.m.LR(1e-2)\n)\n</code></pre> Source code in <code>torchzero/modules/wrappers/optim_wrapper.py</code> <pre><code>class Wrap(Module):\n    \"\"\"\n    Wraps a pytorch optimizer to use it as a module.\n\n    Note:\n        Custom param groups are supported only by ``set_param_groups``, settings passed to Optimizer will be applied to all parameters.\n\n    Args:\n        opt_fn (Callable[..., torch.optim.Optimizer] | torch.optim.Optimizer):\n            function that takes in parameters and returns the optimizer, for example ``torch.optim.Adam``\n            or ``lambda parameters: torch.optim.Adam(parameters, lr=1e-3)``\n        *args:\n        **kwargs:\n            Extra args to be passed to opt_fn. The function is called as ``opt_fn(parameters, *args, **kwargs)``.\n        use_param_groups:\n            Whether to pass settings passed to Optimizer to the wrapped optimizer.\n\n            Note that settings to the first parameter are used for all parameters,\n            so if you specified per-parameter settings, they will be ignored.\n\n    ### Example:\n    wrapping pytorch_optimizer.StableAdamW\n\n    ```python\n\n    from pytorch_optimizer import StableAdamW\n    opt = tz.Optimizer(\n        model.parameters(),\n        tz.m.Wrap(StableAdamW, lr=1),\n        tz.m.Cautious(),\n        tz.m.LR(1e-2)\n    )\n    ```\n\n    \"\"\"\n\n    def __init__(\n        self,\n        opt_fn: Callable[..., torch.optim.Optimizer] | torch.optim.Optimizer,\n        *args,\n        use_param_groups: bool = True,\n        **kwargs,\n    ):\n        defaults = dict(use_param_groups=use_param_groups)\n        super().__init__(defaults=defaults)\n\n        self._opt_fn = opt_fn\n        self._opt_args = args\n        self._opt_kwargs = kwargs\n        self._custom_param_groups = None\n\n        self.optimizer: torch.optim.Optimizer | None = None\n        if isinstance(self._opt_fn, torch.optim.Optimizer) or not callable(self._opt_fn):\n            self.optimizer = self._opt_fn\n\n    def set_param_groups(self, param_groups):\n        self._custom_param_groups = _make_param_groups(param_groups, differentiable=False)\n        return super().set_param_groups(param_groups)\n\n    @torch.no_grad\n    def apply(self, objective):\n        params = objective.params\n\n        # initialize opt on 1st step\n        if self.optimizer is None:\n            assert callable(self._opt_fn)\n            param_groups = params if self._custom_param_groups is None else self._custom_param_groups\n            self.optimizer = self._opt_fn(param_groups, *self._opt_args, **self._opt_kwargs)\n\n        # set optimizer per-parameter settings\n        if self.defaults[\"use_param_groups\"] and objective.modular is not None:\n            for group in self.optimizer.param_groups:\n                first_param = group['params'][0]\n                setting = self.settings[first_param]\n\n                # settings passed in `set_param_groups` are the highest priority\n                # schedulers will override defaults but not settings passed in `set_param_groups`\n                # this is consistent with how Optimizer does it.\n                if self._custom_param_groups is not None:\n                    setting = {k:v for k,v in setting if k not in self._custom_param_groups[0]}\n\n                group.update(setting)\n\n        # set grad to update\n        orig_grad = [p.grad for p in params]\n        for p, u in zip(params, objective.get_updates()):\n            p.grad = u\n\n        # if this is last module, simply use optimizer to update parameters\n        if objective.modular is not None and self is objective.modular.modules[-1]:\n            self.optimizer.step()\n\n            # restore grad\n            for p, g in zip(params, orig_grad):\n                p.grad = g\n\n            objective.stop = True; objective.skip_update = True\n            return objective\n\n        # this is not the last module, meaning update is difference in parameters\n        # and passed to next module\n        params_before_step = [p.clone() for p in params]\n        self.optimizer.step() # step and update params\n        for p, g in zip(params, orig_grad):\n            p.grad = g\n        objective.updates = list(torch._foreach_sub(params_before_step, params)) # set update to difference between params\n        for p, o in zip(params, params_before_step):\n            p.set_(o) # pyright: ignore[reportArgumentType]\n\n        return objective\n\n    def reset(self):\n        super().reset()\n        assert self.optimizer is not None\n        for g in self.optimizer.param_groups:\n            for p in g['params']:\n                state = self.optimizer.state[p]\n                state.clear()\n</code></pre>"},{"location":"overview/0.%20Introduction/","title":"0. Introduction","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[3]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = torch.optim.SGD(func.parameters(), 1e-4, momentum=0.99)\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = torch.optim.SGD(func.parameters(), 1e-4, momentum=0.99) func.run(optimizer, max_steps=1000) func.plot(log_contour=True) <pre>finished in 0.6s., reached loss = 8.73e-05                                      \n</pre> Out[3]: <pre>&lt;Axes: &gt;</pre> <p>This is equivalent to the following code:</p> In\u00a0[4]: Copied! <pre>def rosen(x, y):\n    return (1 - x) ** 2 + 100 * (y - x ** 2) ** 2\n\nX = torch.tensor([-1.1, 2.5], requires_grad=True)\n\ndef closure(backward=True):\n    loss = rosen(*X)\n    if backward:\n        X.grad = None # same as opt.zero_grad()\n        loss.backward()\n    return loss\n\noptimizer = torch.optim.SGD([X], 1e-4, momentum=0.99)\n\nlosses = []\nfor step in range(1, 1001):\n    loss = optimizer.step(closure)\n    losses.append(loss)\n\nprint(min(losses))\n\n# ... and a bunch of plotting code\n</pre>  def rosen(x, y):     return (1 - x) ** 2 + 100 * (y - x ** 2) ** 2  X = torch.tensor([-1.1, 2.5], requires_grad=True)  def closure(backward=True):     loss = rosen(*X)     if backward:         X.grad = None # same as opt.zero_grad()         loss.backward()     return loss  optimizer = torch.optim.SGD([X], 1e-4, momentum=0.99)  losses = [] for step in range(1, 1001):     loss = optimizer.step(closure)     losses.append(loss)  print(min(losses))  # ... and a bunch of plotting code <pre>tensor(8.7284e-05, grad_fn=&lt;AddBackward0&gt;)\n</pre>"},{"location":"overview/0.%20Introduction/#0-introduction","title":"0. Introduction\u00b6","text":"<p>Notebooks in this section provide an overview of various classes of optimization algorithms available in torchzero with explanations, visualizations and benchmarks, I also hope that the overview will be useful even if you aren't using torchzero. They don't have to be viewed in order.</p> <p>For many algorithms I've included a visualization on a 2D function. Performance on 2D functions doesn't really represent performance on real problems and only serves as a way to visualize how an algorithm works. I am also in the process of adding benchmarks on a set of large scale problems to most sections.</p>"},{"location":"overview/0.%20Introduction/#classes-of-algorithms","title":"Classes of algorithms\u00b6","text":"<ol> <li>First order methods - gradient descent with various step size choices, such as Polyak's, Barzilai\u2013Borwein step size, line searches.</li> <li>Momentum - Momentum methods - Polyak's momentum, Nesterov's momentum, exponential moving averages, cautious momentum, matrix momentum.</li> <li>Adaptive methods - adaptive methods most widely used for training neural networks such as Adam.</li> <li>Second order methods - methods that use exact second order derivatives such as Newton's method, NewtonCG, subspace Newton methods.</li> <li>Quasi-Newton methods - methods that estimate second order derivatives using gradients or function values - BFGS, LBFGS, 2SPSA/2SG, etc.</li> <li>Conjugate gradient - methods that are based on conjugate directions.</li> <li>Least squares - methods for optimizing sum of squares.</li> <li>Line search - line search methods - backtracking, strong wolfe, etc.</li> <li>Trust region - trust region and other step regularization methods - Powell's dog leg method, Levenberg\u2013Marquardt, Cubic regularization, etc.</li> <li>Variance reduction - variance reduction methods for stochastic optimization - SVRG, MARS.</li> <li>Regularization - regularization methods such as weight decay, gradient clipping, sharpness-aware minimization.</li> <li>Zeroth order methods - methods that use only function values and do not require gradients.</li> </ol>"},{"location":"overview/0.%20Introduction/#math","title":"Math\u00b6","text":"<p>Most notebooks have a few formula written using $\\mathbf{LaTeX}$. If the formulas look weird, give them some time, sometimes it takes a few seconds to load.</p>"},{"location":"overview/0.%20Introduction/#visualizations","title":"Visualizations\u00b6","text":"<p>Most visualizations are produced using the visualbench library (I will publish it soon too). It is basically a library to visualize and benchmark pytorch optimizers, so you might see something like this:</p>"},{"location":"overview/1.%20First%20order%20methods/","title":"1. First order methods","text":"In\u00a0[1]: Copied! <pre>import torch\ntorch.manual_seed(0)\n\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import torch torch.manual_seed(0)  import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[9]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.LR(1e-3))\nfunc.run(optimizer, max_steps=5000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.LR(1e-3)) func.run(optimizer, max_steps=5000) func.plot(log_contour=True) <pre>finished in 4.9s., reached loss = 0.00726                                      \n</pre> Out[9]: <pre>&lt;Axes: &gt;</pre> In\u00a0[2]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe(a_init='first-order', c2=0.1))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe(a_init='first-order', c2=0.1)) func.run(optimizer, max_steps=2000) func.plot() <pre>finished in 3.9s., reached loss = 0.000378                                      \n</pre> Out[2]: <pre>&lt;Axes: &gt;</pre> In\u00a0[3]: Copied! <pre>func = FunctionDescent('booth')\noptimizer = tz.Optimizer(func.parameters(), tz.m.PolyakStepSize())\nfunc.run(optimizer, max_steps=50)\nfunc.plot()\n</pre> func = FunctionDescent('booth') optimizer = tz.Optimizer(func.parameters(), tz.m.PolyakStepSize()) func.run(optimizer, max_steps=50) func.plot() <pre>finished in 0.1s., reached loss = 3.87e-12                                      \n</pre> Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.BarzilaiBorwein())\nfunc.run(optimizer, max_steps=300)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.BarzilaiBorwein()) func.run(optimizer, max_steps=300) func.plot() <pre>finished in 0.3s., reached loss = 7.16e-09                                      \n</pre> Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.BBStab())\nfunc.run(optimizer, max_steps=500)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.BBStab()) func.run(optimizer, max_steps=500) func.plot() <pre>finished in 0.6s., reached loss = 1.37e-07                                      \n</pre> Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[6]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.AdGD(variant=2))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.AdGD(variant=2)) func.run(optimizer, max_steps=2000) func.plot() <pre>finished in 2.4s., reached loss = 0.000282                                      \n</pre> Out[6]: <pre>&lt;Axes: &gt;</pre> In\u00a0[7]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(), \n    tz.m.TrustCG(\n        hess_module=tz.m.Identity(),\n        rho_good=0,\n        rho_bad=0\n    )\n)\nfunc.run(optimizer, max_steps=2000)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),      tz.m.TrustCG(         hess_module=tz.m.Identity(),         rho_good=0,         rho_bad=0     ) ) func.run(optimizer, max_steps=2000) func.plot() <pre>finished in 4.0s., reached loss = 0.00381                                      \n</pre> Out[7]: <pre>&lt;Axes: &gt;</pre> In\u00a0[10]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.LevenbergMarquardt(\n        hess_module=tz.m.BarzilaiBorwein(),\n        rho_good=0,\n        rho_bad=0,\n    )\n)\nfunc.run(optimizer, max_steps=500)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.LevenbergMarquardt(         hess_module=tz.m.BarzilaiBorwein(),         rho_good=0,         rho_bad=0,     ) ) func.run(optimizer, max_steps=500) func.plot() <pre>finished in 1.0s., reached loss = 2.13e-05                                      \n</pre> Out[10]: <pre>&lt;Axes: &gt;</pre> In\u00a0[13]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Normalize(), tz.m.LR(2e-1))\nfunc.run(optimizer, max_steps=1000)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Normalize(), tz.m.LR(2e-1)) func.run(optimizer, max_steps=1000) func.plot() <pre>finished in 1.0s., reached loss = 1.258                                      \n</pre> Out[13]: <pre>&lt;Axes: &gt;</pre> In\u00a0[14]: Copied! <pre>func = FunctionDescent('booth')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Sign(), tz.m.LR(4e-1))\nfunc.run(optimizer, max_steps=100)\nfunc.plot()\n</pre> func = FunctionDescent('booth') optimizer = tz.Optimizer(func.parameters(), tz.m.Sign(), tz.m.LR(4e-1)) func.run(optimizer, max_steps=100) func.plot() <pre>finished in 0.1s., reached loss = 0.08                                      \n</pre> Out[14]: <pre>&lt;Axes: &gt;</pre>"},{"location":"overview/1.%20First%20order%20methods/#1-first-order-methods","title":"1. First order methods\u00b6","text":"<p>First order methods make use of the gradient of the objective function $\\nabla f(x_t)$. The simplest 1-st order method is gradient descent, where on step $t$ gradient $\\nabla f(x_t)$ is multiplied by step size $\\eta$ and subtracted from parameters $x_t$:</p> <p>$$ x_{t+1} \\leftarrow x_t - \\eta \\nabla f(x_t) $$</p> <p>The step size $\\eta$ can be fixed, set to a pre-determined step size schedule, determined via a line search, or via a more sophisticated strategy.</p> <p>Other first order methods modify the direction $-\\nabla f(x_t)$ by incorporating momentum (see 2. Momentum), adaptive per-weight step sizes (see 3. Adaptive methods), etc.</p> <p>In this notebook I focus on methods that use the pure gradient direction $\\nabla f(x_t)$ and differ in the way step size $\\eta$ is determined.</p>"},{"location":"overview/1.%20First%20order%20methods/#11-gd-with-constant-step-size","title":"1.1 GD with constant step size\u00b6","text":"<p>To run GD with fixed step size, all we need to do is add the <code>LR</code> (learning rate) module and specify our step size.</p> <p>For visualization I use Rosenbrock's function: $$ f(x,y) = (1 - x)^2 + 100 * (y - x^2)^2 $$</p>"},{"location":"overview/1.%20First%20order%20methods/#12-gd-with-line-search","title":"1.2 GD with line search\u00b6","text":"<p>A line search tests multiple step sizes until some some criteria are satisfied. For more details on line searches see 8. Line search. We will use the <code>StrongWolfe</code> line search.</p>"},{"location":"overview/1.%20First%20order%20methods/#13-gd-with-polyaks-step-size","title":"1.3 GD with Polyak's step size\u00b6","text":"<p>Polyak's step size determines the step size assuming the function is convex and the objective value at the minimizer $f^*$ is known.</p> <p>$$ \\eta_{\\text{polyak}} = \\frac{f(x_t) - f^*} {\\nabla f(x_t)^T \\nabla f(x_t)} $$</p> <p>Since Rosenbrock isn't convex, for visualization I use Booth's function: $$ f(x, y) = (x + 2y - 7)^2 + (2x + y - 5)^2 $$</p>"},{"location":"overview/1.%20First%20order%20methods/#14-gd-with-barzilaiborwein-step-size","title":"1.4 GD with Barzilai\u2013Borwein step size\u00b6","text":"<p>Barzilai\u2013Borwein (BB) method is a way to determine the step size using a scalar approximation to the quasi-newton methods.</p> <p>There are two variants of the BB - the \"long\" step size and the \"short\" step size. $$ \\eta_{\\text{long}} = \\frac{\\Delta x^T \\cdot \\Delta x} {\\Delta x^T \\cdot \\Delta g} $$ $$ \\eta_{\\text{short}} = \\frac{\\Delta x^T \\cdot \\Delta g} {\\Delta g^T \\cdot \\Delta g} $$</p> <p>Here $\\Delta x=x_t-x_{t-1}$ is difference in parameters between previous and current step, and $\\Delta g=\\nabla f(x_t)-\\nabla f(x_{t-1})$ is difference in gradients.</p> <p>Because BB uses difference in gradients, it is not suitable for stochastic optimization without some kind of variance reduction.</p> <p>Reference: Barzilai, Jonathan, and Jonathan M. Borwein. \"Two-point step size gradient methods.\" IMA journal of numerical analysis 8.1 (1988): 141-148.</p>"},{"location":"overview/1.%20First%20order%20methods/#15-bbstab","title":"1.5 BBstab\u00b6","text":"<p>Stabilized Barzilai-Borwein method uses the Barzilai\u2013Borwein step-size, except the norm of the update is clipped by hyperparameter $\\Delta$. The hyperparameter can be selected adaptively, where first few steps are performed without norm clipping, and $\\Delta$ is set to the norm of the smallest update times $c$ and remains fixed for the remainding steps, where $c$ is a hyperparameter can can be set to 0.2 to 0.3.</p> <p>Reference: Burdakov, Oleg, Yuhong Dai, and Na Huang. \"Stabilized barzilai-borwein method.\" Journal of Computational Mathematics (2019): 916-936.</p>"},{"location":"overview/1.%20First%20order%20methods/#16-adgd-and-adgd-2","title":"1.6 AdGD and AdGD-2\u00b6","text":"<p>Adaptive gradient descent (AdGD) and Adaptive gradient descent-2 (AdGD-2) are completely tuning-free step size methods. Here is the update rule from the paper:</p> <p></p> <p>AdGDs also use difference in gradients, so they aren't suitable for stochastic optimization.</p> <p>Reference: Malitsky, Yura, and Konstantin Mishchenko. \"Adaptive proximal gradient method for convex optimization.\" Advances in Neural Information Processing Systems 37 (2024): 100670-100697.</p>"},{"location":"overview/1.%20First%20order%20methods/#17-gd-with-trust-region","title":"1.7 GD with trust region\u00b6","text":"<p>Another way to determine the step size is by using a trust region. For more details on trust region see 9. Trust Region.</p> <p>Trust regions typically require hessian or approximation, but it is possible to assume hessian to be identity matrix by passing <code>hess_module=Identity()</code>.</p> <p>The <code>TrustCG</code> module, despite having \"CG\" in its name, will use exact solution if it can be calculated efficiently, which it can be in our case.</p> <p><code>rho_good = rho_bad = 0</code> means any step that decreased the function value increases the trust radius, otherwise trust radius is decreased.</p>"},{"location":"overview/1.%20First%20order%20methods/#18-bb-with-trust-region","title":"1.8 BB with trust region\u00b6","text":"<p>BB can also be used with trust region, usually outperforming identity approximation.</p>"},{"location":"overview/1.%20First%20order%20methods/#19-normalized-gd","title":"1.9 Normalized GD\u00b6","text":"<p>Normalized GD is a simple modification to GD where the gradient is normalized to have unit norm.</p> <p>$$ x_{t+1} \\leftarrow x_t - \\eta \\frac{\\nabla f(x_t)}{||\\nabla f(x_t) ||_2} $$</p> <p>Other norms or measures can also be used instead of L2 norm $||\\nabla f(x_t) ||_2$, for example the mean absolute deviation $\\frac{1}{n}\\sum\\limits_{i=1}^{n}|\\nabla f(x_t)|_i$</p>"},{"location":"overview/1.%20First%20order%20methods/#110-signgd","title":"1.10 SignGD\u00b6","text":"<p>SignGD updates parameters with sign of the gradient. It was originally suggested for distributed optimization since it compresses gradient information to just the sign, however it can also outperform GD in some cases due to inherent normalization.</p> <p>$$ x_{t+1} \\leftarrow x_t - \\eta \\text{ sign}(\\nabla f(x_t)) $$</p>"},{"location":"overview/10.%20Variance%20reduction/","title":"10. Variance reduction","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(func.parameters(), tz.m.LBFGS(), tz.m.LR(1e-1),)\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"LBFGS\")\n\nfunc = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(func.parameters(),tz.m.Online(tz.m.LBFGS()), tz.m.LR(1e-1),)\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Online-LBFGS\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6)) ax = np.ravel(ax)  func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(func.parameters(), tz.m.LBFGS(), tz.m.LR(1e-1),) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"LBFGS\")  func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(func.parameters(),tz.m.Online(tz.m.LBFGS()), tz.m.LR(1e-1),) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Online-LBFGS\")  plt.show() <pre>finished in 0.3s., reached loss = 128.554                                      \nfinished in 0.4s., reached loss = 0.000679                                      \n</pre> In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(func.parameters(), tz.m.LBFGS(), tz.m.LR(1e-1),)\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"LBFGS\")\n\nfunc = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(func.parameters(),tz.m.SVRG(100), tz.m.LBFGS(), tz.m.LR(1e-1),)\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True, ax=ax[1], line_alpha=0.5)\nax[1].set_title(\"SVRG-LBFGS\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6)) ax = np.ravel(ax)  func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(func.parameters(), tz.m.LBFGS(), tz.m.LR(1e-1),) func.run(optimizer, max_steps=200) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"LBFGS\")  func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(func.parameters(),tz.m.SVRG(100), tz.m.LBFGS(), tz.m.LR(1e-1),) func.run(optimizer, max_steps=200) func.plot(log_contour=True, ax=ax[1], line_alpha=0.5) ax[1].set_title(\"SVRG-LBFGS\")  plt.show() <pre>finished in 0.8s., reached loss = 127.376                                      \nfinished in 0.6s., reached loss = 0.0716                                      \n</pre>"},{"location":"overview/10.%20Variance%20reduction/#10-variance-reduction","title":"10. Variance reduction\u00b6","text":""},{"location":"overview/10.%20Variance%20reduction/#101-online-methods","title":"10.1 Online methods\u00b6","text":"<p>Many methods use differences between consecutive gradients which makes them not suitable for mini-batch optimization, for example all quasi-newton methods, conjugate gradient methods. If consecutive gradients are sampled from different mini-batches, the difference between them will include difference between mini-batches most often causing such methods to fail.</p> <p>Denote $\\nabla f(x_t, \\xi_t)$ as gradient at parameters $x_t$ with mini-batch $\\xi_t$. When a method uses difference between consecutive gradients $\\Delta g_t = \\nabla f(x_{t}) - \\nabla f(x_{t-1})$, it expects those two gradients to be sampled from the same deterministic objective function. But with mini-batching it receives: $$\\Delta g_t = \\nabla f(x_{t}, \\xi_t) - \\nabla f(x_{t-1}, \\xi_{t-1}),$$ where two gradients are sampled from different mini-batches $\\xi_t$ and $\\xi_{t-1}$ - those are different sub-samples of the objective function. A natural solution is, after receiving new mini-batch $\\xi_{t}$, to use an extra backward pass to evaluate gradient at current mini-batch and previous parameters $\\nabla f(x_{t-1}, \\xi_{t})$ and use it instead of gradient at previous mini-batch and previous parameters $\\nabla f(x_{t-1}, \\xi_{t-1})$: $$\\Delta g_t = \\nabla f(x_{t}, \\xi_t) - \\nabla f(x_{t-1}, \\xi_{t}),$$</p> <p>This way both gradients used to calculated gradient difference are sampled from the same mini-batch $\\xi_t$. Algorithms modified to handle mini-batching like that are often called online (e.g. Online-LBFGS). In torchzero a method needs to be wrapped into <code>tz.m.Online</code> module to become online. A module needs to define <code>reset_for_online</code> method to be compatible with <code>tz.m.Online</code>, which most relevant modules define.</p> <p>For visualization we use booth function where function value and gradient are evaluated at current point plus a random perturbation to emulate mini-batching.</p>"},{"location":"overview/10.%20Variance%20reduction/#102-svrg","title":"10.2 SVRG\u00b6","text":"<p>Stochastic variance reduced gradient method (SVRG) is a variance-reduction method for convex optimization that uses a \"snapshot\" of full-batch gradient. Here is the algorithm:</p> <ol> <li><p>Compute full-batch gradient, for example via gradient accumulation. If new samples are generated on the fly (so there is no \"entire dataset\"), it may be sufficient to just calculate gradient for a large number of samples. Denote the full gradient as $\\nabla f_{\\text{full}}(\\tilde{x})$, it is called snapshot. Note that it was evaluated at parameters $\\tilde{x}$, at the beginning $\\tilde{x}=x_0$.</p> </li> <li><p>Now that we have full gradient at $\\tilde{x}$, we can start performing optimization. The variance-reduced gradient at parameters $x_t$ and mini-batch $\\xi_t$ is computed as:</p> <p>$$  \\nabla f_{\\text{SVRG}}(x_{t}, \\xi_{t}) = \\nabla f(x_{t}, \\xi_{t}) + \\alpha (\\nabla f_{\\text{full}}(\\tilde{x}) - \\nabla f(\\tilde{x}, \\xi_{t}))  $$</p> <p>Here $\\alpha \\in (0, 1]$ is a hyperparameter that determines the amount of variance reduction and is usually set to 1.</p> <p>Use any gradient-based method to optimize for some number of steps using variance-reduced gradients computed by this formula. Typically one epoch of variance-reduced optimization is performed so that all mini-batches are used.</p> </li> <li><p>After optimizing for specified number of steps, set $\\tilde{x} \\leftarrow x_t$ and start from step 1.</p> </li> </ol> <p>The formula computes difference between full and mini-batch gradient at $\\tilde{x}$, which estimates difference between full and mini-batch gradient at $x_t$: $$ \\nabla f_{\\text{full}}(\\tilde{x}) - \\nabla f(\\tilde{x}, \\xi_{t}) \\approx \\nabla f_{\\text{full}}(x_t) - \\nabla f(x_t, \\xi_{t}) $$ So with $\\alpha = 1$ SVRG gradient approximates full-batch gradient: $$ \\nabla f_{\\text{SVRG}}(x_{t}, \\xi_{t}) = \\nabla f(x_{t}, \\xi_{t}) + \\nabla f_{\\text{full}}(\\tilde{x}) - \\nabla f(\\tilde{x}, \\xi_{t}) \\approx \\nabla f(x_{t}, \\xi_{t}) + \\nabla f_{\\text{full}}(x_t) - \\nabla f(x_t, \\xi_{t}) = \\nabla f_{\\text{full}}(x_t) $$</p> <p>Computing variance-reduced gradient requires an extra backward pass to compute $\\nabla f(\\tilde{x}, \\xi_{t})$.</p> <p>In torchzero to use SVRG, put <code>tz.m.SVRG</code> as the first module. It includes optional gradient accumulation to calculate full gradient. It has two main parameters:</p> <ul> <li><code>accum_steps</code> determines number of steps to accumulate the gradients for when calculating full-batch gradient (step 1);</li> <li><code>svrg_steps</code> determines number of optimization steps with variance-reduced gradient to perform (step 2) before restarting (step 3).</li> </ul> <p>By default <code>accum_steps</code> is set to the same value as <code>svrg_steps</code>, and a good value to pass it length of train dataloader. It is also possible to pass <code>full_closure</code> argument to <code>step</code> method if you don't want to use gradient accumulation and wish to calculate full gradients manually.</p> <p>For the booth function we perform 100 gradient accumulation steps and then 100 LBFGS steps with variance-reduced gradients.</p>"},{"location":"overview/11.%20Regularization/","title":"11. Regularization","text":""},{"location":"overview/11.%20Regularization/#11-regularization","title":"11. Regularization\u00b6","text":"<p>Under construction</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/","title":"12. Gradient free methods","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(15,5))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.FDM(formula='forward2'), tz.m.BFGS(), tz.m.Backtracking())\nfunc.run(optimizer, max_steps=50)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"2-point forward - BFGS\")\n\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.FDM(formula='central3'), tz.m.BFGS(), tz.m.Backtracking())\nfunc.run(optimizer, max_steps=50)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"3-point central - BFGS\")\n\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.BFGS(), tz.m.Backtracking())\nfunc.run(optimizer, max_steps=50)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"true gradient - BFGS\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(15,5)) ax = np.ravel(ax)  func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.FDM(formula='forward2'), tz.m.BFGS(), tz.m.Backtracking()) func.run(optimizer, max_steps=50) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"2-point forward - BFGS\")  func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.FDM(formula='central3'), tz.m.BFGS(), tz.m.Backtracking()) func.run(optimizer, max_steps=50) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"3-point central - BFGS\")  func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.BFGS(), tz.m.Backtracking()) func.run(optimizer, max_steps=50) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"true gradient - BFGS\")  plt.show() <pre>finished in 0.2s., reached loss = 0.0424                                      \nfinished in 0.2s., reached loss = 3e-08                                      \nfinished in 0.2s., reached loss = 0                                      \n</pre> In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(15,5))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.SPSA(seed=0), tz.m.Adam(0.9, 0.95), tz.m.LR(2e-1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"SPSA-Adam\")\n\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.RDSA(seed=1), tz.m.Adam(0.9, 0.95), tz.m.LR(2e-1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"RDSA-Adam\")\n\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.GaussianSmoothing(n_samples=10, seed=0), tz.m.Adam(0.9, 0.95), tz.m.LR(2e-1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"GaussianSmoothing-Adam\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(15,5)) ax = np.ravel(ax)  func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.SPSA(seed=0), tz.m.Adam(0.9, 0.95), tz.m.LR(2e-1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"SPSA-Adam\")  func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.RDSA(seed=1), tz.m.Adam(0.9, 0.95), tz.m.LR(2e-1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"RDSA-Adam\")  func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.GaussianSmoothing(n_samples=10, seed=0), tz.m.Adam(0.9, 0.95), tz.m.LR(2e-1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"GaussianSmoothing-Adam\")  plt.show() <pre>finished in 0.9s., reached loss = 0.112                                      \nfinished in 0.9s., reached loss = 0.00129                                      \nfinished in 2.7s., reached loss = 0.000152                                      \n</pre> In\u00a0[4]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.MeZO(),\n    tz.m.LR(1e-3),\n)\nfunc.run(optimizer, max_steps=2000)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.MeZO(),     tz.m.LR(1e-3), ) func.run(optimizer, max_steps=2000) func.plot() <pre>finished in 3.5s., reached loss = 0.0593                                      \n</pre> Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.ForwardGradient(seed=1),\n    tz.m.Adam(0.9, 0.95),\n    tz.m.LR(2e-1),\n)\nfunc.run(optimizer, max_steps=500)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.ForwardGradient(seed=1),     tz.m.Adam(0.9, 0.95),     tz.m.LR(2e-1), ) func.run(optimizer, max_steps=500) func.plot() <pre>finished in 1.0s., reached loss = 0.0937                                      \n</pre> Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[3]: Copied! <pre>func = FunctionDescent('booth')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.SPSA(),\n    tz.m.SG2(seed=0),\n    tz.m.Warmup(10),\n    tz.m.LR(1e-1),\n)\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('booth') optimizer = tz.Optimizer(     func.parameters(),     tz.m.SPSA(),     tz.m.SG2(seed=0),     tz.m.Warmup(10),     tz.m.LR(1e-1), ) func.run(optimizer, max_steps=200) func.plot(log_contour=True) <pre>finished in 0.9s., reached loss = 2.27e-13                                      \n</pre> Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[6]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.FDM(),\n    tz.m.NewtonCG(hvp_method='fd_central'),\n    tz.m.Backtracking(),\n)\nfunc.run(optimizer, max_steps=20)\nfunc.plot()\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.FDM(),     tz.m.NewtonCG(hvp_method='fd_central'),     tz.m.Backtracking(), ) func.run(optimizer, max_steps=20) func.plot() <pre>finished in 0.3s., reached loss = 3.99e-08                                      \n</pre> Out[6]: <pre>&lt;Axes: &gt;</pre> In\u00a0[7]: Copied! <pre>from torchzero.optim.wrappers.scipy import ScipyMinimize\nfig, ax = plt.subplots(ncols=2, nrows=2, figsize=(14,14))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyMinimize(func.parameters(), method='nelder-mead')\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Nelder-Mead\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyMinimize(func.parameters(), method='powell')\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Powell's method\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyMinimize(func.parameters(), method='cobyla')\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"COBYLA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyMinimize(func.parameters(), method='cobyqa')\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[3])\nax[3].set_title(\"COBYQA\")\n\nplt.show()\n</pre> from torchzero.optim.wrappers.scipy import ScipyMinimize fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(14,14)) ax = np.ravel(ax)  func = FunctionDescent('rosen') optimizer = ScipyMinimize(func.parameters(), method='nelder-mead') func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Nelder-Mead\")  func = FunctionDescent('rosen') optimizer = ScipyMinimize(func.parameters(), method='powell') func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Powell's method\")  func = FunctionDescent('rosen') optimizer = ScipyMinimize(func.parameters(), method='cobyla') func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"COBYLA\")  func = FunctionDescent('rosen') optimizer = ScipyMinimize(func.parameters(), method='cobyqa') func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[3]) ax[3].set_title(\"COBYQA\")  plt.show() <pre>finished in 0.1s., reached loss = 6.88e-10                                      \nfinished in 0.3s., reached loss = 1.42e-14                                      \nfinished in 2.8s., reached loss = 0.124                                      \nfinished in 0.5s., reached loss = 1.78e-12                                      \n</pre> In\u00a0[8]: Copied! <pre>from torchzero.optim.wrappers.scipy import ScipyBrute, ScipyDE, ScipyDIRECT, ScipySHGO, ScipyDualAnnealing, ScipyBasinHopping\nfig, ax = plt.subplots(ncols=3, nrows=2, figsize=(18,13))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyDE(func.parameters(), lb=-3, ub=3, seed=0)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[0], line_alpha=0.2)\nax[0].set_title(\"ScipyDE\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyDualAnnealing(func.parameters(), lb=-3, ub=3, rng=0)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[1], line_alpha=0.2)\nax[1].set_title(\"ScipyDualAnnealing\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipySHGO(func.parameters(), lb=-3, ub=3, iters=100)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[2], line_alpha=0.2)\nax[2].set_title(\"ScipySHGO\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyDIRECT(func.parameters(), lb=-3, ub=3)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[3], line_alpha=0.2)\nax[3].set_title(\"ScipyDIRECT\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyBasinHopping(func.parameters(), niter=1000, rng=0)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[4], line_alpha=0.2)\nax[4].set_title(\"ScipyBasinHopping\")\n\nfunc = FunctionDescent('rosen')\noptimizer = ScipyBrute(func.parameters(), lb=-3, ub=3)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[5], line_alpha=0.2)\nax[5].set_title(\"ScipyBrute\")\n\nplt.show()\n</pre> from torchzero.optim.wrappers.scipy import ScipyBrute, ScipyDE, ScipyDIRECT, ScipySHGO, ScipyDualAnnealing, ScipyBasinHopping fig, ax = plt.subplots(ncols=3, nrows=2, figsize=(18,13)) ax = np.ravel(ax)  func = FunctionDescent('rosen') optimizer = ScipyDE(func.parameters(), lb=-3, ub=3, seed=0) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[0], line_alpha=0.2) ax[0].set_title(\"ScipyDE\")  func = FunctionDescent('rosen') optimizer = ScipyDualAnnealing(func.parameters(), lb=-3, ub=3, rng=0) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[1], line_alpha=0.2) ax[1].set_title(\"ScipyDualAnnealing\")  func = FunctionDescent('rosen') optimizer = ScipySHGO(func.parameters(), lb=-3, ub=3, iters=100) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[2], line_alpha=0.2) ax[2].set_title(\"ScipySHGO\")  func = FunctionDescent('rosen') optimizer = ScipyDIRECT(func.parameters(), lb=-3, ub=3) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[3], line_alpha=0.2) ax[3].set_title(\"ScipyDIRECT\")  func = FunctionDescent('rosen') optimizer = ScipyBasinHopping(func.parameters(), niter=1000, rng=0) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[4], line_alpha=0.2) ax[4].set_title(\"ScipyBasinHopping\")  func = FunctionDescent('rosen') optimizer = ScipyBrute(func.parameters(), lb=-3, ub=3) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[5], line_alpha=0.2) ax[5].set_title(\"ScipyBrute\")  plt.show() <pre>finished in 1.0s., reached loss = 0                                      \nfinished in 1.4s., reached loss = 3.59e-13                                      \nfinished in 2.0s., reached loss = 3.55e-15                                      \nfinished in 0.2s., reached loss = 3.23e-10                                      \nfinished in 27.1s., reached loss = 0                                      \nfinished in 0.1s., reached loss = 5.13e-10                                      \n</pre> In\u00a0[9]: Copied! <pre>from torchzero.optim.wrappers.nlopt import NLOptWrapper\nfig, ax = plt.subplots(ncols=3, nrows=4, figsize=(18,22))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'GN_DIRECT_L', lb=-3, ub=3, maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[0], line_alpha=0.2)\nax[0].set_title(\"GN_DIRECT_L\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'GN_CRS2_LM', lb=-3, ub=3, maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[1], line_alpha=0.2)\nax[1].set_title(\"GN_CRS2_LM\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'GN_AGS', lb=-3, ub=3, maxeval=5000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[2], line_alpha=0.2)\nax[2].set_title(\"GN_AGS\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'GN_ISRES', lb=-3, ub=3, maxeval=5000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[3], line_alpha=0.2)\nax[3].set_title(\"GN_ISRES\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'GN_ESCH', lb=-3, ub=3, maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[4], line_alpha=0.2)\nax[4].set_title(\"GN_ESCH\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'LN_COBYLA', maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[5], line_alpha=0.2)\nax[5].set_title(\"LN_COBYLA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'LN_BOBYQA', maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[6], line_alpha=0.2)\nax[6].set_title(\"LN_BOBYQA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'LN_NEWUOA', maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[7], line_alpha=0.2)\nax[7].set_title(\"LN_NEWUOA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'LN_PRAXIS', maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[8], line_alpha=0.2)\nax[8].set_title(\"LN_PRAXIS\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'LN_NELDERMEAD', maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[9], line_alpha=0.2)\nax[9].set_title(\"LN_NELDERMEAD\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NLOptWrapper(func.parameters(), 'LN_SBPLX', maxeval=1000)\nfunc.run(optimizer, max_steps=1)\nfunc.plot(log_contour=True, ax=ax[10], line_alpha=0.2)\nax[10].set_title(\"LN_SBPLX\")\n\nplt.show()\n</pre> from torchzero.optim.wrappers.nlopt import NLOptWrapper fig, ax = plt.subplots(ncols=3, nrows=4, figsize=(18,22)) ax = np.ravel(ax)  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'GN_DIRECT_L', lb=-3, ub=3, maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[0], line_alpha=0.2) ax[0].set_title(\"GN_DIRECT_L\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'GN_CRS2_LM', lb=-3, ub=3, maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[1], line_alpha=0.2) ax[1].set_title(\"GN_CRS2_LM\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'GN_AGS', lb=-3, ub=3, maxeval=5000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[2], line_alpha=0.2) ax[2].set_title(\"GN_AGS\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'GN_ISRES', lb=-3, ub=3, maxeval=5000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[3], line_alpha=0.2) ax[3].set_title(\"GN_ISRES\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'GN_ESCH', lb=-3, ub=3, maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[4], line_alpha=0.2) ax[4].set_title(\"GN_ESCH\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'LN_COBYLA', maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[5], line_alpha=0.2) ax[5].set_title(\"LN_COBYLA\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'LN_BOBYQA', maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[6], line_alpha=0.2) ax[6].set_title(\"LN_BOBYQA\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'LN_NEWUOA', maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[7], line_alpha=0.2) ax[7].set_title(\"LN_NEWUOA\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'LN_PRAXIS', maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[8], line_alpha=0.2) ax[8].set_title(\"LN_PRAXIS\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'LN_NELDERMEAD', maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[9], line_alpha=0.2) ax[9].set_title(\"LN_NELDERMEAD\")  func = FunctionDescent('rosen') optimizer = NLOptWrapper(func.parameters(), 'LN_SBPLX', maxeval=1000) func.run(optimizer, max_steps=1) func.plot(log_contour=True, ax=ax[10], line_alpha=0.2) ax[10].set_title(\"LN_SBPLX\")  plt.show() <pre>finished in 0.3s., reached loss = 3.43e-09                                      \nfinished in 0.3s., reached loss = 3.25e-09                                      \nfinished in 1.2s., reached loss = 0.00429                                      \nfinished in 1.2s., reached loss = 0.0047                                      \nfinished in 0.3s., reached loss = 0.005                                      \nfinished in 0.2s., reached loss = 0.0234                                      \nfinished in 0.1s., reached loss = 0                                      \nfinished in 0.1s., reached loss = 8.88e-14                                      \nfinished in 0.2s., reached loss = 0                                      \nfinished in 0.1s., reached loss = 0                                      \nfinished in 0.1s., reached loss = 2.88e-13                                      \n</pre> In\u00a0[10]: Copied! <pre>import nevergrad as ng\nfrom torchzero.optim.wrappers.nevergrad import NevergradWrapper\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(18,18))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.CMA, budget=1001)\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True, ax=ax[0], line_alpha=0.2)\nax[0].set_title(\"CMA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.DiagonalCMA, budget=1001)\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True, ax=ax[1], line_alpha=0.2)\nax[1].set_title(\"DiagonalCMA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.cGA, budget=10001)\nfunc.run(optimizer, max_steps=10000)\nfunc.plot(log_contour=True, ax=ax[2], line_alpha=0.2)\nax[2].set_title(\"CGA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.ES, budget=10001)\nfunc.run(optimizer, max_steps=10000)\nfunc.plot(log_contour=True, ax=ax[3], line_alpha=0.2)\nax[3].set_title(\"ES\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.PSO, budget=2001)\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True, ax=ax[4], line_alpha=0.2)\nax[4].set_title(\"PSO\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.EDA, budget=2001)\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True, ax=ax[5], line_alpha=0.2)\nax[5].set_title(\"EDA\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.HammersleySearch, budget=1001, lb=-3, ub=3)\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True, ax=ax[6], line_alpha=0.2)\nax[6].set_title(\"HammersleySearch\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.DiscreteLenglerOnePlusOne, budget=2001)\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True, ax=ax[7], line_alpha=0.2)\nax[7].set_title(\"DiscreteLenglerOnePlusOne\")\n\nfunc = FunctionDescent('rosen')\noptimizer = NevergradWrapper(func.parameters(), ng.optimizers.Portfolio, budget=2001)\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True, ax=ax[8], line_alpha=0.2)\nax[8].set_title(\"Portfolio\")\n\n\nplt.show()\n</pre> import nevergrad as ng from torchzero.optim.wrappers.nevergrad import NevergradWrapper fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(18,18)) ax = np.ravel(ax)  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.CMA, budget=1001) func.run(optimizer, max_steps=1000) func.plot(log_contour=True, ax=ax[0], line_alpha=0.2) ax[0].set_title(\"CMA\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.DiagonalCMA, budget=1001) func.run(optimizer, max_steps=1000) func.plot(log_contour=True, ax=ax[1], line_alpha=0.2) ax[1].set_title(\"DiagonalCMA\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.cGA, budget=10001) func.run(optimizer, max_steps=10000) func.plot(log_contour=True, ax=ax[2], line_alpha=0.2) ax[2].set_title(\"CGA\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.ES, budget=10001) func.run(optimizer, max_steps=10000) func.plot(log_contour=True, ax=ax[3], line_alpha=0.2) ax[3].set_title(\"ES\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.PSO, budget=2001) func.run(optimizer, max_steps=2000) func.plot(log_contour=True, ax=ax[4], line_alpha=0.2) ax[4].set_title(\"PSO\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.EDA, budget=2001) func.run(optimizer, max_steps=2000) func.plot(log_contour=True, ax=ax[5], line_alpha=0.2) ax[5].set_title(\"EDA\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.HammersleySearch, budget=1001, lb=-3, ub=3) func.run(optimizer, max_steps=1000) func.plot(log_contour=True, ax=ax[6], line_alpha=0.2) ax[6].set_title(\"HammersleySearch\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.DiscreteLenglerOnePlusOne, budget=2001) func.run(optimizer, max_steps=2000) func.plot(log_contour=True, ax=ax[7], line_alpha=0.2) ax[7].set_title(\"DiscreteLenglerOnePlusOne\")  func = FunctionDescent('rosen') optimizer = NevergradWrapper(func.parameters(), ng.optimizers.Portfolio, budget=2001) func.run(optimizer, max_steps=2000) func.plot(log_contour=True, ax=ax[8], line_alpha=0.2) ax[8].set_title(\"Portfolio\")   plt.show() <pre>finished in 2.0s., reached loss = 0                                      \nfinished in 2.6s., reached loss = 3.189                                      \nfinished in 19.9s., reached loss = 0.0562                                      \nfinished in 10.8s., reached loss = 0.000435                                      \nf175 p175 b174/2000 e174; train loss = inf                          \r</pre> <pre>/var/mnt/issd/dev/miniconda3/envs/pytorch312/lib/python3.12/site-packages/nevergrad/optimization/base.py:149: LossTooLargeWarning: Clipping very high value inf in tell (rescale the cost function?).\n  warnings.warn(msg, e)\n</pre> <pre>finished in 2.4s., reached loss = 0.00188                                      \nfinished in 3.2s., reached loss = 3.689                                      \nfinished in 1.8s., reached loss = 0.0398                                      \nfinished in 2.2s., reached loss = 0.0335                                      \nfinished in 8.5s., reached loss = 7.61e-05                                      \n</pre>"},{"location":"overview/12.%20Zeroth%20order%20methods/#12-gradient-free-methods","title":"12. Gradient free methods\u00b6","text":""},{"location":"overview/12.%20Zeroth%20order%20methods/#121-introduction","title":"12.1 Introduction\u00b6","text":"<p>Gradient-free methods use only function values for minimization, therefore they are suitable for problems where gradients are not known, aren't useful or are too expensive to calculate.</p> <p>There is an enormous number of various gradient-free methods and one notebook is definitely not enough to cover them all. Torchzero only implements a few (for now), but also provides wrappers for some other gradient-free optimization libraries with a lot of methods implemented, here I will mostly focus on methods available in torchzero.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#122-gradient-approximations","title":"12.2 Gradient approximations\u00b6","text":"<p>When gradients are not available, one strategy is to estimate them using function values and use any of the gradient-based methods using the approximated gradients.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1221-finite-difference-estimator","title":"12.2.1 Finite difference estimator\u00b6","text":"<p>The finite difference estimator (FDM) loops over each parameter, adds a small perturbation to it and evaluates the function value, therefore it requires at least $n$ evaluations to estimate the gradient where $n$ is number of parameters. There are various finite difference formulas - 2-point forward/backward, 3-point central, 3-point forward/backward, 4 point central, etc.</p> <p>The 3-point central is widely used. To estimate gradient of $i$-th parameter $x_i$, it evaluates function at $f(x_i - h)$ and $f(x_i + h)$, where $h$ is a hyperparameter controlling accuracy of the estimation. If precision was infinite, smaller $h$ means more accurate estimation, however due to finite precision $h$ can't be too small. Also if $h$ is large, it can have an effect of smoothing the function which is called implicit filtering, and can also be useful for functions with very rough surface. The formula for gradient of $i$-th parameter $g_i$ is the following:</p> <p>$$ \\hat{g_i} = \\frac{f(x_i + h) - f(x_i - h)}{2 \\cdot h} $$</p> <p>This formula has to be ran for each parameter, therefore $2n$ evaluations are required.</p> <p>2-point forward formula is the following: $$ \\hat{g_i} = \\frac{f(x_i + h) - f(x_i)}{h} $$</p> <p>This formula is less accurate, but by evaluating $f(x_i)$ once and reusing when estimating gradient of each parameter, it requires $n+1$ evaluations.</p> <p>In torchzero to use FDM-approximated gradients, add <code>tz.m.FDM</code> as the first module.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1222-randomized-finite-difference-estimator","title":"12.2.2 Randomized finite difference estimator\u00b6","text":"<p>Randomized finite difference estimator (RFDM) perturbs all parameters at once in a random direction.</p> <p>$$ \\hat{g} = p\\frac{(f(x + h p) - f(x - h p))}{2 h} $$</p> <p>Here $h$ controls accuracy of the approximation, $p$ is a random perturbation with zero mean and variance of 1. This formula is direct equivalent of 3-point central formula, and other formulas can be used too.</p> <p>This formula essentially estimates directional derivative in the direction $p$ and multiplies $p$ by it, which is a very rough estimate for full gradient.</p> <p>Often $p$ is sample from the Rademacher distribution, so every value has 50% chance of being 1 and 50% of being -1, leading to the very popular Simultaneous perturbation stochastic approximation (SPSA) method. SPSA formula is often written with $p$ in the denominator (since multiplying and dividing by 1 and -1 is equivalent).</p> <p>If $p$ isn' sampled from Rademacher distribution, we get Random direction stochastic approximation (RDSA) method.</p> <p>It is possible to calculate $\\hat{g}$ multiple times with different random perturbations $p$, and then take the average. Then that average is an estimate of gradient in a subspace spanned by perturbations $p$, which is a slightly better estimate. The gaussian smoothing method averages multiple $p$ sampled from gaussian distribution, and $h$ can be made larger leading to the effect of smoothing the function.</p> <p>RFDM doesn't suffer from having to perform $n$ evaluations per step just to approximate the gradient like in FDM. However the approximation is very rough and won't work with methods that rely on gradient differences, such as conjugate gradient and quasi-newton methods. It works with momentum and adaptive methods.</p> <p>In torchzero to use RFDM-approximated gradients, add <code>tz.m.RandomizedFDM</code> as the first module. Or use one of <code>RandomizedFDM</code> subclasses - <code>tz.m.SPSA</code>, <code>tz.m.RDSA</code> and <code>tz.m.GaussianSmoothing</code>.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1223-mezo","title":"12.2.3 MeZO\u00b6","text":"<p>MeZO is a version of SPSA which uses the same formula, but the random perturbation $p$ is never stored in memory, instead only a seed used to generate it is stored and it is generated from the seed whenever needed. It has been proposed to fine-tune large language models when very limited memory is available. SPSA requires $2n$ extra memory, MeZO requires $n$ extra memory, where $n$ is number of parameters. Theoretically it could use almost no extra memory by generating and subtracting $p$ gradually weight by weight, not at once, but I think that would be hard to implement in a way where it isn't slow.</p> <p>Reference: Malladi, Sadhika, et al. \"Fine-tuning language models with just forward passes.\" Advances in Neural Information Processing Systems 36 (2023): 53038-53075.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1224-forward-gradient","title":"12.2.4 Forward gradient\u00b6","text":"<p>Instead of having to tune finite difference parameter $h$, exact directional derivative in the direction $p$ can be calculated using forward mode autograd via a jacobian-vector product (Jvp). Jvps can be cheap, in PyTorch they are experimental but still use way less memory than backward passes.</p> <p>The formula is $$ \\hat{g} = p \\cdot \\nabla f(x)^T p $$</p> <p>Here $p$ is a random vector, $\\nabla f(x)^T p$ is directional derivative in direction $p$ which can be calculated without calculating full gradient  $\\nabla f(x)$.</p> <p>This approximation has been called \"Forward gradient\".</p> <p>Reference: Baydin, At\u0131l\u0131m G\u00fcne\u015f, et al. \"Gradients without backpropagation.\" arXiv preprint arXiv:2202.08587 (2022).</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1225-2nd-order-spsa","title":"12.2.5 2nd order SPSA\u00b6","text":"<p>2SG is a quasi-newton method that is able to work with stochastic gradients, including SPSA gradient estimates - resulting method is called 2SPSA, or second-order SPSA. With true stochastic gradients it requires three gradients per step; with SPSA gradients it uses four function evaluations per step.</p> <p>Reference: Spall, James C. \"Adaptive stochastic approximation by the simultaneous perturbation method.\" IEEE transactions on automatic control 45.10 (2000): 1839-1853.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1226-finite-difference-hessian-vector-products","title":"12.2.6 Finite difference hessian-vector products\u00b6","text":"<p>Certain second order optimizers such as NewtonCG and sketched Newton do not require the full hessian, they require just the hessian-vector products (Hvps) which can be computed efficiently via autograd. But in many case autograd fails because some rules aren't implemented, or maybe gradients are computed without autograd, then hessian-vector products can be estimated in one or two extra gradient computations using finite difference formulas. And, of course, we can use finite difference gradient approximations too, leading to a zeroth-order approximation to Newton's method.</p> <p>The forward formula for estimating a hessian-vector product $Hv$ with vector $v$ is this: $$ \\widehat{Hv} = \\frac{\\nabla f(x + hv) - \\nabla f(x)}{h} $$</p> <p>Here $h$ controls accuracy of the approximation. By pre-computing $\\nabla f(x)$, it can be re-used for each subsequent hessian-vector product, leading to requiring one extra gradient computation per Hvp.</p> <p>A more accurate central formula requires two extra gradient computations per Hvp: $$ \\widehat{Hv} = \\frac{\\nabla f(x + hv) - \\nabla f(x - hv)}{2h} $$</p> <p>When using those formulas we can use finite difference approximation to $\\nabla f(x)$.</p> <p>In torchzero modules that use hessian-vector products have a <code>hvp_method</code> argument which can be set to <code>\"forward\"</code> to use forward formula or <code>\"central\"</code> to use central formula. By default it is usually set to <code>\"autograd\"</code> and uses automatic differentiation.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#123-other-libraries","title":"12.3 Other libraries\u00b6","text":"<p>There are many python libraries that implement various zeroth-order methods including evolutionary algorithms, bayesian optimization, direct search, etc. Torchzero implements wrappers for a few of them, allowing to use them as pytorch optimizers.</p> <p>Since I haven't studied those methods, I won't give a detailed description unless I implement them as torchzero modules.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1231-scipyoptimizeminimize","title":"12.3.1 scipy.optimize.minimize\u00b6","text":"<p><code>scipy.optimize.minimize</code> implements the following local optimization methods: 'nelder-mead', 'powell', 'cg', 'bfgs', 'newton-cg', 'l-bfgs-b', 'tnc', 'cobyla', 'cobyqa', 'slsqp', 'trust-constr', 'dogleg', 'trust-ncg', 'trust-exact', 'trust-krylov'. Most first and second order methods are also implemented in torchzero, but zeroth-order methods are not (as of yet) - Nelder-Mead, Powell's method, COBYLA and COBYQA.</p> <p>Those methods are all local search methods and suitable for functions with a single global minima.</p> <p>The wrapper for it is <code>torchzero.optim.wrappers.scipy.ScipyMinimize</code>. Note that scipy doesn't support performing a single step - it optimizes until stopping criterion is reached. Therefore a single step with <code>ScipyMinimize</code> will perform a full minimization. The nevergrad wrapper (described later) has some of those methods and supports performing a single step.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1232-other-scipyoptimize-methods","title":"12.3.2 Other scipy.optimize methods\u00b6","text":"<p><code>scipy.optimize</code> also implements differential evolution, dual annealing, SHGO, DIRECT, basin-hopping and brute search, all of them are global optimization methods and are suitable for optimizing functions with many local minima, and all of them except basin-hoping require box bounds to be specified.</p> <p>All of those methods also optimize until stopping criterion is specified, so usually a single step should be performed, and if you want a better control over steps, use the nevergrad wrapper.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1233-nlopt","title":"12.3.3 NLopt\u00b6","text":"<p>NLopt is another optimization library with many gradient based and gradient free methods. The algorithms are listed here https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/.</p> <p>The wrapper for NLOpt is <code>torchzero.optim.wrappers.nlopt.NLOptWrapper</code>. Like scipy, a single step performs full minimization. Make sure to pass some stopping criterion to <code>NLOptWrapper</code> such as <code>maxeval</code>, and some methods require bounds to be specified and without bounds they return the initial point.</p>"},{"location":"overview/12.%20Zeroth%20order%20methods/#1234-nevergrad","title":"12.3.4 Nevergrad\u00b6","text":"<p>Nevergrad implements a large number of zeroth order algorithms including wrappers for NLOpt and Scipy. All algorithms are listed here https://facebookresearch.github.io/nevergrad/optimizers_ref.html#optimizer-api.</p> <p>The wrapper is <code>torchzero.optim.wrappers.nevergrad.NevergradWrapper</code>. Here the step method actually performs a single step, i.e. a single objective function evaluation, so it may be more convenient to use as pytorch optimizer. Some methods in <code>nevergrad</code> require a budget to be specified - maximum number of objective function evaluations, and will raise an exception if it is not given.</p>"},{"location":"overview/2.%20Momentum/","title":"2. Momentum","text":"In\u00a0[1]: Copied! <pre>import torch\ntorch.manual_seed(0)\n\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import torch torch.manual_seed(0)  import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.HeavyBall(0.95), tz.m.LR(2e-4))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.HeavyBall(0.95), tz.m.LR(2e-4)) func.run(optimizer, max_steps=2000) func.plot(log_contour=True) <pre>finished in 2.8s., reached loss = 0.000154                                      \n</pre> Out[2]: <pre>&lt;Axes: &gt;</pre> In\u00a0[3]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.NAG(0.99), tz.m.LR(2e-4))\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.NAG(0.99), tz.m.LR(2e-4)) func.run(optimizer, max_steps=1000) func.plot(log_contour=True) <pre>finished in 1.6s., reached loss = 6.89e-09                                      \n</pre> Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[2]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.EMA(0.95), tz.m.LR(4e-3))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.EMA(0.95), tz.m.LR(4e-3)) func.run(optimizer, max_steps=2000) func.plot(log_contour=True) <pre>finished in 1.8s., reached loss = 0.000117                                      \n</pre> Out[2]: <pre>&lt;Axes: &gt;</pre> In\u00a0[3]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.HeavyBall(0.95), tz.m.Cautious(), tz.m.LR(3e-4))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.HeavyBall(0.95), tz.m.Cautious(), tz.m.LR(3e-4)) func.run(optimizer, max_steps=2000) func.plot(log_contour=True) <pre>finished in 2.1s., reached loss = 1e-05                                      \n</pre> Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>func = FunctionDescent('booth')\noptimizer = tz.Optimizer(func.parameters(), tz.m.MatrixMomentum(lr=1e-2, mu=0.1))\nfunc.run(optimizer, max_steps=100)\nfunc.plot()\n</pre> func = FunctionDescent('booth') optimizer = tz.Optimizer(func.parameters(), tz.m.MatrixMomentum(lr=1e-2, mu=0.1)) func.run(optimizer, max_steps=100) func.plot() <pre>finished in 0.1s., reached loss = 1.26e-06                                      \n</pre> Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[6]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(), \n    tz.m.NAG(0.5),\n    tz.m.NAG(0.5),\n    tz.m.NAG(0.5),\n    tz.m.NAG(0.5),\n    tz.m.NAG(0.5),\n    tz.m.LR(1e-4),\n)\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),      tz.m.NAG(0.5),     tz.m.NAG(0.5),     tz.m.NAG(0.5),     tz.m.NAG(0.5),     tz.m.NAG(0.5),     tz.m.LR(1e-4), ) func.run(optimizer, max_steps=2000) func.plot(log_contour=True) <pre>finished in 2.5s., reached loss = 0.0011                                      \n</pre> Out[6]: <pre>&lt;Axes: &gt;</pre>"},{"location":"overview/2.%20Momentum/#2-momentum","title":"2. Momentum\u00b6","text":""},{"location":"overview/2.%20Momentum/#21-heavy-ball-momentum","title":"2.1 Heavy-ball momentum\u00b6","text":"<p>Momentum can be used to accelerate gradient descent and possibly other algorithms. The idea is to add \"intertia\" to gradient descent by adding previous update to negative gradient. Polyak's momentum, also known as Heavy-ball method, uses the following update rule: $$ x_{t+1} \\leftarrow x_t - \\eta \\nabla f(x_t) + \\beta (x_t - x_{t-1}) $$ Here $\\eta$ is the step size and $\\beta$ is the momentum hyperparameter, often set to 0.9 or 0.95.</p> <p>The formula can be also rewritten in the following equivalent way: $$ m_{t} \\leftarrow \\beta m_{t-1} + \\nabla f(x_t) $$ $$ x_{t+1} \\leftarrow x_t - \\eta m_{t} $$ Here $m_t$ is the momentum buffer which is used to update the parameters.</p> <p>Reference: Polyak, Boris T. \"Some methods of speeding up the convergence of iteration methods.\" Ussr computational mathematics and mathematical physics 4.5 (1964): 1-17.</p>"},{"location":"overview/2.%20Momentum/#22-nesterovs-momentum","title":"2.2 Nesterov's momentum\u00b6","text":"<p>Nesterov's momentum formula tends to reduce oscillations that happen with heavy-ball update rule.</p> <p>$$ m_t \\leftarrow \\beta (m_{t-1} + \\nabla f(x_t)) $$ $$ x_{t+1} \\leftarrow x_t - \\eta (\\nabla f(x_t) + m_t) $$</p> <p>Reference: Nesterov, Yurii. \"A method for solving the convex programming problem with convergence rate O (1/k2).\" Dokl akad nauk Sssr. Vol. 269. 1983.</p>"},{"location":"overview/2.%20Momentum/#23-exponential-moving-average","title":"2.3 Exponential moving average\u00b6","text":"<p>Many optimizers, for example Adam, use the exponential moving average of gradients in place of momentum. The formula is similar to heavy ball formula, but with an extra $(1 - \\beta)$ term: $$ m_t \\leftarrow \\beta m_{t-1} + (1 - \\beta) \\nabla f(x_t) \\\\\\\\ $$ $$ x_{t+1} \\leftarrow x_t - \\eta m_t $$</p>"},{"location":"overview/2.%20Momentum/#24-cautious-momentum","title":"2.4 Cautious momentum\u00b6","text":"<p>The idea of cautious updates is that when signs of gradient and momentum for a weight differ, update for that weight is zeroed. Cautioning can be applied to any momentum-based optimizer.</p> <p>Reference: Liang, Kaizhao, et al. \"Cautious optimizers: Improving training with one line of code.\" arXiv preprint arXiv:2411.16085 (2024).</p>"},{"location":"overview/2.%20Momentum/#25-matrix-momentum","title":"2.5 Matrix momentum\u00b6","text":"<p>Matrix momentum is a modification of Polyak's momentum suitable for convex stochastic optimization, where the momentum parameter $\\beta$ is replaced by an implicit matrix such that it uses second order information while only requiring a hessian-vector product with previous update on each step.</p> <p>The method is based on the observation that at late times, with momentum, dynamics of the training is similar to dynamics without momentum, but with a scaled learning rate: $$ \\mathrm{u_{eff}} = \\frac{\\mathrm{u_0}}{1 - \\beta} $$ here $\\mathrm{u_{eff}}$ is the effective learning rate, $\\mathrm{u_0}$ is the actual learning rate and $\\beta$ is the momentum hyperparameter. In Newton's method learning rate is replaced by inverse of the hessian matrix: $$ x_{t+1} \\leftarrow x_t - H(x_t)^{-1} \\nabla f(x_t) $$ Since newton's method is very fast, we would like effective learning rate to be $H^{-1}$. So if we replace effective learning rate $\\mathrm{u_{eff}}$ with inverse hessian $H^{-1}$ in the 1st formula, we get: $$ H^{-1} = \\mathrm{u_0}(I - \\beta)^{-1} $$ To get a nice formula, multiply both sides by $(I - \\beta)$, then multiply both sides by $H$: $$ H^{-1} (I - \\beta) = \\mathrm{u_0} (I - \\beta)^{-1} (I - \\beta) \\\\\\\\ H^{-1} (I - \\beta) = \\mathrm{u_0} I \\\\\\\\ H H^{-1}  (I - \\beta) = H (\\mathrm{u_0} I) \\\\\\\\ I (I - \\beta) = \\mathrm{u_0} H \\\\\\\\ I - \\beta = \\mathrm{u_0} H \\\\\\\\ \\beta = I - \\mathrm{u_0} H $$ So we have a formula for the momentum parameter $\\beta$, which now becomes a matrix, such that the effective learning rate is $H^{-1}$. If we put this into the Polyak's momentum formula: $$ x_{t+1} \\leftarrow x_t - \\eta \\nabla f(x_t) + \\beta (x_t - x_{t-1}) $$ We replace $\\beta$ with our $I - \\mathrm{u_0} H$ and we obtain the Matrix momentum update formula: $$ x_{t+1} \\leftarrow x_t - \\eta \\nabla f(x_t) + (I - \\mathrm{u_0} H) (x_t - x_{t-1}) $$ Or it can be written as $$ s_t = x_t - x_{t-1} \\\\\\\\ x_{t+1} \\leftarrow x_t - \\eta \\nabla f(x_t) + s_t - \\mathrm{u_0} H s_t $$ So this doesn't need the hessian or the inverse, all it requires is a hessian-vector product $H s_t$. The biggest disadvantage is that $\\mathrm{u_0}$ needs to be tuned, and it needs to be tuned very carefully, otherwise the algorithm becomes unstable, or if it is too small, indistinguishable from plain GD. The value of $\\mathrm{u_0}$ should be smaller than $\\frac{1}{\\lambda_{max}}$, where $\\lambda_{max}$ is the largest eigenvalue of the hessian, which is possible to estimate using the power method before training.</p> <p>Reference: Orr, Genevieve, and Todd Leen. \"Using curvature information for fast stochastic search.\" Advances in neural information processing systems 9 (1996).</p>"},{"location":"overview/2.%20Momentum/#26-nested-momentum","title":"2.6 Nested momentum\u00b6","text":"<p>It is possible to take the output of a momentum module and pass it to another momentum module.</p>"},{"location":"overview/3.%20Adaptive%20methods/","title":"3. Adaptive methods","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Adagrad(), tz.m.LR(4e-1))\nfunc.run(optimizer, max_steps=5000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Adagrad(), tz.m.LR(4e-1)) func.run(optimizer, max_steps=5000) func.plot(log_contour=True) <pre>finished in 6.4s., reached loss = 0.00462                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.RMSprop(smoothing=0.95, eps=1e-4), tz.m.LR(1e-2))\nfunc.run(optimizer, max_steps=4000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.RMSprop(smoothing=0.95, eps=1e-4), tz.m.LR(1e-2)) func.run(optimizer, max_steps=4000) func.plot(log_contour=True) <pre>finished in 4.6s., reached loss = 0.0222                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Adam(beta1=0.95, beta2=0.99), tz.m.LR(3e-1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Adam(beta1=0.95, beta2=0.99), tz.m.LR(3e-1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True) <pre>finished in 0.7s., reached loss = 4.02e-05                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.AdaHessian(beta1=0.95, beta2=0.99, seed=4),  tz.m.LR(1))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.AdaHessian(beta1=0.95, beta2=0.99, seed=4),  tz.m.LR(1)) func.run(optimizer, max_steps=2000) func.plot(log_contour=True) <pre>finished in 4.2s., reached loss = 0.00762                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.SophiaH(seed=0),  tz.m.LR(2e-1))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.SophiaH(seed=0),  tz.m.LR(2e-1)) func.run(optimizer, max_steps=2000) func.plot(log_contour=True) <pre>finished in 2.4s., reached loss = 0.00193                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Lion(),  tz.m.LR(2e-2))\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Lion(),  tz.m.LR(2e-2)) func.run(optimizer, max_steps=1000) func.plot(log_contour=True) <pre>finished in 1.2s., reached loss = 9.61e-10                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Adam(beta1=0.95, beta2=0.95),\n    tz.m.GradSign(),\n    tz.m.LR(3e-1)\n)\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.Adam(beta1=0.95, beta2=0.95),     tz.m.GradSign(),     tz.m.LR(3e-1) ) func.run(optimizer, max_steps=500) func.plot(log_contour=True) <pre>f43 p86 b42/500 e42; train loss = 5.815                          \r</pre> <pre>finished in 0.8s., reached loss = 0.00616                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.RMSprop(0.95),\n    tz.m.Debias(beta1=None, beta2=0.95),\n    tz.m.EMA(0.95),\n    tz.m.Debias(beta1=0.95, beta2=None),\n    tz.m.LR(3e-1)\n)\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.RMSprop(0.95),     tz.m.Debias(beta1=None, beta2=0.95),     tz.m.EMA(0.95),     tz.m.Debias(beta1=0.95, beta2=None),     tz.m.LR(3e-1) ) func.run(optimizer, max_steps=500) func.plot(log_contour=True) <pre>finished in 1.0s., reached loss = 1.88e-05                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Adan(),  tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Adan(),  tz.m.LR(1e-1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True) <pre>finished in 0.8s., reached loss = 3.32e-07                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.MARSCorrection(beta=0.95), tz.m.Adam(beta1=0.95), tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.MARSCorrection(beta=0.95), tz.m.Adam(beta1=0.95), tz.m.LR(1e-1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True) <pre>finished in 0.9s., reached loss = 9.95e-07                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Rprop(), tz.m.LR(1e-3))\nfunc.run(optimizer, max_steps=2000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Rprop(), tz.m.LR(1e-3)) func.run(optimizer, max_steps=2000) func.plot(log_contour=True) <pre>finished in 3.3s., reached loss = 0.0141                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n\n# diagonal Adagrad\nfunc = FunctionDescent('ill2')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Adagrad(), tz.m.LR(2))\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Diagonal Adagrad (1000 steps)\")\n\n# full-matrix Adagrad\nfunc = FunctionDescent('ill2')\noptimizer = tz.Optimizer(func.parameters(), tz.m.FullMatrixAdagrad(init='zeros', reg=1e-4), tz.m.WarmupNormClip(10), tz.m.LR(1))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Full-matrix Adagrad (100 steps)\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6))  # diagonal Adagrad func = FunctionDescent('ill2') optimizer = tz.Optimizer(func.parameters(), tz.m.Adagrad(), tz.m.LR(2)) func.run(optimizer, max_steps=1000) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Diagonal Adagrad (1000 steps)\")  # full-matrix Adagrad func = FunctionDescent('ill2') optimizer = tz.Optimizer(func.parameters(), tz.m.FullMatrixAdagrad(init='zeros', reg=1e-4), tz.m.WarmupNormClip(10), tz.m.LR(1)) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Full-matrix Adagrad (100 steps)\")  plt.show() <pre>finished in 1.1s., reached loss = 0.0196                                      \nfinished in 0.1s., reached loss = 1.82e-05                                      \n</pre> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n\n# diagonal Adam\nfunc = FunctionDescent('ill3')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Adam(0.9, 0.95), tz.m.LR(1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Diagonal Adam (500 steps)\")\n\n# full-matrix Adam\nfunc = FunctionDescent('ill3')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.FullMatrixAdagrad(init='zeros', reg=1e-5, beta=0.95, inner=tz.m.EMA(0.9)),\n    tz.m.Debias(0.9), # FullMatrixAdagrad already debiases beta2\n    tz.m.LR(1)\n)\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Full-matrix Adam (100 steps)\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6))  # diagonal Adam func = FunctionDescent('ill3') optimizer = tz.Optimizer(func.parameters(), tz.m.Adam(0.9, 0.95), tz.m.LR(1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Diagonal Adam (500 steps)\")  # full-matrix Adam func = FunctionDescent('ill3') optimizer = tz.Optimizer(     func.parameters(),     tz.m.FullMatrixAdagrad(init='zeros', reg=1e-5, beta=0.95, inner=tz.m.EMA(0.9)),     tz.m.Debias(0.9), # FullMatrixAdagrad already debiases beta2     tz.m.LR(1) ) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Full-matrix Adam (100 steps)\")  plt.show() <pre>finished in 0.8s., reached loss = 3.52e-05                                      \nfinished in 0.2s., reached loss = 2.18e-06                                      \n</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('ill2')\noptimizer = tz.Optimizer(func.parameters(), tz.m.GGT(damping=0), tz.m.LR(1))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('ill2') optimizer = tz.Optimizer(func.parameters(), tz.m.GGT(damping=0), tz.m.LR(1)) func.run(optimizer, max_steps=100) func.plot(log_contour=True) <pre>finished in 0.3s., reached loss = 6.27e-10                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>class TinyConvNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.c1 = nn.Conv2d(1, 16, 3, 2)\n        self.c2 = nn.Conv2d(16, 24, 3, 2)\n        self.c3 = nn.Conv2d(24, 32, 2, 2)\n        self.head = nn.Sequential(nn.Flatten(), nn.Linear(32*9, 10))\n\n    def forward(self, x):\n        x = F.elu(self.c1(x), inplace=True)\n        x = F.elu(self.c2(x), inplace=True)\n        x = F.elu(self.c3(x), inplace=True)\n        return self.head(x)\n\nmodel = TinyConvNet().cuda()\n\noptimizer = tz.Optimizer(\n    model.parameters(),\n    # same hyperparams as https://github.com/KellerJordan/Muon\n    tz.m.NAG(0.95),\n    tz.m.Split(\n        filter = (model.c2.weight, model.c3.weight),\n        # or `filter = lambda x: x.ndim &gt;= 2` to select all 2D+ params.\n        true = tz.m.Orthogonalize(),\n        false = [tz.m.Adam(0.9, 0.95), tz.m.Mul(1/66)],\n    ),\n    tz.m.LR(1e-2),\n)\n</pre> class TinyConvNet(nn.Module):     def __init__(self):         super().__init__()         self.c1 = nn.Conv2d(1, 16, 3, 2)         self.c2 = nn.Conv2d(16, 24, 3, 2)         self.c3 = nn.Conv2d(24, 32, 2, 2)         self.head = nn.Sequential(nn.Flatten(), nn.Linear(32*9, 10))      def forward(self, x):         x = F.elu(self.c1(x), inplace=True)         x = F.elu(self.c2(x), inplace=True)         x = F.elu(self.c3(x), inplace=True)         return self.head(x)  model = TinyConvNet().cuda()  optimizer = tz.Optimizer(     model.parameters(),     # same hyperparams as https://github.com/KellerJordan/Muon     tz.m.NAG(0.95),     tz.m.Split(         filter = (model.c2.weight, model.c3.weight),         # or `filter = lambda x: x.ndim &gt;= 2` to select all 2D+ params.         true = tz.m.Orthogonalize(),         false = [tz.m.Adam(0.9, 0.95), tz.m.Mul(1/66)],     ),     tz.m.LR(1e-2), ) In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('ill6')\noptimizer = tz.Optimizer(func.parameters(), tz.m.SOAP(), tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('ill6') optimizer = tz.Optimizer(func.parameters(), tz.m.SOAP(), tz.m.LR(1e-1)) func.run(optimizer, max_steps=200) func.plot(log_contour=True) <pre>finished in 0.4s., reached loss = 5.07e-07                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>X = torch.randn(64, 20)\ny = torch.randn(64, 10)\n\nmodel = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10))\nopt = tz.Optimizer(\n    model.parameters(),\n    tz.m.NaturalGradient(),\n    tz.m.LR(3e-2)\n)\n\nfor i in range(100):\n    y_hat = model(X) # (64, 10)\n    losses = (y_hat - y).pow(2).mean(0) # (10, )\n    opt.step(loss=losses)\n    if i % 10 == 0:\n        print(f'{losses.mean() = }')\n</pre> X = torch.randn(64, 20) y = torch.randn(64, 10)  model = nn.Sequential(nn.Linear(20, 64), nn.ELU(), nn.Linear(64, 10)) opt = tz.Optimizer(     model.parameters(),     tz.m.NaturalGradient(),     tz.m.LR(3e-2) )  for i in range(100):     y_hat = model(X) # (64, 10)     losses = (y_hat - y).pow(2).mean(0) # (10, )     opt.step(loss=losses)     if i % 10 == 0:         print(f'{losses.mean() = }') <pre>losses.mean() = tensor(1.1702, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.8838, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.6578, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.4738, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.3156, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.2008, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.1394, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.0933, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.0734, grad_fn=&lt;MeanBackward0&gt;)\nlosses.mean() = tensor(0.0644, grad_fn=&lt;MeanBackward0&gt;)\n</pre> In\u00a0[\u00a0]: Copied! <pre>func = FunctionDescent('ill4')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.experimental.FFTProjection(\n        [tz.m.MARSCorrection(), tz.m.Adan(0.7), tz.m.SOAP(0.3),  tz.m.NAG(-0.9), tz.m.LR(2e-1)]\n    )\n)\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('ill4') optimizer = tz.Optimizer(     func.parameters(),     tz.m.experimental.FFTProjection(         [tz.m.MARSCorrection(), tz.m.Adan(0.7), tz.m.SOAP(0.3),  tz.m.NAG(-0.9), tz.m.LR(2e-1)]     ) ) func.run(optimizer, max_steps=500) func.plot(log_contour=True) <pre>finished in 1.6s., reached loss = 1.31e-07                                      \n</pre> Out[\u00a0]: <pre>&lt;Axes: &gt;</pre>"},{"location":"overview/3.%20Adaptive%20methods/#3-adaptive-methods","title":"3. Adaptive methods\u00b6","text":"<p>Adaptive methods use an adaptive per-parameter step size. Most of them are well suited for large scale stochastic optimization, i.e. training neural nets.</p>"},{"location":"overview/3.%20Adaptive%20methods/#31-adagrad","title":"3.1 Adagrad\u00b6","text":"<p>Adagrad divides the gradient by square root of sum of squares of past gradients, making step size for weights where gradients have been large smaller and vice versa. The update is: $$ v_t \\leftarrow v_{t-1} + \\nabla f(x_t)^2 $$ $$ x_{t+1} \\leftarrow x_t - \\eta \\frac{\\nabla f(x_t)}{\\sqrt{v_t + \\epsilon}} $$</p> <p>Here $\\eta$ is the step size, $v$ accumulates square gradients, and $\\epsilon$ is a small scalar added to avoid division by 0.</p> <p>This is actually the diagonal version of Adagrad, the full version and approximations to it are described later in this notebook.</p> <p>Reference: Duchi, J., Hazan, E., &amp; Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(7)</p>"},{"location":"overview/3.%20Adaptive%20methods/#32-rmsprop","title":"3.2 RMSprop\u00b6","text":"<p>A drawback of Adagrad simple accumulation doesn't forget old gradients that might be no longer relevant. RMSprop solves this by replacing sum of squares of past gradients with an exponential moving average.</p> <p>$$ v_t \\leftarrow \\beta v_{t-1} + (1 - \\beta) \\nabla f(x_t)^2 $$ $$ x_{t+1} \\leftarrow x_t - \\eta \\frac{\\nabla f(x_t)}{\\sqrt{v_t + \\epsilon}} $$</p> <p>Here $\\beta$ is the smoothing hyperparameter that determines how fast old gradients are forgotten, default value is 0.99. If $\\beta=0$, RMSprop becomes equivalent to SignGD, that is it uses the sign of the gradient.</p> <p>Reference: Hinton, Geoffrey, Nitish Srivastava, and Kevin Swersky. \"Neural networks for machine learning lecture 6a overview of mini-batch gradient descent.\" Cited on 14.8 (2012): 2.</p>"},{"location":"overview/3.%20Adaptive%20methods/#33-adam","title":"3.3 Adam\u00b6","text":"<p>Adam is a modification to RMSprop where instead of dividing the gradients, it divides an exponential moving average of gradients, i.e. momentum.</p> <p>It also applies debiasing to both exponential moving averages, explained below.</p> <p>At step $k$ (with $k$ starting from 1) the update rule is: $$ \\text{update exponential moving average of gradients:}\\\\\\\\ m_t \\leftarrow \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla f(x_t) $$ $$ \\text{update exponential moving average of squared gradients:}\\\\\\\\ v_t \\leftarrow \\beta_2 v_{t-1} + (1 - \\beta_2) \\nabla f(x_t)^2 $$ $$ \\text{compute debiased  exponential moving averages } \\hat{m_t} \\text{ and } \\hat{v_t} \\text{:} \\\\\\\\ \\hat{m}_{t} = m_t / (1 - \\beta_1^k)\\\\\\\\ \\hat{v}_{t} = v_t / (1 - \\beta_2^k)\\\\\\\\ $$</p> <p>$$ \\text{update parameters:}\\\\\\\\ x_{t+1} \\leftarrow x_t - \\eta \\frac{\\hat{m}_{t}}{\\sqrt{\\hat{v}_{t} + \\epsilon}} $$ Here $\\beta_1$ controls gradient momentum and $\\beta_2$ controls momentum of squared gradients. The defaults are $\\beta_1 = 0.9, \\beta_2 = 0.999, \\epsilon = 10^{-8}$.</p> <p>The debiasing is useful because exponential moving averages $m_0$ and $v_0$ are initialized with zeros, therefore they are biased towards zero.</p> <p>Consider the first step with $\\beta_2=0.999$, then exponential moving average of squared gradients is $v_1 = 0.999 \\cdot v_0 + 0.001 \\cdot \\nabla f(x_t)^2 = 0.001 \\cdot \\nabla f(x_t)^2$. It has very small values, so when we divide by it's square root in $\\frac{m_{t}}{\\sqrt{v_{t} + \\epsilon}}$, the update magnitude becomes way too large for first few steps.</p> <p>Now with debiasing, the bias-corrected exponential moving average of squared gradients on first step is $\\hat{v}_1 = \\frac{0.001 \\cdot \\nabla f(x_t)^2}{0.001} = \\nabla f(x_t)^2$. It is no longer 1000 times smaller than it should be, so updates are no longer excessively big.</p> <p>$m_t$ is debiased for the same purpose, without debiasing it is smaller than it should be.</p> <p>This is called debiasing because $m_t$ is a biased estimate of the mean of past gradients, and $v_t$ is a biased estimate of variance. And debiasing makes them unbiased.</p> <p>Reference: Kingma, D. P., &amp; Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980</p>"},{"location":"overview/3.%20Adaptive%20methods/#34-adahessian","title":"3.4 AdaHessian\u00b6","text":"<p>AdaHessian is very similar to Adam, except squared gradients are replaced by squared randomized estimates of the hessian diagonal.</p> <p>$$ m_t \\leftarrow \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla f(x_t) $$ $$ D = diag(\\mathbf{H}) = \\mathbb{E}[\\mathbb{z} \\odot \\mathbf{H}\\mathbf{z}] \\approx z \\odot Hz $$ $$ v_t \\leftarrow \\beta_2 v_{t-1} + (1 - \\beta_2) D^2 $$ $$ x_{t+1} \\leftarrow x_t - \\eta \\frac{m_t}{\\sqrt{v_t + \\epsilon}} $$ Here $z$ is a random Rademacher vector, and D is approximated as $z \\odot Hz$, meaning element-wise multiplication of $z$ and hessian-vector product $Hz$. Most automatic differentiation frameworks such as PyTorch allow computing hessian-vector products without having to compute full hessian, alternatively hessian-vector product can be estimated using finite difference with one extra gradient calculation.</p> <p>Reference: Yao, Zhewei, et al. \"Adahessian: An adaptive second order optimizer for machine learning.\" proceedings of the AAAI conference on artificial intelligence. Vol. 35. No. 12. 2021.</p>"},{"location":"overview/3.%20Adaptive%20methods/#35-sophiag-esgd","title":"3.5 SophiaG, ESGD\u00b6","text":"<p>SophiaG[1] and ESGD (Equilibrated stochastic gradient descent)[2] also use hessian-vector products with random vectors. SophiaG is similar to AdaHessian, but hessian-vector products are with normally distributed random vectors, their products with vectors are not squared, and agressive clipping of the update is used. ESGD is essentially Adagrad with squared gradients replaced by squared hessian-vector products.</p> <p>[1] Liu, Hong, et al. \"Sophia: A scalable stochastic second-order optimizer for language model pre-training.\" arXiv preprint arXiv:2305.14342 (2023).</p> <p>[2] Dauphin, Yann, Harm De Vries, and Yoshua Bengio. \"Equilibrated adaptive learning rates for non-convex optimization.\" Advances in neural information processing systems 28 (2015).</p>"},{"location":"overview/3.%20Adaptive%20methods/#36-lion","title":"3.6 Lion\u00b6","text":"<p>Lion (EvoLved Sign Momentum) is a method discovered by an evolutionary search of optimization algorithms. It essentially uses sign of dampened momentum.</p> <p>$$ d_t = sign(\\beta_1 v_{t-1} + (1 - \\beta_1) \\nabla f(x_t)) $$ $$ v_t \\leftarrow \\beta_2 v_{t-1} + (1 - \\beta_2) \\nabla f(x_t) $$ $$ x_{t+1} \\leftarrow x_t - \\eta d_t $$</p> <p>Reference: Chen, Xiangning, et al. \"Symbolic discovery of optimization algorithms.\" Advances in neural information processing systems 36 (2023): 49205-49233.</p>"},{"location":"overview/3.%20Adaptive%20methods/#37-grams","title":"3.7 Grams\u00b6","text":"<p>Grams is Adam, except it uses magnitute of Adam's update, and sign of the gradient. Similar modification can be applied to any other momentum-based optimizer.</p> <p>Reference: Cao, Yang, Xiaoyu Li, and Zhao Song. \"Grams: Gradient descent with adaptive momentum scaling.\" arXiv preprint arXiv:2412.17107 (2024).</p>"},{"location":"overview/3.%20Adaptive%20methods/#38-laprop","title":"3.8 LaProp\u00b6","text":"<p>LaProp, like Adam, is a version of RMSprop with momentum and Adam debiasing. LaProp first divides gradient by the exponential moving average of squared gradients, and then tracks an exponential moving average of that update.</p> <p>Reference: Ziyin, Liu, Zhikang T. Wang, and Masahito Ueda. \"LaProp: Separating momentum and adaptivity in Adam.\" arXiv preprint arXiv:2002.04839 (2020).</p>"},{"location":"overview/3.%20Adaptive%20methods/#39-adan","title":"3.9 Adan\u00b6","text":"<p>Adan (Adaptive nesterov momentum). Adan combines Nesterov's momentum with adaptive per-parameter learning rates and is suggested for large-batch optimization. The update rule is quite long so here is a screenshot from the paper. </p> <p>Reference: Xie, Xingyu, et al. \"Adan: Adaptive nesterov momentum algorithm for faster optimizing deep models.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 46.12 (2024): 9508-9520.</p>"},{"location":"overview/3.%20Adaptive%20methods/#310-mars","title":"3.10 MARS\u00b6","text":"<p>MARS (Make vAriance Reduction Shine) is a variance reduction method which can actually be applied to any other optimizer. It calculates a variance-reduced gradient as follows: $$ c_t = f(x_t, \\xi_t) + \\gamma * \\frac{\\beta}{1 - \\beta} * (\\nabla f(x_t, \\xi_t) - \\nabla f(x_{t-1}, \\xi_t)) $$ $$ \\text{if } ||c_t||_2 &gt; 1, \\text{then } c_t \\rightarrow \\frac{c_t}{||c_t||_2} $$ Here $c_t$ is variance-reduced gradient that can be passed to another optimizer, $\\beta$ should be set to the same value as momentum hyperparameter the optimizer, and $\\gamma$ is a hyperparameter controlling scale of the correction.</p> <p>$\\nabla f(x_t, \\xi_t)$ means gradient at parameters $x_t$ with mini-batch $\\xi_t$. If you look at first formula, it also requires $\\nabla f(x_{t-1}, \\xi_t)$ - gradient at previous parameters $x_{t-1}$ and current mini-batch $\\xi_t$. Funny enough, authors suggest to replace $f(x_{t-1}, \\xi_t)$ with an approximation $f(x_{t-1}, \\xi_{t-1})$ that doesn't require an extra evaluation, and it performs just as well in their experiments despite essentially not doing any variance reduction anymore. Nonetheless whatever MARS correction does appears to consistently speed Adam up.</p> <p>Reference: Yuan, Huizhuo, et al. \"Mars: Unleashing the power of variance reduction for training large models.\" arXiv preprint arXiv:2411.10438 (2024).</p>"},{"location":"overview/3.%20Adaptive%20methods/#311-rprop","title":"3.11 Rprop\u00b6","text":"<p>Rprop uses only the sign of the gradient. It uses a per-parameter adaptive learning rate - if gradient sign for a weight changed after updating parameters, the learning rate for that weight is reduced and the update for that weight is undone, otherwise the learning rate is increased. Rprop requires essentially no tuning, as the learning rates are adapted automatically.</p> <p>Because it uses differences in gradients, it is not suitable for stochastic optimization. However it can be a very strong method for non-stochastic tasks, for example in my experiments it outperformed L-BFGS on training PINNs, although SOAP then beat both.</p> <p>Reference: Riedmiller, Martin, and Heinrich Braun. \"A direct adaptive method for faster backpropagation learning: The RPROP algorithm.\" IEEE international conference on neural networks. IEEE, 1993.</p>"},{"location":"overview/3.%20Adaptive%20methods/#312-full-matrix-adagrad","title":"3.12 Full-matrix Adagrad\u00b6","text":"<p>The full-matrix version of Adagrad uses the following update rule: $$ F_t \\leftarrow F_{t-1} + \\nabla f(x_t) \\nabla f(x_t)^T $$ $$ x_{t+1} \\leftarrow x_t - F_t^{-1/2}\\nabla f(x) $$</p> <p>On each step it adds outer product of the gradient with itself to the accumulator $F$, and calculates the update as inverse square root of $F$ times gradient.</p> <p>What that does is similar ZCA whitening. If we consider a dataset of all past gradients, accumulator $F$ is the empirical covariance matrix of that dataset. ZCA whitening would center the dataset and multiply it by $F^{-1/2}$, which makes covariance matrix of the new transformed dataset identity. Full matrix Adagrad is the same except it doesn't center.</p> <p>In order to demonstrate the power of full-matrix Adagrad we will use the rotated quadratic function, defined as $$ f(x,y) = x^2 + y^2 + 1.99 * x * y $$</p> <p>This is a very hard function, and because it is rotated (i.e. large off-diagonal hessian elements), diagonal methods take a large number of steps to converge (even Adam). Full-matrix Adagrad, however, takes a straight path towards the minima, minimizing the function in less steps.</p>"},{"location":"overview/3.%20Adaptive%20methods/#313-full-matrix-adam","title":"3.13 Full-matrix Adam\u00b6","text":"<p>In torchzero <code>FullMatrixAdagrad</code> is flexible and allows to define a full-matrix version of many other algorithms. Recall that Adam applies preconditioning to momentum, and uses exponential moving average instead of sum. In torchzero many algorithms that implement preconditioning have an <code>inner</code> argument, which accepts modules that the preconditioning will be applied to instead of the gradient, and we can put <code>tz.m.EMA</code> in it.</p> <p>Since we are using Adam, we can up the difficulty of the function by making it even more stretched: $$ f(x,y) = x^2 + y^2 + 1.999 * x * y $$</p>"},{"location":"overview/3.%20Adaptive%20methods/#314-shampoo","title":"3.14 Shampoo\u00b6","text":"<p>Big drawback of Full-matrix Adagrad is that it requires storing a large $n \\times n$ matrix and calculating its inverse square root, so it is really only feasible under around 5,000 parameters. Various methods exist that approximate G, for example Shampoo, SM3.</p> <p>Shampoo utilizes the tensor structure of the parameters - for a $H \\times W$ parameter it computes a kronecker approximation of the covariance matrix.</p> <p>Shampoo update for a matrix parameter $X_t$ with gradien $G_t$ is as follows: $$ G_t = \\nabla f(X_t) \\\\\\\\ L_t \\leftarrow L_{t-1} + GG^T \\\\\\\\ R_t \\leftarrow R_{t-1} + G^TG \\\\\\\\ X_{t+1} \\leftarrow X_t - \\eta L_t^{-1/4} G_t R_t^{-1/4} $$</p> <p>Here the covariance approximation is stored as $L_t \\otimes R_t$, where $\\otimes$ denotes Kronecker product. We need inverse square root of covariance, and by a property of Kronecker product for any two matrices $A$ and $B$ and for any power $p$ it holds that $(A \\otimes B) ^ p = A^p \\otimes B^p$, therefore $(L_t \\otimes R_t) ^ {-1/2} = L_t^{-1/2}\\otimes R_t^{-1/2}$. Note that Shampoo (for some reason) uses $-1/(2*d)$ power, where $d$ is number of dimensions in the tensor, but $-1/2$ is also possible and has been suggested in some other papers.</p> <p>Shampoo is also defined in a similar way for tensor parameters (with dimension larger than 2).</p> <p>Shampoo is available in torchzero as <code>tz.m.Shampoo</code>. Similarly to <code>tz.m.FullMatrixAdagrad</code>, it is flexible and allows defining Shampoo-versions of various algorithms.</p> <p>On a two-dimensional function Shampoo is equivalent to full-matrix Adagrad, so we can't really visualize it.</p> <p>Reference: Gupta, Vineet, Tomer Koren, and Yoram Singer. \"Shampoo: Preconditioned stochastic tensor optimization.\" International Conference on Machine Learning. PMLR, 2018.</p>"},{"location":"overview/3.%20Adaptive%20methods/#315-ggt","title":"3.15 GGT\u00b6","text":"<p>GGT stores a history of past $k$ gradients and computes an update similar to full-matrix Adagrad on those past $k$ gradients, so it is a rank-$k$ preconditioner. There is quite a lot of math, a basic explanation is that because sum of past $k$ gradients is a rank-$k$ matrix, it's eigendecomposition can be computed cheaply without ever forming the full matrix.</p> <p>Consider $F$ - empirical covariance matrix of gradients in full-matrix Adagrad, after $k$ steps. Recall that on each step outer product of gradient with itself is added to $F$. If $F$ was initialized to zeros, after $k$ steps $F$ will be a sum of $k$ outer products - a rank-$k$ matrix.</p> <p>If we stack past $k$ gradients and stack them as columns of $G\\in \\mathbb{R}^{d\\times k}$, then $F=G G^T$. We would like to compute inverse square root of $F$ in order to compute full-matrix Adagrad update rule - $x_{t+1} \\leftarrow x_t - F_t^{-1/2}\\nabla f(x)$. Now because $F$ is low rank, it only has $\\text{k}$ non-zero eigenvalues and all other eigenvalues are zero, so inverse root is undefined - this is not the case in true full-matrix Adagrad because $F$ is usually initialized as identity matrix.</p> <p>However we can simply ignore all zero eigenvalues, and that leads to an efficient update rule. Nonzero eigenvalues and corresponding eigenvectors of a rank-$k$ marix $G^T G$ can be computed efficiently by computing eigendecomposition of a $k \\times k$ matrix $G^T G$.</p> <p>To understand how, consider SVD decomposition of $G$, which decomposes it into $U \\Sigma V^H$. Factors in SVD have the property that if we take any matrix $A$ and compute it's SVD: $A = U \\Sigma V^H$, the left-singular vectors (columns of\u00a0$U$) are eigenvectors of\u00a0$AA^T$; The non-zero singular values (non-zero diagonal elements of\u00a0$\\Sigma$) are the square roots of the non-zero eigenvalues of both\u00a0$A^TA$\u00a0and\u00a0$AA^T$. Therefore in order to compute nonzero eigenvalues and eigenvectors of $G G^T$, we need $U$ and $\\Sigma$ from SVD of tall matrix $G$. Factors $U$ and $\\Sigma$ from SVD of any tall matrix $A$ can be computed more cheaply through eigendecomposition of $A^T A$ - derivation of this is given in step 6 of the algorithm.</p> <p>There update rule:</p> <ol> <li>take past $k$ gradient vectors and stack them as columns into a single matrix $G\\in \\mathbb{R}^{d\\times k}$, where $d$ is dimensionality of the problem.</li> <li>calculate $M = G^TG$, which is a ${k\\times k}$ matrix.</li> <li>add damping to $M$: $$  M = N + I * \\lambda  $$ Here $\\lambda$ is the damping hyperparameter, can be some small value like 1e-6.</li> <li>Calculate eigendecomposition of $M$ $$  Q\u039bQ^T =\\text{eigh}(M)  $$</li> <li>Compute U $$  U = GQ\\sqrt{\u039b}  $$</li> <li>So now we have $U$ and $\\Sigma$ from SVD(G), but computed more efficiently. We want to compute $(GG^T)^{-1/2}$, which can be expressed through SVD of $G$: $$  GG^T = (U \\Sigma V^T)(U \\Sigma V^T)^T = U \\Sigma V^T V \\Sigma^T U^T = U \\Sigma^2 U^T \\\\\\\\  (GG^T)^{-1/2} = (U \\Sigma^2 U^T)^{-1/2} = U (\\Sigma^2)^{-1/2} U^T = U \\Sigma^{-1} U^T  $$ therefore the update rule is $$  x_{t+1} \\leftarrow x_t - \\eta U_t \u039b_t^{-1/2} U_t^T \\nabla f(x_t)  $$</li> </ol> <p>Reference: Agarwal N. et al. Efficient full-matrix adaptive regularization //International Conference on Machine Learning. \u2013 PMLR, 2019. \u2013 \u0421. 102-110.</p>"},{"location":"overview/3.%20Adaptive%20methods/#316-muon","title":"3.16 Muon\u00b6","text":"<p>Muon (MomentUm Orthogonalized by Newton-Schulz) is an optimization algorithm made specifically for matrix parameters - ones that are involved in matrix multiplications. In a typical neural network a linear layer, a convolutional layer, and Q, K and V in a transformer layer are examples of such parameters.</p> <p>Muon approximately orthogonalizes the update for those parameters using an efficient Newton-Schulz iteration. The motivation behind this can be found in author's blogpost - https://kellerjordan.github.io/posts/muon/. In Muon orthogonalization is applied to nesterov's momentum, and non-matrix parameters are optimized using some other optimizer, for example Adam. Muon (ignoring momentum) is also equivalent to memoryless Shampoo where the accumulators are reset after each step.</p> <p>Since Muon only works on matrices, we can't easily visualize it on our 2D function, so I will just give an example of how Muon is constructed.</p> <p>Authors suggest that embeddings, classifier heads, hidden gains/biases and first convolutional layer should be optimized using standard AdamW. Embeddings are not involved in matrix multiplications, while the other recommendations are empirical.</p> <p>In torchzero orthogonalization with a Newton-Schulz solver is implemented as <code>Orthogonalize</code> module. Parameters can be split by using the <code>Split</code> module based on a filter. The filter can either be a callable, a parameter itself, or a list of filters.</p> <p>For example to select 2D+ parameters to optimize with Muon we can do this:</p> <pre>filter = lambda x: x.ndim &gt;= 2\n</pre> <p>or to be more specific, pass an iterable of specific tensors for Muon:</p> <pre>filter = (model.c2.weight, model.c3.weight)\n</pre>"},{"location":"overview/3.%20Adaptive%20methods/#317-soap","title":"3.17 SOAP\u00b6","text":"<p>SOAP (ShampoO with Adam in the Preconditioner\u2019s eigenbasis) runs Adam in the eigenbasis of Shampoo\u2019s preconditioner. SOAP is more stable, computationally efficient and convergent than Shampoo. The update rule is quite long so here is a screenshot from the paper.</p> <p></p> <p>SOAP projects gradients to Shampoo's eigenbasis where $\\mathbb{E}(\\nabla f(x_t) \\nabla f(x_t)^T)$ approximates a diagonal matrix, i.e. gradients for each weight are decorellated. It then applies Adam's update rule to projected gradients. Since projected gradients have approximately diagonal covariance matrix, Adam's diagonal preconditioning captures most of the variance and sets it to 1. Gradients are then un-projected which should give approximately identity covariance matrix.</p> <p>It is able to minimize even the most extreme version of the rotated quadratic function in few steps:</p> <p>$$ f(x,y) = x^2 + y^2 + 1.999999 * x * y $$</p> <p>No other adaptive method is able to minimize this, even quasi-newton methods tend to fail due to extremely large condition number of the hessian.</p> <p>Reference: Vyas, Nikhil, et al. \"SOAP: Improving and Stabilizing Shampoo using Adam.\" arXiv preprint arXiv:2409.11321 (2024).</p>"},{"location":"overview/3.%20Adaptive%20methods/#318-natural-gradient","title":"3.18 Natural gradient\u00b6","text":"<p>Natural gradient uses Fisher information matrix (FIM) as the preconditioner, and once I manage to understand what FIM does, I will promptly attempt to explain it here.</p> <p>Typically we don't have access to FIM. However an approximation exists when we are training a model on a batch of samples, called empirical fisher information matrix (EFIM).</p> <p>Given $k$ samples, we calculate $k$ per-sample gradients and stack them into a matrix $G\\in \\mathbb{R}^{d\\times k}$.</p> <p>Then empirical fisher is calculated as $F = GG^T$.</p> <p>The update is then calculated as: $$ x_{t+1} \\leftarrow x_t - \\eta F_t^{-1}\\nabla f(x_t) $$</p> <p>You might recognize that this is very similar to full-matrix Adagrad, except for some reason it doesn't have a square root.</p> <p>In practice since $F=GG^T$ is a low rank matrix so we don't need to explicitly form it, torchzero implements a more efficient way to calculate $F^{-1}\\nabla f(x)$ and thus doesn't use $N^2$ memory.</p> <p>Since natural gradient requires training on samples, we can't really visualize it on a 2D function. Instead here is a basic training example.</p> <p>We pass <code>loss=losses</code> to <code>opt.step</code>, and it takes care of calculating a batch of gradients. The gradients are calculated in batched mode.</p>"},{"location":"overview/3.%20Adaptive%20methods/#319-combinations","title":"3.19 Combinations\u00b6","text":"<p>If one desires, one can create an abomination by chaining various optimizers together, although the practicality of such approach is questionable.</p>"},{"location":"overview/3.%20Adaptive%20methods/#320-what-should-i-use","title":"3.20 What should I use?\u00b6","text":"<p>I can suggest a very strong baseline:</p> <pre>opt = tz.Optimizer(\n    model.parameters(),\n    tz.m.SOAP(),\n    tz.m.ClipNormByEMA(max_ema_growth=1.2),\n    tz.m.RelativeWeightDecay(1e-2),\n    tz.m.LR(lr).\n)\n</pre> <p>Muon can also have very good performance on some models, and it is much cheaper to compute than SOAP.</p> <p>Another strong baseline is PSGD Kron, although it has not yet been implemented in torchzero.</p>"},{"location":"overview/4.%20Second%20order%20methods/","title":"4. Second order methods","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n\n# GD\nfunc = FunctionDescent('ill1')\noptimizer = tz.Optimizer(func.parameters(), tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"GD (500 steps)\")\n\n# Newton\nfunc = FunctionDescent('ill1')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Newton(), tz.m.LR(1))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Newton (1 step)\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6))  # GD func = FunctionDescent('ill1') optimizer = tz.Optimizer(func.parameters(), tz.m.LR(1e-1)) func.run(optimizer, max_steps=500) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"GD (500 steps)\")  # Newton func = FunctionDescent('ill1') optimizer = tz.Optimizer(func.parameters(), tz.m.Newton(), tz.m.LR(1)) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Newton (1 step)\")  plt.show() <pre>finished in 0.5s., reached loss = 0.000146                                      \nfinished in 0.2s., reached loss = 0                                      \n</pre> In\u00a0[3]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(),\n    tz.m.Backtracking()\n)\nfunc.run(optimizer, max_steps=25)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(),     tz.m.Backtracking() ) func.run(optimizer, max_steps=25) func.plot(log_contour=True) <pre>finished in 0.1s., reached loss = 0                                      \n</pre> Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.LevenbergMarquardt(tz.m.Newton()),\n)\nfunc.run(optimizer, max_steps=25)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.LevenbergMarquardt(tz.m.Newton()), ) func.run(optimizer, max_steps=25) func.plot(log_contour=True) <pre>finished in 0.1s., reached loss = 0                                      \n</pre> Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(18,6))\nax = np.ravel(ax)\n\n# --------------------------------- standard --------------------------------- #\nfunc = FunctionDescent('star')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(),\n    tz.m.Normalize(2e-1)\n)\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Standard Newton flow (gets stuck)\")\n\nfunc = FunctionDescent('star')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(damping=10),\n    tz.m.Normalize(2e-1)\n)\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Newton flow with damping\")\n\n# ------------------------------ absolute value ------------------------------ #\nfunc = FunctionDescent('star')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(eigval_fn=lambda x: x.abs().clip(min=1e-8)),\n    tz.m.Normalize(2e-1)\n)\nfunc.run(optimizer, max_steps=250)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"Newton flow with absolute eigenvalues\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(18,6)) ax = np.ravel(ax)  # --------------------------------- standard --------------------------------- # func = FunctionDescent('star') optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(),     tz.m.Normalize(2e-1) ) func.run(optimizer, max_steps=1000) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Standard Newton flow (gets stuck)\")  func = FunctionDescent('star') optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(damping=10),     tz.m.Normalize(2e-1) ) func.run(optimizer, max_steps=500) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Newton flow with damping\")  # ------------------------------ absolute value ------------------------------ # func = FunctionDescent('star') optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(eigval_fn=lambda x: x.abs().clip(min=1e-8)),     tz.m.Normalize(2e-1) ) func.run(optimizer, max_steps=250) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"Newton flow with absolute eigenvalues\")  plt.show() <pre>finished in 3.0s., reached loss = 42.034                                      \nfinished in 1.3s., reached loss = 0.0177                                      \nfinished in 0.7s., reached loss = 0.0175                                      \n</pre> In\u00a0[6]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.ImprovedNewton(),\n    tz.m.Backtracking(),\n)\nfunc.run(optimizer, max_steps=25)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.ImprovedNewton(),     tz.m.Backtracking(), ) func.run(optimizer, max_steps=25) func.plot(log_contour=True) <pre>finished in 0.1s., reached loss = 1.42e-12                                      \n</pre> Out[6]: <pre>&lt;Axes: &gt;</pre> In\u00a0[7]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(update_freq=10, precompute_inverse=True),\n    tz.m.LR(1e-1),\n)\nfunc.run(optimizer, max_steps=1000)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(update_freq=10, precompute_inverse=True),     tz.m.LR(1e-1), ) func.run(optimizer, max_steps=1000) func.plot(log_contour=True) <pre>finished in 1.2s., reached loss = 5.68e-14                                      \n</pre> Out[7]: <pre>&lt;Axes: &gt;</pre> In\u00a0[8]: Copied! <pre>func = FunctionDescent('convex43')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.InverseFreeNewton()\n)\nfunc.run(optimizer, max_steps=20)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('convex43') optimizer = tz.Optimizer(     func.parameters(),     tz.m.InverseFreeNewton() ) func.run(optimizer, max_steps=20) func.plot(log_contour=True) <pre>finished in 0.1s., reached loss = 0.000658                                      \n</pre> Out[8]: <pre>&lt;Axes: &gt;</pre> In\u00a0[9]: Copied! <pre>DIM = 1_000_000\ndevice = 'cuda' if torch.cuda.is_available() else None\ngenerator = torch.Generator(device).manual_seed(0)\n\ndef quartic(x:torch.Tensor, y):\n    x = x+y\n    return x[1:].pow(4).mean() + x[:-1].mean().pow(4) + x[::2].pow(2).mean() + x[1::2].mean().pow(2)\n\nX = torch.randn(DIM, requires_grad=True, device=device, generator=generator)\ny = torch.randn(DIM, device=device, generator=generator)\n\nopt = tz.Optimizer(\n    [X],\n    tz.m.SubspaceNewton(sketch_size=100, sketch_type='common_directions'),\n    tz.m.Backtracking()\n)\n\ndef closure(backward=True):\n    loss = quartic(X, y)\n    if backward:\n        opt.zero_grad()\n        loss.backward()\n    return loss\n\nfor i in range(1,101):\n    loss = opt.step(closure)\n    if i % 10 == 0: \n        print(f'{i}: {loss = }')\n</pre> DIM = 1_000_000 device = 'cuda' if torch.cuda.is_available() else None generator = torch.Generator(device).manual_seed(0)  def quartic(x:torch.Tensor, y):     x = x+y     return x[1:].pow(4).mean() + x[:-1].mean().pow(4) + x[::2].pow(2).mean() + x[1::2].mean().pow(2)  X = torch.randn(DIM, requires_grad=True, device=device, generator=generator) y = torch.randn(DIM, device=device, generator=generator)  opt = tz.Optimizer(     [X],     tz.m.SubspaceNewton(sketch_size=100, sketch_type='common_directions'),     tz.m.Backtracking() )  def closure(backward=True):     loss = quartic(X, y)     if backward:         opt.zero_grad()         loss.backward()     return loss  for i in range(1,101):     loss = opt.step(closure)     if i % 10 == 0:          print(f'{i}: {loss = }') <pre>10: loss = tensor(0.0063, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n20: loss = tensor(7.3890e-06, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n30: loss = tensor(1.5572e-07, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n40: loss = tensor(1.3818e-08, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n50: loss = tensor(2.0171e-09, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n60: loss = tensor(1.0680e-10, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n70: loss = tensor(2.7088e-11, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n80: loss = tensor(1.1783e-11, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n90: loss = tensor(3.1855e-12, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n100: loss = tensor(1.8520e-12, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n</pre> In\u00a0[10]: Copied! <pre>DIM = 100_000\n\nX = torch.randn(DIM, requires_grad=True, device=device, generator=generator)\ny = torch.randn(DIM, device=device, generator=generator)\n\nopt = tz.Optimizer(\n    [X],\n    tz.m.LevenbergMarquardt(\n        tz.m.NystromSketchAndSolve(rank=200)\n    ),\n)\n\ndef closure(backward=True):\n    loss = quartic(X, y)\n    if backward:\n        opt.zero_grad()\n        loss.backward()\n    return loss\n\nfor i in range(1,101):\n    loss = opt.step(closure)\n    if i % 10 == 0:\n        print(f'{i}: {loss = }')\n</pre> DIM = 100_000  X = torch.randn(DIM, requires_grad=True, device=device, generator=generator) y = torch.randn(DIM, device=device, generator=generator)  opt = tz.Optimizer(     [X],     tz.m.LevenbergMarquardt(         tz.m.NystromSketchAndSolve(rank=200)     ), )  def closure(backward=True):     loss = quartic(X, y)     if backward:         opt.zero_grad()         loss.backward()     return loss  for i in range(1,101):     loss = opt.step(closure)     if i % 10 == 0:         print(f'{i}: {loss = }') <pre>10: loss = tensor(9.8789, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n20: loss = tensor(5.3773, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n30: loss = tensor(2.6538, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n40: loss = tensor(1.6732, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n50: loss = tensor(1.1763, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n60: loss = tensor(0.5428, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n70: loss = tensor(0.2867, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n80: loss = tensor(0.1719, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n90: loss = tensor(0.1107, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n100: loss = tensor(0.0748, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n</pre> In\u00a0[11]: Copied! <pre>DIM = 10_000_000\nX = torch.randn(DIM, requires_grad=True, device=device, generator=generator)\ny = torch.randn(DIM, device=device, generator=generator)\n\nopt = tz.Optimizer([X], tz.m.NewtonCG(tol=1e-8), tz.m.Backtracking())\n\ndef closure(backward=True):\n    loss = quartic(X, y)\n    if backward:\n        opt.zero_grad()\n        loss.backward()\n    return loss\n\nfor i in range(1,11):\n    loss = opt.step(closure)\n    print(f'{i}: {loss = }')\n</pre> DIM = 10_000_000 X = torch.randn(DIM, requires_grad=True, device=device, generator=generator) y = torch.randn(DIM, device=device, generator=generator)  opt = tz.Optimizer([X], tz.m.NewtonCG(tol=1e-8), tz.m.Backtracking())  def closure(backward=True):     loss = quartic(X, y)     if backward:         opt.zero_grad()         loss.backward()     return loss  for i in range(1,11):     loss = opt.step(closure)     print(f'{i}: {loss = }') <pre>1: loss = tensor(13.9965, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n2: loss = tensor(2.8959, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n3: loss = tensor(0.5915, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n4: loss = tensor(0.1105, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n5: loss = tensor(0.0171, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n6: loss = tensor(0.0024, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n7: loss = tensor(0.0005, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n8: loss = tensor(0.0001, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n9: loss = tensor(3.9285e-05, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n10: loss = tensor(1.6109e-05, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n</pre> In\u00a0[12]: Copied! <pre>X = torch.randn(DIM, requires_grad=True, device=device, generator=generator)\ny = torch.randn(DIM, device=device, generator=generator)\nopt = tz.Optimizer([X], tz.m.NewtonCG(maxiter=10), tz.m.Backtracking())\n\ndef closure(backward=True):\n    loss = quartic(X, y)\n    if backward:\n        opt.zero_grad()\n        loss.backward()\n    return loss\n\nfor i in range(1,11):\n    loss = opt.step(closure)\n    print(f'{i}: {loss = }')\n</pre> X = torch.randn(DIM, requires_grad=True, device=device, generator=generator) y = torch.randn(DIM, device=device, generator=generator) opt = tz.Optimizer([X], tz.m.NewtonCG(maxiter=10), tz.m.Backtracking())  def closure(backward=True):     loss = quartic(X, y)     if backward:         opt.zero_grad()         loss.backward()     return loss  for i in range(1,11):     loss = opt.step(closure)     print(f'{i}: {loss = }') <pre>1: loss = tensor(13.9898, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n2: loss = tensor(2.9426, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n3: loss = tensor(0.6059, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n4: loss = tensor(0.1125, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n5: loss = tensor(0.0186, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n6: loss = tensor(0.0028, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n7: loss = tensor(0.0006, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n8: loss = tensor(0.0002, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n9: loss = tensor(5.1458e-05, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n10: loss = tensor(2.1671e-05, device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n</pre> In\u00a0[13]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.NewtonCGSteihaug(),\n)\nfunc.run(optimizer, max_steps=30)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.NewtonCGSteihaug(), ) func.run(optimizer, max_steps=30) func.plot(log_contour=True) <pre>finished in 0.2s., reached loss = 0.000154                                      \n</pre> Out[13]: <pre>&lt;Axes: &gt;</pre> In\u00a0[14]: Copied! <pre>func = FunctionDescent('rosen')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.experimental.HigherOrderNewton(trust_method=None),\n)\n\nfunc.run(optimizer, max_steps=2)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('rosen') optimizer = tz.Optimizer(     func.parameters(),     tz.m.experimental.HigherOrderNewton(trust_method=None), )  func.run(optimizer, max_steps=2) func.plot(log_contour=True) <pre>finished in a very short time, reached loss = 1.68e-10                                      \n</pre> Out[14]: <pre>&lt;Axes: &gt;</pre> In\u00a0[15]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\nax = np.ravel(ax)\n\n# f(x, y) = x^4 + 10|y^3| + 10(xy)^2\nf = lambda x, y: x**4 + ((10*y)**3).abs() + 10*(x*y)**2\n\n# ---------------------------------- newton ---------------------------------- #\nfunc = FunctionDescent(f, x0=(-9,-7), domain=(-10,10,-10,10))\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(),\n)\nfunc.run(optimizer, max_steps=15)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Newton\")\n\n# ------------------------------- newton-newton ------------------------------ #\nfunc = FunctionDescent(f, x0=(-9,-7), domain=(-10,10,-10,10))\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.experimental.NewtonNewton(),\n)\nfunc.run(optimizer, max_steps=4)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"NewtonNewton\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6)) ax = np.ravel(ax)  # f(x, y) = x^4 + 10|y^3| + 10(xy)^2 f = lambda x, y: x**4 + ((10*y)**3).abs() + 10*(x*y)**2  # ---------------------------------- newton ---------------------------------- # func = FunctionDescent(f, x0=(-9,-7), domain=(-10,10,-10,10)) optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(), ) func.run(optimizer, max_steps=15) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Newton\")  # ------------------------------- newton-newton ------------------------------ # func = FunctionDescent(f, x0=(-9,-7), domain=(-10,10,-10,10)) optimizer = tz.Optimizer(     func.parameters(),     tz.m.experimental.NewtonNewton(), ) func.run(optimizer, max_steps=4) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"NewtonNewton\")  plt.show() <pre>finished in 0.1s., reached loss = 6.64e-06                                      \nfinished in 0.0s., reached loss = 3.68e-20                                      \n</pre> In\u00a0[16]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(18,6))\nax = np.ravel(ax)\n\nf = lambda x, y: 100*x**4 + y**6 + (10*x + y)**2 + (x + y)**10\nfunc = FunctionDescent(f, x0=(-9,-2), domain=(-10,10,-10,10))\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(),\n)\nfunc.run(optimizer, max_steps=15)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Newton\")\n\n\nfunc = FunctionDescent(f, x0=(-9,-2), domain=(-10,10,-10,10))\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(),\n    tz.m.BFGS(),\n)\nfunc.run(optimizer, max_steps=15)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Newton-BFGS\")\n\n\nfunc = FunctionDescent(f, x0=(-9,-2), domain=(-10,10,-10,10))\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.Newton(),\n    tz.m.FullMatrixAdagrad(),\n)\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"Newton-FullMatrixAdagrad\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(18,6)) ax = np.ravel(ax)  f = lambda x, y: 100*x**4 + y**6 + (10*x + y)**2 + (x + y)**10 func = FunctionDescent(f, x0=(-9,-2), domain=(-10,10,-10,10)) optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(), ) func.run(optimizer, max_steps=15) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Newton\")   func = FunctionDescent(f, x0=(-9,-2), domain=(-10,10,-10,10)) optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(),     tz.m.BFGS(), ) func.run(optimizer, max_steps=15) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Newton-BFGS\")   func = FunctionDescent(f, x0=(-9,-2), domain=(-10,10,-10,10)) optimizer = tz.Optimizer(     func.parameters(),     tz.m.Newton(),     tz.m.FullMatrixAdagrad(), ) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"Newton-FullMatrixAdagrad\")  plt.show() <pre>finished in 0.0s., reached loss = 1827                                      \nfinished in 0.0s., reached loss = 2.19e-10                                      \nfinished in 0.3s., reached loss = 0.0638                                      \n</pre>"},{"location":"overview/4.%20Second%20order%20methods/#4-second-order-methods","title":"4. Second order methods\u00b6","text":""},{"location":"overview/4.%20Second%20order%20methods/#41-overview","title":"4.1 Overview\u00b6","text":"<p>If first order methods make use of the gradient of the objective function $\\nabla f(x_t)$, second order methods also use second order information, i.e. the hessian matrix $H_t$, which tells us about the curvature of the function and allows the optimization method to converge much quicker on a class of functions.</p> <p>The hessian matrix can be computed via autograd, or it can be estimated using just gradients, which is what quasi-newton methods do (see 5. Quasi-Newton methods). In this notebook we will review the \"true\" second order methods that use exact hessian information via autograd.</p> <p>There are two main classes of second order methods, ones that explicitly use the hessian matrix, thus requiring $N^2$ memory, and matrix-free methods that are suitable for very large scale optimization.</p> <p>In torchzero, since we rely on PyTorch autograd, Newton's method appears to be efficient under ~1000 variables. It will also depend largely on how well PyTorch can vectorize the hessian-vector products for a particular function.</p> <p>Matrix-free Newton uses about $4N$ memory because only needs to store a few variables. It is well suited for very large scale convex problems (e.g. 100,000,000 variables), however for non-convex or very badly scaled problems single step my be slow to compute and require many hessian-vector products. Modifications suitable for non-convex problems exist too.</p>"},{"location":"overview/4.%20Second%20order%20methods/#411-newtons-method","title":"4.1.1 Newton's method\u00b6","text":"<p>Newton's method, also known as Newton\u2013Raphson method, is a root-finding method used to find solutions to equation $f(x)=0$.</p> <p>In order to use Newton's method to minimize a function, we can use it to find solutions to $f'(x)=0$, i.e. the critical points (points where gradient is zero). As long as $f$ is twice-differentiable, any solution to $f'(x)=0$ is either minimum, maximum or a saddle point. Therefore if the function has maximums or saddle points, one needs to be careful as standard Newton's method may converge to them instead of the desired minimum.</p> <p>When applied to minimizing a function, the Newton iteration is: $$ x_{t+1} \\leftarrow x_t - H(x_t)^{-1}\\nabla f(x_t) $$</p> <p>So on each step inverse hessian times gradient is subtracted from parameters.</p> <p>In practice the Newton step is computed as a solution to a linear system because that is faster to compute: $$ \\text{solve:}\\\\\\\\ H(x_t)v_t = \\nabla f(x_t) $$ $$ x_{t+1} \\leftarrow x_t - v_t $$</p> <p>Another interpretation of the Newton's method is that it constructs and minimizes a quadratic approximation of the objective function. Therefore if the objective function is quadratic, the approximation will be perfect and Newton's method converges in a single step with step size of 1.</p> <p>As an example, consider the following hessian for a function of two variables $x_1$ and $x_2$: $$ \\begin{bmatrix} 10 &amp; 8\\\\ 8 &amp; 10 \\end{bmatrix} $$</p> <p>Values of this matrix are double the coefficients of the quadratic model. That is because derivative of $x^2$ is $2x$, so the function with that derivative the coefficients are divided by two. So the quadratic model given by hessian above is: $$ f(x_1, x_2) = (10x_1x_1 + 8x_1x_2 + 8x_2x_1 + 10x_2x_2) / 2 $$ Which is: $$ f(x_1, x_2) = 5x_1^2 + 5x_2^2 + 8x_1x_2 $$</p> <p>Now suppose the gradient $\\nabla f(x_t)$ is $\\frac{df}{dx_1}=6, \\frac{df}{dx_2}=-4$, so it is $[6, -4]$, the model becomes: $$ f(x_1, x_2) = \\underbrace{5x_1^2 + 5x_2^2 + 8x_1x_2}_{\\frac{1}{2}\\mathbf{x}^T H \\mathbf{x}} + \\underbrace{6x_1 - 4x_2}_{\\mathbf{g}^T \\mathbf{x}} $$</p> <p>Or in a more general form, given gradient $g$ and hessian $H$, the model is: $$ f_{\\mathbb{quad}}(v) = \\frac{1}{2}v^T H v + g^T v $$</p> <p>The model is centered around 0, so $f_{\\mathbb{quad}}(v)$ corrensponds to $f(x_t + v)$</p> <p>A Newton step with a step size of 1 minimizes this quadratic model of the objective function.</p>"},{"location":"overview/4.%20Second%20order%20methods/#412-dampened-newton","title":"4.1.2 Dampened Newton\u00b6","text":"<p>Dampened Newton is simply Newton's method with a step size that is allowed to be smaller than 1, for example it can be selected via a line search.</p> <p>$$ x_{t+1} \\leftarrow x_t - \\eta H(x_t)^{-1}\\nabla f(x_t) $$</p> <p>where $\\eta$ is the step size.</p> <p>This is often a better choice as Newton can be very unstable on some functions, especially non-convex ones.</p>"},{"location":"overview/4.%20Second%20order%20methods/#413-newton-with-trust-region","title":"4.1.3 Newton with trust region\u00b6","text":"<p>Newton can also be used with trust regions as an alternative to line searches. Some trust regions can also prevent it from being stuck on saddle points and maximums.</p>"},{"location":"overview/4.%20Second%20order%20methods/#414-newton-for-non-convex-functions","title":"4.1.4 Newton for non-convex functions\u00b6","text":"<p>As mentioned before, Newton may converge to a maximum or a saddle point instead of a minimum.</p> <p>A simple modification to avoid converging to saddle points involves adding an identity matrix multiplied by scalar $m$ to the hessian before computing the Newton step. $$ x_{t+1} \\leftarrow x_t - (H(x_t) + mI)^{-1}\\nabla f(x_t) $$ The scalar $m$ should be selected such that after adding scaled identity matrix to the hessian, all eigenvalues of the hessian become positive. Larger scalars will bring Newton step closer to a gradient descent step, thus some convergence speed may be lost. It may be hard to pick a good scalar without computing the eigendecomposition of the hessian. And if you are willing to compute the eigendecomposition, might as well use the second modification detailed below as it tends to converge much faster.</p> <p>The second modification of Newton's method to avoid converging to maxima involves modifying the eigenvalues of the hessian in some way to be positive. For example one might take absolute value of the eigenvalues or set all negative eigenvalues to some fixed positive number. A similar modification involves a modified cholesky decomposition which should be cheaper than eigendecomposition, but it isn't implemented in torchzero. Fortunately eigendecomposition is still reasonably cheap compared to cost of computing the hessian in Pytorch, plus it is re-used to invert the hessian.</p> <p>In torchzero we can pass an eigenvalue transformation into the <code>eigval_fn</code> argument, for example <code>lambda x: x.abs().clip(min=1e-6)</code>, or <code>lambda x: torch.where(x&lt;1e-8, 1, x)</code>.</p> <p>To demonstrate, we will run Newton on the following non-convex function with a saddle point: $$ f(x,y) = (x-6)^2 + (y - 0.2)^2 + (x * y - 2)^2 $$</p> <p>We will run Newton fix a small normalized step size to show the trajectory each modification takes, while noting that with a backtracking line search standard Newton also fails to minimize this function.</p>"},{"location":"overview/4.%20Second%20order%20methods/#415-improved-newtons-method","title":"4.1.5 Improved Newton's method\u00b6","text":"<p>A modification of Newton's method uses an approximated rational approximation model instead of a quadratic model, which reflects more curvature information. Screenshot from the paper:</p> <p></p> <p>Here $s_k=x_k - x_{k-1}$ and $y_k = \\nabla f(x_k) - \\nabla f(x_{k-1})$. Note that this method is described for root-finding problems; for optimization we replace values vector $F_k$ with gradient $\\nabla f(x_k)$ and jacobian $J_k$ with hessian $H(x_k)$.</p> <p>There is almost no extra computational overhead compared to Newton, and it is faster than Newton on logistic regression.</p> <p>Reference: Saheya, B., et al. \"A new Newton-like method for solving nonlinear equations.\" SpringerPlus 5.1 (2016): 1269.</p>"},{"location":"overview/4.%20Second%20order%20methods/#42-speeding-up","title":"4.2 Speeding up\u00b6","text":"<p>Newton has several big disadvantages:</p> <ul> <li>it requires to compute the hessian which in pytorch is done via $n$ (batched) hessian-vector products.</li> <li>it requires at least $n^2$ memory to store the hessian.</li> <li>it requires to solve an $n \\times n$ linear system on each step.</li> </ul> <p>There are methods to make Newton's method a little bit faster or significantly faster to compute, and there are ways to make it use significantly less memory.</p>"},{"location":"overview/4.%20Second%20order%20methods/#421-update-frequency","title":"4.2.1 Update frequency\u00b6","text":"<p>A simple but effective way to speed Newton up is to compute the hessian every $n&gt;1$ steps rather than every step, for example every 10 or every 100 steps, assuming the hessian doesn't change by too much during those steps. In this case it may be more efficient to also compute hessian inverse $H^{-1}$ and then reuse it until next hessian computation, this saves us from having to solve many linear systems.</p> <p>On large scale problems, despite requiring more steps to converge, this can take significantly less time due to computing less hessians.</p> <p>In some cases it may even be possible to compute the hessian once at the beginning and then reuse it, for root-finding this method is called the Chord method.</p>"},{"location":"overview/4.%20Second%20order%20methods/#422-inverse-free-newton","title":"4.2.2 Inverse-free Newton\u00b6","text":"<p>It is possible to skip solving the $H(x_t)v_t = \\nabla f(x_t)$ linear system and instead estimate $H^{-1}$ in a recurrent fashion, for example using following formula, where $Y_{t}$ approximates $H_t^{-1}$: $$ Y_{t} = Y_{t-1}(2I - H_t Y_{t-1}) $$ $$ x_{t+1} = {x_t} - Y_t \\nabla f(x_t) $$</p> <p>In pytorch in most cases computing the hessian uses far more time that solving the linear system, therefore the time gains from using inverse-free method is small. It is far more useful when expression for hessian (or jacobian in root-finding case) can be computed efficiently. Nontheless it is included in torchzero for completeness.</p> <p>Reference: Massalski, Marcin, and Magdalena Nockowska-Rosiak. \"INVERSE-FREE NEWTON'S METHOD.\" Journal of Applied Analysis &amp; Computation 15.4 (2025): 2238-2257.</p>"},{"location":"overview/4.%20Second%20order%20methods/#423-subspace-newton","title":"4.2.3 Subspace Newton\u00b6","text":"<p>Subspace Newton is a version of Newton's method which computes Newton's step in a smaller subspace. For example, 100-dimensional subspace means hessian is a $100 \\times 100$ matrix which is easy to store and solve the linear system, regardless of dimensionality of the problem. By computing Newton's step in a subspace, we restrict it to only be able to move within that subspace, so it doesn't converge as quickly, but with appropriate choice of subspace it can still be very fast.</p> <p>Mathematically, instead of computing full Newton's step as solution to $H_t v_t = \\nabla f(x_t)$, it computes a smaller sketched $s \\times s$ hessian matrix $S_t^T H_t S_t$, where $S_t$ is a $n \\times s$ sketching matrix, $n$ is number of variables and $s$ is sketch size, and solves $(S_t^T H_t S_t) S^T v_t = S^T \\nabla f(x_t)$.</p> <p>$H_t S_t$ can be computed in $s$ backpropagation passes or even faster by using batched hessian-vector products available in pytorch.</p> <p>The sketching matrix $S$ must be an orthonormal matrix in order for $S^T$ to undo linear transformation of $S$. Random subspace Newton[1] uses a random orthonormal matrix; method of common directions[2] uses an orthonormalized matrix made of past gradient directions.</p> <p>References:</p> <ol> <li>Gower, Robert, et al. \"RSN: randomized subspace Newton.\" Advances in Neural Information Processing Systems 32 (2019).</li> <li>Wang, Po-Wei, Ching-pei Lee, and Chih-Jen Lin. \"The common-directions method for regularized empirical risk minimization.\" Journal of Machine Learning Research 20.58 (2019): 1-49.</li> </ol> <p>Using the method of common directions we are able to solve a 1,000,000-dimensional quartic problem.</p>"},{"location":"overview/4.%20Second%20order%20methods/#424-nystrom-methods","title":"4.2.4 Nystr\u00f6m methods\u00b6","text":"<p>Nystr\u00f6m approximation of symmetric positive definite matrix $A \\in \\mathbb{R}^{m \\times m}$ outputs a rank-$k$ approximation of $A$ factored as truncated eigendecomposition - diagonal matrix $L \\in \\mathbb{R}^{k \\times k}$ with eigenvalues in the diagonal, and orthogonal matrix $Q \\in \\mathbb{R}^{m \\times k}$ with eigenvectors as columns, such that $A \\approx Q L Q^T$.</p> <p>Computing Nystr\u00f6m approximation of $A$ doesn't require $A$ itself, but it requires a matrix-matrix product of $A$ with an $m \\times k$ test matrix. In pytorch we can efficiently compute hessian-matrix product with $m \\times k$ matrix via $k$ batched hessian-vector products, therefore we can obtain Nystr\u00f6m approximation of the hessian without ever forming the full hessian. Additionally factorization as eigenvectors and eigenvalues is very convenient to work with, for example to invert it we simply take reciprocal of the eigenvalues: $(Q L Q^T)^{-1} = Q L^{-1} Q^T$.</p> <p>Nystr\u00f6m sketch-and-solve (<code>tz.m.NystromSketchAndSolve</code>) simply uses this Nystr\u00f6m approximation in place of the real hessian, alhough it solves $(Q L Q^T + \\gamma I)x = b$, where $\\gamma$ is regularization parameter, and that is slightly more involved than just taking reciprocal of the eigenvalues.</p> <p>Alternatively we can use this approximation as a preconditioner to speed up conjugate gradient on ill-conditioned objectives, that method is called Nystrom PCG (<code>tz.m.NystromPCG</code>).</p> <p>Reference: Frangella, Zachary, Joel A. Tropp, and Madeleine Udell. \"Randomized nystr\u00f6m preconditioning.\" SIAM Journal on Matrix Analysis and Applications 44.2 (2023): 718-752.</p>"},{"location":"overview/4.%20Second%20order%20methods/#425-newton-cg","title":"4.2.5 Newton-CG\u00b6","text":"<p>There are matrix-free iterative methods such as the Conjugate Gradient (CG) method that can solve a linear system by using only matrix-vector products.</p> <p>Note that this refers to the linear CG used to solve the linear system, which is different (but related) to the nonlinear CG described in 6. Conjugate gradient which is used directly to minimize objective function.</p> <p>Recall that Newton step is the solution to the following linear system: $$ H(x_t)v_t = \\nabla f(x_t) $$</p> <p>Methods like CG can solve this with just hessian-vector products and require at most $n$ hessian-vector products to solve a positive definite $n \\times n$ system, i.e. for a problem with $n$ variables (assuming infinite precision). Hessian-vector products can be computed efficiently via autograd or finite difference of two backward passes. This is the most memory-efficient method as hessian is never formed and CG itself only stores extra few vectors, yet with enough CG iterations it can compute exact Newton's step. This method is called Newton-CG.</p> <p>When the objective function is non-convex, hessian is non positive definite, and CG is no longer guaranteed to converge. Typically it just converges very slowly and requires many iterations.</p> <p>On a 2D function Newton-CG behaves identically to Newton, so we will solve a very large quartic problem instead.</p>"},{"location":"overview/4.%20Second%20order%20methods/#426-truncated-newton","title":"4.2.6 Truncated Newton\u00b6","text":"<p>The main disadvantage of Newton-CG is that for large scale problems it may use a lot of hessian-vector products and therefore take up a lot of time to compute a single step. Newton-CG can be truncated by limiting maximum number of CG iteration to some small value, and it will still produce reasonable directions.</p>"},{"location":"overview/4.%20Second%20order%20methods/#427-newtoncg-steihaug","title":"4.2.7 NewtonCG-Steihaug\u00b6","text":"<p>NewtonCG-Steihaug utilizes truncation to integrate trust region into Newton-CG. Another approach is to utilize truncation in order to implement trust region. When CG solves $Hv=g$, norm of the the direction $v$ increases with each CG iteration. Therefore when $v$ becomes larger than our trust radius or when negative curvature is detected, CG is terminated and $v$ is modified to be within the trust radius and returned. This determines a good step size, terminates CG much earlier thus requiring much less computation, and prevents it from getting stuck on saddle points.</p>"},{"location":"overview/4.%20Second%20order%20methods/#43-higher-order-newton","title":"4.3 Higher order Newton\u00b6","text":"<p>The $n$-th order version of Newton's method forms and minimizes a polynomial model of the objective function given by it's $n$-th order Taylor polynomial approximation.</p> <p>When the second order model is defined by the gradient and the hessian matrix, the higher order model also incorporates tensors of higher order derivatives. For example hessian is a 2D tensor (a matrix), 3rd order derivatives are given by a tensor of 3 dimensions, etc. Therefore $n$-th order Newton requires $N^n$ storage to store the tensor of $n$-th order derivatives, where $N$ is number of variables.</p> <p>Consider that $i,j,k$-th element of the 3rd-order tensor equals 10, that means that there is a term $\\frac{10x_ix_jx_k}{3!}$ in the third order model. The 3 factorial comes from taylor series formula, for 4th order it becomes 4 factorial etc. Specifically derivative of $x^3$ is $3x^2$, second derivative is $6x$, which is $3!x$.</p> <p>There are actually six such terms given by permutations of $i,j,k$ that are equal to each other - $10x_ix_jx_k$, $10x_ix_kx_j$, $10x_jx_ix_k$, $10x_jx_kx_i$, $10x_kx_ix_j$, $10x_kx_jx_i$. Because there are six terms, and they are divided by six, the sixes actually cancel out.</p> <p>Unfortunately the higher order model doesn't have a simple solution to find the minima, such as $H^{-1}g$ in Newton, so it itself has to be minimized by an iterative method which is in fact usually 2nd order Newton with a trust region, and isn't even guaranteed to converge. The higher order polynomial has known gradient and hessian that can be computed without relying on autograd. So, there may be very specific cases where Higher order Newton is useful, but in most cases it does not appear to be practical, as both computing higher order derivatives and minimizing the model are very expensive.</p> <p>As an example, consider rosenbrock function which is is a 4th order polynomial function. Therefore by calculating derivatives up to 4th order, we obtain a perfect model of rosenbrock and by minimizing it, we minimize rosenbrock in a single iteraion.</p>"},{"location":"overview/4.%20Second%20order%20methods/#44-newtonnewton","title":"4.4 NewtonNewton\u00b6","text":"<p>This is an experimental higher order method that I have devised. Here is how it works:</p> <ol> <li><p>Calculate newton step by solving $Hx=g$ and obtaining $x$.</p> </li> <li><p>Calculate jacobian of $x$ w.r.t. parameters and call it $H_2$. The procedure of calculating $H_2$ is the same as the procedure of calculating the hessian $H$ as jacobian of $g$ w.r.t. parameters.</p> </li> <li><p>Solve $H_2 x_2 = x$ for $x_2$. Now $x_2$ is the NewtonNewton direction.</p> </li> <li><p>Optionally, repeat to get $x_3$ - a NewtonNewtonNewton direction, etc.</p> </li> </ol> <p>NewtonNewton appears to only be suitable for convex functions under ~40 variables where it sometimes outperforms Newton in terms of time needed to converge, but not always.</p>"},{"location":"overview/4.%20Second%20order%20methods/#45-combinations","title":"4.5 Combinations\u00b6","text":"<p>You can pipe Newton into quasi-newton or adaptive methods. It is hard to say what that actually computes, but it does seem to work in some cases.</p>"},{"location":"overview/5.%20Quasi-Newton%20methods/","title":"5. Quasi-Newton methods","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>fig, axes = plt.subplots(ncols=3, nrows=9, figsize=(16,48))\naxes = np.ravel(axes)\naxes_iter = iter(axes)\n\nfor QN in (\n    # full-matrix\n    tz.m.BFGS(),\n    tz.m.DFP(),\n    tz.m.ICUM(),\n    tz.m.PSB(),\n    tz.m.SR1(),\n    tz.m.SSVM(),\n    tz.m.BroydenBad(),\n    tz.m.BroydenGood(),\n    tz.m.FletcherVMM(),\n    tz.m.Greenstadt1(),\n    tz.m.Greenstadt2(),\n    tz.m.Horisho(),\n    tz.m.McCormick(),\n    tz.m.NewSSM(),\n    tz.m.Pearson(),\n    tz.m.ProjectedNewtonRaphson(),\n    tz.m.ThomasOptimalMethod(),\n\n    # stochastic\n    tz.m.SG2(n_samples=2, beta=0.9),\n\n    # limited-memory\n    tz.m.LBFGS(),\n    tz.m.LSR1(),\n\n    # diagonal\n    tz.m.DiagonalBFGS(),\n    tz.m.DiagonalSR1(),\n    tz.m.DiagonalQuasiCauchi(),\n    tz.m.DiagonalWeightedQuasiCauchi(),\n    tz.m.NewDQN(),\n    tz.m.DNRTR(),\n    ):\n\n    func = FunctionDescent(\"rosen\").set_print_inverval(None)\n\n    optimizer = tz.Optimizer(\n        func.parameters(),\n        tz.m.RestartOnStuck(QN),\n        tz.m.StrongWolfe(c2=0.1, fallback=True),\n    )\n\n    func.run(optimizer, max_steps=2000, target_loss=1e-5)\n\n    ax = next(axes_iter)\n    func.plot(log_contour=True, ax=ax)\n    ax.set_title(f\"{QN.__class__.__name__}\\nsteps: {func.num_steps}, loss: {func.lowest_loss:.4f}\")\n\n\nplt.show()\n</pre> fig, axes = plt.subplots(ncols=3, nrows=9, figsize=(16,48)) axes = np.ravel(axes) axes_iter = iter(axes)  for QN in (     # full-matrix     tz.m.BFGS(),     tz.m.DFP(),     tz.m.ICUM(),     tz.m.PSB(),     tz.m.SR1(),     tz.m.SSVM(),     tz.m.BroydenBad(),     tz.m.BroydenGood(),     tz.m.FletcherVMM(),     tz.m.Greenstadt1(),     tz.m.Greenstadt2(),     tz.m.Horisho(),     tz.m.McCormick(),     tz.m.NewSSM(),     tz.m.Pearson(),     tz.m.ProjectedNewtonRaphson(),     tz.m.ThomasOptimalMethod(),      # stochastic     tz.m.SG2(n_samples=2, beta=0.9),      # limited-memory     tz.m.LBFGS(),     tz.m.LSR1(),      # diagonal     tz.m.DiagonalBFGS(),     tz.m.DiagonalSR1(),     tz.m.DiagonalQuasiCauchi(),     tz.m.DiagonalWeightedQuasiCauchi(),     tz.m.NewDQN(),     tz.m.DNRTR(),     ):      func = FunctionDescent(\"rosen\").set_print_inverval(None)      optimizer = tz.Optimizer(         func.parameters(),         tz.m.RestartOnStuck(QN),         tz.m.StrongWolfe(c2=0.1, fallback=True),     )      func.run(optimizer, max_steps=2000, target_loss=1e-5)      ax = next(axes_iter)     func.plot(log_contour=True, ax=ax)     ax.set_title(f\"{QN.__class__.__name__}\\nsteps: {func.num_steps}, loss: {func.lowest_loss:.4f}\")   plt.show() In\u00a0[3]: Copied! <pre>fig, axes = plt.subplots(ncols=3, nrows=6, figsize=(16,30))\naxes = np.ravel(axes)\naxes_iter = iter(axes)\n\nfor QN in (\n    # full-matrix\n    tz.m.BFGS(inverse=False),\n    tz.m.DFP(inverse=False),\n    tz.m.PSB(inverse=False),\n    tz.m.SR1(inverse=False),\n    tz.m.BroydenBad(inverse=False),\n    tz.m.BroydenGood(inverse=False),\n\n    # stochastic\n    tz.m.SG2(n_samples=2, beta=0.9),\n\n    # limited-memory\n    tz.m.LBFGS(),\n    tz.m.LSR1(),\n\n    # diagonal\n    tz.m.DiagonalBFGS(),\n    tz.m.DiagonalSR1(),\n    tz.m.DiagonalQuasiCauchi(),\n    tz.m.DiagonalWeightedQuasiCauchi(),\n    tz.m.NewDQN(),\n    tz.m.DNRTR(),\n\n    # scalar approximation to quasi-newton methods\n    tz.m.BarzilaiBorwein(),\n    ):\n\n    func = FunctionDescent(\"rosen\").set_print_inverval(None)\n\n    # use trust CG for L-BFGS and L-SR1, and LevenbergMarquardt for rest\n    if QN.__class__ in (tz.m.LBFGS, tz.m.LSR1):\n        TrustRegion = tz.m.TrustCG\n    else:\n        TrustRegion = tz.m.LevenbergMarquardt\n\n    optimizer = tz.Optimizer(\n        func.parameters(),\n        TrustRegion(\n            tz.m.RestartOnStuck(QN),\n        )\n    )\n\n    func.run(optimizer, max_steps=2000, target_loss=1e-5)\n\n    ax = next(axes_iter)\n    func.plot(log_contour=True, ax=ax)\n    ax.set_title(f\"{TrustRegion.__name__}({QN.__class__.__name__})\\nsteps: {func.num_steps}, loss: {func.lowest_loss:.4f}\")\n\n\nplt.show()\n</pre> fig, axes = plt.subplots(ncols=3, nrows=6, figsize=(16,30)) axes = np.ravel(axes) axes_iter = iter(axes)  for QN in (     # full-matrix     tz.m.BFGS(inverse=False),     tz.m.DFP(inverse=False),     tz.m.PSB(inverse=False),     tz.m.SR1(inverse=False),     tz.m.BroydenBad(inverse=False),     tz.m.BroydenGood(inverse=False),      # stochastic     tz.m.SG2(n_samples=2, beta=0.9),      # limited-memory     tz.m.LBFGS(),     tz.m.LSR1(),      # diagonal     tz.m.DiagonalBFGS(),     tz.m.DiagonalSR1(),     tz.m.DiagonalQuasiCauchi(),     tz.m.DiagonalWeightedQuasiCauchi(),     tz.m.NewDQN(),     tz.m.DNRTR(),      # scalar approximation to quasi-newton methods     tz.m.BarzilaiBorwein(),     ):      func = FunctionDescent(\"rosen\").set_print_inverval(None)      # use trust CG for L-BFGS and L-SR1, and LevenbergMarquardt for rest     if QN.__class__ in (tz.m.LBFGS, tz.m.LSR1):         TrustRegion = tz.m.TrustCG     else:         TrustRegion = tz.m.LevenbergMarquardt      optimizer = tz.Optimizer(         func.parameters(),         TrustRegion(             tz.m.RestartOnStuck(QN),         )     )      func.run(optimizer, max_steps=2000, target_loss=1e-5)      ax = next(axes_iter)     func.plot(log_contour=True, ax=ax)     ax.set_title(f\"{TrustRegion.__name__}({QN.__class__.__name__})\\nsteps: {func.num_steps}, loss: {func.lowest_loss:.4f}\")   plt.show() In\u00a0[4]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(18,6))\n\n# BFGS\nfunc = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(func.parameters(), tz.m.LBFGS(100), tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"L-BFGS\")\n\n# Online-BFGS\nfunc = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(func.parameters(), tz.m.Online(tz.m.LBFGS(100)), tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Online-LBFGS\")\n\n# SVRG-BFGS\nfunc = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(func.parameters(), tz.m.SVRG(100), tz.m.LBFGS(100), tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"SVRG-LBFGS\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(18,6))  # BFGS func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(func.parameters(), tz.m.LBFGS(100), tz.m.LR(1e-1)) func.run(optimizer, max_steps=200) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"L-BFGS\")  # Online-BFGS func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(func.parameters(), tz.m.Online(tz.m.LBFGS(100)), tz.m.LR(1e-1)) func.run(optimizer, max_steps=200) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Online-LBFGS\")  # SVRG-BFGS func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(func.parameters(), tz.m.SVRG(100), tz.m.LBFGS(100), tz.m.LR(1e-1)) func.run(optimizer, max_steps=200) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"SVRG-LBFGS\")  plt.show() <pre>finished in 1.8s., reached loss = 128.527                                      \nfinished in 2.8s., reached loss = 0.00118                                      \nfinished in 1.1s., reached loss = 0.0734                                      \n</pre> <p>Some methods are designed for stochastic optimization, for example 2SG (second order stochastic gradient).</p> In\u00a0[5]: Copied! <pre>func = FunctionDescent('booth').set_noise(1)\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.SG2(start_step=0, seed=0),\n    tz.m.LR(1e-1),\n)\nfunc.run(optimizer, max_steps=500)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('booth').set_noise(1) optimizer = tz.Optimizer(     func.parameters(),     tz.m.SG2(start_step=0, seed=0),     tz.m.LR(1e-1), ) func.run(optimizer, max_steps=500) func.plot(log_contour=True) <pre>finished in 1.8s., reached loss = 0.000588                                      \n</pre> Out[5]: <pre>&lt;Axes: &gt;</pre> <p>A particular case of stochastic gradients is gradients estimated via randomized finite difference (see 12. Zeroth order methods). Indeed, 2SG is able to work with SPSA gradients, leading to 2SPSA (second order SPSA).</p> In\u00a0[10]: Copied! <pre>func = FunctionDescent('booth')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.SPSA(),\n    tz.m.SG2(seed=0),\n    tz.m.Warmup(10),\n    tz.m.LR(1e-1),\n)\nfunc.run(optimizer, max_steps=200)\nfunc.plot(log_contour=True)\n</pre> func = FunctionDescent('booth') optimizer = tz.Optimizer(     func.parameters(),     tz.m.SPSA(),     tz.m.SG2(seed=0),     tz.m.Warmup(10),     tz.m.LR(1e-1), ) func.run(optimizer, max_steps=200) func.plot(log_contour=True) <pre>finished in 0.9s., reached loss = 0                                       \n</pre> Out[10]: <pre>&lt;Axes: &gt;</pre>"},{"location":"overview/5.%20Quasi-Newton%20methods/#5-quasi-newton-methods","title":"5. Quasi-Newton methods\u00b6","text":""},{"location":"overview/5.%20Quasi-Newton%20methods/#51-introduction","title":"5.1 Introduction\u00b6","text":"<p>Quasi-Newton (QN) methods estimate the hessian using only gradients, which is useful in the case when hessian is too expensive or not available. QN methods are suitable for all kinds of objectives, including non-convex and even non-smooth where exact Newton's method may fail. The performance on smooth objectives is however typically better, so for example in a neural network you may get better results by replacing ReLU with ELU.</p> <p>There are three main classes of QN methods - full-matrix methods, limited-memory methods, and methods where hessian isn't approximated by a dense matrix.</p> <p>The full-matrix methods store the full hessian approximation and thus require $N^2$ memory. Since in pytorch we can use GPU acceleration, full-matrix methods are fast to compute for problems under ~10,000 variables, although that number depends on how good your GPU is. Full-matrix methods usually have the fastest convergence, and they are faster to compute compared to limited-memory methods as long as the CPU/GPU can handle it.</p> <p>Limited-memory methods do not store the full hessian and instead use a history of past parameter and gradient differences, so they are suitable for large scale optimization.</p> <p>Finally some methods maintain a diagonal hessian approximation or even a scalar (as in Barzilai\u2013Borwein method), so they also do not suffer from $N^2$ memory requirement, but the quality of the approximation is not as good.</p>"},{"location":"overview/5.%20Quasi-Newton%20methods/#611-quick-recommendations","title":"6.1.1 Quick recommendations:\u00b6","text":"<p>There are a lot of QN methods in torchzero. However the following are very good baselines:</p> <p>Problems under ~10,000 parameters:</p> <pre>tz.Optimizer(\n    model.parameters(),\n    tz.m.RestartOnStuck(tz.m.BFGS()),\n    tz.m.Backtracking(),\n)\n</pre> <p>Problems under ~5,000 parameters</p> <pre>tz.Optimizer(\n    model.parameters(),\n    tz.m.LevenbergMarquardt(\n        tz.m.RestartOnStuck(tz.m.SR1(inverse=False))\n    ),\n)\n</pre> <p>Large scale optimization (<code>history_size</code> can be increased to 100 if affordable):</p> <pre>tz.Optimizer(\n    model.parameters(),\n    tz.m.LBFGS(history_size=10),\n    tz.m.Backtracking(),\n)\n</pre>"},{"location":"overview/5.%20Quasi-Newton%20methods/#612-notation","title":"6.1.2 Notation\u00b6","text":"<p>QN methods make heavy use of differences between parameters and differences between gradients. They are usually denoted as $s_k=x_k - x_{k-1}$ and $y_k = \\nabla f(x_k) - \\nabla f(x_{k-1})$, which I will use as well.</p> <p>For some devious reason, when usually $H$ denotes the hessian, in quasi-newton literature $H$ universally denotes hessian inverse approximation and $B$ denotes hessian approximation, and I will use the same notation.</p>"},{"location":"overview/5.%20Quasi-Newton%20methods/#613-full-matrix-methods","title":"6.1.3 Full-matrix methods\u00b6","text":"<p>Full-matrix methods can maintain hessian or hessian inverse approximation. This is controlled by passing <code>inverse=True</code> or <code>inverse=False</code> when constructing the module, e.g. <code>tz.m.BFGS(inverse=False)</code>.</p> <p>So, a full-matrix QN method proceeds by the following iteration: $$ B_{t} \\leftarrow \\text{update}(B_{t-1}) $$ $$ x_{t+1} \\leftarrow B_t^{-1} \\nabla f(x_t) $$ Here $\\text{update}$ is the update rule to hessian approximation $B$ of some particular quasi-newton algorithm, usually it is some solution to the secant equation: $$ B_{k+1} s_k = y_k $$</p> <p>To understand the secant equation, consider hessian matrix $H$ and an arbitrary vector $s$. Define $y$ as hessian-vector product with vector $s$, so $Hs = y$. This is the secant equation. In quasi-newton methods $y_k = \\nabla f(x_k) - \\nabla f(x_{k-1})$ actually estimates hessian-vector product with $s_k=x_k - x_{k-1}$ through the finite difference formula (I am too lazy to write it now but it's very easy to show). And you can, indeed, use any other vector in place of $s$, provided you can compute a hessian-vector product with it.</p> <p>There are many solutions to $B_{k+1} s_k = y_k$, so usually a solution is picked such that $B_{k+1}$ is as close as possible to $B_k$ in some norm. Keeping $B_{k+1}$ close to $B_k$ makes sure as little information from $B_k$ is lost as possible. Other constraints are may be imposed as well such as keeping $B$ positive definite and symmetric.</p> <p>For example, here is BFGS update for $B$: $$ B_{k+1} = B_{k} + \\frac{y_k y_k^T}{y_k^T s_k} - \\frac {B_ks_k s_k^T B_k^T}{s_k^T B_k s_k} $$</p> <p>Also for BFGS the update is generally skipped whenever curvature condition is not satisfied, that is when $s_k^Ty_k&lt;=0$, which ensures $B$ stays positive definite.</p> <p>The iteration involves solving a linear system $B_tv_t=\\nabla f(x_t)$. It is also possible to maintain hessian inverse approximation $H$ and proceed by the following iteration which does not require a solve: $$ H_{k+1} \\leftarrow \\text{update}(H_k) $$ $$ x_{k+1} \\leftarrow H_k \\nabla f(x_k) $$ The  $\\text{update}$ formula becomes different and satisfies secant equation $H_{k+1} y_k = s_k$, for example here is BFGS one: $$ H_{k+1} = H_k + \\frac{(s_k^T y_k + y_k^T H_k y_k) s_k s_k^T}{(s_k^T y_k)^2} - \\frac{H_k y_k s_k^T + s_k y_k^T H_k}{s_k^T y_k} $$</p>"},{"location":"overview/5.%20Quasi-Newton%20methods/#614-limited-memory-methods","title":"6.1.4 Limited-memory methods\u00b6","text":"<p>Limited-memory methods do not explicitly form $H_k$, instead they compute $H_k \\nabla f(x_k)$ using a recursive algorithm on a history of $s_k$ and $y_k$, such as the L-BFGS two-loop recursion or algorithms based on compact representation. Usually the history is limited to some number of past $s_k$ and $y_k$ pairs, e.g. 10 or 100. Many of the full-matrix methods have limited-memory variants, torchzero implements LBFGS and LSR1.</p>"},{"location":"overview/5.%20Quasi-Newton%20methods/#62-qn-with-line-search","title":"6.2 QN with line search\u00b6","text":"<p>QN method should be used either with a line search or a trust region approach. Some QN methods work well with backtracking line search, for example BFGS.</p> <p>Some however require line search to find step sizes that satisfy the curvature condition as best as possible, for example SR1. On convex problems it is possible to use <code>tz.m.StrongWolfe()</code>, on more complicated problems use a trust region.</p> <p><code>RestartOnStuck</code> is always recommended - it resets the QN hessian approximation when no progress is made for multiple steps in a row.</p>"},{"location":"overview/5.%20Quasi-Newton%20methods/#63-qn-with-trust-region","title":"6.3 QN with trust region\u00b6","text":"<p>QN methods can use two main trust regions - <code>TrustCG</code>, which uses a CG solver that terminates when solution exceeds trust radius, or <code>LevenbergMarquardt</code> which adds a scaled identity matrix. It is also possible to use <code>CubicRegularization</code>, although it tends to work better with exact hessian. Generally <code>LevenbergMarquardt</code> is the recommended trust region as it is the fastest to compute.</p> <p>In all cases in order for a QN method to be used in trust region, it must maintain hessian approximation $B$, not the inverse $H$. In full-matrix methods this is achieved by passing <code>inverse=False</code>. In torchzero formula for $B$ isn't implemented on all methods, but ones where it is implemented are listed below. Diagonal and limited-memory methods work and do not need the <code>inverse=False</code> argument. Limited-memory methods only support <code>TrustCG</code>.</p>"},{"location":"overview/5.%20Quasi-Newton%20methods/#64-stochastic-quasi-newthon-methods","title":"6.4 Stochastic Quasi-Newthon methods\u00b6","text":"<p>Quasi-newton methods are generally not suitable for stochastic optimization due to utilizing differences in consecutive gradients.</p> <p>It is possible to use an additional evaluation to calculate gradient at previous parameters at current mini-batch, and use that to compute the gradient difference. To do that, wrap a method that relies on gradient differences in <code>tz.m.Online</code>.</p> <p>Alternatively use variance reduction method, such as SVRG. Check 9. Variance reduction for more information on SVRG.</p> <p>To emulate stochasticity, function value and gradient on the booth function are evaluated at current point plus random perturbation.</p>"},{"location":"overview/6.%20Conjugate%20gradient/","title":"6. Conjugate gradient","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\nax = np.ravel(ax)\n# ---------------------------------- GD ---------------------------------- #\nfunc = FunctionDescent(\"lstsq\")\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\"),\n)\nfunc.run(optimizer, max_steps=10)\nfunc.plot(ax=ax[0])\nax[0].set_title(\"GD\")\n\n# ------------------------------- CG ------------------------------ #\nfunc = FunctionDescent(\"lstsq\")\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.FletcherReeves(),\n    tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\"),\n)\nfunc.run(optimizer, max_steps=2)\nfunc.plot( ax=ax[1])\nax[1].set_title(\"CG\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6)) ax = np.ravel(ax) # ---------------------------------- GD ---------------------------------- # func = FunctionDescent(\"lstsq\") optimizer = tz.Optimizer(     func.parameters(),     tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\"), ) func.run(optimizer, max_steps=10) func.plot(ax=ax[0]) ax[0].set_title(\"GD\")  # ------------------------------- CG ------------------------------ # func = FunctionDescent(\"lstsq\") optimizer = tz.Optimizer(     func.parameters(),     tz.m.FletcherReeves(),     tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\"), ) func.run(optimizer, max_steps=2) func.plot( ax=ax[1]) ax[1].set_title(\"CG\")  plt.show() <pre>finished in 0.0s., reached loss = 9.86e-10                                      \nfinished in 0.0s., reached loss = 4.8e-11                                      \n</pre> <p>The way CG should generally be used in torchzero is this:</p> <pre>optimizer = tz.Optimizer(\n    model.parameters(),\n    tz.m.FletcherReeves(),\n    tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\", fallback=True),\n)\n</pre> <p>CG should be restarted every once in a while. For example a simple restarting strategy is restarting every $n$ steps, where $n$ is number of variables, which we can do by passing <code>restart_interval=\"auto\"</code> which is the default value, or specify an integer. Torchzero also implements Powell's[1] and Birgin-Martinez[2] restart strategies.</p> <p>The <code>StrongWolfe</code> line search is recommended because CG requires step size to be determined accurately to work.</p> <p>For the Strong wolfe line search we use the following settings:</p> <ul> <li><p>CG doesn't produce well-scaled updates, therefore we use the <code>a_init=\"first-order\"</code> argument which sets initial step size by assuming first-order change in the function at current iterate will be the same as that obtained at the previous step.</p> </li> <li><p><code>c2=0.1</code> sets tolerance for curvature condition to 0.1 (by default it is 0.9), meaning curvature condition is stronger. The value of 0.1 is suggested in Jorge Nocedal and Stephen J. Wright - Numerical Optimization.</p> </li> <li><p>However it is possible that there is no point which satisfies curvature condition of 0.1, especially on weirder functions, meaning the line search will never propose a new point and optimization gets stuck. By setting <code>fallback=True</code>, when no point satisfying the conditions is found after maximum number of iterations, we allow line search to return the lowest point it found.</p> </li> </ul> <p>[1] Powell, Michael James David. \"Restart procedures for the conjugate gradient method.\" Mathematical programming 12.1 (1977): 241-254.</p> <p>[2] Birgin, Ernesto G., and Jos\u00e9 Mario Mart\u00ednez. \"A spectral conjugate gradient method for unconstrained optimization.\" Applied Mathematics &amp; Optimization 43.2 (2001): 117-128.</p> In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12,6))\nax = np.ravel(ax)\n# ---------------------------------- GD ---------------------------------- #\nfunc = FunctionDescent(\"rosen\")\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\", fallback=True),\n)\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"GD\")\n\n# ------------------------------- CG ------------------------------ #\nfunc = FunctionDescent(\"rosen\")\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.FletcherReeves(),\n    tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\", fallback=True),\n)\nfunc.run(optimizer, max_steps=50)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"CG\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12,6)) ax = np.ravel(ax) # ---------------------------------- GD ---------------------------------- # func = FunctionDescent(\"rosen\") optimizer = tz.Optimizer(     func.parameters(),     tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\", fallback=True), ) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"GD\")  # ------------------------------- CG ------------------------------ # func = FunctionDescent(\"rosen\") optimizer = tz.Optimizer(     func.parameters(),     tz.m.FletcherReeves(),     tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\", fallback=True), ) func.run(optimizer, max_steps=50) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"CG\")  plt.show() <pre>finished in 0.5s., reached loss = 5.527                                      \nfinished in 0.4s., reached loss = 3.69e-13                                      \n</pre> <p>torchzero implements the following NCGs:</p> <ul> <li>FletcherReeves</li> <li>PolakRibiere</li> <li>DaiYuan</li> <li>HagerZhang</li> <li>HestenesStiefel</li> <li>LiuStorey</li> <li>ConjugateDescent</li> <li>DYHS</li> <li>ProjectedGradientMethod</li> </ul> <p>Different formulas will perform better on different problems.</p> <p>Projected gradient method described in [1] (algorithm 5 in section 6) directly projects the gradient onto a subspace that is conjugate to past directions, however it requires $N^2$ memory. If you can afford that, the projected gradient method may compete with quasi-newton methods. (note that this is different from projected gradient descent for constrained optimization).</p> <p>Another related algorithm is Shor's r-algorithm[2], which with hyperparameter $\\alpha=1$ becomes a conjugate gradient method and with $\\alpha=0$ is equivalent to steepest descent. Shor's r-algorithm is specifically intended for non-smooth functions. It typically works best with $\\alpha=0.5$, and is for example extremely efficient on wide ReLU nets, although it also uses $N^2$ memory.</p> <p>[1] Pearson, J. D. (1969). Variable metric methods of minimisation. The Computer Journal, 12(2), 171\u2013178. doi:10.1093/comjnl/12.2.171.</p> <p>[2] S HOR , N. Z. (1985) Minimization Methods for Non-differentiable Functions. New York: Springer.</p> In\u00a0[4]: Copied! <pre>fig, axes = plt.subplots(ncols=3, nrows=4, figsize=(16,21))\naxes = np.ravel(axes)\naxes_iter = iter(axes)\n\nfor CG in (\n    tz.m.FletcherReeves(),\n    tz.m.PolakRibiere(),\n    tz.m.DaiYuan(),\n    tz.m.HagerZhang(),\n    tz.m.HestenesStiefel(),\n    tz.m.LiuStorey(),\n    tz.m.ConjugateDescent(),\n    tz.m.DYHS(),\n    tz.m.ProjectedGradientMethod(),\n    tz.m.ShorR(alpha=0.75),\n):\n    ax = next(axes_iter)\n    func = FunctionDescent(\"rosen\")\n    optimizer = tz.Optimizer(\n        func.parameters(),\n        CG,\n        tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\", fallback=True),\n    )\n    func.run(optimizer, max_steps=50)\n    func.plot(log_contour=True, ax=ax)\n    ax.set_title(CG.__class__.__name__)\n\n\nplt.show()\n</pre> fig, axes = plt.subplots(ncols=3, nrows=4, figsize=(16,21)) axes = np.ravel(axes) axes_iter = iter(axes)  for CG in (     tz.m.FletcherReeves(),     tz.m.PolakRibiere(),     tz.m.DaiYuan(),     tz.m.HagerZhang(),     tz.m.HestenesStiefel(),     tz.m.LiuStorey(),     tz.m.ConjugateDescent(),     tz.m.DYHS(),     tz.m.ProjectedGradientMethod(),     tz.m.ShorR(alpha=0.75), ):     ax = next(axes_iter)     func = FunctionDescent(\"rosen\")     optimizer = tz.Optimizer(         func.parameters(),         CG,         tz.m.StrongWolfe(c2=0.1, a_init=\"first-order\", fallback=True),     )     func.run(optimizer, max_steps=50)     func.plot(log_contour=True, ax=ax)     ax.set_title(CG.__class__.__name__)   plt.show() <pre>finished in 0.2s., reached loss = 3.69e-13                                      \nfinished in 0.2s., reached loss = 3.54e-07                                      \nfinished in 0.1s., reached loss = 8.58e-09                                      \nfinished in 0.1s., reached loss = 6e-13                                      \nfinished in 0.1s., reached loss = 5.68e-14                                      \nfinished in 0.1s., reached loss = 1.72e-12                                      \nfinished in 0.1s., reached loss = 1.64e-12                                      \nfinished in 0.2s., reached loss = 5.68e-12                                      \nfinished in 0.2s., reached loss = 1.28e-13                                      \nfinished in 0.1s., reached loss = 1.17e-07                                      \n</pre> In\u00a0[5]: Copied! <pre>func = FunctionDescent('lstsq')\noptimizer = tz.Optimizer(\n    func.parameters(),\n    tz.m.AdaptiveHeavyBall(),\n)\nfunc.run(optimizer, max_steps=4)\nfunc.plot()\n</pre> func = FunctionDescent('lstsq') optimizer = tz.Optimizer(     func.parameters(),     tz.m.AdaptiveHeavyBall(), ) func.run(optimizer, max_steps=4) func.plot() <pre>finished in 0.0s., reached loss = 0                                      \n</pre> Out[5]: <pre>&lt;Axes: &gt;</pre>"},{"location":"overview/6.%20Conjugate%20gradient/#6-conjugate-gradient","title":"6. Conjugate gradient\u00b6","text":""},{"location":"overview/6.%20Conjugate%20gradient/#61-introduction","title":"6.1 Introduction\u00b6","text":"<p>Nonlinear conjugate gradient (NCG) methods are methods of the following form: $$ s_t \\leftarrow \\nabla f(x_t) + \\beta_t s_{t-1} $$ $$ x_{t+1} \\leftarrow x_t - \\eta s_t $$ So a conjugate gradient direction is gradient plus previous direction times $\\beta_t$. The only difference between most conjugate gradient methods is how $\\beta_t$ is calculated. For example Fletcher\u2013Reeves formula is the following: $$ \\beta_t^\\text{FR}=\\frac{g_t^T g_t}{g_{t-1}^T g_{t-1}} $$ Here $g_t$ is gradient: $\\nabla f(x_t)$. I will write it as $g_t$ to make it more readable.</p>"},{"location":"overview/6.%20Conjugate%20gradient/#62-derivation","title":"6.2 Derivation\u00b6","text":"<p>Conjugate gradient implicitly uses a quadratic model of the function. Given gradient $g$ and hessian $H$, the model is: $$ f(x) = \\frac{1}{2}x^T H x + g^T x $$ CG uses the fact that given n-dimensional convex quadratic function with hessian $H$, performing $n$ exact line searches along $n$ H-orthogonal directions (in any order) guarantees finding the minimum in at most $n$ steps.</p> <p>Vectors $\\{s_1, s_2, ..., s_n\\}$ are called H-orthogonal, or conjugate, if: $s_i^T H s_j = 0$ for $i \\neq j$. Geometrically that means those vectors are orthogonal in space transformed by $H$.</p> <p>We start with initial direction $s_0$, which is set to the gradient:</p> <p>$$s_0 = \\nabla f(x_t)$$ $$x_1 = x_0 - \\eta_0 s_0$$</p> <p>Then by conjugate gradient formula next direction $s_1$ is gradient plus previous direction times $\\beta_1$.</p> <p>$$s_1 \\leftarrow \\nabla f(x_1) + \\beta_1 s_{0}$$</p> <p>We want to find $\\beta_1$ such that $s_1$ is $H$-orthogonal to $s_0$. Basically if you do a bunch of derivation it comes out as: $$ \\beta_1^\\text{FR}=\\frac{g_1^T g_1}{g_{0}^T g_{0}} $$ Which is the Fletcher\u2013Reeves formula. Or you can derive it differently and obtain different formulas such as Polak-Ribiere, but all formulas are equivalent on quadratic functions. Each new $s_t$ will be $H$-orthogonal to all previous directions $s_{t-1}, s_{t-2}, ..., s_0$.</p>"},{"location":"overview/6.%20Conjugate%20gradient/#63-using-cg","title":"6.3 Using CG\u00b6","text":"<p>Conjugate gradient is guaranteed to minimize convex quadratic function of $n$ variables in at most $n$ steps. All conjugate gradient methods are equivalent on a quadratic function, so the difference is how they behave on other functions. Generally CG can be used of as very computationally inexpensive alternative to Quasi-Newton methods.</p> <p>Consider the following quadratic function: $$ f(x) = (2*x + 3*y - 5)^2 + (5*x - 2*y - 3)^2 $$</p> <p>If we run gradient descent with a line search, we see a staircase-like path, whereas CG is guaranteed to minimize it in two steps.</p>"},{"location":"overview/6.%20Conjugate%20gradient/#64-adaptive-heavy-ball","title":"6.4 Adaptive Heavy-ball\u00b6","text":"<p>Adaptive Heavy-ball is a combination of CG, heavy-ball momentum and Polyak's step size. It is mainly suitable for convex quadratic functions with known value at minima $f*$, although it may work on non-quadratic convex functions too. Other than having to know $f*$, adaptive Heavy-ball requires no tuning and no line search.</p> <p>Reference: Goujaud, Baptiste, Adrien Taylor, and Aymeric Dieuleveut. \"Short Paper-Quadratic minimization: from conjugate gradient to an adaptive Polyak\u2019s momentum method with Polyak step-sizes.\" Open Journal of Mathematical Optimization 5 (2024): 1-10.</p>"},{"location":"overview/7.%20Least%20squares/","title":"7. Non-linear least squares","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(18,6))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen_mo').set_multiobjective()\noptimizer = tz.Optimizer(func.parameters(), tz.m.GaussNewton(), tz.m.LR(1e-1))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Gauss-Newton with fixed step size\")\n\nfunc = FunctionDescent('rosen_mo').set_multiobjective()\noptimizer = tz.Optimizer(func.parameters(), tz.m.GaussNewton(), tz.m.Backtracking())\nfunc.run(optimizer, max_steps=10)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Gauss-Newton with line search\")\n\nfunc = FunctionDescent('rosen_mo').set_multiobjective()\noptimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton()))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"Gauss-Newton with trust region\")\n\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(18,6)) ax = np.ravel(ax)  func = FunctionDescent('rosen_mo').set_multiobjective() optimizer = tz.Optimizer(func.parameters(), tz.m.GaussNewton(), tz.m.LR(1e-1)) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Gauss-Newton with fixed step size\")  func = FunctionDescent('rosen_mo').set_multiobjective() optimizer = tz.Optimizer(func.parameters(), tz.m.GaussNewton(), tz.m.Backtracking()) func.run(optimizer, max_steps=10) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Gauss-Newton with line search\")  func = FunctionDescent('rosen_mo').set_multiobjective() optimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton())) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"Gauss-Newton with trust region\")   plt.show() <pre>finished in 0.1s., reached loss = 5.58e-06                                      \nfinished in 0.0s., reached loss = 0                                      \nfinished in 0.4s., reached loss = 2.4e-12                                      \n</pre> In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(18,6))\nax = np.ravel(ax)\n\nfunc = FunctionDescent('rosen_mo').set_multiobjective()\noptimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton(), y=0))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"y=0\")\n\nfunc = FunctionDescent('rosen_mo').set_multiobjective()\noptimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton(), y=0.0001))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"y=0.0001\")\n\nfunc = FunctionDescent('rosen_mo').set_multiobjective()\noptimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton(), y=1))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"y=1\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(18,6)) ax = np.ravel(ax)  func = FunctionDescent('rosen_mo').set_multiobjective() optimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton(), y=0)) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"y=0\")  func = FunctionDescent('rosen_mo').set_multiobjective() optimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton(), y=0.0001)) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"y=0.0001\")  func = FunctionDescent('rosen_mo').set_multiobjective() optimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.GaussNewton(), y=1)) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"y=1\")  plt.show() <pre>finished in 0.5s., reached loss = 2.4e-12                                      \nfinished in 0.4s., reached loss = 3.2e-14                                      \nfinished in 0.3s., reached loss = 3.55e-11                                      \n</pre>"},{"location":"overview/7.%20Least%20squares/#7-non-linear-least-squares","title":"7. Non-linear least squares\u00b6","text":""},{"location":"overview/7.%20Least%20squares/#71-gauss-newton","title":"7.1 Gauss-Newton\u00b6","text":"<p>A non-linear least squares problem is a problem of the form: $$ \\underset{x}{\\operatorname{argmin}} \\sum_{i=1}^{m} f(x)_i^2 $$ Here instead of outputing a single value, the objective function $f$ outputs $m$ values, and the goal is to minimize the sum of their squares. Of course it is possible to simply compute sum of their squares and use any normal optimization method to minimize that scalar value. But we can minimize this problem very efficiently using the Gauss-Newton method which uses those $m$ values and their jacobian to estimate the hessian.</p> <p>Suppose we have a function of $n$ parameters that outputs a vector $r \\in \\mathbb{R}^m$, this vector is called vector of residuals, and the goal is for all residuals to be as small as possible. Gauss-Newton uses the Jacobian matrix $J \\in \\mathbb{R}^{m \\times n}$ of $r$ with respect to parameters $x$. It can be calculated by stacking gradients of each value $r_1, r_2, ..., r_m$ as rows of $J$. Then the Gauss-Newton step is: $$ x_{t+1} \\leftarrow x_t - \\eta (J^T J)^{\\dagger} J^T r $$</p> <p>Here $\\eta$ is a step size which can be fixed or determined via a line search. $(J^T J)^{\\dagger}$ means Moore-Penrose inverse (i.e. pseudoinverse) of $J^T J$. Since most of the time $m$ &lt; $n$, then $J^T J$ has no inverse, therefore pseudo-inverse is used instead.</p> <p>Same as with Newton's method, in practice the Gauss-Newton step is computed as a linear least-squares solution to a linear system because that is faster to compute: $$ \\text{solve:}\\\\\\\\ (J^T J)v_t = J^T r $$ $$ x_{t+1} \\leftarrow x_t - v_t $$</p> <p>However if $m$ &lt; $n$, the linear system can be solved much more efficiently with this update rule: $$ \\text{solve:}\\\\\\\\ (J J^T)z_t = r $$ $$ v_t = J^T z_t $$ $$ x_{t+1} \\leftarrow x_t - v_t $$</p> <p>To prove that $v_t$ is indeed the solution, suppose that $z$ is a solution to $(J J^T)z = r$, and suppose that $v = J^T z$. With those presuppositions we can prove that $(J^T J)v = J^T r$ by replacing $v$ with $J^T z$: $$ (J^T J)v = (J^T J) (J^T z) = J^T (J J^T) z = J^T r $$</p> <p>For visualization we use Rosenbrock's function. The standard Rosenbrock's function is: $$ f(x,y) = (1 - x)^2 + 100 * (y - x^2)^2 $$</p> <p>You can easily see that this function is a sum of squares of two terms: $(1 - x)$ and $(y - x^2)$, and second term is multiplied by 100. So we can rewrite this function to return a vector of two residuals and solve it with Gauss-Newton: $$ f(x, y) = [(1 - x), 100 * (y - x^2)] $$</p> <p>In torchzero to use <code>GaussNewton</code>, the closure must return a vector of residuals. The closure should not perform a backward pass, it is handled by <code>GaussNewton</code> module. The gradients are calculated in a batch which is usually much faster that a for loop.</p>"},{"location":"overview/7.%20Least%20squares/#72-levenberg-marquardt","title":"7.2 Levenberg-Marquardt\u00b6","text":"<p>Levenberg-Marquardt is a trust region method (see 9. Trust region) where scaled identity matrix is added to hessian or hessian approximation, in this case to Gauss-Newton approximation $J^T J$. Very often term \"Levenberg-Marquardt\" refers specifically to Gauss-Newton algorithm with trust region.</p> <p>For Gauss-Newton approximation identity matrix is sometimes replaced with diagonal of $J^T J$, this is called modified Marquadt method[1]. In torchzero this is determined by <code>y</code> argument. If it is 0, scaled identity is used, if it is 1, diagonal of $J^T J$ is used. Values between 0 and 1 interpolate.</p> <p>References:</p> <ol> <li>Fletcher, Roger. \"A modified Marquardt subroutine for non-linear least squares.\" (1971).</li> </ol>"},{"location":"overview/8.%20Line%20search/","title":"8. Line search","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[3]: Copied! <pre>func = FunctionDescent('booth')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Backtracking(c=0.001))\nfunc.run(optimizer, max_steps=50)\nfunc.plot()\n</pre> func = FunctionDescent('booth') optimizer = tz.Optimizer(func.parameters(), tz.m.Backtracking(c=0.001)) func.run(optimizer, max_steps=50) func.plot() <pre>finished in 0.1s., reached loss = 0                                      \n</pre> Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>func = FunctionDescent('booth')\noptimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe())\nfunc.run(optimizer, max_steps=50)\nfunc.plot()\n</pre> func = FunctionDescent('booth') optimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe()) func.run(optimizer, max_steps=50) func.plot() <pre>finished in 0.2s., reached loss = 0                                      \n</pre> Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[11]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(15,5))\nax = np.ravel(ax)\n\n# --------------------------------- no init --------------------------------- #\nfunc = FunctionDescent('ill2')\noptimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe())\nfunc.run(optimizer, max_steps=50)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"a_init='fixed'\")\n\n# -------------------------------- first-order ------------------------------- #\nfunc = FunctionDescent('ill2')\noptimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe(a_init='first-order'))\n\nfunc.run(optimizer, max_steps=50)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"a_init='first-order'\")\n\n# ------------------------------ quadratic ------------------------------ #\nfunc = FunctionDescent('ill2')\noptimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe(a_init='quadratic'))\n\nfunc.run(optimizer, max_steps=50)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"a_init='quadratic'\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(15,5)) ax = np.ravel(ax)  # --------------------------------- no init --------------------------------- # func = FunctionDescent('ill2') optimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe()) func.run(optimizer, max_steps=50) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"a_init='fixed'\")  # -------------------------------- first-order ------------------------------- # func = FunctionDescent('ill2') optimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe(a_init='first-order'))  func.run(optimizer, max_steps=50) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"a_init='first-order'\")  # ------------------------------ quadratic ------------------------------ # func = FunctionDescent('ill2') optimizer = tz.Optimizer(func.parameters(), tz.m.StrongWolfe(a_init='quadratic'))  func.run(optimizer, max_steps=50) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"a_init='quadratic'\")  plt.show() <pre>finished in 0.1s., reached loss = 0.139                                      \nfinished in 0.1s., reached loss = 0                                      \nfinished in 0.1s., reached loss = 5.7e-12                                      \n</pre>"},{"location":"overview/8.%20Line%20search/#8-line-search","title":"8. Line search\u00b6","text":""},{"location":"overview/8.%20Line%20search/#81-introduction","title":"8.1 Introduction\u00b6","text":"<p>Given a direction $d_t$ produced by some optimization algorithm, e.g. gradient descent or BFGS, a line search minimizes the function along $d_t$. In other words it tries to find a good step size which leads to decrease of the function value or satisfies some other condition.</p>"},{"location":"overview/8.%20Line%20search/#82-backtracking","title":"8.2 Backtracking\u00b6","text":"<p>Backtracking line search starts with initial step size (typically 1), then it keeps decreasing the step size by multiplying by $\\tau$ (typically 0.5) until the sufficient decrease condition is satisfied.</p> <p>We might terminate the line search as soon as it finds a step size that leads to decrease of the objective function. However if the decrease is too small, the progress can be too slow. Therefore usually we don't accept any decrease, instead we accept decrease that satisfies the sufficient decrease condition (also known as Armijo condition). The condition is satisfied if: $$ f(x_t - \\alpha d_t) \\leq f(x_t) - c \\cdot \\alpha \\cdot \\nabla f(x_t)^T d_t $$ Here $\\alpha$ is the step size, $c$ is the Armijo condition parameter (between 0 and 1), $\\nabla f(x_t)^T d_t$ is directional derivative in the direction $d_t$.</p> <p>Geometrically the step size is accepted if it is under the line that goes through $x_t$ (where $\\alpha = 0$). If $c$ = 0, the line is horizontal; if $c$ = 1, the line is tangent to the function. In practice $c$ is often set to a small value such as 0.01.</p> <p></p> <p>image from https://tm23forest.com/contents/linesearch-armijo-wolfe-condition-explained-visually</p>"},{"location":"overview/8.%20Line%20search/#83-strong-wolfe","title":"8.3 Strong-Wolfe\u00b6","text":"<p>The strong curvature condition is satisfied if: $$ |g(-\\alpha)| \\leq c \\cdot |g(0)| $$</p> <p>Here $g(0)$ is directional derivative at initial point $x_t$ computed as $\\nabla f(x_t)^T d_t$,</p> <p>$g(-\\alpha)$ is directional derivative at $x_t - \\alpha d_t$ computed as $\\nabla f(x_t - \\alpha d_t)^T d_t$,</p> <p>$c$ is a condition parameter, typically set to 0.9 for quasi-newton methods and to 0.1 for conjugate gradient methods.</p> <p>Geometrically strong curvature condition is satisfied if the slope at $f(-\\alpha)$ is smaller than at f(0). If $c=0$, the slope must be 0.</p> <p>A particular kind of line search with bracketing and zooming phases, which often uses cubic interpolation, is sometimes called Strong-Wolfe line search. It terminates when both sufficient decrease and strong curvature conditions are satisfied (the combination of those is called the Strong-Wolfe condition). The algorithm is described in [1] on pages 60-61. This kind of line search is faster due to use of interpolation, however unlike backtracking line search it requires gradients to be evaluated at each point during the line search.</p> <p>Reference:</p> <ol> <li>Wright, Stephen, and Jorge Nocedal. \"Numerical optimization.\" Springer Science 35.67-68 (1999): 7.</li> </ol>"},{"location":"overview/8.%20Line%20search/#84-what-line-search-to-use","title":"8.4 What line search to use\u00b6","text":"<p>Strong-Wolfe line search returns step sizes that satisfy the strong curvature condition, which is actually necessary for some algorithms such as SR1 and conjugate gradient methods.</p> <p>If curvature condition need not be satisfied and the algorithm produces well-scaled directions (e.g. in Newton methods, BFGS/L-BGFS), backtracking line search often performs better.</p> <p>When the algorithm does not produce well scaled directions, for example gradient descent and conjugate gradient, the initial step size guess in Strong-Wolfe line search should be estimated using past function values and derivatives. This can be done by passing <code>a_init=\"quadratic\"</code> or <code>a_init=\"first-order\"</code>.</p>"},{"location":"overview/9.%20Trust%20region/","title":"9. Trust region","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\ntorch.manual_seed(0)\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchzero as tz\nfrom visualbench import FunctionDescent, test_functions\n</pre> import numpy as np import matplotlib.pyplot as plt import torch torch.manual_seed(0) from torch import nn import torch.nn.functional as F import torchzero as tz from visualbench import FunctionDescent, test_functions In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(15,5))\nax = np.ravel(ax)\n\n# --------------------------------- Newton --------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.Newton()))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"LM-Newton\")\n\n# ----------------------------------- BFGS ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.BFGS(inverse=False)))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"LM-BFGS\")\n\n# ------------------------------------ SR1 ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False)))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"LM-SR1\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(15,5)) ax = np.ravel(ax)  # --------------------------------- Newton --------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.Newton())) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"LM-Newton\")  # ----------------------------------- BFGS ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.BFGS(inverse=False))) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"LM-BFGS\")  # ------------------------------------ SR1 ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.LevenbergMarquardt(tz.m.SR1(inverse=False))) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"LM-SR1\")  plt.show() <pre>finished in 1.1s., reached loss = 0                                      \nfinished in 0.5s., reached loss = 0                                      \nfinished in 0.2s., reached loss = 1.98e-11                                      \n</pre> In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(15,5))\nax = np.ravel(ax)\n\n# --------------------------------- Newton --------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.TrustCG(tz.m.Newton()))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"TrustCG-Newton\")\n\n# ----------------------------------- BFGS ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.TrustCG(tz.m.BFGS(inverse=False)))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"TrustCG-LBFGS\")\n\n# ------------------------------------ SR1 ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.TrustCG(tz.m.SR1(inverse=False)))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"TrustCG-LSR1\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(15,5)) ax = np.ravel(ax)  # --------------------------------- Newton --------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.TrustCG(tz.m.Newton())) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"TrustCG-Newton\")  # ----------------------------------- BFGS ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.TrustCG(tz.m.BFGS(inverse=False))) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"TrustCG-LBFGS\")  # ------------------------------------ SR1 ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.TrustCG(tz.m.SR1(inverse=False))) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"TrustCG-LSR1\")  plt.show() <pre>finished in 0.8s., reached loss = 0                                      \nfinished in 0.7s., reached loss = 0                                      \nfinished in 0.7s., reached loss = 0                                      \n</pre> In\u00a0[4]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(15,5))\nax = np.ravel(ax)\n\n# --------------------------------- Newton --------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Dogleg(tz.m.Newton()))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"Dogleg-Newton\")\n\n# ----------------------------------- BFGS ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Dogleg(tz.m.BFGS(inverse=False)))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"Dogleg-LBFGS\")\n\n# ------------------------------------ SR1 ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.Dogleg(tz.m.SR1(inverse=False)))\n\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"Dogleg-LSR1\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(15,5)) ax = np.ravel(ax)  # --------------------------------- Newton --------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Dogleg(tz.m.Newton())) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"Dogleg-Newton\")  # ----------------------------------- BFGS ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Dogleg(tz.m.BFGS(inverse=False))) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"Dogleg-LBFGS\")  # ------------------------------------ SR1 ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.Dogleg(tz.m.SR1(inverse=False)))  func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"Dogleg-LSR1\")  plt.show() <pre>finished in 0.8s., reached loss = 0                                      \nfinished in 0.9s., reached loss = 2.596                                      \nfinished in 1.0s., reached loss = 4.924                                      \n</pre> In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots(ncols=3, figsize=(15,5))\nax = np.ravel(ax)\n\n# --------------------------------- Newton --------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.CubicRegularization(tz.m.Newton()))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[0])\nax[0].set_title(\"CR-Newton\")\n\n# ----------------------------------- BFGS ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.CubicRegularization(tz.m.BFGS(inverse=False)))\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[1])\nax[1].set_title(\"CR-LBFGS\")\n\n# ------------------------------------ SR1 ----------------------------------- #\nfunc = FunctionDescent('rosen')\noptimizer = tz.Optimizer(func.parameters(), tz.m.CubicRegularization(tz.m.SR1(inverse=False)))\n\nfunc.run(optimizer, max_steps=100)\nfunc.plot(log_contour=True, ax=ax[2])\nax[2].set_title(\"CR-LSR1\")\n\nplt.show()\n</pre> fig, ax = plt.subplots(ncols=3, figsize=(15,5)) ax = np.ravel(ax)  # --------------------------------- Newton --------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.CubicRegularization(tz.m.Newton())) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[0]) ax[0].set_title(\"CR-Newton\")  # ----------------------------------- BFGS ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.CubicRegularization(tz.m.BFGS(inverse=False))) func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[1]) ax[1].set_title(\"CR-LBFGS\")  # ------------------------------------ SR1 ----------------------------------- # func = FunctionDescent('rosen') optimizer = tz.Optimizer(func.parameters(), tz.m.CubicRegularization(tz.m.SR1(inverse=False)))  func.run(optimizer, max_steps=100) func.plot(log_contour=True, ax=ax[2]) ax[2].set_title(\"CR-LSR1\")  plt.show() <pre>finished in 1.0s., reached loss = 0                                      \nfinished in 1.7s., reached loss = 0                                      \nfinished in 1.1s., reached loss = 0.0437                                      \n</pre>"},{"location":"overview/9.%20Trust%20region/#9-trust-region","title":"9. Trust region\u00b6","text":""},{"location":"overview/9.%20Trust%20region/#91-introduction","title":"9.1 Introduction\u00b6","text":"<p>Recall from 5. Second order methods that whenever we have hessian or hessian estimate, the objective function is modelled by a quadratic model, where given gradient $g$ and hessian $H$, the model is: $$ f(v) = \\frac{1}{2}v^T H v + g^T v $$</p> <p>If the objective function has higher order terms or discontinuities, the quadratic model becomes less and less accurate the further we get from the current point. We therefore introduce trust region - region around the current point where our quadratic model is considered accurate.</p> <p>Here is a general trust region algorithm scheme:</p> <ol> <li><p>At the current point $x_t$ obtain gradient $g_t$, hessian or a hessian estimate $H_t$, then our quadratic model is given by $f_{\\mathbb{quad}}(v) = \\frac{1}{2}v^T H_t v + g_t^T v$. Importantly the quadratic model is centered around zero, so $f_{\\mathbb{quad}}(v)$ corrensponds to $f(x_t + v)$. We have trust radius value $\\tau_t$, which is size of the region where quadratic model is assumed to be accurate.</p> </li> <li><p>Trust region subproblem: minimize the quadratic model within the trust radius $\\tau_t$ to obtain the solution $\\hat{v}$. That means we want to minimize $f_{\\mathbb{quad}}(\\hat{v}) = \\frac{1}{2}\\hat{v}^T H_t \\hat{v} + g_t^T \\hat{v}$ under the constraint that $x_t + \\hat{v}$ isn't far from $x_t$. What \"too far\" means depends on a specific trust region algorithm, for example we can impose an L2 norm constraint: $||\\hat{v}||_2 \\leq \\tau_t$.</p> </li> <li><p>Evaluate function value at solution $\\hat{v}$ of the objective function $F_{\\mathbb{true}} = f(x_t + \\hat{v})$ and of the quadratic model $F_{\\mathbb{predicted}} = \\frac{1}{2}\\hat{v}^T H_t \\hat{v} + g_t^T \\hat{v}$. If the values $F_{\\mathbb{true}}$ and $F_{\\mathbb{predicted}}$ are close, the quadratic model is accurate within trust radius $\\tau_t$ and we can try to increase the trust radius. If the values are very different, the quadratic model within trust radius $\\tau_t$ is inaccurate, therefore we decrease trust radius. The particular strategy of how to change $\\tau_t$ depends on trust region algorithm.</p> </li> <li><p>If solution $\\hat{v}$ is better, accept it: if $f(x_t + \\hat{v}) \\le f(x_t)$, set $x_{t+1} \\leftarrow x_t + \\hat{v}$. Otherwise we stay at $x_t$, reduce the trust radius and restart from step 2.</p> </li> </ol>"},{"location":"overview/9.%20Trust%20region/#92-levenberg-marquardt","title":"9.2 Levenberg Marquardt\u00b6","text":"<p>The Levenberg\u2013Marquardt algorithm (LM) is also known as the damped least-squares method, as it is commonly used as trust region for least squares problems, however it works well for minimization problems too.</p> <p>In LM scaled identity matrix is added to the hessian matrix before solving the linear system, and the smaller trust radius is, the larger the identity matrix scale is. Given gradient $g_t$, hessian $H_t$ and trust radius $\\tau_t$, the trust region solution $\\hat{v}$ is given by solving $(H_t + \\frac{1}{\\tau_t} I )\\hat{v} = g_t$.</p> <p>Geometrically solving $(H_t + \\frac{1}{\\tau_t} I )\\hat{v} = g_t$ constrains $d_t$ to have L2 norm no larger than some value which becomes smaller as identity matrix scale becomes larger, however there is no simple correspondance between $\\tau_t$ and that value. In fact in some implementatations $\\tau_t$ determines L2 norm bound, then appropriate identity matrix scale is found using root finding, which requires multiple linear system solves. In torchzero we just use $\\frac{1}{\\tau_t} I$ because it seems to work just as well with a single solve.</p> <p>When LM is used with Gauss-Newton, identity matrix is often replaced by diagonal of Gauss-Newton hessian approximation.</p> <p>A note on terminology - \"Levenberg-Marquardt\" often refers specifically to Gauss-Newton with this kind of trust region. The trust region itself is called \"Levenberg\u2013Marquardt penalty\". Newton's method with this penality is sometimes called \"Regularized Newton\", although that can also refer to other regularizers.</p> <p><code>LevenbergMarquardt</code> is the trust region that I recommend in most cases because it is fast to compute and has good performance. The only downside is that in involves adding a diagonal matrix, which is not possible in some cases where full matrix isn't formed such as L-BFGS.</p>"},{"location":"overview/9.%20Trust%20region/#93-trustcg","title":"9.3 TrustCG\u00b6","text":"<p><code>TrustCG</code> solves $Hv=g$ using an iterative conjugate gradient (CG) solver. By using the fact that norm of the the direction $v$ increases with each CG iteration, when $v$ becomes larger than our trust radius $\\tau_t$ or when negative curvature is detected, CG is terminated and $v$ is modified to be within the trust radius and returned.</p> <p>Unlike Levenberg-Marquardt, here $\\tau_t$ corresponds directly to L2 norm of the update. <code>TrustCG</code>, being an iterative method, is typically slower than Levenberg-Marquardt to compute, however it has the advantage that it only uses matrix-vector multiplications, making it suitable for limited memory methods such as L-BFGS.</p>"},{"location":"overview/9.%20Trust%20region/#94-powells-dog-leg-method","title":"9.4 Powell's dog leg method\u00b6","text":"<p>The dog leg method takes cauchy point - minimizer of the quadratic model along the steepest descent direction, it takes Newton's step point, and draws a line between them. The intersection of that line with a circle of radius $\\tau_t$ is the solution to the trust region subproblem. If circle radius is so small that the line is outside it, it uses intersection between the circle and the cauchy point line.</p> <p></p> <p>Image from Lourakis, Manolis LA, and Antonis A. Argyros. \"Is Levenberg-Marquardt the most efficient optimization algorithm for implementing bundle adjustment?.\" Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1. Vol. 2. IEEE, 2005.</p> <p>Dog leg method is only suitable for Newton and Gauss-Newton, and doesn't work well with hessian approximations. It has similar computational cost to Levenberg\u2013Marquardt.</p>"},{"location":"overview/9.%20Trust%20region/#95-cubic-regularization","title":"9.5 Cubic regularization\u00b6","text":"<p>Cubic regularization adds an extra cubic term  $||v||^3$ to the trust region subproblem, penalizing cubed norm of update dirction $v$. Therefore the trust region subproblem becomes:</p> <p>$$ f_{\\mathbb{subproblem}}(v) = \\frac{1}{2}v^T H_t v + g_t^T v + \\frac {\\tau}{6}||v||^3 $$</p> <p>Here $\\tau$ controls strength of the penalty and has a similar function to trust radius. Solvers exist that solve this subproblem relatively efficiently, although it is still more computationally expensive than other trust region methods. For torchzero I used the solver implemented here https://github.com/konstmish/opt_methods/blob/master/optmethods/second_order/cubic.py</p> <p>Cubic regularization seems to work better with exact hessian than with approximation. With exact hessian the convergence can be better than other trust region methods at a cost of being more computationally expensive.</p>"},{"location":"overview/advanced/A1.%20Preconditioning%20and%20whitening/","title":"A1. Preconditioning and whitening","text":""},{"location":"overview/advanced/A1.%20Preconditioning%20and%20whitening/#a1-preconditioning-and-whitening","title":"A1. Preconditioning and whitening\u00b6","text":"<p>Under construction</p>"}]}